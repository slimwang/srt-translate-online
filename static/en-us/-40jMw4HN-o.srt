1
00:00:00,000 --> 00:00:03,139
In the next homework, we're going to implement some pretty cool image blurring techniques.

2
00:00:03,139 --> 00:00:05,920
You now know enough that you can go and implement that program

3
00:00:05,920 --> 00:00:11,254
on a massively parallel GPU, and you'd get a correct answer, and it would be pretty fast.

4
00:00:11,254 --> 00:00:12,337
But we can do better.

5
00:00:12,337 --> 00:00:17,354
Now we have all the ingredients to start talking about writing efficient parallel programs in CUDA.

6
00:00:17,354 --> 00:00:19,417
For now I'm only going to talk about high level strategies.

7
00:00:19,417 --> 00:00:23,169
We're going to have a whole unit later on about detailed optimization approaches

8
00:00:23,169 --> 00:00:25,793
to help you really squeeze the maximum performance out of the GPU.

9
00:00:25,793 --> 00:00:30,317
So think of this as a preview that covers some of the really important things high level things that you have

10
00:00:30,317 --> 00:00:32,619
to keep in mind when you are writing a GPU program.

11
00:00:32,619 --> 00:00:36,513
So the first thing to keep in mind is that GPUs have really incredible computational horsepower.

12
00:00:36,513 --> 00:00:42,100
A high-end GPU can do over 3 trillion math operations per second.

13
00:00:42,100 --> 00:00:45,680
You'll sometimes see this written down as T FLOPS, okay?

14
00:00:45,680 --> 00:00:48,494
A FLOPS stands for a Floating Point Operation Per Second.

15
00:00:48,494 --> 00:00:54,961
T FLOPS is Tera-FLOPS, and minor GPU's can do over 3 trillion of these every second at the high end.

16
00:00:54,961 --> 00:00:58,191
But all that power is wasted if the arithmetic units that are doing the math

17
00:00:58,191 --> 00:01:02,631
need to spend their time waiting while the system fetches the operands from memory.

18
00:01:02,631 --> 00:01:07,210
So the first strategy we need to keep in mind is to maximize arithmetic intensity.

19
00:01:07,210 --> 00:01:13,404
Arithmetic intensity is basically the amount of math we do per amount of memory that we access.

20
00:01:13,404 --> 00:01:17,513
So we can increase arithmetic intensity by making the numerator bigger

21
00:01:17,513 --> 00:01:19,657
or by making the denominator smaller.

22
00:01:19,657 --> 00:01:25,188
So this corresponds to maximizing the work we do per thread or minimizing the memory we do per thread.

23
00:01:25,188 --> 00:01:27,489
And let's be more exact about what we mean here.

24
00:01:27,489 --> 00:01:30,968
Really what we're talking about is maximizing the number

25
00:01:30,968 --> 00:01:34,497
of useful compute operations per thread.

26
00:01:34,497 --> 00:01:40,243
Really what we care about here is minimizing the time spent on memory per thread.

27
00:01:40,243 --> 00:01:44,772
And I phrased this carefully because it is not the total number of memory operations that we care about

28
00:01:44,772 --> 00:01:46,962
and it's not the total amount of memory that comes

29
00:01:46,962 --> 00:01:49,310
and goes in the course of the thread executing its program.

30
00:01:49,310 --> 00:01:51,215
It's how long it takes us to do that,

31
00:01:51,215 --> 00:01:54,189
so there are a lot of ways to spend less time on memory accesses.

32
00:01:54,189 --> 00:01:55,801
And that's what we're going to talk about now.
