1
00:00:00,012 --> 00:00:03,741
I want to make a point here that--it's a bit of a ninja topic,

2
00:00:03,741 --> 00:00:10,013
but it turns out that exploding every last bit of parallelism isn't always the very best performing code.

3
00:00:10,013 --> 00:00:12,780
Sometimes it helps to do more work per thread,

4
00:00:12,780 --> 00:00:19,190
and this leads to an advanced optimization technique called granularity coarsening that we'll talk about later.

5
00:00:19,190 --> 00:00:22,972
With that said, the first problem is almost always to find enough parallelism.

6
00:00:22,972 --> 00:00:25,513
So keeping that in mind, are we done?

7
00:00:25,513 --> 00:00:30,367
Is this 0.7 milliseconds the fastest that we can transpose this matrix on this GPU?

8
00:00:30,367 --> 00:00:32,136
Let's reason that out.

9
00:00:32,136 --> 00:00:34,751
So 2 things can limit your performance on any code:

10
00:00:34,751 --> 00:00:38,089
Time spent fetching and storing data from and to memory,

11
00:00:38,089 --> 00:00:41,592
or time spent performing compute operations on that data.

12
00:00:41,592 --> 00:00:47,753
Now the transpose code has almost no computation at all; it's entirely about moving data around.

13
00:00:47,753 --> 00:00:52,222
So let's ignore compute for the moment and focus on memory.

14
00:00:52,222 --> 00:00:57,814
My question is, are we moving that data around efficiently? How can we tell?

15
00:00:57,814 --> 00:01:02,410
There's a handy utility called Device Query that's included in the CUDA SDK.

16
00:01:02,410 --> 00:01:04,339
Let's run it.

17
00:01:04,339 --> 00:01:06,600
Device Query spits out an enormous amount of information,

18
00:01:06,600 --> 00:01:08,839
and most of which you really don't need to know right now,

19
00:01:08,839 --> 00:01:11,276
but buried in here are a few things that I want to point out.

20
00:01:11,276 --> 00:01:16,369
The GPU clock rate is how fast the actual processors in the GPU are going.

21
00:01:16,369 --> 00:01:20,457
The memory clock rate shows you how fast the memory in the GPU is operating.

22
00:01:20,457 --> 00:01:24,088
And the memory bus width describes how many bits of memory

23
00:01:24,088 --> 00:01:27,603
are actually being transferred for each of these clock cycles.

24
00:01:27,603 --> 00:01:31,402
So from this we can actually figure out the maximum speed of the memory,

25
00:01:31,402 --> 00:01:36,466
the maximum bandwidth, the maximum amount of data that we can transfer in a second.
