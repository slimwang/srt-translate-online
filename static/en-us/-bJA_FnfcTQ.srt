1
00:00:00,380 --> 00:00:05,050
Now we have spent a lot of time looking
at various methods of processing images.

2
00:00:05,050 --> 00:00:09,970
So in essence, the same kinds
of stuff can be done for videos.

3
00:00:09,970 --> 00:00:12,250
So rather than apply
to individual frames,

4
00:00:12,250 --> 00:00:14,353
we want to apply it to
whole video volume.

5
00:00:14,353 --> 00:00:18,671
Again, remember, in essence, what
we're talking about is now, basically,

6
00:00:18,671 --> 00:00:19,949
this a stack of volume.

7
00:00:19,949 --> 00:00:23,445
And when the t deck sees this putting
up this way, x and y, sorry, y and

8
00:00:23,445 --> 00:00:24,850
x are still there.

9
00:00:24,850 --> 00:00:28,150
So, in essence, what we're trying to
talk about is how we're going to now

10
00:00:28,150 --> 00:00:31,540
take a video volume, and
this is of course the number of frames,

11
00:00:31,540 --> 00:00:34,260
how would we actually run the filtering
mechanisms we've talked about.

12
00:00:34,260 --> 00:00:37,350
So all of the stuff that we
learned about convolutions,

13
00:00:37,350 --> 00:00:40,441
cross correlation, and
using those methods can be

14
00:00:40,441 --> 00:00:43,554
applied in this case to
a three-dimensional dataset.

15
00:00:43,554 --> 00:00:47,107
So of course,
we can do all of this stuff in 3D.

16
00:00:47,107 --> 00:00:52,680
What we basically do is, our space
that we interact with is x, y, and t.

17
00:00:52,680 --> 00:00:56,670
An interesting point to also remember is
that this kind of motion information and

18
00:00:56,670 --> 00:01:01,410
filtering is widely used in compression
for videos too, not only do in images.

19
00:01:01,410 --> 00:01:03,650
Remember we talked about
compression briefly.

20
00:01:03,650 --> 00:01:06,495
We just did this in space,
that is in x and y, but

21
00:01:06,495 --> 00:01:08,565
now we can actually do this x, y, and

22
00:01:08,565 --> 00:01:11,973
also use the motion information in t,
to compress the amount of data.

23
00:01:11,973 --> 00:01:16,255
Similarly, all the stuff we looked at,
change detection for

24
00:01:16,255 --> 00:01:19,637
doing gradient computation,
we looked at how to do this in x and

25
00:01:19,637 --> 00:01:22,847
y where we can do this
thing also in video.

26
00:01:22,847 --> 00:01:26,397
Except that this time around
we can apply an x and t and

27
00:01:26,397 --> 00:01:28,977
also y and t, besides x and y.

28
00:01:28,977 --> 00:01:31,387
So now we have three
different dimentions.

29
00:01:31,387 --> 00:01:35,087
So simple observation that I like to
make right now is that if I have two

30
00:01:35,087 --> 00:01:40,490
images, and if each and every pixel
from that one image to the other

31
00:01:40,490 --> 00:01:45,650
image is different, then it's just
likely that there is a drastic change,

32
00:01:45,650 --> 00:01:48,060
or a motion change
from those two frames.

33
00:01:48,060 --> 00:01:51,868
So, for example here in this image,
you're seeing a lotta changes,

34
00:01:51,868 --> 00:01:54,820
but they're changes right
in certain parts of it.

35
00:01:54,820 --> 00:01:57,880
What we could be actually doing is,
if this whole image, each and

36
00:01:57,880 --> 00:02:02,460
every pixel changes, then we can
actually look for a much drastic change.

37
00:02:02,460 --> 00:02:05,320
And those kinds of drastic
motion change could actually

38
00:02:05,320 --> 00:02:07,950
be indicative of something
special about the video also.
