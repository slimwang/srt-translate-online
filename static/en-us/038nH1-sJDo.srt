1
00:00:00,080 --> 00:00:04,070
To summarize, the performance results
for Flash show the following.

2
00:00:04,070 --> 00:00:08,980
When the data is in cache, the basic
SPED model performs much better than

3
00:00:08,980 --> 00:00:13,720
the AMPED Flash,
because it doesn't require the test for

4
00:00:13,720 --> 00:00:17,145
memory presence,
which was necessary in the AMPED Flash.

5
00:00:17,145 --> 00:00:21,387
Both SPED and the AMPED Flash
are better than the multi-threaded or

6
00:00:21,387 --> 00:00:25,755
multi-process models, because they don't
incur any of the synchronization or

7
00:00:25,755 --> 00:00:29,085
context switching overheads that
are necessary with these models.

8
00:00:29,085 --> 00:00:33,665
When the workload is disk-bound,
however, AMPED performs much better than

9
00:00:33,665 --> 00:00:38,970
the single-process event-driven model,
because the single process model blocks,

10
00:00:38,970 --> 00:00:41,450
since there's no support for
asynchronous I/O.

11
00:00:41,450 --> 00:00:45,250
AMPED Flash performs better than both
the multi-threaded and the multi-process

12
00:00:45,250 --> 00:00:50,390
model, because it has much more
memory efficient implementation,

13
00:00:50,390 --> 00:00:54,380
and it doesn't require the same level of
context switching as in these models.

14
00:00:55,410 --> 00:01:00,330
Again, only the number of concurrent
I/O bound requests result

15
00:01:00,330 --> 00:01:04,680
in concurrent processes or
concurrent threads in this model.

16
00:01:04,680 --> 00:01:10,080
The model is not necessarily suitable
for every single type of server process.

17
00:01:10,080 --> 00:01:13,310
There are certain challenges
with event-driven architecture.

18
00:01:13,310 --> 00:01:17,990
We said, some of these can come from the
fact that we need to take advantage of

19
00:01:17,990 --> 00:01:23,470
multiple cores and we need to be able to
route events to the appropriate core.

20
00:01:23,470 --> 00:01:26,350
In other cases,
perhaps the processing itself,

21
00:01:26,350 --> 00:01:30,060
is not as suitable for
this type of architecture.

22
00:01:30,060 --> 00:01:34,230
But if you look at some of the high
performance server implementations

23
00:01:34,230 --> 00:01:39,470
that are in use today, you will see
that a lot of them do in fact use

24
00:01:39,470 --> 00:01:43,470
a event-driven model,
combined with a synchronous I/O support.
