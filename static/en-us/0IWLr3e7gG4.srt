1
00:00:00,150 --> 00:00:02,700
So what do I mean by the cross-correlation method?

2
00:00:02,700 --> 00:00:07,460
In signal processing, cross-correlation is a measure of similarity of two

3
00:00:07,460 --> 00:00:12,570
different waveforms as a function of the time-lag applied to one of them.

4
00:00:12,570 --> 00:00:17,450
What that basically means is that I have two different signals, two different

5
00:00:17,450 --> 00:00:22,280
waveforms, and I want to combine them to figure out what are the best ways that

6
00:00:22,280 --> 00:00:26,060
I can correlate the two different signals together, and allow me to kind of

7
00:00:26,060 --> 00:00:29,100
do things, of measuring the similarity between those signals.

8
00:00:29,100 --> 00:00:32,380
We will look at that for a variety of reasons when we get into feature

9
00:00:32,380 --> 00:00:36,170
detection and stuff in the later lectures, but this is an important part of

10
00:00:36,170 --> 00:00:39,690
what we want to actually look at a little bit more carefully now.

11
00:00:39,690 --> 00:00:42,420
And then actually we'll use that to develop other concepts.

12
00:00:42,420 --> 00:00:46,010
Another way of looking at the cross-correlation is also considering it

13
00:00:46,010 --> 00:00:51,010
as a sliding dot product, or an inner-product of two different signals.

14
00:00:51,010 --> 00:00:54,210
And you witness this when we actually look at a smaller kernel and

15
00:00:54,210 --> 00:00:59,530
we slid it over a bigger image and actually computed at the center, or

16
00:00:59,530 --> 00:01:03,190
a representative point, the output which was the combination, or

17
00:01:03,190 --> 00:01:07,080
an inert dot product of those two signals.

18
00:01:07,080 --> 00:01:10,900
And that's an important part on how the process unfolded as we looked at

19
00:01:10,900 --> 00:01:14,810
how we did the processing or filtering in the last lecture.

20
00:01:14,810 --> 00:01:18,600
Mathematical notation of cross-correlation is shown here.

21
00:01:18,600 --> 00:01:20,720
Again, we are using the two summations and

22
00:01:20,720 --> 00:01:25,930
looping over the whole image here with non-uniform attribute weights.

23
00:01:25,930 --> 00:01:29,700
Mathematically, we will denote this by symbol here,

24
00:01:29,700 --> 00:01:34,840
where basically the kernel h is being cross-correlated with the out,

25
00:01:34,840 --> 00:01:37,920
input signal, F, to generate an output G.

26
00:01:37,920 --> 00:01:41,040
So what do we mean when we say now, we are filtering an image?

27
00:01:41,040 --> 00:01:43,870
What we mean by filtering an image here is,

28
00:01:43,870 --> 00:01:47,050
what we are doing is replacing each pixel in the output with

29
00:01:47,050 --> 00:01:52,390
a linear combination of its neighbors with a kernel matrix.

30
00:01:52,390 --> 00:01:58,160
And for each one of them, there is a kernel or a mask signal, h here.

31
00:01:58,160 --> 00:02:03,090
And basically that is a prescription, a function

32
00:02:03,090 --> 00:02:07,330
of weights which is applied as a linear combination to generate an output G.

33
00:02:08,650 --> 00:02:10,508
And we saw this as I rubbed over,

34
00:02:10,508 --> 00:02:14,820
again h over the input image F to generate the output G, earlier.
