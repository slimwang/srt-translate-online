1
00:00:00,054 --> 00:00:04,431
Okay, so here we've run NVVP on the function again.

2
00:00:04,431 --> 00:00:10,334
I'll zoom in on these second functions. Here's our transpose per element tile.

3
00:00:10,334 --> 00:00:12,741
This is the kernel we just wrote.

4
00:00:12,741 --> 00:00:19,369
And as you can see, it's running with 32 by 32 thread blocks, each of which has 32 by 32 threads.

5
00:00:19,369 --> 00:00:25,482
And sure enough we're achieving a 100% global load efficiency and 100% global store efficiency.

6
00:00:25,482 --> 00:00:29,699
And yet, our DRAM utilization has actually gone down slightly.

7
00:00:29,699 --> 00:00:34,589
So whats going on? Why is our achieved bandwidth still so low?

8
00:00:34,589 --> 00:00:40,509
The answer is going to come down to this statistic here--Shared Memory Replay Overhead.

9
00:00:40,509 --> 00:00:43,979
But before we get into the details of Shared Memory Replay Overhead,

10
00:00:43,979 --> 00:00:47,110
what that means and what to do about it, I want to back up for a little bit

11
00:00:47,110 --> 00:00:52,192
and talk about a general principle of how do we make the GPU fast.
