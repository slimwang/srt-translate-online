1
00:00:00,390 --> 00:00:05,163
If you think about RNNs in general,
they are a very general, trainable model

2
00:00:05,163 --> 00:00:09,370
that maps variable-length
sequences to fixed-length vectors.

3
00:00:09,370 --> 00:00:12,490
In fact, thanks to the sequence
generation and Beam search that we've

4
00:00:12,490 --> 00:00:16,940
just discussed, they can also be made to
map fixed-length vectors to sequences.

5
00:00:18,028 --> 00:00:23,110
Start from a vector, map it to the state
of your RNN, then produce a prediction.

6
00:00:23,110 --> 00:00:25,500
Then sample from it,
or use Beam search, and

7
00:00:25,500 --> 00:00:27,940
feed them back into the RNN
to get the next one.

8
00:00:29,180 --> 00:00:32,700
Now you have those two building blocks,
and you can stitch them together.

9
00:00:32,700 --> 00:00:35,550
It gives you a new model that maps
sequences of arbitrary lengths to other

10
00:00:35,550 --> 00:00:36,870
sequences of arbitrary length.

11
00:00:36,870 --> 00:00:40,450
And it's fully trainable.

12
00:00:41,590 --> 00:00:43,080
What can you do with?

13
00:00:43,080 --> 00:00:44,160
Many things.

14
00:00:44,160 --> 00:00:46,845
Imagine that your input is
a sequence of English words and

15
00:00:46,845 --> 00:00:48,850
you output a sequence of French words.

16
00:00:48,850 --> 00:00:50,690
You've just built a machine
translation system.

17
00:00:51,840 --> 00:00:53,660
All you need is some parallel text.

18
00:00:54,890 --> 00:00:58,010
Imagine that your input is sounds and
your output words.

19
00:00:58,010 --> 00:01:00,300
You've just built an end-to-end
speech recognition system.

20
00:01:01,350 --> 00:01:06,160
Real systems based on variations on this
design exist and are very competitive.

21
00:01:06,160 --> 00:01:08,990
In practice,
they do require a lot of data and

22
00:01:08,990 --> 00:01:10,204
a lot of compute to work very well.

23
00:01:11,455 --> 00:01:14,935
We've also talked about conv nets,
which basically map images

24
00:01:14,935 --> 00:01:18,335
into vectors that represent
the content of that image.

25
00:01:18,335 --> 00:01:23,655
So picture what would happen if you took
a conv net and connected it to an RNN.

26
00:01:23,655 --> 00:01:26,959
You have an image going in, and
a sequence of things coming out.

27
00:01:26,959 --> 00:01:28,675
A sequence of words maybe.

28
00:01:28,675 --> 00:01:30,015
Maybe the caption for that image.

29
00:01:31,230 --> 00:01:34,440
To do that,
you need training images and captions.

30
00:01:34,440 --> 00:01:37,190
There are a few data sets out
there that you can use for that.

31
00:01:37,190 --> 00:01:38,793
Most notably the coco data set.

32
00:01:38,793 --> 00:01:42,740
It does images and
crowdsourced captions for them.

33
00:01:42,740 --> 00:01:46,393
You can train a model that uses
a cov net to analyze the image and

34
00:01:46,393 --> 00:01:48,229
generate captions from them.

35
00:01:48,229 --> 00:01:49,390
And it works.

36
00:01:49,390 --> 00:01:53,250
You can get great captions,
generated completely automatically, and

37
00:01:53,250 --> 00:01:55,470
it sometimes fails in very,
very funny ways.
