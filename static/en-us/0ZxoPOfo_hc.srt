1
00:00:00,000 --> 00:00:03,339
Okay, so the second half of this unit concentrates on sort.

2
00:00:03,339 --> 00:00:08,077
Sorting is a fundamental operation, and understanding how we might approach this problem in

3
00:00:08,077 --> 00:00:13,618
the parallel world gives a lot of insight as to what works well and what doesn't work well on GPUs.

4
00:00:13,618 --> 00:00:15,817
There's a lot of neat algorithms in sorting,

5
00:00:15,817 --> 00:00:18,321
and I hope the rest of the unit gives you some new ideas about

6
00:00:18,321 --> 00:00:22,133
how to approach the design of efficient parallel algorithms.

7
00:00:22,133 --> 00:00:26,596
Now, sort is a challenging problem on GPUs for several reasons.

8
00:00:26,596 --> 00:00:32,843
The first is that most sort algorithms are serial algorithms, or at least, usually expressed in a serial fashion,

9
00:00:32,843 --> 00:00:35,473
particularly those you might have learned in an algorithms class.

10
00:00:35,473 --> 00:00:39,976
So all those nice algorithms that you learned in school are not necessarily applicable here,

11
00:00:39,976 --> 00:00:42,876
and we'll see this in a bit. The second is that for performance reasons,

12
00:00:42,876 --> 00:00:47,651
we prefer to look at algorithms, parallel algorithms that coalesce memory axises and have little

13
00:00:47,651 --> 00:00:51,350
branch divergents among threads, and particularly that are able to keep the

14
00:00:51,350 --> 00:00:54,899
hardware busy by keeping lots of threads busy at the same time.

15
00:00:54,899 --> 00:00:59,329
So the sort of algorithms that you might have learned in an algorithm course tend to be moving

16
00:00:59,329 --> 00:01:02,838
around little bits of memory at a time and they have very branchy code,

17
00:01:02,838 --> 00:01:07,636
and they're not often very parallel, so we'd like to take a look at algorithms that

18
00:01:07,636 --> 00:01:12,075
have the other characteristics, that can keep the hardware busy, that do limit branch divergence,

19
00:01:12,075 --> 00:01:14,508
that do prefer coalesced memory accesses.

20
00:01:14,508 --> 00:01:18,949
What we're going to do is look at some classic sorting algorithms and discuss how they

21
00:01:18,949 --> 00:01:21,381
might map onto a parallel world.

22
00:01:21,381 --> 00:01:26,384
We'll start with one of the simplest algorithms and one that maps nicely to a parallel implementation.

23
00:01:26,384 --> 00:01:31,858
Odd-even sort, also known as brick sort. If you're familiar with the serial algorithm called bubble sort,

24
00:01:31,858 --> 00:01:34,361
this is the parallel version of bubble sort.

25
00:01:34,361 --> 00:01:38,164
So, we're going to start by putting all of our elements to sort in a row,

26
00:01:38,164 --> 00:01:43,303
And then we're going to mark all the even elements as black and all the odd elements as red.

27
00:01:43,303 --> 00:01:48,476
In an odd-even sort, in the first phase, each red element looks down the line to the left

28
00:01:48,476 --> 00:01:53,139
toward the left end and pairs up with the black elements it's facing.

29
00:01:53,139 --> 00:01:56,947
Now if that pair is out of order, they swap places and colors as well.

30
00:01:56,947 --> 00:02:01,939
Otherwise, they stay in the same places. Now, every red element turns around, faces to its right,

31
00:02:01,939 --> 00:02:06,824
and pairs up with the black element in the other direction. Again, they swap if they're out of order.

32
00:02:06,824 --> 00:02:10,526
So we continue until the sequence is sorted. So let's try an example.

33
00:02:10,526 --> 00:02:14,829
So just to show this with some real numbers, we'll try a sample with these five numbers.

34
00:02:14,829 --> 00:02:17,068
We start by pairing them up, starting at the left,

35
00:02:17,068 --> 00:02:19,916
and we swap each pair if they're out of order.

36
00:02:19,916 --> 00:02:23,376
Then we pair them with the opposite polarity and continue the process.

37
00:02:23,376 --> 00:02:25,914
We return to pairing them the way we did in the first step

38
00:02:25,914 --> 00:02:29,918
and continue to pair them one way then the other way, then one way then the other way,

39
00:02:29,918 --> 00:02:32,552
until we finally conclude with a sorted sequence.

40
00:02:32,552 --> 00:02:35,253
So it's very important that we understand how to measure

41
00:02:35,253 --> 00:02:40,056
the step and work complexity of these algorithms, because that's often the dominant factor in their run time.

42
00:02:40,056 --> 00:02:44,227
So, for this algorithm, what is the step complexity of this algorithm?

43
00:02:44,227 --> 00:02:48,999
Order of 1, log n, n, n log n, or n squared, the number of steps.

44
00:02:48,999 --> 00:02:52,839
And what is the total amount of work that we need to do with the same choices?

45
00:02:52,839 --> 00:02:54,000
Please check your choice.
