1
00:00:00,000 --> 00:00:06,021
So in CUDA a stream is a sequence of operations that will execute in order on the GPU.

2
00:00:06,021 --> 00:00:10,253
And the particular operations we care about are memory transfers and kernel launches.

3
00:00:10,253 --> 00:00:14,362
If I perform a cudaMemcpyAsync, launch kernel A,

4
00:00:14,362 --> 00:00:18,429
then perform a second cudaMemcpyAsync and then launch kernel B,

5
00:00:18,429 --> 00:00:21,628
then each operation completes before the next starts.

6
00:00:21,628 --> 00:00:26,040
So the first Memcpy happens, then kernel A runs to completion.

7
00:00:26,040 --> 00:00:30,406
Then the second Memcpy happens and then the second kernel runs.

8
00:00:30,406 --> 00:00:35,479
But if I do those same operations and this time I put them each in a different stream

9
00:00:35,479 --> 00:00:38,313
by adding a parameter which is the stream,

10
00:00:38,313 --> 00:00:44,098
then now these operations can potentially run concurrently, therefore completing in much less time.

11
00:00:44,098 --> 00:00:48,459
So this operation is in stream 1, this operation is in stream 2,

12
00:00:48,459 --> 00:00:52,867
this operation is in stream 3, this operation is in stream 4.

13
00:00:52,867 --> 00:00:55,467
Since we didn't specify a stream for any of these,

14
00:00:55,467 --> 00:01:00,541
we would say that they are in the default stream, which happens to be stream 0.

15
00:01:00,541 --> 00:01:06,740
A couple of notes. A CUDA stream object is of type cudaStream_t.

16
00:01:06,740 --> 00:01:10,584
For example, here we declare a stream called s1.

17
00:01:10,584 --> 00:01:14,092
You create streams using the cudaStreamCreate call,

18
00:01:14,092 --> 00:01:19,396
passing in a pointer to the stream you want to create, and you destroy them by calling cudaStreamDestroy.

19
00:01:19,396 --> 00:01:21,964
And remember, to get asynchronous memory transfers

20
00:01:21,964 --> 00:01:27,865
you need to be using cudaMemcopyAsync, which in turn must be called on pinned host memory.
