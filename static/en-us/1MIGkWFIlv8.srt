1
00:00:00,390 --> 00:00:02,830
Okay, Michael. Which of these two decision trees is smaller?

2
00:00:02,830 --> 00:00:05,910
>> [LAUGH] The one on the right is smaller.

3
00:00:05,910 --> 00:00:08,360
>> That's exactly right because it's easier, it's,

4
00:00:08,360 --> 00:00:10,810
it's easier to represent it in sort of almost

5
00:00:10,810 --> 00:00:12,190
any obvious way that you could think of. It

6
00:00:12,190 --> 00:00:15,890
has fewer nodes, so smaller decision trees, trees with

7
00:00:15,890 --> 00:00:18,320
fewer nodes, less depth, whatever you need to

8
00:00:18,320 --> 00:00:21,420
make it smaller, have smaller lengths than bigger decision

9
00:00:21,420 --> 00:00:23,420
trees. So that means that if all we cared

10
00:00:23,420 --> 00:00:25,980
about was the second term here. We would prefer

11
00:00:25,980 --> 00:00:28,380
smaller decision trees, over bigger decisions trees.

12
00:00:28,380 --> 00:00:29,300
>> Which we do.

13
00:00:29,300 --> 00:00:32,880
>> Which we do. Now what about this over here? The, what

14
00:00:32,880 --> 00:00:35,310
does it mean? So this is pretty straight forward. You got this right?

15
00:00:35,310 --> 00:00:37,350
>> That the length of. Well, I mean guess

16
00:00:37,350 --> 00:00:39,270
what's weird that you, you're kind of moving back and

17
00:00:39,270 --> 00:00:41,430
forth between a notion of a prior, which is

18
00:00:41,430 --> 00:00:43,510
where the p of h came from and a notion

19
00:00:43,510 --> 00:00:45,670
of Well, you know, if we're going to actually have

20
00:00:45,670 --> 00:00:47,630
to describe the hypothesis you're going to have to write

21
00:00:47,630 --> 00:00:49,570
it down in some way, and this gives you

22
00:00:49,570 --> 00:00:51,020
a way of measuring how long it takes to write

23
00:00:51,020 --> 00:00:53,400
it down. But I guess what this whole derivation

24
00:00:53,400 --> 00:00:55,120
is doing is linking those two concepts, so that

25
00:00:55,120 --> 00:00:57,740
you can think about our bias for shorter decision

26
00:00:57,740 --> 00:01:00,980
trees as actually being the prior, right? Actually being the

27
00:01:00,980 --> 00:01:03,820
thing that says the smaller ones are more likely

28
00:01:03,820 --> 00:01:05,900
And vica versa, that when we think about things that

29
00:01:05,900 --> 00:01:08,510
are priors, that are assigning higher probability to certain

30
00:01:08,510 --> 00:01:10,520
things, it's kind of like giving them a shorter description.

31
00:01:10,520 --> 00:01:13,310
>> Right, so infact if you were to take

32
00:01:13,310 --> 00:01:16,090
this example literally here, that we prefer smaller trees

33
00:01:16,090 --> 00:01:19,420
to bigger trees, this kind of a bayesian argument for occam's razor.

34
00:01:19,420 --> 00:01:20,340
>> And pruning.

35
00:01:20,340 --> 00:01:23,660
>> And pruning. Well, you, often use

36
00:01:23,660 --> 00:01:25,950
razors to prune, so it makes perfect sense.

37
00:01:25,950 --> 00:01:29,130
>> Ok, so this is kind of straight foreward, that basically smaller

38
00:01:29,130 --> 00:01:33,940
trees are smaller than bigger trees. It sort of makes sense.

39
00:01:33,940 --> 00:01:36,190
Now, what about this over here? What does it mean to

40
00:01:36,190 --> 00:01:41,200
talk about the length of the data given a particular hypothesis.

41
00:01:41,200 --> 00:01:44,130
>> Uh...I could think of one interpretation there. So

42
00:01:44,130 --> 00:01:47,550
like, if the hypothesis generates the data really well, then

43
00:01:47,550 --> 00:01:49,950
you don't really need the data at all, right?

44
00:01:49,950 --> 00:01:52,800
You just have...you already have the hypothesis. The data is

45
00:01:52,800 --> 00:01:55,410
free. Right? But if it deviates a lot from

46
00:01:55,410 --> 00:01:58,140
the hypothesis, then you're going to have to have a long

47
00:01:58,140 --> 00:02:01,650
description of where the deviations are. So maybe it's kind of

48
00:02:01,650 --> 00:02:04,120
capturing this sort of notion of how well it fits.

49
00:02:04,120 --> 00:02:06,210
>> Right, that's exactly right. So I like that

50
00:02:06,210 --> 00:02:08,449
explanation so let me write it down. So here

51
00:02:08,449 --> 00:02:13,550
we literally just mean something like size of h.

52
00:02:13,550 --> 00:02:17,360
But over here we are talking about, well sort

53
00:02:17,360 --> 00:02:19,480
of error right? if the hypo, if just exactly what

54
00:02:19,480 --> 00:02:23,290
you said if the hypothesis perfectly describes the data,

55
00:02:23,290 --> 00:02:24,980
then you don't need any of the data. But lets

56
00:02:24,980 --> 00:02:27,310
imagine that the hypothesis gets all of the data

57
00:02:27,310 --> 00:02:31,600
labels wrong. Then when you send the hypothesis over To

58
00:02:31,600 --> 00:02:33,800
this person. This, this sort of person we're making up

59
00:02:33,800 --> 00:02:36,570
who, trying to understand the Daden hypothesis. And you're also

60
00:02:36,570 --> 00:02:38,810
going to have to send over what all the correct answers

61
00:02:38,810 --> 00:02:43,340
were. So, what this really is, is a notion of miss-classification

62
00:02:43,340 --> 00:02:46,200
error, or just error in general. If we're thinking about

63
00:02:46,200 --> 00:02:50,450
regression. So, basically, what we're saying is, if we're trying

64
00:02:50,450 --> 00:02:54,060
to find the maximum a posteriori Hypothesis. We want to maximize this

65
00:02:54,060 --> 00:02:58,020
expression. We want to find the h that maximizes this expression.

66
00:02:58,020 --> 00:02:59,560
That's the same as finding the h that

67
00:02:59,560 --> 00:03:02,350
maximizes the log of that expression, which gives you

68
00:03:02,350 --> 00:03:05,650
this. Which is the same as minimizing this expression,

69
00:03:05,650 --> 00:03:08,300
which is just maximizing this expression but throwing a

70
00:03:08,300 --> 00:03:13,010
minus one in front But these terms actually have meanings in information theory,

71
00:03:13,010 --> 00:03:18,110
the best hypothesis, the hypothesis with the maximum a posteriori probability is

72
00:03:18,110 --> 00:03:24,240
the one that minimizes error and the size of your hypothesis.

73
00:03:24,240 --> 00:03:27,990
You want the most simple hypothesis that minimizes

74
00:03:27,990 --> 00:03:32,990
your error. That is pretty much literally occam's razor.

75
00:03:32,990 --> 00:03:36,290
What is important here In reality is that

76
00:03:36,290 --> 00:03:38,890
these are often traded off of one another.

77
00:03:38,890 --> 00:03:41,730
If I give a more complicated or bigger

78
00:03:41,730 --> 00:03:44,810
hypothesis, I can typically drive down my error.

79
00:03:44,810 --> 00:03:49,340
Or I can have a little bit of error for a smaller hypothesis. But this is the

80
00:03:49,340 --> 00:03:53,010
sort of fundamental tradeoff here. You want to find The simplest

81
00:03:53,010 --> 00:03:56,480
hypothesis that still explains your data, that is, minimizes your error.

82
00:03:56,480 --> 00:03:56,970
>> Hm.

83
00:03:56,970 --> 00:03:59,150
>> So this actually has a name, and

84
00:03:59,150 --> 00:04:02,340
that is the minimum description, and there have

85
00:04:02,340 --> 00:04:03,890
been many algorithms over the years that have

86
00:04:03,890 --> 00:04:06,460
tried to do this directly by simply trading

87
00:04:06,460 --> 00:04:09,080
off some notion of error, and some notion

88
00:04:09,080 --> 00:04:11,780
of size. And finding the tradeoff between them

89
00:04:11,780 --> 00:04:13,160
that actually works. Now, if you think about

90
00:04:13,160 --> 00:04:14,910
it for a little whiel Michael you'll realize that

91
00:04:14,910 --> 00:04:17,529
yea this sort of makes sense at the hand wavy level

92
00:04:17,529 --> 00:04:20,399
at which I just talked about it. But, you do have some

93
00:04:20,399 --> 00:04:24,560
real issues here about for example units. So, I don't know if

94
00:04:24,560 --> 00:04:28,290
the units of the size of the hypothesis are directly comparable to

95
00:04:28,290 --> 00:04:31,600
the counts of errors or you know sum of squared errors

96
00:04:31,600 --> 00:04:33,990
or something like that and so you have to come up with

97
00:04:33,990 --> 00:04:36,530
some way of translating between them... And some way of making the

98
00:04:36,530 --> 00:04:40,430
decision whether you would rather minimize this or you'd rather minimize that

99
00:04:40,430 --> 00:04:42,580
if you were forced to make a decision. But the

100
00:04:42,580 --> 00:04:45,320
basic idea is still the same here. That the best

101
00:04:45,320 --> 00:04:49,180
hypothesis is the one that minimizes error without paying too

102
00:04:49,180 --> 00:04:51,970
much of a price for the complexity of the hypothesis.

103
00:04:51,970 --> 00:04:55,860
>> Wow. So I've been sitting here thinking about, so with decision trees,

104
00:04:55,860 --> 00:04:59,530
this notion of length feels... Like you could translate it directly into bits

105
00:04:59,530 --> 00:05:02,820
right like you actually had to write it down and transmit it, it

106
00:05:02,820 --> 00:05:05,430
makes a lot of sense. But then I was thinking about neural networks.

107
00:05:05,430 --> 00:05:08,870
And, and, and given that a fixed neural network architecture it's always

108
00:05:08,870 --> 00:05:12,750
the same number of weights and they're just numbers. So you just

109
00:05:12,750 --> 00:05:15,750
transmit those numbers. So I thought, hmmm, this isn't really helping us

110
00:05:15,750 --> 00:05:17,552
understand? ? ? ? ? ? and then it occurred to me

111
00:05:17,552 --> 00:05:21,237
that those weights, if they get really you're going to need more

112
00:05:21,237 --> 00:05:25,380
bits to express those big weights. And in fact that's exactly when

113
00:05:25,380 --> 00:05:27,540
we get over fitting with neural nets if we let the weights

114
00:05:27,540 --> 00:05:30,970
get too big. So like this gives a really nice story for understanding

115
00:05:30,970 --> 00:05:32,520
neural nets as well.

116
00:05:32,520 --> 00:05:35,310
>> Right. That the complexity is not in the number of parameters

117
00:05:35,310 --> 00:05:37,860
directly but in what you need to represent the value of the parameters.

118
00:05:37,860 --> 00:05:38,550
>> Wow.

119
00:05:38,550 --> 00:05:40,690
>> So I could have ten parameters that are all

120
00:05:40,690 --> 00:05:43,810
binary, in which case I need ten bits. Or they

121
00:05:43,810 --> 00:05:46,800
could be arbitrary real numbers, in which case I might

122
00:05:46,800 --> 00:05:49,730
need, well, an arbitrary number of bits. That's really weird.

123
00:05:49,730 --> 00:05:52,660
>> Yeah, but the point here, Michael, I want to wrap this

124
00:05:52,660 --> 00:05:55,980
up. The point here is we've now used Bayesian learning to derive

125
00:05:55,980 --> 00:05:58,330
a bunch of different things that we've actually been using

126
00:05:58,330 --> 00:06:01,240
all along, and so again the beauty of Bayesian learning is

127
00:06:01,240 --> 00:06:03,930
that it gives you a sort of handle on why

128
00:06:03,930 --> 00:06:05,810
you might be making some of the decisions that you're making.

129
00:06:05,810 --> 00:06:07,850
>> It seems like this raises the theory question

130
00:06:07,850 --> 00:06:11,360
that you threw at me in a previous unit. Right.

131
00:06:11,360 --> 00:06:13,330
Which is like well so if it doesn't really tell

132
00:06:13,330 --> 00:06:16,260
us anything we didn't already know, how important is it?

133
00:06:16,260 --> 00:06:17,940
>> Well in this case, I think it is important

134
00:06:17,940 --> 00:06:21,080
because it told us something that we were thinking and tells

135
00:06:21,080 --> 00:06:23,220
us in fact we were right. So now we can

136
00:06:23,220 --> 00:06:25,300
comfortably go out in the world minimizing some of squared

137
00:06:25,300 --> 00:06:27,940
error when we're in a world where there is some

138
00:06:27,940 --> 00:06:31,520
kind of Gaussian transmission noise. We can go about trying to

139
00:06:31,520 --> 00:06:35,270
Believe Occam's Razor because Bayes told us so. [LAUGH] Thanks

140
00:06:35,270 --> 00:06:37,190
to Shannon. And so on and so forth. We can

141
00:06:37,190 --> 00:06:39,990
do these things and know that in some sense, they're

142
00:06:39,990 --> 00:06:41,930
the right things to do, at least in a Bayesian sense.

143
00:06:41,930 --> 00:06:42,780
>> Neat.

144
00:06:42,780 --> 00:06:45,980
>> Okay, good. Now one more thing, Michael, I'm going to show you.

145
00:06:45,980 --> 00:06:49,810
Which is that everything I've told you so far is a lie. [SOUND]
