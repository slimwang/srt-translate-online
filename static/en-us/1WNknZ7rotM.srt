1
00:00:00,270 --> 00:00:05,040
So today I'm talking Doctor Jimeng Sun
from right here at Georgia Tech.

2
00:00:05,040 --> 00:00:10,900
Jimeng joined us earlier this year
after many years at IBM, where his

3
00:00:10,900 --> 00:00:16,440
work has depended heavily on analyzing
data from electronic health records.

4
00:00:16,440 --> 00:00:21,090
Jimeng thanks very much for
taking the time to be in the course.

5
00:00:21,090 --> 00:00:25,700
I've heard you talk many times about the
difficulties of working with EHR data.

6
00:00:25,700 --> 00:00:28,490
Could you explain some of
those to the students?

7
00:00:28,490 --> 00:00:29,030
>> Sure.

8
00:00:29,030 --> 00:00:30,990
First, Mark great to be here.

9
00:00:32,420 --> 00:00:37,470
So electronic health records very
important for my research and

10
00:00:37,470 --> 00:00:41,660
many other people who work
on clinical informatics,

11
00:00:41,660 --> 00:00:46,600
house care informatics, also need
to access electronic house records.

12
00:00:46,600 --> 00:00:53,220
But electronic house record is very
messy, and lot of missing data in there,

13
00:00:53,220 --> 00:00:59,630
because they are collected for
billing and clinical operation purpose.

14
00:00:59,630 --> 00:01:01,750
They're not designed for research.

15
00:01:01,750 --> 00:01:06,730
So there are a lot of information
in the HR systems, but for a given

16
00:01:06,730 --> 00:01:12,520
patient they only have a small subset
of those, and they're not uniform.

17
00:01:12,520 --> 00:01:16,340
So some patient have a lot more
information than the others, and

18
00:01:16,340 --> 00:01:21,060
that makes the electronic health records
very messy, very difficult to deal with.

19
00:01:21,060 --> 00:01:24,800
The other thing is,
there are just a lot of different kinds

20
00:01:24,800 --> 00:01:29,050
of information that are in EHR systems,
and it's getting more and more.

21
00:01:29,050 --> 00:01:34,910
For example, there are diagnosis
information such as ICD code in there.

22
00:01:34,910 --> 00:01:38,760
And their medication information,
there's lab test.

23
00:01:38,760 --> 00:01:42,630
And their clinical notes
represented as free text.

24
00:01:42,630 --> 00:01:44,000
And their medical images.

25
00:01:45,280 --> 00:01:49,590
And more and more genomic data
getting into the EHR system.

26
00:01:49,590 --> 00:01:54,640
So all of those different type of
information requires different kind of

27
00:01:54,640 --> 00:01:58,330
techniques to process them,
to analyze them.

28
00:01:58,330 --> 00:01:59,040
For example,

29
00:01:59,040 --> 00:02:04,920
for text data like clinical notes,
you need natural language processing.

30
00:02:04,920 --> 00:02:10,160
And for image, you need specialized
medical image analysis tools.

31
00:02:10,160 --> 00:02:13,690
For structured data like
diagnosis medications,

32
00:02:13,690 --> 00:02:17,820
you would use general
data mining techniques.

33
00:02:17,820 --> 00:02:22,880
So people have to be able to pick the
right tools to deal with the right data.

34
00:02:22,880 --> 00:02:25,750
>> In a moment, we're going to talk
about some work you've done around

35
00:02:25,750 --> 00:02:28,830
the early diagnosis of
congestive heart failure.

36
00:02:28,830 --> 00:02:32,130
Which is interesting, particularly
within the context of this course,

37
00:02:32,130 --> 00:02:36,280
because chronic disease has really been
the exemplar I've used throughout.

38
00:02:36,280 --> 00:02:42,730
But first, in that work,
you've had to use that free text data.

39
00:02:42,730 --> 00:02:47,210
And in fact, you've extracted from it,
clinical features.

40
00:02:47,210 --> 00:02:51,090
That can be used by a machine
learning algorithms.

41
00:02:51,090 --> 00:02:52,430
So how do you do that?

42
00:02:52,430 --> 00:02:53,040
How does that work?

43
00:02:54,090 --> 00:02:56,850
>> Right so first for
people who are not so

44
00:02:56,850 --> 00:03:01,920
familiar with clinical notes,
it's very rich information.

45
00:03:01,920 --> 00:03:08,170
A lot of subtlety and a lot of
symptoms are represented in the notes.

46
00:03:08,170 --> 00:03:10,160
Only in the notes,
not in the structured data.

47
00:03:10,160 --> 00:03:14,350
So, it's very important to process
the clinical notes, to extract

48
00:03:14,350 --> 00:03:19,250
those symptom information, the severity
information that are hidden in the text.

49
00:03:19,250 --> 00:03:23,820
So, that's the reason of why we
need to process clinical notes.

50
00:03:23,820 --> 00:03:30,130
And the way we did that is
to use a softer pipeline for

51
00:03:30,130 --> 00:03:34,768
dealing with test called UIMA,
unstructure information

52
00:03:34,768 --> 00:03:40,520
management architecture that's
originally developed at IBM research and

53
00:03:40,520 --> 00:03:45,780
later on becomes an open source project
that many people are using that.

54
00:03:45,780 --> 00:03:48,006
Including later on the Watson project.

55
00:03:48,006 --> 00:03:54,480
So it's facilitate natural language
processing development and you develop

56
00:03:54,480 --> 00:03:59,820
a pipeline of extractors to go through
the text, extracting the information

57
00:03:59,820 --> 00:04:04,540
that you cares about like symptoms
that related to heart failures so

58
00:04:04,540 --> 00:04:10,370
we used heart failure signs and
symptoms, and also the context.

59
00:04:10,370 --> 00:04:14,940
You not only want to know the symptoms
are present in the texts, but

60
00:04:14,940 --> 00:04:18,950
also whether it's in
the positive context,

61
00:04:18,950 --> 00:04:22,550
meaning that the patient is
confirmed to have the symptoms, or

62
00:04:22,550 --> 00:04:27,290
it's in the negative context,
the patient doesn't have the symptom.

63
00:04:27,290 --> 00:04:29,800
So, you also need to know the context.

64
00:04:29,800 --> 00:04:32,920
So, we did many different extractors and

65
00:04:32,920 --> 00:04:35,700
to extract that information and
also the context.

66
00:04:35,700 --> 00:04:37,280
So, it's a lot of work.

67
00:04:37,280 --> 00:04:39,350
>> So armed with that information and

68
00:04:39,350 --> 00:04:43,840
the structured information, you've
developed a machine monitoring algorithm

69
00:04:43,840 --> 00:04:47,190
to diagnose congestive
heart failure earlier.

70
00:04:47,190 --> 00:04:51,230
I should mention to the students
without a clinical background that

71
00:04:51,230 --> 00:04:54,880
congestive heart failure is the single
most expensive medical condition.

72
00:04:56,440 --> 00:05:01,040
And that diagnosing and treating it
early, as we discussed in the course,

73
00:05:01,040 --> 00:05:02,510
is true of most chronic diseases,

74
00:05:02,510 --> 00:05:07,500
we can hope to avoid the complications
that are very expensive to treat.

75
00:05:07,500 --> 00:05:13,680
But it's very subtle at first, there
is no test like a blood glucose you can

76
00:05:13,680 --> 00:05:18,420
take, or a hemoglobin A1C to say
you've got congestive heart failure.

77
00:05:18,420 --> 00:05:23,760
So clinicians often don't pick up on
it as early as might be the case.

78
00:05:23,760 --> 00:05:26,100
Your model does,
can you tell us how you did that?

79
00:05:27,180 --> 00:05:32,510
>> Right, so that's a project we
started when I was at IBM Research

80
00:05:32,510 --> 00:05:37,860
a few years ago in collaboration
with Geisinger health systems.

81
00:05:37,860 --> 00:05:41,980
So we would visit Geisinger and I mean,
trying to learn about what are the most

82
00:05:41,980 --> 00:05:45,605
important or challenging problems
that we can tackle together,

83
00:05:45,605 --> 00:05:49,300
using data-mining machine
learning techniques.

84
00:05:49,300 --> 00:05:52,400
And they identify heart failures, one.

85
00:05:52,400 --> 00:05:57,480
And at times, there are already many
groups are interested in heart failures.

86
00:05:57,480 --> 00:06:03,220
Mostly in the post-diagnosis
phases in terms of readmission,

87
00:06:03,220 --> 00:06:06,515
hospitalization, readmission
after heart failure's diagnosis.

88
00:06:06,515 --> 00:06:09,616
But that groups in Geisinger, the focuc,

89
00:06:09,616 --> 00:06:14,613
they wanted to look at pre-diagnosis,
look at what are the signs and

90
00:06:14,613 --> 00:06:18,650
symptoms that lead to
diagnosis of heart failures.

91
00:06:18,650 --> 00:06:24,320
Can we identify the patient of high risk
of developing heart failures earlier?

92
00:06:24,320 --> 00:06:27,620
So the goal is for early detection.

93
00:06:27,620 --> 00:06:32,080
And we leverage The first thing we
did is we want to see whether that's

94
00:06:32,080 --> 00:06:32,930
even possible.

95
00:06:32,930 --> 00:06:39,030
Are there relevant signal in the data
that earlier than the diagnosis time?

96
00:06:39,030 --> 00:06:43,550
And we look at the clinical notes and
that's where we first developed

97
00:06:43,550 --> 00:06:48,090
natural language processing
techniques to extract that and

98
00:06:48,090 --> 00:06:52,930
the findings from those
notes are very shocking.

99
00:06:52,930 --> 00:06:57,309
In fact,
just defining from the clinical notes,

100
00:06:57,309 --> 00:07:02,540
we're able to publish in
the journal in cardiac failures.

101
00:07:02,540 --> 00:07:05,010
And thus, are medical journals
that clinicians write.

102
00:07:05,010 --> 00:07:09,090
There are some exciting
findings in terms of signs and

103
00:07:09,090 --> 00:07:11,530
symptoms that in
the electronic house records

104
00:07:11,530 --> 00:07:15,570
two years prior to the diagnosis,
and that's very surprising.

105
00:07:15,570 --> 00:07:17,522
Many people don't believe those.

106
00:07:17,522 --> 00:07:19,809
I mean% of patients have that sign and

107
00:07:19,809 --> 00:07:24,360
symptom already in the clinical notes
two years before the diagnosis.

108
00:07:24,360 --> 00:07:27,560
So those make us believe
we can do something.

109
00:07:27,560 --> 00:07:34,100
Then the question is how do we really
leverage that reach the HR information.

110
00:07:34,100 --> 00:07:39,870
So, it would be the integrated data
analysis tools to integrate diagnosis,

111
00:07:39,870 --> 00:07:42,980
lab measure, and medication, and

112
00:07:42,980 --> 00:07:47,970
also clinical notes together to view
the very reach patient profiles.

113
00:07:47,970 --> 00:07:51,430
Then score those patient
profiles using advanced

114
00:07:52,510 --> 00:07:56,167
machine learning techniques to
be able to predict a model.

115
00:07:56,167 --> 00:08:00,650
And that helped us to develop this very
accurate predicting model that can

116
00:08:00,650 --> 00:08:06,780
predict heart failures diagnosis six to
12 months before the actual diagnosis.
