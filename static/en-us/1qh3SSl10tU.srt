1
00:00:00,000 --> 00:00:02,250
NVIDIA called and said, "We'd like you to come here

2
00:00:02,250 --> 00:00:07,835
and start looking at how we can apply this in a more product-orientated sense."

3
00:00:07,835 --> 00:00:09,836
Yeah, NVIDIA was a great partner in the research.

4
00:00:09,836 --> 00:00:12,181
They were giving us access to the hardware and some of the early specs

5
00:00:12,181 --> 00:00:15,791
so we could think about where they were going and how it influenced our research.

6
00:00:15,791 --> 00:00:20,139
When we were all said and done, I got the opportunity to come to NVIDIA and do it for real.

7
00:00:20,139 --> 00:00:23,100
I started the CUDA group with one other guy.--it was just the two of us--

8
00:00:23,100 --> 00:00:28,025
and we hired in a compiler and library and QA guys, and we slowly built our way up,

9
00:00:28,025 --> 00:00:33,053
this time really taking the learnings from Brook and starting over a little bit,

10
00:00:33,053 --> 00:00:37,257
also influencing some of the hardware design, the hardware architecture.

11
00:00:37,257 --> 00:00:41,206
What could we do the generalize the architecture just a little bit to make it a little easier,

12
00:00:41,206 --> 00:00:43,625
to eliminate those roadblocks that we discovered with Brook,

13
00:00:43,625 --> 00:00:46,682
and then eventually come up with our sort of CUDA 1.0?

14
00:00:46,682 --> 00:00:49,431
So how long did you take from the day you got there and you started on this project

15
00:00:49,431 --> 00:00:50,958
to the time it launched?

16
00:00:50,958 --> 00:00:55,627
It was probably a good 2 years of development work that we were pushing to do this work.

17
00:00:55,627 --> 00:01:00,156
A lot of it was spec writing, kind of coming up with paper specs, writing some sample code examples,

18
00:01:00,156 --> 00:01:02,088
seeing if it was usable, easy to use,

19
00:01:02,088 --> 00:01:07,459
picking between a variety of different approaches for how to express the parallelism.

20
00:01:07,459 --> 00:01:10,669
Eventually we latched on to a very basic idea of threading

21
00:01:10,669 --> 00:01:16,336
because we knew that most C and C++ programmers understood the concept of a thread,

22
00:01:16,336 --> 00:01:19,253
at least at the simplest level, and if we could latch on to that

23
00:01:19,253 --> 00:01:21,876
we could actually present a program model that was familiar.

24
00:01:21,876 --> 00:01:24,938
Very early on in the CUDA project we did a road show.

25
00:01:24,938 --> 00:01:28,351
We went out and we talked to every customer who was willing to talk to us, saying,

26
00:01:28,351 --> 00:01:31,262
"Tell us your problems around computing. How can we help you?"

27
00:01:31,262 --> 00:01:33,796
And one of the big sentiments was they didn't want to learn a new language.

28
00:01:33,796 --> 00:01:38,630
And while it was tempting as a researcher to come up with the new parallel programming language

29
00:01:38,630 --> 00:01:42,127
of the world, they just wanted an easy way to get access to the performance,

30
00:01:42,127 --> 00:01:45,045
and they had a bunch of C or C++ or Fortran programmers.

31
00:01:45,045 --> 00:01:48,131
So when we set out to start CUDA, we made sure it's not a new language.

32
00:01:48,131 --> 00:01:51,182
It's just a couple of simple extensions to C and C++

33
00:01:51,182 --> 00:01:56,144
so that anyone who knows those languages plus has a basic understanding of threading

34
00:01:56,144 --> 00:01:59,000
could get access to the GPU's performance.
