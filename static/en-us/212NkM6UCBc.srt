1
00:00:00,000 --> 00:00:07,000
In this problem, a passive TD-reinforcement learning agent starts at S and moves to G

2
00:00:07,000 --> 00:00:13,000
under a fixed policy which says first, make moves that get closest to G.

3
00:00:13,000 --> 00:00:18,000
So if we started here, we'd want to go in this direction because it's closest to G,

4
00:00:18,000 --> 00:00:22,000
and (b) stay on these gray squares which represent roads,

5
00:00:22,000 --> 00:00:28,000
and (c) if you do happen to go off the road, then move it back onto the road immediately.

6
00:00:28,000 --> 00:00:32,000
The actions are stochastic, and they may go in the intended direction,

7
00:00:32,000 --> 00:00:38,000
or they may go 90 degrees off, so if we were here, we'd plan to start under this policy

8
00:00:38,000 --> 00:00:44,000
going in this direction. We might end up there, but we might end up here or here.

9
00:00:44,000 --> 00:00:49,000
And if we did end up here, then we'd immediately head back towards the road,

10
00:00:49,000 --> 00:00:52,000
so we'd aim back down in this direction.

11
00:00:52,000 --> 00:00:57,000
And what I want you to do is click on all the squares that would never be explored

12
00:00:57,000 --> 99:59:59,999
by this reinforcement learning agent following this passive fixed policy.
