1
00:00:00,650 --> 00:00:05,670
Lots of work to be done by the runtime system, to manage and map_reduce

2
00:00:05,670 --> 00:00:10,160
computation. The master data structures include the

3
00:00:10,160 --> 00:00:13,170
location of files created by the completed mappers.

4
00:00:13,170 --> 00:00:16,760
Remember that each mapper is working on

5
00:00:16,760 --> 00:00:19,820
some node of the computational cluster. Producing

6
00:00:19,820 --> 00:00:26,610
its output as files on its local disk. So the master has to have knowledge

7
00:00:26,610 --> 00:00:34,460
of where those files reside. Created by those mappers, and the namespace of

8
00:00:34,460 --> 00:00:40,350
the files that have been created by the mappers. And it also has to keep a score

9
00:00:40,350 --> 00:00:43,490
board, of the mappers and reducers that

10
00:00:43,490 --> 00:00:47,080
are currently assigned to work on different splits.

11
00:00:47,080 --> 00:00:48,960
Because the number of machines that may be

12
00:00:48,960 --> 00:00:52,080
available, may be less than the total number

13
00:00:52,080 --> 00:00:54,810
of machines that will be needed. If I wanted to

14
00:00:54,810 --> 00:00:58,620
do all of the input m splits in parallel and

15
00:00:58,620 --> 00:01:02,540
all of the R output splits in parallel. And therefore,

16
00:01:02,540 --> 00:01:05,690
the scoreboard is saying, at any point in time, who are

17
00:01:05,690 --> 00:01:08,100
all the workers carrying all the mapper functions? Who are

18
00:01:08,100 --> 00:01:10,700
all the workers carrying all the reducer functions? When are they

19
00:01:10,700 --> 00:01:14,720
done? And when they are done. How should I reassign

20
00:01:14,720 --> 00:01:17,280
that worker to a new task. So these are the kind

21
00:01:17,280 --> 00:01:21,330
of things that the master data structures facilitate

22
00:01:21,330 --> 00:01:24,360
the master to do. Then the big thing is

23
00:01:24,360 --> 00:01:27,630
fault tolerance. For a variety of reasons, the

24
00:01:27,630 --> 00:01:30,710
master may find, that an instance, of a map

25
00:01:30,710 --> 00:01:33,640
function that it started, is not responding in

26
00:01:33,640 --> 00:01:36,890
a timely manner. Maybe that node is down for

27
00:01:36,890 --> 00:01:38,820
some reason, maybe the link is down for

28
00:01:38,820 --> 00:01:42,280
some reason, or maybe that processor is taking a

29
00:01:42,280 --> 00:01:46,070
little more time than what the master

30
00:01:46,070 --> 00:01:49,080
expects. It can happen very easily, because in

31
00:01:49,080 --> 00:01:51,870
a. Data center environment where you have

32
00:01:51,870 --> 00:01:54,520
thousands of machines, there could be some machines

33
00:01:54,520 --> 00:01:56,610
that are slower than other machines, there

34
00:01:56,610 --> 00:02:01,070
could be generational differences between the machines that

35
00:02:01,070 --> 00:02:03,360
populate the data center, even though they

36
00:02:03,360 --> 00:02:07,140
may be homogenous in terms of the capabilities.

37
00:02:07,140 --> 00:02:11,530
Programming alignments and even the machine architecture. They

38
00:02:11,530 --> 00:02:14,990
may have speeds that are different because they

39
00:02:14,990 --> 00:02:17,830
correspond to different generations of processes. In any

40
00:02:17,830 --> 00:02:20,970
event, what might happen is that a master may

41
00:02:20,970 --> 00:02:24,070
notice that there is no timely response from

42
00:02:24,070 --> 00:02:27,190
a particular instance. Let's say of a mapper. In

43
00:02:27,190 --> 00:02:28,960
that case, it might say well I'm going

44
00:02:28,960 --> 00:02:32,110
to go ahead assume that that mapper is dead.

45
00:02:32,110 --> 00:02:34,670
I'm going to restart that mapping function on

46
00:02:34,670 --> 00:02:37,320
a different node of the cluster. Now, when

47
00:02:37,320 --> 00:02:41,460
that happens it is possible that the original

48
00:02:41,460 --> 00:02:44,390
mapper is actually dead, or it could be

49
00:02:44,390 --> 00:02:47,130
that it was just slow. In that case,

50
00:02:47,130 --> 00:02:49,730
you could get completion message from more than

51
00:02:49,730 --> 00:02:53,150
one mapper for the same split. So when

52
00:02:53,150 --> 00:02:57,780
you get multiple completion messages from redundant stragglers,

53
00:02:57,780 --> 00:03:00,300
the master has to be able to filter

54
00:03:00,300 --> 00:03:03,820
the mordancy. This is something that is redundant work.

55
00:03:03,820 --> 00:03:05,720
I don't have to care about that. So that's

56
00:03:05,720 --> 00:03:08,660
part of fault tolerance that the master has to

57
00:03:08,660 --> 00:03:12,950
worry about. Locality management is another important thing. In

58
00:03:12,950 --> 00:03:16,690
the memory hierarchy, making sure that the working set

59
00:03:16,690 --> 00:03:20,570
of computations fit in the closest level of the

60
00:03:20,570 --> 00:03:23,290
memory hierarchy of a process is very important, and

61
00:03:23,290 --> 00:03:25,500
this is another thing that has to

62
00:03:25,500 --> 00:03:29,080
be managed very carefully so that the computation

63
00:03:29,080 --> 00:03:32,480
can make good forward progress. In completing the

64
00:03:32,480 --> 00:03:36,050
map produce function. There is an inherent assumption

65
00:03:36,050 --> 00:03:38,270
in the fault tolerance model of the

66
00:03:38,270 --> 00:03:42,620
map produce framework. And that is item potency

67
00:03:42,620 --> 00:03:48,460
of the mapper. That is, even though the same input data split is being worked on

68
00:03:48,460 --> 00:03:52,050
by multiple mappers, It doesn't affect the

69
00:03:52,050 --> 00:03:53,960
semantics of the computation as a whole,

70
00:03:53,960 --> 00:03:55,640
and that is the reason why the

71
00:03:55,640 --> 00:03:59,660
master can simply ignore the redundant stragglers'

72
00:03:59,660 --> 00:04:05,510
message if in fact it was a slow computation engine that was working on a

73
00:04:05,510 --> 00:04:13,480
particular map function. And if it finishes later than when it was supposed to,

74
00:04:13,480 --> 00:04:18,680
and the master has already started another redundant

75
00:04:18,680 --> 00:04:23,470
computation to take care of that particular split, ignoring that

76
00:04:23,470 --> 00:04:28,820
redundant straggler message. Is okay because of the item potency assumption

77
00:04:28,820 --> 00:04:32,960
about the mapping operation. In a similar manner, the master may assign a new

78
00:04:32,960 --> 00:04:35,770
node to carry out reduced function corresponding

79
00:04:35,770 --> 00:04:38,510
to a particular split if there's no timely

80
00:04:38,510 --> 00:04:41,700
response from one of the reduced workers. And

81
00:04:41,700 --> 00:04:44,910
here again, the output file generation that is

82
00:04:44,910 --> 00:04:49,750
associated with a particular. A reducer split depends

83
00:04:49,750 --> 00:04:52,910
on the atomicity of the rename system call

84
00:04:52,910 --> 00:04:57,990
that is used to finally say that oh, this is the old profile generated, and the

85
00:04:57,990 --> 00:05:00,050
master says okay, I'm going to commit this

86
00:05:00,050 --> 00:05:03,690
as the real output file of the computation.

87
00:05:03,690 --> 00:05:06,570
Each reducer is writing a local file, and

88
00:05:06,570 --> 00:05:09,680
finally when the master gets the notification from

89
00:05:09,680 --> 00:05:12,460
the reducer, that it has completed its work,

90
00:05:12,460 --> 00:05:16,780
at that point, master renames that local file

91
00:05:16,780 --> 00:05:19,050
as the final output file, and this is

92
00:05:19,050 --> 00:05:22,320
where can get rid of redundant stranglers who

93
00:05:22,320 --> 00:05:24,050
come along later and say I produce the

94
00:05:24,050 --> 00:05:28,740
same output file for the same split. Master will

95
00:05:28,740 --> 00:05:33,030
say, I already got it, I don't need this, and it can ignore the completion

96
00:05:33,030 --> 00:05:36,660
message from that redundant straggler. The other

97
00:05:36,660 --> 00:05:39,230
thing that the programming environment has to worry

98
00:05:39,230 --> 00:05:42,280
about is locality management, and this is

99
00:05:42,280 --> 00:05:48,250
accomplished using the Google file system that provides

100
00:05:48,250 --> 00:05:50,600
a way by which, efficiently, data can

101
00:05:50,600 --> 00:05:54,090
be. Migrated from the mappers to the reducers.

102
00:05:54,090 --> 00:05:57,670
Task granularity is another important issue. As I

103
00:05:57,670 --> 00:06:00,920
mentioned, the number of nodes available in the

104
00:06:00,920 --> 00:06:05,940
computation cluster may be less than the sum M plus R, where M is the number

105
00:06:05,940 --> 00:06:08,140
of input splits, and R is the number

106
00:06:08,140 --> 00:06:11,970
of. Reducer splits. And it is the responsibility

107
00:06:11,970 --> 00:06:15,660
of the programming framework to come up with

108
00:06:15,660 --> 00:06:19,180
the right task granularity so that there can

109
00:06:19,180 --> 00:06:21,260
be good load balance of the computational

110
00:06:21,260 --> 00:06:24,740
resources. And the programming framework also offers

111
00:06:24,740 --> 00:06:27,720
several refinements to the basic model. The

112
00:06:27,720 --> 00:06:31,200
way the partitioning of the input data space

113
00:06:31,200 --> 00:06:37,260
is done, is by using a hash function that is built into the programming

114
00:06:37,260 --> 00:06:40,445
environment. But the user can override that

115
00:06:40,445 --> 00:06:44,346
partitioning function with his or her own partitioning

116
00:06:44,346 --> 00:06:47,583
function if they think that that'll result in

117
00:06:47,583 --> 00:06:50,496
a better way of organizing the data. And

118
00:06:50,496 --> 00:06:53,016
in the map reduced framework, there is no

119
00:06:53,016 --> 00:06:56,976
interaction between the mappers, but if there's some ordering

120
00:06:56,976 --> 00:06:59,856
guarantees needed in terms of ordering the keys

121
00:06:59,856 --> 00:07:02,376
and so on, that is something that the user

122
00:07:02,376 --> 00:07:05,120
may have to take care of. The other

123
00:07:05,120 --> 00:07:10,120
thing that the user may also do is combining.

124
00:07:10,120 --> 00:07:13,040
A partial merging to increase the granularity

125
00:07:13,040 --> 00:07:16,520
of the tasks that execute a mapping function.

126
00:07:16,520 --> 00:07:19,460
Remember that when we looked at the simple

127
00:07:19,460 --> 00:07:23,078
example of looking for specific names and input

128
00:07:23,078 --> 00:07:29,960
corpus of data, I mentioned that. The mapper can be as simple as emitting a one

129
00:07:29,960 --> 00:07:32,630
for a value every time it encounters the

130
00:07:32,630 --> 00:07:35,310
name Kishore for instance in an input file.

131
00:07:35,310 --> 00:07:38,230
Or, it could take an input file and count

132
00:07:38,230 --> 00:07:41,030
all the occurrences of Kishore in that input file

133
00:07:41,030 --> 00:07:44,110
and finally emit the total value as the output

134
00:07:44,110 --> 00:07:46,060
of the mapper. That kind of combining function is

135
00:07:46,060 --> 00:07:49,956
something that. A user may choose to incorporate in

136
00:07:49,956 --> 00:07:53,388
writing his mapping and reduce functions. It is very

137
00:07:53,388 --> 00:07:56,412
important to recognize that in order for the fault

138
00:07:56,412 --> 00:08:00,588
tolerance model of the programming environment to work correctly,

139
00:08:00,588 --> 00:08:03,950
map and reduce functions have to be item potent.

140
00:08:03,950 --> 00:08:07,600
That's a fundamental assumption. That the fault tolerant monitoring

141
00:08:07,600 --> 00:08:10,780
of the programming framework is based on. And there

142
00:08:10,780 --> 00:08:14,590
are also other bells and whistles in the programming framework

143
00:08:14,590 --> 00:08:17,350
for getting status information and logs and so on

144
00:08:17,350 --> 00:08:20,270
and so forth, but the basic idea I want to

145
00:08:20,270 --> 00:08:23,250
leave you with is the fact that the programming

146
00:08:23,250 --> 00:08:26,080
framework is a very simple one. It has two operations,

147
00:08:26,080 --> 00:08:32,280
map and reduce and using those two operations. You can specify a

148
00:08:32,280 --> 00:08:37,850
complex application that you want to call up, to run on a data

149
00:08:37,850 --> 00:08:41,780
center, using the computation resources that's available in the data center.
