1
00:00:00,000 --> 00:00:05,532
(Peter) So here's Michael Grotik in Barcelona, wants to know, "What kind of computer processing do you need

2
00:00:05,533 --> 00:00:10,032
on an autonomous vehicle? Do you need fancy CPUs and a lot of RAM?"

3
00:00:10,033 --> 00:00:17,432
(Sebastian) Well, you need a lot of processing. We tend to have usually a quad core computer or two on the device.

4
00:00:17,433 --> 00:00:26,132
Most of the processing is actually sensor data, so camera data tends to occupy at least one or two cores of a CPU.

5
00:00:26,133 --> 00:00:31,832
And then exadata, in our case, comes a million points a second, occupies another core.

6
00:00:31,833 --> 00:00:37,966
And then it goes down into the processing needs. So our current (unintelligible) cars can safely live

7
00:00:37,967 --> 00:00:41,699
on a single quad core computer and drive just fine.

8
00:00:41,700 --> 00:00:48,899
It's actually not an exercise in computing. Evaluating a Google instant query takes, I don't know, I'm guessing,

9
00:00:48,900 --> 00:00:54,132
10,000 times as many computers, for a short amount of time, and they're really fast.

10
00:00:54,133 --> 00:00:58,866
It's much more a question of algorithms. To make sure that the computer software actually makes the right decisions

11
00:00:58,867 --> 00:01:05,632
is much harder. So if someone gave us a supercomputer, we actually wouldn't know what to do with it on a car.

12
00:01:05,633 --> 00:01:11,499
So here's by Pravin in Chennai, Indiana--actually, India.

13
00:01:11,500 --> 00:01:16,366
"This is definitely one of the best classes I've ever had. Thank you, instructors. It would be really great

14
00:01:16,367 --> 00:01:22,232
"if you considered doing a class in advanced A.I. What are the research options that can be formulated

15
00:01:22,233 --> 00:01:26,399
"by some of the ideas described in this class?" Peter?

16
00:01:26,400 --> 00:01:30,899
(Peter) Yeah, so they keep on asking for the advanced A.I. class. I guess we'll have to get around to that.

17
00:01:30,900 --> 00:01:33,299
(Sebastian) Do you think there's a message in there, "Let's do it?" (Peter) Yeah, we should do it.

18
00:01:33,300 --> 00:01:37,866
(Sebastian) You know what? I like sleep, I like my family. (Peter) We're going to sleep for a little while,

19
00:01:37,867 --> 00:01:42,799
but then we'll think about getting back to it. (Sebastian) And I love all of you who are seeing this online.

20
00:01:42,800 --> 00:01:47,199
You guys are my heroes. I've received some unbelievable emails that really broke my heart.

21
00:01:47,200 --> 00:01:53,499
I received recently an email from a mother of three children who was raising their kids and doing their midterm exam

22
00:01:53,500 --> 00:02:00,166
with one hand while having a teething child in her other hand, and it was just completely mind-blowing,

23
00:02:00,167 --> 00:02:06,132
what effect this class has had, and how many of you feel so positive about it. I'm really humbled by it.

24
00:02:06,133 --> 00:02:09,098
I just want to express this.

25
00:02:09,100 --> 00:02:15,032
The second part of the question was--let's see, let me scroll up again--

26
00:02:15,033 --> 00:02:19,532
"What are the research options that can be formulated from the ideas described in this class?"

27
00:02:19,533 --> 00:02:26,666
I think we covered, basically we did a short coverage of all of A.I. That's not quite true. There's areas of A.I. that are missing.

28
00:02:26,667 --> 00:02:32,599
Like genetic algorithms and ontologies and knowledge-based systems. And we probably brought to air

29
00:02:32,600 --> 00:02:37,532
some of our personal biases in the direction of the material. But if you go to a modern-day A.I. conference,

30
00:02:37,533 --> 00:02:44,066
like, there's a couple (unintelligible) I'm sharing in 2013, in China, you would find that this is kind of basically

31
00:02:44,067 --> 00:02:51,066
what's happening in the field. And all of those we touched just superficially. So if you read Peter's amazing book,

32
00:02:51,067 --> 00:02:55,866
you'd find in the book alone you get twice, three times as deep a treatment of all of those.

33
00:02:55,867 --> 00:03:00,832
The key thing for researchers, in my opinion, just pick a problem, something that bothers you.

34
00:03:00,833 --> 00:03:04,799
Like if you're walking to your house and you're bothered by the fact that you have to flip on the light switch,

35
00:03:04,800 --> 00:03:09,699
just solve it, okay? If you open your fridge and you have like old produce and you keep forgetting that

36
00:03:09,700 --> 00:03:15,066
the salad only lasts for a week, and you want to make it so that in the future, that your produce doesn't get old,

37
00:03:15,067 --> 00:03:21,266
just solve it. And if you solve this problem through A.I. and you can leverage some of the skills you learned in this class,

38
00:03:21,267 --> 00:03:26,532
and it'll be amazing. (Peter) Yeah. So I agree with that. We talked about that in a lot of office hours,

39
00:03:26,533 --> 00:03:32,399
of just picking out a problem and doing it. I think another way to look at it, though, is you can look at it from the side of,

40
00:03:32,400 --> 00:03:38,599
"What do I want?" or you can look at it from the side of, "What do I have?" and that if you have a lot of data available,

41
00:03:38,600 --> 00:03:44,932
if you have an autonomous car, then do something with that. If you have a copy of the web, then do something

42
00:03:44,933 --> 00:03:50,199
with that data. So you can approach it in either direction, or maybe have the two meet somewhere in the middle.

43
00:03:50,200 --> 00:03:54,632
(Sebastian) And there are so many other options. If you have a smartphone, you can make it learn how fast you walked,

44
00:03:54,633 --> 00:04:00,632
how far you walked. The problem of finding out what the angular orientation is of a smartphone is an open problem,

45
00:04:00,633 --> 00:04:06,832
because compasses aren't very reliable. Little small things sometimes are just really amazing to do A.I. about.

46
00:04:06,833 --> 00:04:10,999
Here's a question from Washington, D.C., by Terry, who's a Stanford alum.

47
00:04:11,000 --> 00:04:16,732
"Thank you for this great experiment." Of course, I love reading these questions. They're all about how great the class was.

48
00:04:16,733 --> 00:04:23,932
"It's been long since my days at Stanford. I'm so proud that my alma mater is doing such pioneering work.

49
00:04:23,933 --> 00:04:28,599
"And makes sure that it should catch up with other institutions." So here's the real question, Peter:

50
00:04:28,600 --> 00:04:34,332
"How does this online teaching experience compare to your regular teaching experience?"

51
00:04:34,333 --> 00:04:41,632
(Peter) Well, like most things in life that are worth doing, it ends up being a lot harder than you ever thought it was going to be.

52
00:04:41,633 --> 00:04:46,132
I thought that doing the online work would be a little bit harder because you've got to prepare the videos,

53
00:04:46,133 --> 00:04:50,532
and if you stumble in the middle of a video, you've got to rewind and do it over again.

54
00:04:50,533 --> 00:05:00,032
What I didn't realize is how hard it is to anticipate what you all are thinking, and try to put that into the video in the right way.

55
00:05:00,033 --> 00:05:05,399
When you're in class and I'm talking and things aren't going right, I can see the puzzled faces,

56
00:05:05,400 --> 00:05:11,466
and then I can back up and try something new. But with the videos, I don't have that immediate feedback.

57
00:05:11,467 --> 00:05:17,199
So I have to anticipate what could possibly go wrong, and try to get that all right the first time.

58
00:05:17,200 --> 00:05:23,566
And so it really leads to a little bit different material in terms of what you teach, and a very different approach

59
00:05:23,567 --> 00:05:29,866
in terms of the quiz questions that we came up with. And I think we were really breaking ground as we were going,

60
00:05:29,867 --> 00:05:34,632
trying to think of what are good mechanisms for coming up with good quiz questions?

61
00:05:34,633 --> 00:05:39,499
And I hope we did okay, and I know we can learn more and do a better job with it next time.

62
00:05:39,500 --> 00:05:47,266
(Sebastian) Yeah, I learned a good number of things. I learned that, I think the digital medium is a much more amenable tool

63
00:05:47,267 --> 00:05:57,266
to interaction than I thought. I got a lot of feedback that even though technically--I'm not really talking to you right now, personally--

64
00:05:57,267 --> 00:06:03,099
But we still got a lot of intimacy in the setting, by asking questions, and we got a lot of engagement

65
00:06:03,100 --> 00:06:08,032
by students solving problems. It was much better than, I think, the Stanford classroom,

66
00:06:08,033 --> 00:06:13,199
where I'm basically just lecturing students and they all get the skill of listening, but they don't get the skill of problem-solving.

67
00:06:13,200 --> 00:06:19,766
In fact, all my Stanford students have extensively watched our online videos, and they all say their experience

68
00:06:19,767 --> 00:06:25,499
is substantially better as a result. So I'm getting to the point of asking, "Why am I lecturing?"

69
00:06:25,500 --> 00:06:29,366
And I might just not lecture again in the same class at Stanford.

70
00:06:29,367 --> 00:06:37,732
The second thing I've learned is that while I'm kind of primed as a teacher to make really hard questions,

71
00:06:37,733 --> 00:06:43,999
and at Stanford we do this a lot, and it's frustrating for the students, I've learned this is much more about

72
00:06:44,000 --> 00:06:49,132
empowering the students, you guys, than showing what a smart question I can ask.

73
00:06:49,133 --> 00:06:55,199
So I've really focused on trying to get material together to make this experience as positive for all of you

74
00:06:55,200 --> 00:06:59,499
as I possibly could. And I'm not sure I succeeded, but I worked really hard.

75
00:06:59,500 --> 00:07:05,432
The final thing I've learned is I get about maybe one invitation per day to give a keynote at a conference,

76
00:07:05,433 --> 00:07:10,099
and I've said no to every single one of them since the class started. And the reason is,

77
00:07:10,100 --> 00:07:16,566
I can fly to India, I can fly to China, I can talk to maybe three, four (unintelligible) 2,000 people.

78
00:07:16,567 --> 00:07:25,766
But talking to 30,000 people is such an amazing (feast). I feel my personal time is much better spent making this class

79
00:07:25,767 --> 00:07:33,032
than pretty much anything I do right now. Possibly with the exception of changing a lot of transportation.

80
00:07:33,033 --> 00:07:37,232
It's been really amazing. I mean to some extent, we're sitting in front of a video camera right now,

81
00:07:37,233 --> 00:07:42,166
and we can't really see all of you. But then we're getting so many beautiful emails and so many beautiful questions

82
00:07:42,167 --> 00:07:46,332
on this forum that I can actually see everyone, and I'm going to try my best to respond to emails.

83
00:07:46,333 --> 00:07:51,766
I haven't responded to every single one of them. But I've often spent an hour or two a day just responding to email.

84
00:07:51,767 --> 00:08:00,766
And we try to respond to you through these questions. It's been really gratifying what kind of scale we can achieve with this new medium.

85
00:08:00,767 --> 00:08:07,899
(Peter) All right. Here's one from Andy in New York. "I made a bot with (Dred), Sonar and Bluetooth for $200

86
00:08:07,900 --> 00:08:15,166
"to do some mapping experiments, and Bluetooth allows processing on a P.C. Did not have laser rangefinders.

87
00:08:15,167 --> 00:08:18,332
"Can you suggest other inexpensive platforms for experimenting?"

88
00:08:18,333 --> 00:08:27,032
(Sebastian) Yeah, there's a company called Neato that does a vacuum cleaning robot, and they built

89
00:08:27,033 --> 00:08:34,566
an insanely cheap laser rangefinder. Rumors have it that the laser rangefinder is made for about $10 apiece.

90
00:08:34,567 --> 00:08:41,399
If you build a robot for $200, that's wonderful. I would love to see more insanely low-cost robots in the market

91
00:08:41,400 --> 00:08:45,632
that people can program and play with. There's Lego Mindstorm, there's a few other kits that people can use,

92
00:08:45,633 --> 00:08:50,599
and they generally tend to be out of people's price range. I think if you had platforms--

93
00:08:50,600 --> 00:08:55,866
In fact, if you had a platform that people could buy for very little money, I'd be much more enticed to teach a robotics class

94
00:08:55,867 --> 00:09:01,466
because I think (unintelligible) could be a really essential experience in robotics.

95
00:09:01,467 --> 00:09:05,666
So (unintelligible) question. Monica in San Francisco, California--hi, Monica, hi, San Francisco--

96
00:09:05,667 --> 00:09:11,932
says, "I've decided to take this class because I studied A.I. in college and used Peter Norvig's book at the time.

97
00:09:11,933 --> 00:09:17,232
"I've been beyond impressed with the enthusiasm and passion of the professors, and the quality of the content.

98
00:09:17,233 --> 00:09:22,132
"Thank you." Not a question. (Peter) You're welcome. That's the answer.

99
00:09:22,133 --> 00:09:28,999
(Sebastian) Garachi in Budapest. "This was definitely one of my best classes ever. I really enjoyed your big picture approach.

100
00:09:29,000 --> 00:09:33,799
"Now it is high time to get my hands dirty programming some of the concepts I've learned.

101
00:09:33,800 --> 00:09:40,299
"Well, after the exam period, that is, and of course, past the holidays, Christmas. Thanks for the awesome experience."

102
00:09:40,300 --> 00:09:44,766
(Peter) You're welcome, too. (Sebastian) Yeah, it's great. Do get your hands dirty. We really regret we didn't

103
00:09:44,767 --> 00:09:47,600
have a programming component, and it's going to happen in the future. (Peter) Yeah.
