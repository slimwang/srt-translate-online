1
00:00:00,400 --> 00:00:01,589
Alright, what do you think, Charles?

2
00:00:01,589 --> 00:00:03,940
>> Okay, so I think a couple of things. Let me

3
00:00:03,940 --> 00:00:07,850
just talk this out loud. So we're trying to learn incrementally.

4
00:00:07,850 --> 00:00:10,270
We're trying to figure out, how if we just kind of

5
00:00:10,270 --> 00:00:12,270
keep adding these random variables in a sort of way to

6
00:00:12,270 --> 00:00:15,050
what you described before what we would end up at. So

7
00:00:15,050 --> 00:00:19,300
why do we want to choose alpha t with a particular

8
00:00:19,300 --> 00:00:22,750
kind of property well if you look at it, it's clear

9
00:00:22,750 --> 00:00:25,410
that alpha t at each time step is moving closer and closer

10
00:00:25,410 --> 00:00:27,510
to zero. So it means you start out learning a

11
00:00:27,510 --> 00:00:30,150
lot and you sort of believe things less and less and

12
00:00:30,150 --> 00:00:32,670
less or you let things change you less and less and

13
00:00:32,670 --> 00:00:36,800
less over time. So what is that likely to end up

14
00:00:36,800 --> 00:00:38,870
at? Well the first thing I notice that well if

15
00:00:38,870 --> 00:00:42,220
it's going to do that then it has to converge. Some

16
00:00:42,220 --> 00:00:45,680
point. It just makes sense. So I, that helps me to

17
00:00:45,680 --> 00:00:50,630
eliminate the second answer. But actually, that also lets me eliminate

18
00:00:50,630 --> 00:00:54,660
the fourth answer because in some ways they, that says the same thing.

19
00:00:54,660 --> 00:00:59,200
So that leaves us with the expected value of x and the expected value

20
00:00:59,200 --> 00:01:02,750
of x squared. For the expected value of x squared. Whichever one it is

21
00:01:02,750 --> 00:01:07,660
that is variance. Okay so, I'm going to go with, the expected value of x.

22
00:01:07,660 --> 00:01:11,230
>> So, the expected value of x, right. So, so it turns out that this

23
00:01:11,230 --> 00:01:13,510
is actually a wave computing the average

24
00:01:13,510 --> 00:01:15,790
by just, you know, repeatedly sampling and updating

25
00:01:15,790 --> 00:01:17,410
your values. And, and the way to think about it,

26
00:01:17,410 --> 00:01:20,370
is that sometimes the x values that we draw are going

27
00:01:20,370 --> 00:01:22,530
to be a bit above the average, and it's going to

28
00:01:22,530 --> 00:01:25,200
pull the v value up. Sometimes it's a little bit below

29
00:01:25,200 --> 00:01:27,310
the average, and it's going to pull the value down.

30
00:01:27,310 --> 00:01:30,430
But in the limit, all those pulls and pushes are going

31
00:01:30,430 --> 00:01:33,060
to cancel out, and it's going to settle in on the

32
00:01:33,060 --> 00:01:36,730
actual average value or the expected value of this random variable.

33
00:01:36,730 --> 00:01:38,700
>> Right, because in principle, you're going

34
00:01:38,700 --> 00:01:41,060
to see an infinite number of those things.

35
00:01:41,060 --> 00:01:43,550
And effectively all you are doing is adding them all up, and sort

36
00:01:43,550 --> 00:01:47,300
of, you know. Well you're effectively averaging them one little bit at a time.

37
00:01:47,300 --> 00:01:48,660
>> Yeah, that's a good thing about it, that

38
00:01:48,660 --> 00:01:50,960
in fact it's adding them up and it's computing

39
00:01:50,960 --> 00:01:54,810
a weighted average, but the weights are these alpha's

40
00:01:54,810 --> 00:01:56,540
and the weights are decaying over time so we're

41
00:01:56,540 --> 00:01:58,460
going to put more weight on the more recent

42
00:01:58,460 --> 00:02:00,280
ones, but some more weight on the further away

43
00:02:00,280 --> 00:02:02,960
ones but it sort of doesn't matter because the

44
00:02:02,960 --> 00:02:06,240
order, since we're drawing this iid, the order doesn't

45
00:02:06,240 --> 00:02:08,520
matter and the thing that has to converge to is the mean.

46
00:02:08,520 --> 00:02:10,008
>> Right. I like it.

47
00:02:10,008 --> 00:02:14,234
>> So let's relate that back to what we do in Q-learning.
