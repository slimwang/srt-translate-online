1
00:00:00,340 --> 00:00:02,490
>> Alright. So is this, is it clear what these answers are?

2
00:00:02,490 --> 00:00:06,780
>> Let's find out. So, let's see. we, we already worked out

3
00:00:06,780 --> 00:00:10,262
the math on this. So we know that, for gamma, greater than

4
00:00:10,262 --> 00:00:14,110
1 6th, cooperating is better than defecting, in general. So if I'm

5
00:00:14,110 --> 00:00:15,450
going against someone who's always going to

6
00:00:15,450 --> 00:00:17,610
cooperate, then I should always cooperate.

7
00:00:17,610 --> 00:00:18,660
>> Incorrect.

8
00:00:18,660 --> 00:00:20,000
>> What?

9
00:00:20,000 --> 00:00:23,240
>> Yes, so, so, we didn't actually work that out. What we worked

10
00:00:23,240 --> 00:00:25,680
out was what to do if you were playing against tit for tat.

11
00:00:25,680 --> 00:00:26,990
If you were playing against someone who was

12
00:00:26,990 --> 00:00:29,190
always cooperating, and is completely oblivious to us.

13
00:00:29,190 --> 00:00:30,680
>> No, no, no, no, no, you're right. You should

14
00:00:30,680 --> 00:00:33,620
always defect because you're always going to win. Yes, yes, yes.

15
00:00:33,620 --> 00:00:36,040
>> You're always going to win. You're going to get zero on every time step.

16
00:00:36,040 --> 00:00:37,350
>> Right, right.

17
00:00:37,350 --> 00:00:37,980
>> Yeah.

18
00:00:37,980 --> 00:00:39,870
>> No, that makes sense. That's beautiful.

19
00:00:39,870 --> 00:00:41,830
>> Alright, what about always defect?

20
00:00:41,830 --> 00:00:45,080
>> Well, if you're always going to defect, you might as well defect.

21
00:00:45,080 --> 00:00:45,580
>> Indeed.

22
00:00:45,580 --> 00:00:50,360
>> because we're just in the regular old prisoner's dilemma world. [LAUGH]

23
00:00:50,360 --> 00:00:50,650
>> good,

24
00:00:50,650 --> 00:00:55,100
alright. So now we, now we have this, this other strange beast here.

25
00:00:55,100 --> 00:00:58,700
So our opponent is playing tit for tat. So we could always defect.

26
00:00:58,700 --> 00:00:59,210
>> Right.

27
00:00:59,210 --> 00:01:01,150
>> But we would do, we'd get a higher score

28
00:01:01,150 --> 00:01:03,390
if we can convince tit for tat to cooperate with us.

29
00:01:03,390 --> 00:01:05,360
>> For a gamma greater than a 6th.

30
00:01:05,360 --> 00:01:06,180
>> That's right.

31
00:01:06,180 --> 00:01:07,790
>> So that you should always cooperate.

32
00:01:07,790 --> 00:01:09,730
>> That is true, however.

33
00:01:09,730 --> 00:01:11,080
>> Mm-hm.

34
00:01:11,080 --> 00:01:13,485
>> What if we played tit for tat against tit for tat.

35
00:01:13,485 --> 00:01:15,230
>> You'll end up in the same place.

36
00:01:15,230 --> 00:01:16,130
>> Yeah,

37
00:01:16,130 --> 00:01:17,160
so that's just as good.

38
00:01:17,160 --> 00:01:18,055
>> Mm-hm.

39
00:01:18,055 --> 00:01:19,430
>> And that's, that's kind of interesting.

40
00:01:19,430 --> 00:01:23,748
If you think about mutual best responses.

41
00:01:23,748 --> 00:01:24,510
>> Yes.

42
00:01:24,510 --> 00:01:29,300
>> So that's a strategy that, a pair of strategies where each is a best

43
00:01:29,300 --> 00:01:31,000
response to the other, there's a, we

44
00:01:31,000 --> 00:01:32,370
have another name for that. Do you remember?

45
00:01:32,370 --> 00:01:33,040
>> No.

46
00:01:33,040 --> 00:01:36,400
>> [LAUGH] You taught, you told us what it was.

47
00:01:36,400 --> 00:01:38,100
>> Yeah, but I probably used different words.

48
00:01:38,100 --> 00:01:39,440
>> It's, it's a Nash equilibrium.

49
00:01:39,440 --> 00:01:39,580
>> Oh.

50
00:01:39,580 --> 00:01:41,170
>> This, that's what a Nash equilibrium is. A pair

51
00:01:41,170 --> 00:01:44,860
of strategies where each is a best response to the other. Each, ea there's

52
00:01:44,860 --> 00:01:47,220
no way that either would prefer to

53
00:01:47,220 --> 00:01:49,020
switch to something else to get higher reward.

54
00:01:49,020 --> 00:01:50,420
>> And that makes perfect sense. You're in

55
00:01:50,420 --> 00:01:53,420
an equilibrium. And that is a Nash equilibrium. Okay.

56
00:01:53,420 --> 00:01:55,550
>> So we can use this little table here

57
00:01:55,550 --> 00:01:58,870
to actually identify Nash equilibrium. So, what would a

58
00:01:58,870 --> 00:02:02,140
strategy be? So, so if one player plays always

59
00:02:02,140 --> 00:02:05,230
cooperate, then the best response to that is always defect.

60
00:02:05,230 --> 00:02:07,073
>> Mm-hm.

61
00:02:07,073 --> 00:02:09,270
>> But the best response to always defect, is always

62
00:02:09,270 --> 00:02:12,250
defect. So always cooperate is not part of a Nash equilibrium.

63
00:02:12,250 --> 00:02:12,690
>> Right.

64
00:02:12,690 --> 00:02:15,330
>> But what about always defect versus always defect?

65
00:02:15,330 --> 00:02:16,600
>> No, it is.

66
00:02:16,600 --> 00:02:17,530
>> So that's a Nash. Right?

67
00:02:17,530 --> 00:02:17,630
>> Yep.

68
00:02:17,630 --> 00:02:19,670
>> Because they're both doing the thing

69
00:02:19,670 --> 00:02:21,070
that is the best response to the other.

70
00:02:21,070 --> 00:02:21,600
>> Right.

71
00:02:21,600 --> 00:02:24,110
>> Alright, this box here, always cooperate

72
00:02:24,110 --> 00:02:26,140
against tit for tat. That's not okay,

73
00:02:26,140 --> 00:02:29,280
because if a player does always cooperate,

74
00:02:29,280 --> 00:02:31,110
it's always better to switch to always defect.

75
00:02:31,110 --> 00:02:31,300
>> Yep.

76
00:02:31,300 --> 00:02:32,890
>> But,

77
00:02:32,890 --> 00:02:36,250
check this out. If you are playing tit for tat,

78
00:02:36,250 --> 00:02:38,540
and the other player's playing tit for tat, there's no reason

79
00:02:38,540 --> 00:02:40,860
to switch because it's actually a best response, it's the

80
00:02:40,860 --> 00:02:43,900
optimal thing to do. And that works from both players' perspectives.

81
00:02:43,900 --> 00:02:47,070
>> And that makes sense. So like you said check this

82
00:02:47,070 --> 00:02:49,060
out and you've been using check marks that's very good. [LAUGH].

83
00:02:49,060 --> 00:02:52,630
>> So we're in this situation where we have two Nash equilibria.

84
00:02:52,630 --> 00:02:55,528
>> Indeed, and one of these Nash equilibria, [NOISE]

85
00:02:55,528 --> 00:02:57,920
is cooperative. Which is the thing that we were

86
00:02:57,920 --> 00:02:59,820
sad about, or at least that I was feeling really sad

87
00:02:59,820 --> 00:03:02,880
about, in the, in the last lesson. The idea that, man,

88
00:03:02,880 --> 00:03:05,060
there's just, it's clear that they should just try to get

89
00:03:05,060 --> 00:03:08,560
along. You explained that you can modify the reward structure, and

90
00:03:08,560 --> 00:03:12,590
then they would get along better. But here it turns out,

91
00:03:12,590 --> 00:03:14,680
well, no, another thing you can do is just open it

92
00:03:14,680 --> 00:03:18,550
up to the possibility of playing multiple rounds, as long as

93
00:03:18,550 --> 00:03:23,420
you don't know how many rounds, it becomes possible to to

94
00:03:23,420 --> 00:03:27,800
have a strategy that is best off cooperating, and is in fact a Nash Equilibrium.

95
00:03:27,800 --> 00:03:29,990
>> Isn't that equivalent to changing the reward structure?

96
00:03:29,990 --> 00:03:32,240
>> It's definitely related to changing the reward

97
00:03:32,240 --> 00:03:34,000
structure. It's a particular way of changing it.

98
00:03:34,000 --> 00:03:34,830
>> A very particular way.

99
00:03:34,830 --> 00:03:38,030
>> But it's. Yeah, because it's not true any more that we can do this

100
00:03:38,030 --> 00:03:41,700
in the one shot case. You have to be in the, in the repeated game, setting.

101
00:03:41,700 --> 00:03:44,630
>> Right, so you change your rewards structure to be a sum of

102
00:03:44,630 --> 00:03:48,710
rewards. But it's actually an expected sum of rewards, and you don't know

103
00:03:48,710 --> 00:03:53,280
where it is you're going to stop. So I guess you're changed, you're changed

104
00:03:53,280 --> 00:03:57,110
the game, you changed the, the rewards. But in a, sort of very subtle way.

105
00:03:57,110 --> 00:03:59,010
>> Yeah, the whole game is different, really.

106
00:03:59,010 --> 00:04:01,950
>> Yeah man, you changed the game. [LAUGH].

107
00:04:01,950 --> 00:04:04,090
>> Sometimes you gotta change the game. Don't hate the game.

108
00:04:04,090 --> 00:04:05,580
>> No, you are supposed to hate the

109
00:04:05,580 --> 00:04:07,250
game. Don't hate the player, hate the game.
