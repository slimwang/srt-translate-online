1
00:00:00,180 --> 00:00:03,460
Now that we've got a sense of our
critical questions and that they've

2
00:00:03,460 --> 00:00:07,170
all been answered, we need to consider
how many times they've been answered.

3
00:00:08,250 --> 00:00:12,840
How many users do we need to test with
to feel confident in our results?

4
00:00:12,840 --> 00:00:13,410
Luckily for

5
00:00:13,410 --> 00:00:17,240
us, it turns out that we really only
need a few people to get good data.

6
00:00:18,300 --> 00:00:21,390
Each prototype should be
shown to three to five users,

7
00:00:21,390 --> 00:00:23,440
in order to catch most of
the issues in the design.

8
00:00:23,440 --> 00:00:28,010
One of the most fascinating articles
in user research by Jakob Nielsen,

9
00:00:28,010 --> 00:00:32,119
shows that on average a study of 3 users
will find upwards of 60% of the issues

10
00:00:32,119 --> 00:00:33,950
with your prototype.

11
00:00:33,950 --> 00:00:39,490
A study of 5 users will average
upwards of 75% of the issues.

12
00:00:39,490 --> 00:00:43,040
In either case, that's enough to get
a sense of how the prototype did, and

13
00:00:43,040 --> 00:00:46,370
further research gives
vastly diminishing returns.

14
00:00:46,370 --> 00:00:50,080
The art of prototyping is
not the art of extensive QA.

15
00:00:50,080 --> 00:00:52,630
It is a waste of time to find 100% of

16
00:00:52,630 --> 00:00:56,460
the issues in an app design
that you plan on throwing out.

17
00:00:56,460 --> 00:00:59,900
When you have three to five users
being asked the same questions,

18
00:00:59,900 --> 00:01:01,770
you start to see trends.

19
00:01:01,770 --> 00:01:06,260
User B will probably find some
of the same flaws as user A, and

20
00:01:06,260 --> 00:01:08,370
these flaws should be
counted as more glaring.

21
00:01:09,470 --> 00:01:12,580
When you're thinking about how to
weigh data from various users,

22
00:01:12,580 --> 00:01:15,980
it's useful to go back to how
critical the question was.

23
00:01:15,980 --> 00:01:18,110
If a critical part of
the app is going wrong for

24
00:01:18,110 --> 00:01:20,810
multiple users, you have a problem.

25
00:01:20,810 --> 00:01:23,930
When you're thinking about how to
weigh data from various users,

26
00:01:23,930 --> 00:01:27,240
it's useful to go back to
how critical a question was.

27
00:01:27,240 --> 00:01:29,450
If a critical part of
the app is going wrong for

28
00:01:29,450 --> 00:01:32,400
multiple users, you have a problem.

29
00:01:32,400 --> 00:01:35,710
If a less critical part of the app
is going wrong for multiple users,

30
00:01:35,710 --> 00:01:40,590
you're probably still fine and can iron
that out in meeting fidelity prototypes.

31
00:01:41,770 --> 00:01:46,140
So, for our app, we'll want to bucket
feedback from all of our users.

32
00:01:46,140 --> 00:01:48,630
In to some style of yes or
no by question.

33
00:01:49,660 --> 00:01:52,930
That will allow us to actually make
a decision about our app moving forward.

34
00:01:54,070 --> 00:01:57,820
You'll note that we've only done
research with two users for our study.

35
00:01:57,820 --> 00:02:00,450
That's because when we
include your user testing,

36
00:02:00,450 --> 00:02:02,710
we'll have a full study of three users.

37
00:02:02,710 --> 00:02:07,030
In the next node, we'll decide whether
to make another Lo-Fi prototype, or

38
00:02:07,030 --> 00:02:09,210
whether to move on to
a medium fidelity one.
