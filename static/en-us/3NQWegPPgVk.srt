1
00:00:00,580 --> 00:00:04,180
We just saw an example where visual spatial knowledge by itself,

2
00:00:04,180 --> 00:00:07,630
suffices too in our logical reasoning under certain conditions.

3
00:00:07,630 --> 00:00:12,050
Now let us look at a different problem. There suddenly are situations where we

4
00:00:12,050 --> 00:00:16,470
might want AI agents to be able to extract [UNKNOWN] presentations.

5
00:00:16,470 --> 00:00:20,423
Your projects one, two, and three did exactly that. One task,

6
00:00:20,423 --> 00:00:24,926
where AI agent might want build proper [INAUDIBLE] representations out of

7
00:00:24,926 --> 00:00:30,055
regional spatial knowledge is when an AI is given a design drawing. So

8
00:00:30,055 --> 00:00:34,340
here is a vector graphics drawing of a simple engineering system.

9
00:00:34,340 --> 00:00:38,490
Perhaps some of you can recognize what is happening here. This is a cylinder and

10
00:00:38,490 --> 00:00:43,550
this a piston. This is the rod of the piston. The piston moves. Left and

11
00:00:43,550 --> 00:00:48,740
right. The other end of the rod is connected to a crankshaft.

12
00:00:48,740 --> 00:00:52,830
As this piston moves left and right, this particular crankshaft starts moving

13
00:00:52,830 --> 00:00:58,430
anticlockwise. This device translates linear motion into rotational motion.

14
00:00:58,430 --> 00:01:02,178
I just gave you a causal account. Although because [INAUDIBLE] only implicit in

15
00:01:02,178 --> 00:01:06,940
this [INAUDIBLE] spatial knowledge. You and I were able to extract a causal

16
00:01:06,940 --> 00:01:12,220
account out of this. How did we do it? How can we help AI agents do it?

17
00:01:13,390 --> 00:01:18,650
At present if you were to make a CAD drawing using any CAD tool that you want,

18
00:01:18,650 --> 00:01:23,410
the machine does not understand the drawing. But can machines of tomorrow

19
00:01:23,410 --> 00:01:28,690
understand drawings by automatically building these causal models out of them?

20
00:01:28,690 --> 00:01:32,610
Put it another way. There is a story that has been captured in this particular

21
00:01:32,610 --> 00:01:39,450
diagram. Can a machine automatically extract the story from this diagram?

22
00:01:39,450 --> 00:01:44,630
In 2007, Patrick Yaner built an AI program called Archytas. Archytas was

23
00:01:44,630 --> 00:01:48,520
able to extract causal models out of vector graphics drawings of the kind that I

24
00:01:48,520 --> 00:01:51,910
just showed you. This figure is coming from paper and Archytas and

25
00:01:51,910 --> 00:01:56,350
hence the form of the figure. We'll have a pointer to the paper in the notes.

26
00:01:56,350 --> 00:02:02,570
This is how Archytas works. It began with a library of source drawings.

27
00:02:02,570 --> 00:02:06,880
These were drawings that we already knew about. For each drawing order it

28
00:02:06,880 --> 00:02:10,830
knew about it already had done the segmentation. The basic shapes for

29
00:02:10,830 --> 00:02:15,520
example might be things like circles and the composite shapes which were then

30
00:02:15,520 --> 00:02:20,360
labeled like piston and cylinder. Then a behavioral model or

31
00:02:20,360 --> 00:02:24,310
a causal model which said what happens when the piston moves in and

32
00:02:24,310 --> 00:02:29,201
out, namely the crankshaft turns. And then a functional specification we've said

33
00:02:29,201 --> 00:02:33,170
this particular system can work in linear motion into rotational motion. So

34
00:02:33,170 --> 00:02:38,740
there was a lot of knowledge with each previous drawing that Archytas already

35
00:02:38,740 --> 00:02:43,610
had seen. All of this knowledge was put into a library. When a new drawing was

36
00:02:43,610 --> 00:02:47,400
input into Archytas then it generated line segments and arcs and

37
00:02:47,400 --> 00:02:52,480
intersections from it. And then, it started mapping them to the lines and

38
00:02:52,480 --> 00:02:55,300
segments and arcs of previously known drawings.

39
00:02:56,320 --> 00:03:01,350
Retrieve the drawing that was the closest match in drawing to the new drawing.

40
00:03:01,350 --> 00:03:05,120
And then started transferring basic shapes, and then composite shapes, and

41
00:03:05,120 --> 00:03:09,920
it transferred each element through this abstraction hierarchy all the way up to

42
00:03:09,920 --> 00:03:15,201
the functional level. As an example, if Archytas library contains piston and

43
00:03:15,201 --> 00:03:18,570
crankshaft drawings like this along with causal functional models for

44
00:03:18,570 --> 00:03:22,420
them, then given a new drawing of a piston and

45
00:03:22,420 --> 00:03:26,400
crankshaft device Archytas will then be able to assemble a causal

46
00:03:26,400 --> 00:03:31,207
functional model for the new drawing. Thus Archytas extracted causal

47
00:03:31,207 --> 00:03:34,400
information from which spatial presentations to analogical reasoning.
