1
00:00:00,295 --> 00:00:08,080
Ben wants to implement a smoothing operation on a 4096 element one-dimensional array

2
00:00:08,080 --> 00:00:14,884
This array is indexed by i and the value at each index is V [ i ].

3
00:00:14,884 --> 00:00:32,502
The smoothing operation on element i = 0.25 x V [i - 1] + 0.5 x V [ i ] + 0.25 x V [ i + 1].

4
00:00:32,502 --> 00:00:33,911
And a quick note.

5
00:00:33,911 --> 00:00:37,136
At the boundary, assume that all values beyond the boundary

6
00:00:37,136 --> 00:00:48,417
like V [-1] or V [4096] are equal to the value at that boundary, V [0] or V [4095].

7
00:00:48,417 --> 00:00:54,811
The new values, Vnew [ i ] at each step can be computed in parallel.

8
00:00:54,811 --> 00:00:58,756
Then Vnew becomes V, and we continue.

9
00:00:58,756 --> 00:01:01,454
Ben wants to implement this in CUDA.

10
00:01:01,454 --> 00:01:12,062
He wants to launch 4096 threads to solve this problem, and he decides to launch 16 blocks of 256 threads each.

11
00:01:12,062 --> 00:01:14,271
And here is Ben's code.

12
00:01:14,271 --> 00:01:19,039
Ben says his code works but is running much slower than he would like.

13
00:01:19,039 --> 00:01:22,137
So rewrite Ben's code to increase the speed.

14
00:01:22,137 --> 00:01:26,810
In particular, can you reduce the number of global memory transfers?
