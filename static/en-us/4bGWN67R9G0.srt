1
00:00:00,000 --> 00:00:05,000
Now obviously you can answer this question without understanding anything about regression.

2
00:00:05,000 --> 00:00:10,000
But what you find is this is different from classification as before.

3
00:00:10,000 --> 00:00:13,000
This is not a binary concept anymore of like expensive and cheap.

4
00:00:13,000 --> 00:00:17,000
It really is a relationship between two variables.

5
00:00:17,000 --> 00:00:20,000
One you care about--the house price, and one that you can observe,

6
00:00:20,000 --> 00:00:23,000
which is the house size in square feet.

7
00:00:23,000 --> 00:00:28,000
And your goal is to fit a curve that best explains the data.

8
00:00:28,000 --> 00:00:31,000
Once again, we have a case where we can play Occam's razor.

9
00:00:31,000 --> 00:00:35,000
There clearly is a data fit that is not linear that might be better,

10
00:00:35,000 --> 00:00:37,000
like this one over here.

11
00:00:37,000 --> 00:00:40,000
And when you go to high non-linear curves,

12
00:00:40,000 --> 00:00:44,000
you might even be inclined to draw a curve like this.

13
00:00:44,000 --> 00:00:49,000
Now of course the curve I'm drawing right now is likely an overfit.

14
00:00:49,000 --> 00:00:54,000
And you don't want to postulate that this is the general relationship

15
00:00:54,000 --> 00:00:57,000
between the size of a house and the sales price.

16
00:00:57,000 --> 00:01:01,000
So even though my black curve might describe the data better,

17
00:01:01,000 --> 00:01:08,000
the blue curve or the dashed linear curve over here might be a better explanation overture of Occam's razor.

18
00:01:08,000 --> 00:01:15,000
So let's look a little bit deeper into what we call regression.

19
00:01:15,000 --> 00:01:19,000
As in all regression problems, our data will be comprised of

20
00:01:19,000 --> 00:01:25,000
input vectors of length N that map to another continuous value.

21
00:01:25,000 --> 00:01:30,000
And we might be given a total of M data points.

22
00:01:30,000 --> 00:01:36,000
This is from the classification case, except this time the Ys are continuous.

23
00:01:36,000 --> 00:01:44,000
Once again, we're looking for function f that maps our vector x into y.

24
00:01:44,000 --> 00:01:54,000
In linear regression, the function has a particular form which is W1 times X plus W0.

25
00:01:54,000 --> 00:01:59,000
In this case X is one dimensional which is N = 1.

26
00:01:59,000 --> 00:02:07,000
Or in the high-dimensional space, we might just write W times X plus W0,

27
00:02:07,000 --> 00:02:12,000
where W is a vector and X is a vector.

28
00:02:12,000 --> 00:02:16,000
And this is the inner product of these 2 vectors over here.

29
00:02:16,000 --> 00:02:20,000
Let's for now just consider the one-dimensional case.

30
00:02:20,000 --> 00:02:27,000
In this quiz, I've given you a linear regression form with 2 unknown parameters, W1 and W0.

31
00:02:27,000 --> 00:02:30,000
I've given you a data set.

32
00:02:30,000 --> 00:02:36,000
And this data set happens to be fittable by a linear regression model without any residual error.

33
00:02:36,000 --> 99:59:59,999
Without any math, can you look at this and find out to me what the 2 parameters, W0 and W1 are?
