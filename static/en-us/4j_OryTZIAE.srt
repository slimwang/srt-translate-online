1
00:00:07,840 --> 00:00:09,870
>> I think most of us would give the same answer.

2
00:00:09,870 --> 00:00:13,680
The pitcher, not the backpack or the car or this box. Now for humans, for

3
00:00:13,680 --> 00:00:15,760
you and me, this is a little bit of an easy problem.

4
00:00:15,760 --> 00:00:19,230
All of us get it right pretty much all the time. And what about a machine?

5
00:00:19,230 --> 00:00:24,200
What about a robot? How would a robot decide that a pitcher is a good utensil to

6
00:00:24,200 --> 00:00:27,200
use for transporting soup from the kitchen to the dining table, but

7
00:00:27,200 --> 00:00:32,540
not a backpack and not a box? For a robot, this is a surprisingly hard problem.

8
00:00:32,540 --> 00:00:36,280
So the question then becomes, well, what is it that makes it easy for humans and

9
00:00:36,280 --> 00:00:40,480
hard for robots? How can we program AI agents so that it would be easy for

10
00:00:40,480 --> 00:00:45,250
them as well? One important thing to note here, this is another example of

11
00:00:45,250 --> 00:00:49,130
incremental learning. Now we have come across incremental learning earlier,

12
00:00:49,130 --> 00:00:51,870
when we were talking about incremental concept learning.

13
00:00:51,870 --> 00:00:56,580
There we were given one example at a time, that was the example of art, and

14
00:00:56,580 --> 00:01:01,010
we were learning one concept, the concept of art. This is in contrast to other

15
00:01:01,010 --> 00:01:05,269
methods of machine learning. Where one is given a, large amount of data, and

16
00:01:05,269 --> 00:01:09,280
one has to detect patterns with a variety in that data. Here,

17
00:01:09,280 --> 00:01:14,040
there is learning occurring one step at a time, from a small number of examples,

18
00:01:14,040 --> 00:01:17,720
one single concept has been learned. We also came across the notion of

19
00:01:17,720 --> 00:01:21,320
incremental learning, when we were talking about chunking. Day two,

20
00:01:21,320 --> 00:01:25,679
there was one particular problem, and from a small number of previous episodes,

21
00:01:25,679 --> 00:01:30,430
we chunked a particular rule. This notion of incremental learning, for

22
00:01:30,430 --> 00:01:35,336
me it's much of knowledge based AI. Another thing to note here, this notion or

23
00:01:35,336 --> 00:01:38,980
expression based learning is related to creativity.

24
00:01:38,980 --> 00:01:42,886
We talked earlier about the relationship between creativity and novelty.

25
00:01:42,886 --> 00:01:47,350
Here is an example in which an AI agent is dealing with a novel situation.

26
00:01:47,350 --> 00:01:49,930
Usual utensils for taking soup from the kitchen to

27
00:01:49,930 --> 00:01:53,080
the dining table are not available. What should the robot do?

28
00:01:53,080 --> 00:01:57,650
The robot comes up with a creative solution of taking the pitcher as the utensil
