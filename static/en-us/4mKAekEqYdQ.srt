1
00:00:00,420 --> 00:00:03,160
So, to summarize the Spinlock algorithm that we've seen

2
00:00:03,160 --> 00:00:06,350
so far, we saw that the read spin on

3
00:00:06,350 --> 00:00:11,450
read and spin on test and set and spin on test and set with a delay. All of

4
00:00:11,450 --> 00:00:15,460
these spin algorithms, there's no fairness associated with them.

5
00:00:16,510 --> 00:00:19,450
And if you think about the ticket lock algorithm,

6
00:00:19,450 --> 00:00:25,900
it is fair but it is noisy. So, all of them are not quite there yet in terms of

7
00:00:25,900 --> 00:00:31,150
our twin objectives of reducing latency and reducing

8
00:00:31,150 --> 00:00:34,452
contention and if you think about it, let's

9
00:00:34,452 --> 00:00:36,300
say that you know, that currently this T1

10
00:00:36,300 --> 00:00:39,540
has got this lock. And all of these guys

11
00:00:39,540 --> 00:00:41,340
are waiting for this lock to get released.

12
00:00:42,370 --> 00:00:46,130
You know when T1 releases the lock, exactly one

13
00:00:46,130 --> 00:00:51,380
of them is going to get it. Why should all of them be attempting to see if they,

14
00:00:51,380 --> 00:00:54,910
they've got the lock. Ideally, what we would

15
00:00:54,910 --> 00:00:59,480
want is that when T1 releases a lock.

16
00:00:59,480 --> 00:01:01,880
Exactly one guy, one of these white reading

17
00:01:01,880 --> 00:01:05,400
guys is, is a signal to indicate that

18
00:01:05,400 --> 00:01:08,480
you've got the lock. Because exactly one guys

19
00:01:08,480 --> 00:01:10,700
can, can get the lock to start with.

20
00:01:10,700 --> 00:01:14,170
And therefore, ideally T1 should signal exactly on

21
00:01:14,170 --> 00:01:16,270
the next thread and not all of them.

22
00:01:16,270 --> 00:01:20,650
Now, this is the idea. Behind, queueing locks that you're going to see next.
