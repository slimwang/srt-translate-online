1
00:00:00,030 --> 00:00:04,355
The next optimization technique in Stratton's taxonomy is called privatization.

2
00:00:04,355 --> 00:00:08,518
So where tiling exploited the fact that multiple threads are reading from the

3
00:00:08,518 --> 00:00:13,797
same memory locations, thread sharing input is good, privatization helps avoid

4
00:00:13,797 --> 00:00:16,729
having multiple threads write to the same output locations.

5
00:00:16,729 --> 00:00:21,878
So privatization takes some output data shared by multiple threads and duplicates it,

6
00:00:21,878 --> 00:00:25,636
so that different parallel threads can operate in their own private copy.

7
00:00:25,636 --> 00:00:30,407
The private copies are eventually merged together to recreate the result that would of been

8
00:00:30,407 --> 00:00:33,714
produced in the share data used by all the threads before privatization.

9
00:00:33,714 --> 00:00:36,397
So histogram makes a good example.

10
00:00:36,397 --> 00:00:39,262
As you've learned from our previous discussions and problem sets on histogram,

11
00:00:39,262 --> 00:00:41,438
there's a bunch of ways that you can approach the problem.

12
00:00:41,438 --> 00:00:44,077
In particular, you can program the kernel to have each

13
00:00:44,077 --> 00:00:47,927
thread keep its own local histogram as it looked at a bunch of pixels,

14
00:00:47,927 --> 00:00:52,315
and then use atomics or a global reduce operation to combine the buckets from the

15
00:00:52,315 --> 00:00:55,381
histograms from all the threads into one set of shared results.

16
00:00:55,381 --> 00:00:57,908
You can also apply this idea hierarchically.

17
00:00:57,908 --> 00:01:02,259
For example, you can have each thread block compute a combined histogram in shared memory,

18
00:01:02,259 --> 00:01:05,177
and then have other thread blocks do the same,

19
00:01:05,177 --> 00:01:09,744
and then accumulate the results into a single global histogram.

20
00:01:09,744 --> 00:01:13,725
So in this example we would have per-thread privatized histograms,

21
00:01:13,725 --> 00:01:16,754
and per-block privatized histograms.

22
00:01:16,754 --> 00:01:19,343
Now in practice, the GPU has so many threads that

23
00:01:19,343 --> 00:01:22,096
you don't want each one to have a huge private data structure.

24
00:01:22,096 --> 00:01:25,654
So this approach might work well for a small histogram-- say 5 or 10 buckets--

25
00:01:25,654 --> 00:01:30,185
but you would probably skip the per-thread privatized copies for a histogram with hundreds of buckets,

26
00:01:30,185 --> 00:01:33,616
and just do the local version per block.
