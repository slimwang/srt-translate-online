1
00:00:00,120 --> 00:00:02,650
So I think there's one more class

2
00:00:02,650 --> 00:00:04,520
of problems that we didn't
really get a chance get.

3
00:00:04,520 --> 00:00:07,520
There are tons by the way just
to be clear, algorithms and

4
00:00:07,520 --> 00:00:10,070
representation that we
didn't really get into.

5
00:00:10,070 --> 00:00:13,907
A lot of them actually coming out of
big data like k-d trees for example.

6
00:00:13,907 --> 00:00:17,162
But there's a whole class of problems
we didn't really discuss that's

7
00:00:17,162 --> 00:00:18,970
actually quite important.

8
00:00:18,970 --> 00:00:22,390
And that's because it reveals one
of the assumptions that we've had.

9
00:00:22,390 --> 00:00:28,230
I'm going to call them
the assumption of balanced labels.

10
00:00:28,230 --> 00:00:29,190
>> Balanced labels.

11
00:00:29,190 --> 00:00:32,119
>> Yeah, which is related to
cost-sensitive learning and

12
00:00:32,119 --> 00:00:33,455
a variety of other things.

13
00:00:33,455 --> 00:00:36,972
So implicit in a lot of the work that
we talked about was this idea that

14
00:00:36,972 --> 00:00:40,552
if you're a big data set, about half
of them are labeled negative and

15
00:00:40,552 --> 00:00:42,734
about half of them are labeled positive.

16
00:00:42,734 --> 00:00:43,910
>> Sure.
>> Right?

17
00:00:43,910 --> 00:00:47,150
But in practice,
the world doesn't work that way, and

18
00:00:47,150 --> 00:00:50,010
you have to actually
take that into account.

19
00:00:50,010 --> 00:00:50,943
>> So, what would be an example?

20
00:00:50,943 --> 00:00:51,919
>> So, here's my favorite example.

21
00:00:51,919 --> 00:00:54,073
So imagine you have a camera.

22
00:00:54,073 --> 00:00:55,441
>> [LAUGH]
>> Close your eyes.

23
00:00:55,441 --> 00:00:57,948
Now imagine you have a camera, and

24
00:00:57,948 --> 00:01:02,470
let's say that it's in an airport,
like we are now.

25
00:01:02,470 --> 00:01:05,918
And people are going through constantly
and in fact, you're in Atlanta Airport,

26
00:01:05,918 --> 00:01:09,269
which is the world's busiest airport,
and there are cameras constantly taking

27
00:01:09,269 --> 00:01:12,480
pictures of you, and there are, and
we're trying to find terrorists.

28
00:01:12,480 --> 00:01:15,750
So we're taking pictures of people,
and of their faces say, and

29
00:01:15,750 --> 00:01:17,170
maybe what they're wearing, and

30
00:01:17,170 --> 00:01:19,828
we just want to label which ones
are terrorists and which ones aren't.

31
00:01:19,828 --> 00:01:23,430
Well the vast majority of
people are not terrorists,

32
00:01:23,430 --> 00:01:26,170
we hope,
even the ones going through airports.

33
00:01:26,170 --> 00:01:30,370
And so let's say 99% of
the people that come through,

34
00:01:30,370 --> 00:01:34,610
you would label negative, and
less than 1% you would label positive.

35
00:01:34,610 --> 00:01:36,260
Does that make sense as a problem?

36
00:01:36,260 --> 00:01:37,900
>> Yeah, though I'm thinking
about this issue about

37
00:01:37,900 --> 00:01:39,920
most people aren't terrorists.

38
00:01:39,920 --> 00:01:40,490
Like I feel like.

39
00:01:40,490 --> 00:01:42,050
>> That most people are?

40
00:01:42,050 --> 00:01:44,323
>> Are there really any non-terrorists,
or

41
00:01:44,323 --> 00:01:47,869
are we all just terrorists who
just haven't gotten inspired yet?

42
00:01:47,869 --> 00:01:48,783
>> You've met my son.

43
00:01:48,783 --> 00:01:49,677
>> [LAUGH]
>> So

44
00:01:49,677 --> 00:01:53,719
let's say terror is by some
definition ruling to accept.

45
00:01:53,719 --> 00:01:54,469
>> Yeah, yeah.

46
00:01:54,469 --> 00:01:55,782
Let's talk-
>> How about a threat?

47
00:01:55,782 --> 00:01:57,500
A threat-
>> That's where I was going to go.

48
00:01:57,500 --> 00:02:00,253
Yes, forget whether they're terrorists
or not, just In the airport, the airport

49
00:02:00,253 --> 00:02:02,600
terrorists, this person is threatening
to the safety of the airport.

50
00:02:02,600 --> 00:02:04,010
>> And in fact we can back
it up a little bit and

51
00:02:04,010 --> 00:02:06,160
say it was not even terrorists, it's
just someone's that's going to cause

52
00:02:06,160 --> 00:02:07,890
some kind of trouble as
defined by the airports.

53
00:02:07,890 --> 00:02:10,490
So you know we'll get irritated
as they go through the line.

54
00:02:10,490 --> 00:02:13,920
>> Okay, that explains why the last
time that we got together in Atlanta I

55
00:02:13,920 --> 00:02:15,310
was chased by police.

56
00:02:15,310 --> 00:02:16,560
>> You were chased by police.

57
00:02:16,560 --> 00:02:17,400
That's a funny story,

58
00:02:17,400 --> 00:02:20,040
he was literally chased by
the police in the Atlanta airport.

59
00:02:20,040 --> 00:02:21,320
You got outta that one
pretty well I thought.

60
00:02:21,320 --> 00:02:22,500
>> Thanks.

61
00:02:22,500 --> 00:02:23,260
>> Eventually.

62
00:02:23,260 --> 00:02:23,890
>> Yeah.

63
00:02:23,890 --> 00:02:25,387
>> If we're not happy with-

64
00:02:25,387 --> 00:02:26,770
>> [LAUGH]
>> Anyway.

65
00:02:26,770 --> 00:02:30,975
>> So anyway, let's say maybe 3%
of people cause trouble in a day.

66
00:02:30,975 --> 00:02:32,160
>> [LAUGH]
>> Michael.

67
00:02:32,160 --> 00:02:32,670
>> Yeah.

68
00:02:32,670 --> 00:02:34,340
>> And let's say the other 97% don't, so

69
00:02:34,340 --> 00:02:37,230
if you were going to throw this
at a learner, what would happen.

70
00:02:38,470 --> 00:02:40,440
>> Yeah.
>> The best learner is probably the one

71
00:02:40,440 --> 00:02:41,710
that just says.

72
00:02:41,710 --> 00:02:42,648
>> No one will cause trouble.

73
00:02:42,648 --> 00:02:43,462
>> No one will cause trouble.

74
00:02:43,462 --> 00:02:45,737
>> because it could be wrong sometimes,
yeah that's right.

75
00:02:45,737 --> 00:02:47,790
It'll be wrong sometimes,
but very rarely.

76
00:02:47,790 --> 00:02:51,210
>> Yeah, 97% is pretty good,
well that's the problem.

77
00:02:51,210 --> 00:02:53,090
That's what's called
the majority classifier.

78
00:02:53,090 --> 00:02:53,640
>> Yes.

79
00:02:53,640 --> 00:02:57,840
>> And it's a baseline,
which we've talked about a little bit.

80
00:02:57,840 --> 00:02:59,960
And the problem is that when
your algorithm does 97%,

81
00:02:59,960 --> 00:03:02,730
that's actually not very
impressive on the one hand.

82
00:03:02,730 --> 00:03:04,604
But there's another issue which is that.

83
00:03:04,604 --> 00:03:05,700
>> On this date it's not so impressive.

84
00:03:05,700 --> 00:03:06,795
>> On this date it's not so impressive.

85
00:03:06,795 --> 00:03:12,470
But this other issue which
is the cost of being wrong.

86
00:03:12,470 --> 00:03:16,250
When somebody really is going
to cause trouble is much higher.

87
00:03:16,250 --> 00:03:19,690
So it's actually very important
that you get that 3%,

88
00:03:19,690 --> 00:03:21,230
you can't just treat it as 3%.

89
00:03:21,230 --> 00:03:23,620
So I'm just going to just very
briefly go through this and

90
00:03:23,620 --> 00:03:24,630
then we're going to move on.

91
00:03:24,630 --> 00:03:26,248
There's a bunch of approaches to this.

92
00:03:26,248 --> 00:03:27,880
You could re-weight
the way you do error,

93
00:03:27,880 --> 00:03:29,840
there's all kinds of
clever things you can do.

94
00:03:29,840 --> 00:03:33,460
But there's one that I really like which
is do to Paul Viola and Mike Jones,

95
00:03:33,460 --> 00:03:35,115
it was applied to a vision problem.

96
00:03:35,115 --> 00:03:37,310
It's called cascade learning.

97
00:03:37,310 --> 00:03:38,750
I like this because,
it's a seminal paper.

98
00:03:38,750 --> 00:03:40,140
I like this because it
is rally good work.

99
00:03:40,140 --> 00:03:42,343
And also because Paul Viola
is one of my advisers and

100
00:03:42,343 --> 00:03:45,380
Mike Jones was my office mate
when I was in grad school.

101
00:03:45,380 --> 00:03:48,165
They did all of this while I was sitting
there and didn't put me on their paper.

102
00:03:48,165 --> 00:03:51,630
>> [LAUGH] You think you should be on
the paper just by virtue of the fact you

103
00:03:51,630 --> 00:03:53,450
were there inspiring
them with your presence.

104
00:03:53,450 --> 00:03:55,278
>> My [SOUND] agent
lets them go up by one.

105
00:03:55,278 --> 00:03:56,192
>> Yeah.

106
00:03:56,192 --> 00:03:57,040
>> And that's important.
