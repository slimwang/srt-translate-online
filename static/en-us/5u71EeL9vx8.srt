1
00:00:00,064 --> 00:00:03,074
And the answer, of course, is that modern DRAM systems

2
00:00:03,074 --> 00:00:08,191
such as the ones used by high-performance GPUs transfer large chunks of data per transaction,

3
00:00:08,191 --> 00:00:12,082
and therefore, if you can coalesce your memory request by many threads

4
00:00:12,082 --> 00:00:17,819
that are performing a transaction at the same time, then you'll get many more useful bytes out of that transaction.

5
00:00:17,819 --> 00:00:23,021
So the second statement, that DRAM systems transfer data in many small chunks, is simply false,

6
00:00:23,021 --> 00:00:29,538
and the third statement, that GPUs have no on-chip caches to prefetch data, that's also false.

7
00:00:29,554 --> 00:00:31,900
Modern GPUs do have on-chip caches,

8
00:00:31,900 --> 00:00:38,183
although it is the case that prefetching data is not a particularly effective strategy for GPUs.

9
00:00:38,183 --> 00:00:41,878
The caches are quite small considering the number of threads that are trying to use them,

10
00:00:41,878 --> 00:00:47,083
and so you can't really afford to speculatively load data that some thread might use.

11
00:00:47,083 --> 00:00:51,254
Okay, you have tens of thousands of threads that are actually trying to use those caches to hold data,

12
00:00:51,254 --> 00:00:54,722
so prefetching is not an effective strategy, and this is also not a correct answer.
