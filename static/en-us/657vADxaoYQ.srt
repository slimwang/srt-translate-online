1
00:00:00,000 --> 00:00:03,474
[BLANK_AUDIO]

2
00:00:03,474 --> 00:00:07,253
One of the biggest hurdles that new
users to our platform run into is

3
00:00:07,253 --> 00:00:11,642
something called overfitting, where
they're using only the feedback from

4
00:00:11,642 --> 00:00:15,152
the public leaderboards to
evaluate how they're doing, and

5
00:00:15,152 --> 00:00:17,460
to make modeling decisions.

6
00:00:17,460 --> 00:00:21,190
So what this ends up being,
it works fine if you do it just once and

7
00:00:21,190 --> 00:00:23,290
submit to the public leaderboard once.

8
00:00:23,290 --> 00:00:25,160
If you're submitting a hundred times,

9
00:00:25,160 --> 00:00:27,510
then you're inching your
score up on that leaderboard.

10
00:00:27,510 --> 00:00:32,055
However, you start learning from
things that are byproducts instead of

11
00:00:32,055 --> 00:00:36,825
related to the problem itself, and
that means that your public leaderboard

12
00:00:36,825 --> 00:00:40,945
score no longer accurately
represents your performance.

13
00:00:40,945 --> 00:00:45,417
One example for that, one of our
users early on had a blog post called

14
00:00:45,417 --> 00:00:49,725
How To Drop 50 Places in One Minute
in a Kaggle competition.

15
00:00:49,725 --> 00:00:52,455
He'd worked on one of our early
problems, got up to number

16
00:00:52,455 --> 00:00:56,615
two on the public leaderboards by
creatively testing many ideas against

17
00:00:56,615 --> 00:01:01,920
the leader board, submitting over and
over again, and making many submissions.

18
00:01:01,920 --> 00:01:03,940
And then he was very eagerly,

19
00:01:03,940 --> 00:01:07,480
our competitions end at 5
PM Pacific Time Midnight UTC.

20
00:01:07,480 --> 00:01:11,280
At the 5 PM Pacific time, he was
hitting refresh on the leaderboard,

21
00:01:11,280 --> 00:01:14,350
refresh on the leaderboard, and then
refresh on the leaderboard, waiting for

22
00:01:14,350 --> 00:01:15,980
it to roll over.

23
00:01:15,980 --> 00:01:18,511
And then he finally hit
the cutoff point in time,

24
00:01:18,511 --> 00:01:21,250
it swapped over to
the private leaderboard.

25
00:01:21,250 --> 00:01:23,896
He looked at the first place
hoping he'd be there and

26
00:01:23,896 --> 00:01:26,317
hoping that it turned out
he'd win on that set.

27
00:01:26,317 --> 00:01:27,120
Nope, not there.

28
00:01:27,120 --> 00:01:30,432
He looked at the second place hoping
okay maybe I at least maintained my

29
00:01:30,432 --> 00:01:31,530
position.

30
00:01:31,530 --> 00:01:32,510
Nope, not there.

31
00:01:32,510 --> 00:01:35,200
Then he started scrolling down and
scrolling down.

32
00:01:35,200 --> 00:01:40,220
It turned out he dropped 50 places,
so the 52nd place in the competition,

33
00:01:40,220 --> 00:01:42,730
because he over fit to
the public leaderboard.

34
00:01:42,730 --> 00:01:47,375
And that is the single most powerful
way to learn about overfitting,

35
00:01:47,375 --> 00:01:50,390
is the shock and
embarrassment of watching yourself drop

36
00:01:50,390 --> 00:01:53,550
many many places in a competition
because of that mistake.

37
00:01:53,550 --> 00:01:56,220
And then needless to say he's
never overfit another competition.

38
00:01:56,220 --> 00:02:01,130
So our standard competition structure
involves actually two test sets.

39
00:02:01,130 --> 00:02:04,840
One which we call the public leaderboard
set is used to create a real time

40
00:02:04,840 --> 00:02:07,870
leaderboard that shown through
everyone throughout the competition.

41
00:02:07,870 --> 00:02:10,710
And that is a powerful
incentive mechanism for

42
00:02:10,710 --> 00:02:14,100
people participating in
the competition because

43
00:02:14,100 --> 00:02:16,440
it shows people how they're
doing with respect to others.

44
00:02:17,930 --> 00:02:22,090
And then the second set is what we
call the private leaderboard set,

45
00:02:22,090 --> 00:02:25,490
which we only show the scores on it
once at the end of the competition, and

46
00:02:25,490 --> 00:02:28,450
then we use that to determine
the final rankings and prize money.

47
00:02:28,450 --> 00:02:30,785
And that's our protection
against overfitting.

48
00:02:30,785 --> 00:02:32,100
Otherwise it becomes a game for

49
00:02:32,100 --> 00:02:35,197
who can make the most submissions to
overfit to the public leaderboard.

50
00:02:35,197 --> 00:02:38,272
[BLANK_AUDIO]

51
00:02:38,272 --> 00:02:43,077
One of the hardest things when you're
competing in a Kaggle competition or

52
00:02:43,077 --> 00:02:47,194
working on many other machine
learning projects is the failures

53
00:02:47,194 --> 00:02:49,900
dramatically outnumber the successes.

54
00:02:49,900 --> 00:02:54,900
So for every ten ideas that you try,
only one of them might actually work or

55
00:02:54,900 --> 00:02:56,760
help improve the results.

56
00:02:56,760 --> 00:03:00,050
So it's really important not to become
demoralised when you first take a crack

57
00:03:00,050 --> 00:03:04,210
on the problem and it doesn't work
well at all or take another crack and

58
00:03:04,210 --> 00:03:07,700
it still doesn't work well, but
instead to power on through and

59
00:03:07,700 --> 00:03:12,640
keep trying different ideas and
where possible to learn

60
00:03:12,640 --> 00:03:16,540
from why things didn't work out, and

61
00:03:16,540 --> 00:03:19,970
then power through until you find the
couple things that really do work out.
