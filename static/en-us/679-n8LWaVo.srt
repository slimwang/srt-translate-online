1
00:00:00,000 --> 00:00:03,000
[Dave:] This is Brian Gawalt who works on text analysis,

2
00:00:03,000 --> 00:00:06,000
which is a really important problem for search engines if we want to be able to do

3
00:00:06,000 --> 00:00:08,000
a better job of identifying the right documents.

4
00:00:08,000 --> 00:00:10,000
Tell us how that works.

5
00:00:10,000 --> 00:00:14,000
[Brian:] There are lots of different approaches, but the model that we tend to take

6
00:00:14,000 --> 00:00:18,000
transforms them into a really nice hashtable representation.

7
00:00:18,000 --> 00:00:24,000
Text is long and unwieldy and unstructured and prose flows and goes,

8
00:00:24,000 --> 00:00:27,000
but computers like things that are nice and structured

9
00:00:27,000 --> 00:00:34,000
and amenable in familiar things like lists, hashtables, etc.

10
00:00:34,000 --> 00:00:38,000
What we've got is a way to turn unstructured text

11
00:00:38,000 --> 00:00:43,000
into a data structure that computers are really happy with.

12
00:00:43,000 --> 00:00:46,000
One of those is the hashtable and the ???.

13
00:00:46,000 --> 00:00:50,000
We can start with a document that says, "Obama announces candidacy,"

14
00:00:50,000 --> 00:00:55,000
and we can turn that into a representation of that document, and imperfect representation

15
00:00:55,000 --> 00:01:00,000
that just says let's keep track of every word and the number of times that word appeared

16
00:01:00,000 --> 00:01:02,000
in the document.

17
00:01:02,000 --> 00:01:06,000
We would just go through and say "Obama"--go to the hashtable and hash Obama

18
00:01:06,000 --> 00:01:09,000
and make sure the value associated with it is 1.

19
00:01:09,000 --> 00:01:13,000
Similarly, "announces" hashes to 1, and "candidacyO hashes to 1.

20
00:01:13,000 --> 00:01:16,000
If we were dealing with longer documents, these values would grow,

21
00:01:16,000 --> 00:01:19,000
and the number of elements in the hashtable would grow as well.

22
00:01:19,000 --> 00:01:23,000
Then we come across document 2, and we can represent that with a whole new hashtable.

23
00:01:23,000 --> 00:01:29,000
"Barak Obama elected"--Barak maps to 1, Obama maps to 1, and elected maps to 1.

24
00:01:29,000 --> 00:01:34,000
If it also said "President" down here, we'd add more and more keys

25
00:01:34,000 --> 00:01:36,000
and keep track of the value associated with each one.

26
00:01:36,000 --> 00:01:41,000
When it comes time to relate documents to each other, like we would do with our search engine,

27
00:01:41,000 --> 00:01:47,000
we can look and say, hey, there's an overlap between these two documents

28
00:01:47,000 --> 00:01:51,000
and the fact that they both used "Obama."

29
00:01:51,000 --> 00:01:54,000
If we've got enough documents and there are enough patterns between them,

30
00:01:54,000 --> 00:01:59,000
then we can start saying I'm seeing this pattern of "Barak" shows up in a lot of them

31
00:01:59,000 --> 00:02:02,000
or "candidacy" or "announcements" seem to come from him a lot.

32
00:02:02,000 --> 00:02:06,000
Now you've got a way of expanding this key word that maybe we're searching for "Obama"

33
00:02:06,000 --> 00:02:10,000
and the search engine can think when you say "Obama" you're really talking about

34
00:02:10,000 --> 00:02:16,000
this wide pantheon of topics that all of the do with the 44th presidency.

35
00:02:16,000 --> 00:02:18,000
[Dave:] How did you get started working on this?

36
00:02:18,000 --> 00:02:22,000
[Brian:] Well, I was an electrical engineer, and I went from circuits to signals

37
00:02:22,000 --> 00:02:26,000
to statistical signal processing, and it turns out I was working on how to tell

38
00:02:26,000 --> 00:02:31,000
if a cell phone is sending a 1 or a 0, and the math behind that wound up being

39
00:02:31,000 --> 00:02:35,000
broadly applicable to general problems, including how to tell if an email is spam or not.

40
00:02:35,000 --> 00:02:39,000
That's kind of the entrance to text processing in general from my background.

41
00:02:39,000 --> 00:02:41,000
[Dave:] I see. So what's the next step then?

42
00:02:41,000 --> 00:02:44,000
Well, a lot of the stuff that we work with all comes down to being able to compare

43
00:02:44,000 --> 00:02:47,000
two documents and then finding out how that comparison matches

44
00:02:47,000 --> 00:02:50,000
to whatever you're target is--detecting spam or not.

45
00:02:50,000 --> 00:02:53,000
All that works really well if the documents are next to each other,

46
00:02:53,000 --> 00:02:56,000
living close to each other within a single system,

47
00:02:56,000 --> 00:03:00,000
but that gives you a maximum of how many documents get analyzed.

48
00:03:00,000 --> 00:03:03,000
So distributing the solutions to these problems

49
00:03:03,000 --> 00:03:07,000
is, I think, where a lot of energy is being put forth.
