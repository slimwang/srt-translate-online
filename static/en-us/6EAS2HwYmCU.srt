1
00:00:00,450 --> 00:00:02,960
That's all we're going to talk
about in terms of HMMs in gesture.

2
00:00:02,960 --> 00:00:06,689
I'll say the good things about it were,
it was a learning paradigm, right.

3
00:00:06,689 --> 00:00:11,940
So, you define some features, by the way
you have to define the right features,

4
00:00:11,940 --> 00:00:15,900
you collect some well-annotated data,
which also takes some work.

5
00:00:15,900 --> 00:00:20,020
But given that, you're able to train
your HMMs by just giving it the data.

6
00:00:20,020 --> 00:00:22,380
So it's a learning paradigm and
that's good.

7
00:00:22,380 --> 00:00:25,190
The training is a little bit slow,
it's not very slow.

8
00:00:25,190 --> 00:00:29,290
But recognition can be very
fast because of that recursive

9
00:00:29,290 --> 00:00:31,290
those recursive algorithms
we talked about.

10
00:00:31,290 --> 00:00:33,860
Running those is very quick.

11
00:00:33,860 --> 00:00:35,890
So, so that works really well.

12
00:00:35,890 --> 00:00:38,500
You know, of course,
not everything is perfect.

13
00:00:38,500 --> 00:00:43,930
They're not as good for segmentation
labeling as some newer methods.

14
00:00:43,930 --> 00:00:46,150
I mentioned conditional
random fields earlier.

15
00:00:46,150 --> 00:00:49,270
If you actually have something
where your training data

16
00:00:49,270 --> 00:00:52,850
has particular underlying states and
you know what those states are.

17
00:00:52,850 --> 00:00:55,490
So it's not even really
a hidden marker model.

18
00:00:55,490 --> 00:00:57,400
It is a, It is a marker model, but

19
00:00:57,400 --> 00:01:00,340
your training data you know
the underlying states.

20
00:01:00,340 --> 00:01:04,620
And you're seeing an observation and
you want that state sequence for, for

21
00:01:04,620 --> 00:01:07,170
that segmentation,
there are now better methods and

22
00:01:07,170 --> 00:01:08,930
I mentioned in
conditioned random fields.

23
00:01:08,930 --> 00:01:10,290
You know, in general,

24
00:01:10,290 --> 00:01:13,630
this stuff requires a reasonable
amount of data to train one

25
00:01:13,630 --> 00:01:17,520
of the reasons it was used for speech is
we have lots and lots and lots of data.

26
00:01:17,520 --> 00:01:21,690
Although I will say that HMMs may
require less data than some of these

27
00:01:21,690 --> 00:01:23,410
more discriminative methods.

28
00:01:23,410 --> 00:01:26,980
And then I put down something
that I think is tonalogical,

29
00:01:26,980 --> 00:01:29,426
but also important to know.

30
00:01:29,426 --> 00:01:32,270
I said it works well
when the problem is easy.

31
00:01:32,270 --> 00:01:34,990
We did a lot of work on HMMs,
gesture, etc., whatever.

32
00:01:34,990 --> 00:01:37,570
And it's very powerful for

33
00:01:37,570 --> 00:01:40,450
capturing regularities,
when the regularities are quite clear.

34
00:01:41,620 --> 00:01:44,240
You have to do a lot more work
on your feature selection and

35
00:01:44,240 --> 00:01:48,600
a bunch of other things when those
differences are a little bit harder to,

36
00:01:48,600 --> 00:01:51,010
to see number of states and
those kind of things.

37
00:01:51,010 --> 00:01:55,640
So you know that, and that's probably
true of most classification methods.

38
00:01:55,640 --> 00:01:58,110
When the problem is easy,
they all work great.

39
00:01:58,110 --> 00:02:01,030
It's when the problem is not so
easy that, that the challenge comes in.

40
00:02:01,030 --> 00:02:03,349
And that's when people start
reporting on small differences.

41
00:02:04,750 --> 00:02:07,600
That means the real issue in def,
in choosing your classifiers

42
00:02:07,600 --> 00:02:11,988
to understand where the complexity and
where the difficulty of your problem is.

43
00:02:11,988 --> 00:02:15,414
But in general, people still use
HMMs a lot, and they use it for

44
00:02:15,414 --> 00:02:18,930
describing activity or,
or, or time series.

45
00:02:18,930 --> 00:02:21,310
And you know, it's, in some sense,

46
00:02:21,310 --> 00:02:24,896
your first line of defense
against activity recognition.
