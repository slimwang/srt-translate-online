1
00:00:00,000 --> 00:00:05,470
If we have a Monte Carlo algorithm that produces the best possible solution with probability 1/2

2
00:00:05,470 --> 00:00:08,039
and we run it a couple of times, then what happens.

3
00:00:08,039 --> 00:00:14,320
If we run it the first time, we can be 50% sure that we already have the best possible answer.

4
00:00:14,320 --> 00:00:19,080
Then we run it again so the probability in the second run is again 1/2

5
00:00:19,080 --> 00:00:24,640
that we do not get the best possible answer and in the third run, it's again 1/2 and so on.

6
00:00:24,640 --> 00:00:30,990
Now this is the probability of getting a suboptimal solution and of course, if we want to be

7
00:00:30,990 --> 00:00:38,810
99.9% sure that we get the best possible solution, the probability of getting a suboptimal solution

8
00:00:38,810 --> 00:00:47,070
should be smaller than 0.1% and then the problem becomes (1/2)^n and n is the number of times

9
00:00:47,070 --> 00:00:55,780
that we run this algorithm here should be smaller than 0.001, which is the same as 0.1%

10
00:00:55,780 --> 00:00:58,500
and then you can just solve for n and get the answer and we have to

11
00:00:58,500 --> 00:01:02,250
run this algorithm just 10 times which is pretty neat.

12
00:01:02,250 --> 00:01:08,810
Now of course for an NP complete problem, it's very unlikely that we get a probability like this

13
00:01:08,810 --> 00:01:13,740
because as you can see we could very, very, very quickly in polynomial time

14
00:01:13,740 --> 00:01:16,680
get a solution that is almost guarantee to be optimal.

15
00:01:16,680 --> 00:01:22,270
So what you will find for most Monte Carlo algorithms for challenging problems

16
00:01:22,270 --> 00:01:27,740
is that the probability here first of all becomes sometimes even exponentially small

17
00:01:27,740 --> 99:59:59,999
and second that it also depends on the input size but we'll soon see how that works out concretely.
