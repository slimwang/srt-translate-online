1
00:00:00,490 --> 00:00:03,890
Now once again let's think about the semantics of RPC.

2
00:00:03,890 --> 00:00:06,200
The client has made the call and the client is

3
00:00:06,200 --> 00:00:09,220
blocked and since the client is blocked, we don't need

4
00:00:09,220 --> 00:00:12,420
to buffer the message on the client's side. If the

5
00:00:12,420 --> 00:00:15,710
message gets lost for some reason, you don't hear back

6
00:00:15,710 --> 00:00:20,210
the result of the RPC from the destination, in a

7
00:00:20,210 --> 00:00:23,350
certain amount of time, you can resend the call, from

8
00:00:23,350 --> 00:00:25,850
the client side. And therefore you don't have to buffer

9
00:00:25,850 --> 00:00:28,460
the client side RPC message but it can

10
00:00:28,460 --> 00:00:32,450
reconstruct the client side message and resend the call.

11
00:00:32,450 --> 00:00:34,510
Therefore client side buffering is something that you

12
00:00:34,510 --> 00:00:38,090
can get rid of, once again, because the LAN

13
00:00:38,090 --> 00:00:41,320
is reliable. The next source of overhead, similar

14
00:00:41,320 --> 00:00:44,240
to client side buffering, happens on the server side,

15
00:00:44,240 --> 00:00:47,160
and that is the server is sending the

16
00:00:47,160 --> 00:00:51,450
results and the results may get lost. LAN reliable

17
00:00:51,450 --> 00:00:53,675
may not happen that often but it could happen

18
00:00:53,675 --> 00:00:56,850
,and therefore we do want do the buffering. On

19
00:00:56,850 --> 00:01:00,320
the server side because if we don't buffer it

20
00:01:00,320 --> 00:01:02,520
then you have to reexecute the server procedure to

21
00:01:02,520 --> 00:01:04,720
produce a result and that's not something that you

22
00:01:04,720 --> 00:01:08,920
want to do because it involves reexecuting the server procedure

23
00:01:08,920 --> 00:01:13,510
which may be much more latency intensive then simply

24
00:01:13,510 --> 00:01:16,790
buffering the packet that corresponds to the result of

25
00:01:16,790 --> 00:01:19,850
executing the server procedure so you do want to buffer

26
00:01:19,850 --> 00:01:22,260
on the server site but. The buffering on the

27
00:01:22,260 --> 00:01:26,040
server side can be overlapped with the transmission of

28
00:01:26,040 --> 00:01:28,890
the message. So in other words the result has been

29
00:01:28,890 --> 00:01:33,020
computed by the server procedure. Now go ahead and

30
00:01:33,020 --> 00:01:36,020
send the result. While you are sending the result back

31
00:01:36,020 --> 00:01:38,380
to the client, do the buffering. That you can

32
00:01:38,380 --> 00:01:42,450
overlap the service side buffering with the result transmission, and

33
00:01:42,450 --> 00:01:44,000
get it out of the critical path

34
00:01:44,000 --> 00:01:48,320
of the latency for protocol processing. So, removing

35
00:01:48,320 --> 00:01:51,100
low level asks, employing hardware check sum and

36
00:01:51,100 --> 00:01:54,010
not doing check sum in software. Eliminating client

37
00:01:54,010 --> 00:01:57,340
side buffering all together. And overlapping the

38
00:01:57,340 --> 00:02:00,040
server side buffering with the result transmission are

39
00:02:00,040 --> 00:02:03,720
optimizations that you can do. In protocol processing,

40
00:02:03,720 --> 00:02:07,980
recognizing that the LAN is reliable and therefore

41
00:02:07,980 --> 00:02:10,440
we don't have to focus so much on

42
00:02:10,440 --> 00:02:15,370
the reliability of message transmission. But focus rather on

43
00:02:15,370 --> 00:02:18,040
the latency, and how we can reduce the

44
00:02:18,040 --> 00:02:21,280
latency, by making the protocol processing lean and mean
