1
00:00:00,260 --> 00:00:00,940
So let's see if we can be a

2
00:00:00,940 --> 00:00:05,150
bit more formal about this notion of usefulness. Okay?

3
00:00:05,150 --> 00:00:08,010
So, I erased all the stuff I had before

4
00:00:08,010 --> 00:00:10,580
but basically you could summarize that last side, as

5
00:00:10,580 --> 00:00:12,800
saying that relevance measures the effect on the

6
00:00:12,800 --> 00:00:16,420
bayes optimal classifier. Right? So a variable is relevant

7
00:00:16,420 --> 00:00:19,350
if it can make the bayes optimal classifiers performance

8
00:00:19,350 --> 00:00:24,210
better or worse. So, really relevance is about information.

9
00:00:25,360 --> 00:00:27,750
So, when you were talking earlier about things that you might use for

10
00:00:27,750 --> 00:00:30,870
filtering you said, well, I like things that have variance or things that have

11
00:00:30,870 --> 00:00:34,880
entropy or things that give me information gain. Those are all measures of

12
00:00:34,880 --> 00:00:36,660
the information that is present in a

13
00:00:36,660 --> 00:00:39,410
particular variable or a particular feature. Right?

14
00:00:39,410 --> 00:00:39,810
>> Yeah.

15
00:00:39,810 --> 00:00:41,800
>> So really from the bayes optimal

16
00:00:41,800 --> 00:00:43,570
classify point of view the only thing that

17
00:00:43,570 --> 00:00:46,470
matters is how much information a particular variable

18
00:00:46,470 --> 00:00:51,050
provides. You know, conditioned on some label or

19
00:00:51,050 --> 00:00:53,270
just in general how much information it provides so a

20
00:00:53,270 --> 00:00:57,300
variable like C here which doesn't change has zero entropy, provides

21
00:00:57,300 --> 00:01:00,550
no information, independent of the value of the label and therefore

22
00:01:00,550 --> 00:01:04,680
cannot be relevant to the bayes optimal classifier. That make sense?

23
00:01:04,680 --> 00:01:07,020
>> It does. Now I, and, and the,

24
00:01:07,020 --> 00:01:10,370
this this notion of help, usefulness. Not helpfulness, but

25
00:01:10,370 --> 00:01:13,930
usefulness. Is when we condition on particular predictor

26
00:01:13,930 --> 00:01:16,270
and that's why we can have C being useful

27
00:01:16,270 --> 00:01:18,290
in the context of a, perceptron.

28
00:01:18,290 --> 00:01:24,100
>> Right. So usefulness is exactly about effect on error given a

29
00:01:24,100 --> 00:01:27,050
particular classifier, or some specific model.

30
00:01:27,050 --> 00:01:31,380
So usefulness is exactly about minimizing error

31
00:01:32,630 --> 00:01:37,640
given some particular model or some particular learning algorithm, right? So, in

32
00:01:37,640 --> 00:01:42,470
this case although C is clearly not relevant, it is in fact useful

33
00:01:42,470 --> 00:01:47,030
at least for something like W transpose X. Now,

34
00:01:47,030 --> 00:01:50,610
this is not useful for a decision tree, nor

35
00:01:50,610 --> 00:01:52,740
is it relevant. It is not relevant to this

36
00:01:52,740 --> 00:01:56,540
particular problem, but it is however useful for some algorithms.

37
00:01:56,540 --> 00:01:58,320
>> Now, just to clarify so, so it

38
00:01:58,320 --> 00:02:00,130
seems like the base optimal classifier has a

39
00:02:00,130 --> 00:02:02,660
privileged position in this definition right, so can

40
00:02:02,660 --> 00:02:06,110
we define relevant as measuring effect on, a perceptron.

41
00:02:06,110 --> 00:02:07,420
>> Relevance, no.

42
00:02:07,420 --> 00:02:07,726
>> No I'm

43
00:02:07,726 --> 00:02:10,122
saying, but it, you just, you plugged in, a, a kind of

44
00:02:10,122 --> 00:02:12,805
classifier there. Why can't we plug it some other kind of classifier?

45
00:02:12,805 --> 00:02:14,610
>> For the base optimal classifier?

46
00:02:14,610 --> 00:02:16,010
>> Yeah, why is that one special?

47
00:02:16,010 --> 00:02:17,510
>> Because the base optimal classifier

48
00:02:17,510 --> 00:02:21,190
captures this notion of the optimal thing

49
00:02:21,190 --> 00:02:24,390
that you could do. It's not a specific algorithm. I mean you could write

50
00:02:24,390 --> 00:02:27,510
down an algorithm that would compute the base optimal classifier, except that it

51
00:02:27,510 --> 00:02:29,660
requires you looking at all possibly infinite

52
00:02:29,660 --> 00:02:33,190
number of hypotheses. Right? But it is,

53
00:02:33,190 --> 00:02:36,100
the, it the base optimal classifier computes

54
00:02:36,100 --> 00:02:38,760
the best label, given all the probabilities

55
00:02:38,760 --> 00:02:41,330
that you could, ostensibly compute over all

56
00:02:41,330 --> 00:02:44,310
the hypothesis space. It doesn't have to

57
00:02:44,310 --> 00:02:46,550
actually require specific algorithm to do so.

58
00:02:46,550 --> 00:02:49,060
It truly is a measure of information

59
00:02:49,060 --> 00:02:51,310
of variables. So, any other algorithm you

60
00:02:51,310 --> 00:02:53,540
have has a bias, in particular inductive bias.

61
00:02:53,540 --> 00:02:54,120
>> Okay.

62
00:02:54,120 --> 00:02:56,280
>> [LAUGH]

63
00:02:56,280 --> 00:02:58,280
Okay, that's a fine answer. So, at the very

64
00:02:58,280 --> 00:03:01,560
beginning of our discussion, Michael, you actually asked me this

65
00:03:01,560 --> 00:03:04,440
question of what the criteria was? When I said that

66
00:03:04,440 --> 00:03:07,260
features selection was about maximizing

67
00:03:07,260 --> 00:03:09,590
some criteria, removing features according

68
00:03:09,590 --> 00:03:11,920
to some criteria and I told you that eventually we'd

69
00:03:11,920 --> 00:03:13,750
kind of get to the point of what the criteria is.

70
00:03:13,750 --> 00:03:16,490
The notion of relevance versus usefulness gives us an idea

71
00:03:16,490 --> 00:03:19,940
of thinking about what that criteria is. Ultimately we've been

72
00:03:19,940 --> 00:03:23,280
talking about unsupervised learning, mostly in a kind of vacuum but

73
00:03:23,280 --> 00:03:25,170
presumably you know wheather some

74
00:03:25,170 --> 00:03:27,220
particular description compact or otherwise, some

75
00:03:27,220 --> 00:03:30,630
particular label is in fact a good one based on how

76
00:03:30,630 --> 00:03:33,510
it's used later on. So, one way of thinking about this

77
00:03:33,510 --> 00:03:35,690
is the labels that I come up with for a set of

78
00:03:35,690 --> 00:03:38,500
data are exactly good ones in so far as they help

79
00:03:38,500 --> 00:03:41,890
me to do something else like classification later. All that clustering

80
00:03:41,890 --> 00:03:44,920
that we did before, like with k means and E M.

81
00:03:44,920 --> 00:03:48,390
You could think of those as a kind of feature transformation algorithm

82
00:03:48,390 --> 00:03:51,950
which is what we'll be talking about next where you've taken a bunch

83
00:03:51,950 --> 00:03:55,410
of features and you've converted them into something simple like a label. And

84
00:03:55,410 --> 00:03:58,630
whether that label is a good label or a bad label, depends entirely

85
00:03:58,630 --> 00:04:00,580
upon whether you can then do some

86
00:04:00,580 --> 00:04:02,520
kind of classification or regression problem later.

87
00:04:02,520 --> 00:04:06,130
>> Label in this case meaning the cluster name? Right.

88
00:04:06,130 --> 00:04:06,920
>> Got it.

89
00:04:06,920 --> 00:04:07,070
>> Okay.

90
00:04:07,070 --> 00:04:08,270
>> That's interesting.

91
00:04:08,270 --> 00:04:11,320
>> So, you'll actually find if you go through the

92
00:04:11,320 --> 00:04:13,460
literature and you, you look at some algorithms people have

93
00:04:13,460 --> 00:04:17,399
predicted, that a lot of the, measures like information

94
00:04:17,399 --> 00:04:20,790
gain or entropy or whatever, often end up being couched

95
00:04:20,790 --> 00:04:24,110
in terms of relevance. But ultimately, what we really

96
00:04:24,110 --> 00:04:27,080
care about is usefulness, or at least one could argue.

97
00:04:27,080 --> 00:04:27,280
>> Cool.

98
00:04:27,280 --> 00:04:30,770
>> Okay. So that's pretty much what I wanted to talk about

99
00:04:30,770 --> 00:04:33,670
for a feature selection. There's a lot of algorithms and, I mean,

100
00:04:33,670 --> 00:04:36,040
if you go and you look at the material we've made available

101
00:04:36,040 --> 00:04:38,760
to everyone you'll be able to see some of these algorithms discussed

102
00:04:38,760 --> 00:04:41,440
in more detail. But at a high level these are the, the key

103
00:04:41,440 --> 00:04:44,510
issues that I wanted you to see. So, with that Michael, let's wrap up.
