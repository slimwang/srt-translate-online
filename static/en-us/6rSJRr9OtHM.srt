1
00:00:00,100 --> 00:00:02,570
So, let's talk a little bit about our procedure here. The first thing

2
00:00:02,570 --> 00:00:05,750
we want to do is build a list of all carrier values. We could do

3
00:00:05,750 --> 00:00:08,690
that by hand, might actually be a little easier to do it that way

4
00:00:08,690 --> 00:00:11,760
just by looking at the HTML. We then need to build a list of

5
00:00:11,760 --> 00:00:14,820
airport values. Now there are a lot of values here. So what we

6
00:00:14,820 --> 00:00:16,880
probably want to do is actually write a

7
00:00:16,880 --> 00:00:18,630
little script that will actually pull those

8
00:00:18,630 --> 00:00:22,860
out. Okay. So all pages are going to have exactly the same list for

9
00:00:22,860 --> 00:00:25,250
both of these. So we can just use the browser to download an example

10
00:00:25,250 --> 00:00:28,520
page and pull those values out. Next, what we need to do

11
00:00:28,520 --> 00:00:32,270
is make HTTP requests to download all the data. I'll talk about

12
00:00:32,270 --> 00:00:35,460
why we want to download it all in just a minute. Then what

13
00:00:35,460 --> 00:00:38,415
we want to to is parse the data files. The reason why we

14
00:00:38,415 --> 00:00:41,822
want to do it this way, is because, in building our parser we

15
00:00:41,822 --> 00:00:45,080
want to make sure we're working with data that isn't going to change.

16
00:00:45,080 --> 00:00:47,230
And after the fact, once we do a little bit of data

17
00:00:47,230 --> 00:00:50,260
cleaning, we may discover that the reason why we've got some dirty

18
00:00:50,260 --> 00:00:53,960
data is actually because we have a bug in our parser. Much easier

19
00:00:53,960 --> 00:00:56,570
to figure out where that bug is if we've still got the original data

20
00:00:56,570 --> 00:00:59,160
we were using to parse. I should also point out that it really

21
00:00:59,160 --> 00:01:02,540
doesn't make sense to download the data over and over again as we're figuring

22
00:01:02,540 --> 00:01:04,910
out how to parse it. Something else you might want to keep in

23
00:01:04,910 --> 00:01:08,890
mind is that for years prior to the current year the data isn't going

24
00:01:08,890 --> 00:01:12,410
to change, so there's no reason to retrieve it more than once. So this

25
00:01:12,410 --> 00:01:15,370
is actually a bit of a best practice. When you've got a situation like

26
00:01:15,370 --> 00:01:17,700
the one we have here and when you've got a scraping

27
00:01:17,700 --> 00:01:20,800
task it's often going to look something like this. You really want

28
00:01:20,800 --> 00:01:23,720
to grab all the data you need first and then do your

29
00:01:23,720 --> 00:01:28,580
scraping into separate process. So what we have for this particular problem

30
00:01:28,580 --> 00:01:31,830
is essentially three different steps. We first have to build all the

31
00:01:31,830 --> 00:01:34,680
values we're going to use to make HTTP request. We then need

32
00:01:34,680 --> 00:01:37,570
to make all the HTTP request, and download the data we need.

33
00:01:37,570 --> 00:01:40,750
And then finally, we're going to parse the data we want out

34
00:01:40,750 --> 00:01:44,400
of those data files, shaping it into the particular pieces

35
00:01:44,400 --> 00:01:46,660
of data, the particular items that we want to use.
