1
00:00:00,540 --> 00:00:04,290
So popping a level, what we can learn from

2
00:00:04,290 --> 00:00:07,074
the example that I just gave you with page

3
00:00:07,074 --> 00:00:10,520
fault service is in order to design a scalable

4
00:00:10,520 --> 00:00:13,530
operating system service in a parallel operating system. You

5
00:00:13,530 --> 00:00:15,880
have to think about what is the right recipe.

6
00:00:15,880 --> 00:00:18,770
For every subsystem that you want to design, first

7
00:00:18,770 --> 00:00:21,330
determine functionally what needs to be done for that

8
00:00:21,330 --> 00:00:26,180
service. Now you've got parallel hardware and therefore the functional

9
00:00:26,180 --> 00:00:28,670
part of that service can be executed in

10
00:00:28,670 --> 00:00:31,734
parallel in the different processors that are available. That's,

11
00:00:31,734 --> 00:00:33,550
that's the easy part but in order to

12
00:00:33,550 --> 00:00:36,930
ensure concurrent execution of the service, you have to

13
00:00:36,930 --> 00:00:39,650
minimize the shared data structures. Only if you

14
00:00:39,650 --> 00:00:42,440
minimize the shared data structures will you really be

15
00:00:42,440 --> 00:00:46,210
able to execute the functional part of that service

16
00:00:46,210 --> 00:00:51,300
concurrently on the available processors. So, less sharing will

17
00:00:51,300 --> 00:00:54,750
result in more scalable implementation of the service.

18
00:00:54,750 --> 00:00:57,340
Now the problem is, it is easy to say

19
00:00:57,340 --> 00:01:00,060
avoid sharing data structures, but it is hard

20
00:01:00,060 --> 00:01:03,755
to practice. Because it is always not very clear

21
00:01:03,755 --> 00:01:08,380
how in designing the subsystem, we can limit

22
00:01:08,380 --> 00:01:10,940
the amount of sharing of shared data structures. Now

23
00:01:10,940 --> 00:01:13,320
coming back to the example of the page fault

24
00:01:13,320 --> 00:01:16,670
service, the page table data structure that the operating

25
00:01:16,670 --> 00:01:20,400
system maintains on behalf of the process, it is

26
00:01:20,400 --> 00:01:23,200
a logically shared data structure. But if you want

27
00:01:23,200 --> 00:01:27,350
true concurrency for updating this data structure, it is

28
00:01:27,350 --> 00:01:30,480
inappropriate to have a single data structure that represents a

29
00:01:30,480 --> 00:01:33,070
page table for a process. Because if you have

30
00:01:33,070 --> 00:01:35,770
a single data structure that represents a page table for

31
00:01:35,770 --> 00:01:38,540
a process, in order to do the function of

32
00:01:38,540 --> 00:01:41,810
page fault service, you have to lock the data structure.

33
00:01:41,810 --> 00:01:44,470
That leads to a serial bottleneck. But at the

34
00:01:44,470 --> 00:01:48,090
same time if we say, well, you know, let's

35
00:01:48,090 --> 00:01:51,306
take this page table data structure and replicate it

36
00:01:51,306 --> 00:01:55,250
on all the nodes of the multiprocessor, that probably

37
00:01:55,250 --> 00:01:57,120
is not also a very good idea. Because then

38
00:01:57,120 --> 00:02:01,400
the operating system has to worry about the consistency

39
00:02:01,400 --> 00:02:03,870
of the shared data structure copies that are existing

40
00:02:03,870 --> 00:02:06,988
on all the processors, and making them up to

41
00:02:06,988 --> 00:02:11,700
date all the time and so on. So we can now quickly see what the dilemma is

42
00:02:11,700 --> 00:02:14,820
of the operating system designer. So as an

43
00:02:14,820 --> 00:02:18,590
operating system designer, we want the freedom to think

44
00:02:18,590 --> 00:02:22,850
logically about shared data structures. But later, depending

45
00:02:22,850 --> 00:02:25,680
on the usage of the data structure, we want

46
00:02:25,680 --> 00:02:29,400
to replicate or partition the data structure so

47
00:02:29,400 --> 00:02:33,630
that we can have less locking and more concurrency.

48
00:02:33,630 --> 00:02:36,730
That's the real trick. The trick is, you

49
00:02:36,730 --> 00:02:38,570
want to think logically. Yes, it's a shared

50
00:02:38,570 --> 00:02:42,090
data structure, but based on the usage, we'll

51
00:02:42,090 --> 00:02:45,100
replicate or partition the system data structures so

52
00:02:45,100 --> 00:02:48,440
that you have more concurrency and less locking

53
00:02:48,440 --> 00:02:51,570
for those shared data structures. So we'll keep

54
00:02:51,570 --> 00:02:54,300
this recipe and the principles we talked about

55
00:02:54,300 --> 00:02:58,640
in mind, and talk about one particular service,

56
00:02:58,640 --> 00:03:03,030
namely the memory management subsystem, and how we can avoid serial

57
00:03:03,030 --> 00:03:08,350
bottlenecks using the techniques that are proposed in one of the papers

58
00:03:08,350 --> 00:03:10,930
that I've assigned you for reading, which is called the Tornado

59
00:03:10,930 --> 00:03:16,617
System. The key property is less sharing leads to more scalable design.
