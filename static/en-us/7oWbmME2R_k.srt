1
00:00:00,290 --> 00:00:02,498
>> Earlier I mentioned sampling and I asked you whether that

2
00:00:02,498 --> 00:00:05,250
sounded useful, and you said it was. So, let's do a

3
00:00:05,250 --> 00:00:08,760
little exercise. Why? Why [LAUGH] is that a useful thing? Why

4
00:00:08,760 --> 00:00:10,800
is it good idea to be able to sample from a distribution?

5
00:00:10,800 --> 00:00:15,310
>> Well, because it's one of the two things that distributions are for.

6
00:00:15,310 --> 00:00:16,830
>> What does that mean?

7
00:00:16,830 --> 00:00:17,775
>> Well so why do you have a

8
00:00:17,775 --> 00:00:20,940
distribution? A distribution is so that given some

9
00:00:20,940 --> 00:00:22,978
value, you can, you can tell me what's

10
00:00:22,978 --> 00:00:25,300
the probability of me seeing that value which

11
00:00:25,300 --> 00:00:28,460
is kind of what it looks like when you have the probability function, but

12
00:00:28,460 --> 00:00:29,880
also if you have a nice distribution

13
00:00:29,880 --> 00:00:32,980
you can generate values according to that distribution.

14
00:00:32,980 --> 00:00:37,930
>> Okay. That's a little bit circular in the sense that it didn't tell me why

15
00:00:37,930 --> 00:00:40,550
it was useful to generate them other than it's one of the things you can do.

16
00:00:40,550 --> 00:00:43,820
>> Well, you didn't ask me to actually make sense. But I mean, this is

17
00:00:43,820 --> 00:00:46,130
the, the thing that you use distributions for.

18
00:00:46,130 --> 00:00:47,940
Now why would you want to do that?

19
00:00:47,940 --> 00:00:49,280
>> Yeah.

20
00:00:49,280 --> 00:00:50,110
>> So,

21
00:00:51,150 --> 00:00:55,650
if a distribution represents kind of a process, it would

22
00:00:55,650 --> 00:00:59,790
be nice if I could duplicate that process, right? So, I

23
00:00:59,790 --> 00:01:02,190
would have to be able to generate values in the

24
00:01:02,190 --> 00:01:05,260
right way, consistent with the distribution in order to generate that

25
00:01:05,260 --> 00:01:07,781
process. So it's like flipping a coin, or I want

26
00:01:07,781 --> 00:01:10,500
to flip a coin and find out whether I'm going to

27
00:01:10,500 --> 00:01:13,230
get heads or tails. It would be nice if I can

28
00:01:13,230 --> 00:01:16,210
do that in a way that's consistent with whatever the underlying

29
00:01:16,210 --> 00:01:17,305
bias of the coin is.

30
00:01:17,305 --> 00:01:19,520
>> Okay, so yeah, if this distribution

31
00:01:19,520 --> 00:01:21,760
represented something complex, we might, you know, for

32
00:01:21,760 --> 00:01:23,920
whatever reason need to simulate that world

33
00:01:23,920 --> 00:01:26,498
and, and act according to those probabilities. So,

34
00:01:26,498 --> 00:01:30,130
yeah, that, that's a reasonable one. What else, what if, what if I showed you

35
00:01:30,130 --> 00:01:31,980
this, if i took this distribution that

36
00:01:31,980 --> 00:01:33,730
we used for the lightning and thunder example.

37
00:01:33,730 --> 00:01:34,373
>> Mm-hm.

38
00:01:34,373 --> 00:01:36,430
>> What if you wanted to get a handle on it? How can we

39
00:01:36,430 --> 00:01:38,110
use sampling for the distribution to give

40
00:01:38,110 --> 00:01:40,940
you some insight into how the storms work?

41
00:01:40,940 --> 00:01:41,574
>> Okay

42
00:01:41,574 --> 00:01:43,890
so let's see, I've, I've, I've got this representation

43
00:01:43,890 --> 00:01:46,478
of the joint distribution, but it's just a representation of

44
00:01:46,478 --> 00:01:48,310
the joint distribution. If I want to asked a

45
00:01:48,310 --> 00:01:51,860
question like, well what's the chance that it's, oh let's

46
00:01:51,860 --> 00:01:56,730
say, storming outside if I've heard thunder, I could

47
00:01:56,730 --> 00:02:00,840
go through and, and, you know, back compute the reverse

48
00:02:00,840 --> 00:02:03,850
of the conditional probability tables. And I could do things

49
00:02:03,850 --> 00:02:06,739
like, or I could just generate a bunch of samples

50
00:02:08,110 --> 00:02:12,250
where I had thunder and I can just see how

51
00:02:12,250 --> 00:02:15,030
often the storm was also true. Does that make sense?

52
00:02:15,030 --> 00:02:16,590
>> It does, though I'm not going to use

53
00:02:16,590 --> 00:02:18,480
the words that you just used to write that down.

54
00:02:18,480 --> 00:02:18,820
>> Okay.

55
00:02:18,820 --> 00:02:22,250
>> I'm going to call that approximate inference. So the basic idea is that

56
00:02:22,250 --> 00:02:24,460
you would like to do some inference, you'd like to figure out what might

57
00:02:24,460 --> 00:02:25,830
be true of the world in different

58
00:02:25,830 --> 00:02:29,110
situations. Instead of doing some complex probability

59
00:02:29,110 --> 00:02:30,800
calculation, you're just going to imagine a

60
00:02:30,800 --> 00:02:33,200
bunch of possible worlds and see how often

61
00:02:33,200 --> 00:02:35,320
is it the case that whatever it is you

62
00:02:35,320 --> 00:02:38,410
want to figure out is true. So yeah, that, that

63
00:02:38,410 --> 00:02:39,410
turns out to be a really good way to

64
00:02:39,410 --> 00:02:41,250
do it. In fact, sometimes I think that's a lot

65
00:02:41,250 --> 00:02:42,760
of what people are doing when we're, when we're

66
00:02:42,760 --> 00:02:45,290
making judgments in the world. We're just really, really good

67
00:02:45,290 --> 00:02:47,710
at this kind of sampling from past realities that

68
00:02:47,710 --> 00:02:50,770
are relevant, and we can make judgments based on that.

69
00:02:50,770 --> 00:02:53,180
>> Hm. So, how would you do that?

70
00:02:53,180 --> 00:02:54,790
>> How would I do what?

71
00:02:54,790 --> 00:02:56,300
>> How would you do this approximate inference?

72
00:02:56,300 --> 00:02:57,900
>> We're going to get to that but I wanted to.

73
00:02:57,900 --> 00:02:58,190
>> Oh, okay, cool.

74
00:02:58,190 --> 00:02:58,280
>> But

75
00:02:58,280 --> 00:02:59,240
there, but there's one or two other

76
00:02:59,240 --> 00:03:01,140
things about sampling that I wanted to mention.

77
00:03:01,140 --> 00:03:01,580
>> Okay.

78
00:03:01,580 --> 00:03:04,330
>> Another thing that I could imagine using this for

79
00:03:04,330 --> 00:03:07,870
is this notion of visualization. Which may be, I mean this

80
00:03:07,870 --> 00:03:10,910
in a, in a broader way than it sounds, not

81
00:03:10,910 --> 00:03:13,850
necessarily to actually see what the distribution is like, but to

82
00:03:13,850 --> 00:03:18,080
kind of get a feel for it. So, I bet if I was to run that if I was to draw

83
00:03:18,080 --> 00:03:20,750
a bunch of samples from the lightening thundering set, you

84
00:03:20,750 --> 00:03:23,800
would have a better feel for how likely different things are.

85
00:03:23,800 --> 00:03:25,990
Just you as a person might get a sense of how these

86
00:03:25,990 --> 00:03:30,040
things work. So, you can imagine in, in a medical domain a doctor

87
00:03:30,040 --> 00:03:33,080
who's, who's thinking about prescri, prescribing a particular kind of drug for a

88
00:03:33,080 --> 00:03:35,100
particular kind of person, if the

89
00:03:35,100 --> 00:03:37,970
information about drug interactions and so forth

90
00:03:37,970 --> 00:03:40,680
was, was represented as a big belief net, it might be hard to

91
00:03:40,680 --> 00:03:43,110
look at it and know anything. But if it ge, if you use

92
00:03:43,110 --> 00:03:45,550
that to generate a bunch of artificial patients you might start to get

93
00:03:45,550 --> 00:03:49,710
to feel for oh, you know what, these kinds of people tend to

94
00:03:49,710 --> 00:03:51,800
react badly in these kinds of circumstances.

95
00:03:51,800 --> 00:03:55,670
>> That's still a kind of approximate inference, right?

96
00:03:55,670 --> 00:03:58,380
>> That's right. So this is, this is a kind of an

97
00:03:58,380 --> 00:04:01,900
in the machine sense, and this is kind of in the human sense.

98
00:04:01,900 --> 00:04:04,190
>> Okay, I like that. So let's see, let's see

99
00:04:04,190 --> 00:04:07,000
if I, if I understand this. So the, the nice thing

100
00:04:07,000 --> 00:04:09,980
about the storm, the thunder, and the lightning example is that

101
00:04:09,980 --> 00:04:14,840
it has pedagogical value. Because it's easy for a student to

102
00:04:14,840 --> 00:04:16,620
look at that and go okay, I understand what's

103
00:04:16,620 --> 00:04:19,103
going on here. One because there's only three nodes

104
00:04:19,103 --> 00:04:21,708
and two arrows, and the other is because, we

105
00:04:21,708 --> 00:04:25,670
think we understand how storms, thunder and lightning work. Right.

106
00:04:25,670 --> 00:04:26,120
>> Yup.

107
00:04:26,120 --> 00:04:28,220
>> Or most people do. So that makes a lot of sense. Of course

108
00:04:28,220 --> 00:04:31,860
the downside of it is, we think we understand it. And so it's hard to

109
00:04:31,860 --> 00:04:34,780
see why you would need to do samples, I mean, there's just a couple of

110
00:04:34,780 --> 00:04:36,420
probability distributions and we kind of know

111
00:04:36,420 --> 00:04:39,580
what it means. But in the real world,

112
00:04:39,580 --> 00:04:42,490
there are perhaps hundreds and hundreds of variables

113
00:04:42,490 --> 00:04:46,660
with complicated relationships and conditional independencies that, that aren't

114
00:04:46,660 --> 00:04:50,550
necessary intuitive just by looking at the graph. And

115
00:04:50,550 --> 00:04:53,100
so picking one conditional probability table and looking at

116
00:04:53,100 --> 00:04:55,190
it isn't going to tell you much. But by

117
00:04:55,190 --> 00:04:59,340
sampling I get real examples that are concrete that,

118
00:04:59,340 --> 00:05:01,920
as a human being, I can understand without having

119
00:05:01,920 --> 00:05:04,740
to, you know, really glock all the 25 different

120
00:05:04,740 --> 00:05:07,827
conditional probability tables. Does that sound right? Is that. [CROSSTALK]

121
00:05:07,827 --> 00:05:08,250
>> Yeah, yeah.

122
00:05:08,250 --> 00:05:08,950
>> What you're trying to say?

123
00:05:08,950 --> 00:05:10,010
>> That's exactly right. Thanks.

124
00:05:10,010 --> 00:05:10,698
>> Okay.

125
00:05:10,698 --> 00:05:12,690
>> I want to draw your attention to this, this

126
00:05:12,690 --> 00:05:16,120
word here for a moment. This notion of approximate inference. Now

127
00:05:16,120 --> 00:05:19,680
generally we don't like approximations when we can do things, things

128
00:05:19,680 --> 00:05:22,900
exactly. So why are, why are we not doing things exactly?

129
00:05:22,900 --> 00:05:24,250
>> because it's hard.

130
00:05:24,250 --> 00:05:27,720
>> It's hard, that's exactly right. So or,

131
00:05:27,720 --> 00:05:29,700
or, even if it weren't hard, it may,

132
00:05:29,700 --> 00:05:32,782
it may be in some cases faster. So I would be,

133
00:05:32,782 --> 00:05:35,076
I'm not going to do it now, but I'd be happy

134
00:05:35,076 --> 00:05:37,928
if I guess if there's ground swell of support among the

135
00:05:37,928 --> 00:05:41,600
students. To I can go through the argument as to why

136
00:05:41,600 --> 00:05:45,390
this inference is hard. There's a nice little reduction to problems,

137
00:05:45,390 --> 00:05:48,520
N, NP complete problems like satisfiability. But it turns out roughly

138
00:05:48,520 --> 00:05:51,280
that if you could do inference exactly on any belief net

139
00:05:51,280 --> 00:05:54,760
that you want, then you could solve very, very hard problems efficiently

140
00:05:54,760 --> 00:05:58,960
using that idea. So it's, it's cute, but it's kind of takes us

141
00:05:58,960 --> 00:06:01,520
a little bit off our path, so I'm not going to get into that.

142
00:06:01,520 --> 00:06:05,850
>> Okay, so sampling is useful, Michael, which I always suspected in my

143
00:06:05,850 --> 00:06:09,120
heart, and now we've got some good arguments for why it actually is.
