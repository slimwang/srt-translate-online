1
00:00:00,000 --> 00:00:04,000
Welcome back. We're about to start the final unit in this course.

2
00:00:04,000 --> 00:00:08,000
This time we're mostly going to focus on review and some practice problems

3
00:00:08,000 --> 00:00:11,000
to get you ready for the exam or at least to get you in the mood for the exam.

4
00:00:11,000 --> 00:00:13,000
But there may also be just a little bit of fun.

5
00:00:13,000 --> 00:00:16,000
You may get the chance to hear someone who is not Wes Weimer talking.

6
00:00:16,000 --> 00:00:18,000
I know, I know.

7
00:00:18,000 --> 00:00:21,000
Someone with real voice inflection? Be still, your beating heart.

8
00:00:21,000 --> 00:00:24,000
But before we get going with practice problems, let us make The List,

9
00:00:24,000 --> 00:00:27,000
a high level summary of everything you've learned thus far.

10
00:00:27,000 --> 00:00:32,000
We started off by introducing the concept of a language as a set of strings.

11
00:00:32,000 --> 00:00:35,000
Regular expressions, finite state machines, formal grammars--

12
00:00:35,000 --> 00:00:39,000
these all denote or accept or correspond to sets of strings.

13
00:00:39,000 --> 00:00:44,000
In fact, the set of all valid JavaScript programs is just a set of really big strings.

14
00:00:44,000 --> 00:00:48,000
One of the first tools we introduced was regular expressions,

15
00:00:48,000 --> 00:00:52,000
which are just a concise notation for specifying some sets of strings.

16
00:00:52,000 --> 00:00:55,000
Those sets of strings are called regular languages.

17
00:00:55,000 --> 00:00:59,000
An incredible surprise move: regular expressions denote regular languages.

18
00:00:59,000 --> 00:01:05,000
And we learned a bunch of regular expressions--+, *, disjunctive choice,

19
00:01:05,000 --> 00:01:10,000
ranges of letters, 0 or 1 copies--and we ended up using these to specify tokens.

20
00:01:10,000 --> 00:01:12,000
More on that in just a bit.

21
00:01:12,000 --> 00:01:15,000
Then we learned about finite state machines, which are a cool way

22
00:01:15,000 --> 00:01:19,000
to draw regular expressions and also, it turns out,

23
00:01:19,000 --> 00:01:21,000
a way that we implement them under the hood.

24
00:01:21,000 --> 00:01:23,000
That's how Python actually does it.

25
00:01:23,000 --> 00:01:26,000
Here I've shown a finite state machine for ab*.

26
00:01:26,000 --> 00:01:30,000
Possible to have ambiguity or epsilon transitions in a finite state machine.

27
00:01:30,000 --> 00:01:33,000
That makes a finite state machine nondeterministic,

28
00:01:33,000 --> 00:01:37,000
because if you're trying to simulate it, you don't know exactly where to go at any given point.

29
00:01:37,000 --> 00:01:40,000
It turns out, however, that is not a problem at all.

30
00:01:40,000 --> 00:01:43,000
We can convert nondeterministic finite state machines

31
00:01:43,000 --> 00:01:45,000
down into deterministic finite state machines.

32
00:01:45,000 --> 00:01:47,000
They may get a little bit bigger, but it will totally work.

33
00:01:47,000 --> 00:01:51,000
Then we moved on to the more powerful context-free grammars,

34
00:01:51,000 --> 00:01:54,000
which are a concise notation for specifying some sets of strings.

35
00:01:54,000 --> 00:01:56,000
Wait! I thought that's what regular expressions were.

36
00:01:56,000 --> 00:02:02,000
Actually, they're both just concise notations for specifying possibly infinite sets of strings.

37
00:02:02,000 --> 00:02:07,000
And your typical context-free grammar is just a set of rewrite rules

38
00:02:07,000 --> 00:02:10,000
with a nonterminal symbol on the left, an arrow,

39
00:02:10,000 --> 00:02:13,000
and then some terminals and nonterminals on the right.

40
00:02:13,000 --> 00:02:16,000
Terminals are the same thing as tokens.

41
00:02:16,000 --> 00:02:18,000
They're the actual input that we're trying to match.

42
00:02:18,000 --> 00:02:21,000
There are some cool things that we can do with context-free grammars,

43
00:02:21,000 --> 00:02:24,000
like matching balanced parentheses, that we could not do--

44
00:02:24,000 --> 00:02:29,000
we're certain we cannot do it, it is impossible to do correctly--with regular expressions.

45
00:02:29,000 --> 00:02:34,000
We often want to check and see if a string is in the language of a context-free grammar

46
00:02:34,000 --> 00:02:36,000
or matches that context-free grammar,

47
00:02:36,000 --> 00:02:39,000
can be derived or generated by that context-free grammar--

48
00:02:39,000 --> 00:02:43,000
these are all the same question--and one way to do that was memoization,

49
00:02:43,000 --> 00:02:48,000
which for many years I always wanted to call "memorization," but it's just not.

50
00:02:48,000 --> 00:02:52,000
It's also called dynamic programming, which sounds really exciting,

51
00:02:52,000 --> 00:02:57,000
but in practice basically builds charts where we write down previously computed results

52
00:02:57,000 --> 00:02:59,000
so that we don't have to compute them again.

53
00:02:59,000 --> 00:03:04,000
This is called being lazy, and it's a phenomenal virtue when you're writing programs.

54
00:03:04,000 --> 00:03:08,000
We can combine context-free grammars and, potentially, memoization together

55
00:03:08,000 --> 00:03:13,000
to get parsing, which is the process of determining if a list of tokens

56
00:03:13,000 --> 00:03:16,000
is in the language of a context-free grammar.

57
00:03:16,000 --> 00:03:18,000
If so, we produce a parse tree.

58
00:03:18,000 --> 00:03:20,000
Where did we get that list of tokens, you ask?

59
00:03:20,000 --> 00:03:25,000
The process of lexing breaks a big string, like a web page, up into a list of tokens

60
00:03:25,000 --> 00:03:27,000
or important words.

61
00:03:27,000 --> 00:03:30,000
The tokens are specified using regular expressions,

62
00:03:30,000 --> 00:03:33,000
which means that a lexer is implemented using finite state machines.

63
00:03:33,000 --> 00:03:35,000
We do lexing first and then parsing.

64
00:03:35,000 --> 00:03:39,000
I have written them out of order to shake things up.

65
00:03:39,000 --> 00:03:44,000
Once we have our parse tree, we're getting closer and closer to the meaning of a program.

66
00:03:44,000 --> 00:03:47,000
One aspect of program semantics or program meanings

67
00:03:47,000 --> 00:03:54,000
is the notion of types--that we can classify objects or values like 1, 2, and 3 into groups

68
00:03:54,000 --> 00:03:56,000
and say, "Those are all numbers."

69
00:03:56,000 --> 00:04:01,000
So a type is just a set of values and some associated operations that you can apply.

70
00:04:01,000 --> 00:04:05,000
So the values might be things like all numbers, all strings, or all lists,

71
00:04:05,000 --> 00:04:09,000
and the operations might be things like + - / or length.

72
00:04:09,000 --> 00:04:11,000
I can apply length to a string or a list but not a number.

73
00:04:11,000 --> 00:04:15,000
I can add numbers, strings, and lists, but it means something different every time.

74
00:04:15,000 --> 00:04:19,000
I can divide numbers, but I can't really divide strings or lists,

75
00:04:19,000 --> 00:04:21,000
at least not using this division operator.

76
00:04:21,000 --> 00:04:24,000
Types are our first step along the road to meaning,

77
00:04:24,000 --> 00:04:27,000
and in computer science we formally call that semantics.

78
00:04:27,000 --> 00:04:29,000
By the way, if you've been wondering the whole time,

79
00:04:29,000 --> 00:04:32,000
semantics is a tricky word that essentially always ends in an S,

80
00:04:32,000 --> 00:04:36,000
even when we're using it in sort of a singular fashion.

81
00:04:36,000 --> 00:04:39,000
Semantics of a program: its meaning, what does it compute.

82
00:04:39,000 --> 00:04:44,000
A program may have type errors, like if you try to divide a string by an integer,

83
00:04:44,000 --> 00:04:46,000
or it may have any number of other exceptions.

84
00:04:46,000 --> 00:04:49,000
But in the general case, it produces a value.

85
00:04:49,000 --> 00:04:52,000
This means that we have computed something. That was the result.

86
00:04:52,000 --> 00:04:57,000
That's the meaning of our program, just like a sentence in English or French

87
00:04:57,000 --> 00:04:59,000
or Cantonese might have a meaning.

88
00:04:59,000 --> 00:05:02,000
Once we have a grip on semantics, we can introduce optimization,

89
00:05:02,000 --> 00:05:07,000
where we replace one program with another or, conceptually, one part of a program

90
00:05:07,000 --> 00:05:11,000
with another as long as the whole thing has the same semantics.

91
00:05:11,000 --> 00:05:13,000
This is the critical rule of optimization.

92
00:05:13,000 --> 00:05:15,000
You can't change the meaning of the program.

93
00:05:15,000 --> 00:05:17,000
If you can't change the meaning, what can you change?

94
00:05:17,000 --> 00:05:22,000
Typically, the new code you've brought in uses fewer resources--

95
00:05:22,000 --> 00:05:26,000
less time, less memory, consumes less power--

96
00:05:26,000 --> 00:05:28,000
and we've seen a bunch of examples of these.

97
00:05:28,000 --> 00:05:32,000
x * 1 could be replaced with just x,

98
00:05:32,000 --> 00:05:36,000
but x / x cannot be replaced with 1

99
00:05:36,000 --> 00:05:39,000
because in the single case where x is 0, this changes the meaning of the program.

100
00:05:39,000 --> 00:05:44,000
After optimizing, or not--you never have to optimize--we can move on to interpretation.

101
00:05:44,000 --> 00:05:46,000
This is the fun part.

102
00:05:46,000 --> 00:05:49,000
We recursively walk over the parse tree,

103
00:05:49,000 --> 00:05:54,000
and the meaning of a program, the final result, the picture we should display for a web page,

104
00:05:54,000 --> 00:05:57,000
the result of a computation in a financial program,

105
00:05:57,000 --> 00:06:01,000
is computed from the meanings of its subexpressions.

106
00:06:01,000 --> 00:06:04,000
So if I'm in a state or environment where a maps to 5,

107
00:06:04,000 --> 00:06:08,000
I can compute the meaning of this abstract syntax tree expression.

108
00:06:08,000 --> 00:06:12,000
Well, we have times and plus. I'll go down here and figure out what a is.

109
00:06:12,000 --> 00:06:16,000
a is 5, 3 is 3. I multiply them together and I get 15.

110
00:06:16,000 --> 00:06:18,000
Over here, 1 and 2. I add them together and I get 3.

111
00:06:18,000 --> 00:06:20,000
The whole thing I get 18.

112
00:06:20,000 --> 00:06:24,000
Walk down the tree on both sides, and only as I'm coming back up do I compute the values.

113
00:06:24,000 --> 00:06:27,000
Typically, to perform interpretation we have to track state,

114
00:06:27,000 --> 00:06:32,000
like the values of variables which may change, in environments.

115
00:06:32,000 --> 00:06:36,000
And environments are often chained together, especially as you make function calls.

116
00:06:36,000 --> 00:06:40,000
Finally, we put all of that together to build our web browser.

117
00:06:40,000 --> 00:06:42,000
We followed a particular architecture.

118
00:06:42,000 --> 00:06:45,000
You could imagine doing another one, but this is the one we used for this class.

119
00:06:45,000 --> 00:06:50,000
We start by lexing and parsing HTML, treating any embedded JavaScript

120
00:06:50,000 --> 00:06:52,000
as a special token.

121
00:06:52,000 --> 00:06:55,000
Our HTML interpreter walks over the HTML parse tree,

122
00:06:55,000 --> 00:07:00,000
and whenever it gets to this special JavaScript token, it calls the JavaScript interpreter,

123
00:07:00,000 --> 00:07:02,000
which just returns a string.

124
00:07:02,000 --> 00:07:04,000
We got the string from a bunch of calls to document.write().

125
00:07:04,000 --> 00:07:08,000
The HTML interpreter gathers up all the words--words in HTML

126
00:07:08,000 --> 00:07:12,000
or words computed by JavaScript--and just calls the graphics library to display them.

127
00:07:12,000 --> 99:59:59,999
Wow! And then we're done.
