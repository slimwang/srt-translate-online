1
00:00:00,380 --> 00:00:03,719
Thanks Dean. Throughout this lesson and others, Dean will give us more

2
00:00:03,719 --> 00:00:07,850
advice and discuss the big picture when doing EDA. For now, let's

3
00:00:07,850 --> 00:00:10,700
start by loading up some data. You can find a data file

4
00:00:10,700 --> 00:00:14,030
in the instructor notes. This data file contains all the Facebook data

5
00:00:14,030 --> 00:00:16,920
that we're going to be looking at. To load up the data, let's

6
00:00:16,920 --> 00:00:19,526
first make sure that we're in the right directory. Here is my

7
00:00:19,526 --> 00:00:21,970
current directory and I can see that I'm in a folder that

8
00:00:21,970 --> 00:00:25,410
has the data sets. I can use the list.files command to figure

9
00:00:25,410 --> 00:00:28,640
out what that files are within this directory and here is

10
00:00:28,640 --> 00:00:32,600
the data set that I want. The pseudo_facebook data set. To read

11
00:00:32,600 --> 00:00:36,110
in the data set I'm going to use the read.csv command. But

12
00:00:36,110 --> 00:00:38,260
I need to be a little bit careful. I need to indicate

13
00:00:38,260 --> 00:00:41,280
that the separator is really a tab. And that's because we're

14
00:00:41,280 --> 00:00:44,960
working with a tab separated values file. Running the command, I can

15
00:00:44,960 --> 00:00:47,840
see that I get my data set up in R. Now this

16
00:00:47,840 --> 00:00:50,530
data set is similar to the kind that data scientists see from

17
00:00:50,530 --> 00:00:52,900
time to time at Facebook. And it's especially the type

18
00:00:52,900 --> 00:00:55,800
of data that they'll use when doing EDA. This file

19
00:00:55,800 --> 00:01:00,070
has approximately 99,000 rows or observations in it with 15

20
00:01:00,070 --> 00:01:04,030
variables. Each observation represents a user and that user will

21
00:01:04,030 --> 00:01:06,660
have different information such as their age, their name or

22
00:01:06,660 --> 00:01:09,042
their date of birth. We can see all these variables

23
00:01:09,042 --> 00:01:12,760
by running the names command. Now in this entire process

24
00:01:12,760 --> 00:01:17,268
our goal is to understand our user's behavior and their demographics.

25
00:01:17,268 --> 00:01:19,840
We're going to want to understand what they're doing on Facebook

26
00:01:19,840 --> 00:01:22,330
and what they use. This is why you see things

27
00:01:22,330 --> 00:01:27,750
like friend_count, www_likes and mobile_likes. We created this data

28
00:01:27,750 --> 00:01:30,850
set specifically for this course to have many features common

29
00:01:30,850 --> 00:01:34,305
to such user level behavioral and demographic data. But

30
00:01:34,305 --> 00:01:36,615
I need to say that this data isn't actual Facebook

31
00:01:36,615 --> 00:01:39,770
data. So not all statistics in this data set

32
00:01:39,770 --> 00:01:42,610
are going to be accurate representations of how people use Facebook

33
00:01:42,610 --> 00:01:45,310
on a day to day basis. So our lawyers want me

34
00:01:45,310 --> 00:01:48,460
to make the disclaimer that this isn't actual data from Facebook

35
00:01:48,460 --> 00:01:51,480
users. But we did use a complex model to generate it,

36
00:01:51,480 --> 00:01:53,670
and I think we can learn some very interesting things about it.
