1
00:00:00,110 --> 00:00:02,344
So let's keep track of what we're doing.

2
00:00:02,344 --> 00:00:05,173
Version 1 is serial in a single thread,

3
00:00:05,173 --> 00:00:08,280
and it took about 466 milliseconds.

4
00:00:08,280 --> 00:00:10,811
So 466 milliseconds is pretty slow,

5
00:00:10,811 --> 00:00:13,106
but sometimes that's okay.

6
00:00:13,106 --> 00:00:15,034
For code that's only going to be executed once,

7
00:00:15,034 --> 00:00:18,534
code that's not performance critical at all, or code that's going to run on a really small data set,

8
00:00:18,534 --> 00:00:23,793
like that 8 by 8 matrix that we started with, it's just not worthwhile to optimize the heck out of this.

9
00:00:23,793 --> 00:00:27,230
So even though this simple serial kernel may seem very naive,

10
00:00:27,230 --> 00:00:30,166
that's really sometimes the right thing to do,

11
00:00:30,166 --> 00:00:32,269
so keep this in mind when you're optimizing.

12
00:00:32,269 --> 00:00:35,238
Think about what you need to optimize, whether it's important.

13
00:00:35,238 --> 00:00:41,574
Now let's assume that in fact, performance is critical on this section, and that's why we're optimizing it,

14
00:00:41,574 --> 00:00:44,196
and let's go back to the code and see what we can do.

15
00:00:44,196 --> 00:00:48,718
Now one easy step would be to launch 1 thread for each row of the input, okay?

16
00:00:48,718 --> 00:00:51,388
So now here's the code that does that.

17
00:00:51,388 --> 00:00:54,958
In this code, we're going to launch 1 thread per row of the output matrix.

18
00:00:54,958 --> 00:00:59,603
So the value of i is going to be fixed by the thread ID,

19
00:00:59,603 --> 00:01:01,973
and every thread is going to execute

20
00:01:01,973 --> 00:01:06,009
just the outer loop of this code we saw before,

21
00:01:06,009 --> 00:01:11,182
and the inner loop we're essentially handing off to be run across many different threads.

22
00:01:11,182 --> 00:01:13,674
So these 2 codes are almost identical,

23
00:01:13,674 --> 00:01:18,747
and the only difference is that we're launching threads instead of looping over values of i.

24
00:01:18,747 --> 00:01:21,325
Let's time this.

25
00:01:21,325 --> 00:01:23,687
Okay so here's the code for calling our new function.

26
00:01:23,687 --> 00:01:27,086
We're going to launch the function transpose parallel per row as a kernel.

27
00:01:27,086 --> 00:01:30,094
We're going to launch a single thread block consisting of n threads.

28
00:01:30,094 --> 00:01:33,563
Remember, n is the size of our matrix, 1,024, currently.

29
00:01:33,563 --> 00:01:37,831
We're going to pass in the input matrix, pull out the output matrix, copy it,

30
00:01:37,831 --> 00:01:40,702
and then we're going to print out the timing and verify it.

31
00:01:40,702 --> 00:01:42,772
Let's compile and run this code.

32
00:01:42,772 --> 00:01:44,841
Okay.

33
00:01:44,841 --> 00:01:48,478
Transpose serial ran 484 milliseconds again, roughly what we saw before.

34
00:01:48,478 --> 00:01:52,148
Transpose parallel per row is running in 4.7 milliseconds.

35
00:01:52,148 --> 00:01:54,919
So obviously we're making a huge improvement

36
00:01:54,919 --> 00:01:58,869
by parallelizing this just across the threads of a single thread block.

37
00:01:58,869 --> 00:02:00,955
So let's note that down:

38
00:02:00,955 --> 00:02:04,955
4.7 milliseconds, roughly a 100x improvement.
