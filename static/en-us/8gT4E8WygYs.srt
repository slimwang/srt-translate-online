1
00:00:00,910 --> 00:00:01,422
Okay, so

2
00:00:01,422 --> 00:00:05,142
how often can we expect to guess
correctly in a way prediction cache?

3
00:00:05,142 --> 00:00:10,220
We can get an idea for this by looking
at the smaller direct mapped cache.

4
00:00:10,220 --> 00:00:13,720
Basically, let's say we have
a two way set associative cache.

5
00:00:13,720 --> 00:00:17,181
Each set of this cache has two ways,
two lines in it.

6
00:00:17,181 --> 00:00:21,790
And by doing way prediction, we are
effectively using one of these at first.

7
00:00:21,790 --> 00:00:25,430
And only if we don't find it there,
we look at the other one.

8
00:00:25,430 --> 00:00:29,310
So effectively, a way prediction cache

9
00:00:29,310 --> 00:00:33,460
first tries to access what looks
like a smaller direct mapped cache.

10
00:00:33,460 --> 00:00:36,820
Then it will try the entire
set associative cache.

11
00:00:36,820 --> 00:00:41,310
So we can get a pretty good estimate for
the hit rate and hit latency and so

12
00:00:41,310 --> 00:00:45,849
on of a way prediction cache, if we
look at the direct mapped cache and

13
00:00:45,849 --> 00:00:47,730
the set associative cache.

14
00:00:47,730 --> 00:00:52,220
So let's look at the basic 32 kilobyte,
8-way set associative cache.

15
00:00:52,220 --> 00:00:57,660
Let's look at its hit rate, hit latency,
miss penalty, and the over AMAT.

16
00:00:57,660 --> 00:01:00,532
And we will also look at a 32 kilobyte,

17
00:01:00,532 --> 00:01:04,200
8-way set-associative
cache with way prediction.

18
00:01:04,200 --> 00:01:08,530
The hit rate of this cache,
let's say its around 90%.

19
00:01:08,530 --> 00:01:14,070
The hit latency might be 2 cycle
because it's highly associative.

20
00:01:14,070 --> 00:01:16,990
The miss penalty will be 20 cycles,
for example.

21
00:01:18,040 --> 00:01:22,800
And the overall AMAT would then be 2 for
the hit latency,

22
00:01:22,800 --> 00:01:27,640
plus 10% of the time we
have the miss penalty.

23
00:01:27,640 --> 00:01:29,340
And we get 4 here.

24
00:01:29,340 --> 00:01:31,800
Now we already said that way prediction

25
00:01:31,800 --> 00:01:35,670
behaves like accessing only
one of the ways in the cache.

26
00:01:35,670 --> 00:01:38,370
With way prediction in
a 8-way associative cache,

27
00:01:38,370 --> 00:01:42,490
we are really guessing which of the 8
places is going to have the block.

28
00:01:42,490 --> 00:01:46,330
So you effectively, with way prediction,
our first attempt will

29
00:01:46,330 --> 00:01:51,770
be to a 4 kilobyte direct
mapped subset of this cache.

30
00:01:51,770 --> 00:01:55,040
If we look at the normal 4
kilobyte direct mapped cache,

31
00:01:55,040 --> 00:01:59,860
that's going to have, for
example, a 70% hit rate,

32
00:01:59,860 --> 00:02:03,050
but the 1 cycle hit latency,
because it's faster.

33
00:02:03,050 --> 00:02:05,460
And the miss penalty will be the same.

34
00:02:05,460 --> 00:02:09,820
If we now try to get the AMAT for
this basic direct mapped cache,

35
00:02:09,820 --> 00:02:15,715
we will have 1 + 0.3, the miss rate,

36
00:02:15,715 --> 00:02:21,670
times 20, and this is going to
be 1 plus 6 so it gives us 7.

37
00:02:21,670 --> 00:02:26,540
So obviously we are better off with
a 8 way set associative cache.

38
00:02:26,540 --> 00:02:30,220
However, we are paying an extra
cycle each time we access it for

39
00:02:30,220 --> 00:02:36,440
the hit latency in order to get
the low missed penalties here.

40
00:02:36,440 --> 00:02:40,840
With the way prediction cache,
what we're getting is 70% of the time

41
00:02:41,930 --> 00:02:46,100
we're going to find what we're looking
for in the 4 kilobyte subset that we

42
00:02:46,100 --> 00:02:49,620
are checking first and
we will have a 1 cycle latency for that.

43
00:02:49,620 --> 00:02:55,040
In the remaining 20%, we're going to
check the rest of the cache so

44
00:02:55,040 --> 00:02:57,250
our overall hit rate will be 90%.

45
00:02:57,250 --> 00:02:59,520
What we don't find here,

46
00:02:59,520 --> 00:03:03,530
we will still find here if
it's in the 32 kilobyte cache.

47
00:03:04,600 --> 00:03:08,170
So we get a 90% hit rate overall.

48
00:03:08,170 --> 00:03:11,020
Our hit latency is now 1 or 2.

49
00:03:12,330 --> 00:03:15,990
And our miss penalty is 20, so
how do we compute the AMAT?

50
00:03:15,990 --> 00:03:21,480
Well, what we now have
is that 70% of the time,

51
00:03:21,480 --> 00:03:23,704
we find what we are looking for
in one cycle.

52
00:03:23,704 --> 00:03:27,552
The other 30% of the time,
whether we have a hit or

53
00:03:27,552 --> 00:03:31,148
a miss in the 8-way cache,
we have to check it.

54
00:03:31,148 --> 00:03:35,558
So the other 30% of the time we're
checking all of the ways for

55
00:03:35,558 --> 00:03:40,865
which we pay a 2 cycle latency, and
then 10% of the time we don't find what

56
00:03:40,865 --> 00:03:45,786
we are looking for in all of the ways,
so we have to pay the miss penalty.

57
00:03:45,786 --> 00:03:49,455
So now we have what
looks like our hit time.

58
00:03:49,455 --> 00:03:51,288
70% of the time, it's 1.

59
00:03:51,288 --> 00:03:55,154
30% of the time, we have to use a 2, so

60
00:03:55,154 --> 00:04:00,570
we end up having a 1.3
cycle on average hit time.

61
00:04:00,570 --> 00:04:04,980
And a miss penalty of the 8-way
set associative cache

62
00:04:04,980 --> 00:04:06,830
which is still going to be 2.

63
00:04:06,830 --> 00:04:10,980
And this is how we improve things,
we now get an AMAT of 3.3.

64
00:04:10,980 --> 00:04:16,390
Because what we effectively
got was the misses of an 8-way

65
00:04:16,390 --> 00:04:21,050
set associative cache, but
the hit time that is much closer to

66
00:04:21,050 --> 00:04:24,150
a direct mapped cache then it is
to an 8-way set associative cache.
