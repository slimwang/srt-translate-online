1
00:00:00,350 --> 00:00:05,370
Now I can draw the decision boundary, this time in scikit-learn, and voila.

2
00:00:05,370 --> 00:00:06,780
This is what it looks like.

3
00:00:06,780 --> 00:00:10,082
So, you can see immediately, where before in Naive Bayes,

4
00:00:10,082 --> 00:00:14,220
we had something that was a little bit, little bit curvy maybe.

5
00:00:14,220 --> 00:00:17,040
Our SVM decision boundary is now perfectly straight.

6
00:00:17,040 --> 00:00:20,420
And of course, this is the line that's going to give us the maximum margin

7
00:00:20,420 --> 00:00:24,070
between the decision boundary and any misclassified points, so

8
00:00:24,070 --> 00:00:25,790
the points on either side.

9
00:00:25,790 --> 00:00:29,730
So, just to make that a little bit more illustrated on this particular example,

10
00:00:29,730 --> 00:00:31,550
that's, that means that it's going to have,

11
00:00:31,550 --> 00:00:34,450
it's going to maximize all of these distances here.

12
00:00:34,450 --> 00:00:38,040
The points that are nearby the decision boundary, it's going to try and

13
00:00:38,040 --> 00:00:42,000
find a decision boundary where all of these little orange lines are as big as

14
00:00:42,000 --> 00:00:42,570
we can make them.

15
00:00:42,570 --> 00:00:46,140
That means that there's as much separation between the two classes as possible.
