1
00:00:00,000 --> 00:00:05,000
[Thrun] Here is the application of HMM to a real robot localization example.

2
00:00:05,000 --> 00:00:09,000
This robot is in a world that's 1-dimensional and it is lost.

3
00:00:09,000 --> 00:00:12,000
It has initial uncertainty about where it is,

4
00:00:12,000 --> 00:00:16,000
and it is actually located next to a door but it doesn't know.

5
00:00:16,000 --> 00:00:18,000
It's also given a map of the world,

6
00:00:18,000 --> 00:00:24,000
and the distribution of all possible states, here noted as s, is given by this histogram.

7
00:00:24,000 --> 00:00:31,000
We bin the world into small bins, and for each bin we assign a single numerical probability

8
00:00:31,000 --> 00:00:33,000
of the robot being there.

9
00:00:33,000 --> 00:00:37,000
The fact they have all the same height means that the robot is maximally uncertain

10
00:00:37,000 --> 00:00:39,000
as to where it is.

11
00:00:39,000 --> 00:00:41,000
Let's assume this robot is going to sense

12
00:00:41,000 --> 00:00:43,000
and it senses to be next to a door.

13
00:00:43,000 --> 00:00:47,000
The red graph over here is the probability of seeing a door

14
00:00:47,000 --> 00:00:49,000
for different locations in the environment.

15
00:00:49,000 --> 00:00:53,000
There are 3 different doors, and seeing a door is more likely here

16
00:00:53,000 --> 00:00:55,000
than it is in between.

17
00:00:55,000 --> 00:00:58,000
It might still see a door here, but it's just less likely.

18
00:00:58,000 --> 00:01:00,000
We now apply Bayes rule.

19
00:01:00,000 --> 00:01:07,000
We multiply the prior with this measurement probability to obtain the posterior.

20
00:01:07,000 --> 00:01:10,000
That was our measurement update. It's that simple.

21
00:01:10,000 --> 00:01:17,000
So you can see how all these uniform values over here become nonuniform values over here

22
00:01:17,000 --> 00:01:20,000
multiplied by this curve over here.

23
00:01:20,000 --> 00:01:25,000
The story progresses by the robot taking an action to the right,

24
00:01:25,000 --> 00:01:30,000
and this is now the next state prediction part, the what we call convolution part

25
00:01:30,000 --> 00:01:36,000
or state transition part, where these little bumps over here get shifted along with the robot

26
00:01:36,000 --> 00:01:40,000
and they are flattened out a little bit just because robot motion has used uncertainty.

27
00:01:40,000 --> 00:01:43,000
Again, it's a really simple operation.

28
00:01:43,000 --> 00:01:46,000
You shift those to the right and you smooth them out a little bit

29
00:01:46,000 --> 00:01:51,000
to account for the control noise in the robot's actuators.

30
00:01:51,000 --> 00:01:53,000
And now we get to the point that the robot senses again,

31
00:01:53,000 --> 00:01:56,000
and this robot senses a door again.

32
00:01:56,000 --> 00:01:59,000
And see what happens. It multiplies.

33
00:01:59,000 --> 00:02:06,000
It's now a nonuniform prior over here with the same measurement probability as before,

34
00:02:06,000 --> 00:02:09,000
but now we get a distribution that's peaked over here

35
00:02:09,000 --> 00:02:12,000
and has smaller bumps at various other places,

36
00:02:12,000 --> 00:02:17,000
the reason being the only place where my prior has a higher probability

37
00:02:17,000 --> 00:02:21,000
and my measurement probability is also high probability is the second door,

38
00:02:21,000 --> 00:02:24,000
and as a result of our distribution over here, it assumes a much larger value.

39
00:02:24,000 --> 00:02:28,000
If you look at that picture, that is really easy to implement,

40
00:02:28,000 --> 00:02:32,000
and that's what we did all along when we talked about rain and sun and so on.

41
00:02:32,000 --> 00:02:35,000
It's really a very simple algorithm.

42
00:02:35,000 --> 00:02:41,000
Measurements are multiplications, and motion become essentially convolutions

43
00:02:41,000 --> 99:59:59,999
which are shifts with added noise.
