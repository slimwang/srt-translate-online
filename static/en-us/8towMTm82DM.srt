1
00:00:00,284 --> 00:00:03,673
So what are the kind of problems you've looked at recently as you were designing this

2
00:00:03,673 --> 00:00:08,642
where dynamic parallelism really makes a difference either in terms of usability or performance?

3
00:00:08,642 --> 00:00:12,626
>> In terms of usability, obviously, it's simpler to program when you

4
00:00:12,626 --> 00:00:14,958
don't have to keep going backwards and forwards to the CPU.

5
00:00:14,958 --> 00:00:21,958
So any kind of problem which dynamically discovers the work as it goes--iteratively works it's way through something.

6
00:00:21,958 --> 00:00:24,127
Imagine you're constructing a tree.

7
00:00:24,127 --> 00:00:29,369
You're partitioning something into an Octree, which is a common 3D spatial problem.

8
00:00:29,369 --> 00:00:35,138
You don't necessarily know how many objects are going into which part of your tree

9
00:00:35,138 --> 00:00:37,914
until you reach that point in your tree.

10
00:00:37,914 --> 00:00:41,676
So typically the approach would be to do this level by level by level

11
00:00:41,676 --> 00:00:45,120
which is not the most balanced way of doing things necessarily.

12
00:00:45,120 --> 00:00:49,052
So as you discover the type of work that you need to do,

13
00:00:49,052 --> 00:00:52,160
the ability to simply launch that work is much, much simpler.

14
00:00:52,160 --> 00:00:56,660
We were very motivated by irregular parallelism, if you like;

15
00:00:56,660 --> 00:01:00,335
problems which did not have nice, well-balanced things.

16
00:01:00,335 --> 00:01:05,870
A similar sort of category or problem to that is task parallelism

17
00:01:05,870 --> 00:01:12,042
where I might be wanting not just to do one thing that fills my whole GPU, which is often difficult.

18
00:01:12,042 --> 00:01:15,178
Now the GPUs these days are a teraflop of performance.

19
00:01:15,178 --> 00:01:20,791
It might be much easier to have half a dozen or a dozen things running on my GPU at a time,

20
00:01:20,791 --> 00:01:24,962
and so if each of these can autonomously make forward progress,

21
00:01:24,962 --> 00:01:27,588
it's much easier to manage them if they're just managing themselves

22
00:01:27,588 --> 00:01:32,128
instead of having my CPU now juggle 12 different different things instead of just 1.

23
00:01:32,128 --> 00:01:38,535
And finally there's the there's the new type of algorithm that you can approach.

24
00:01:38,535 --> 00:01:40,937
You can approach recursive types of algorithm--

25
00:01:40,937 --> 00:01:45,175
things where the category is generally the divide and conquer algorithm,

26
00:01:45,175 --> 00:01:49,443
where you take all of the work that you need to do,

27
00:01:49,443 --> 00:01:53,117
and you conquer it by subdividing and subdividing and subdividing repeatedly,

28
00:01:53,117 --> 00:01:55,952
and a typical example would be quicksort, for example--

29
00:01:55,952 --> 00:02:01,290
a well-known problem where you take your data that you want to sort

30
00:02:01,290 --> 00:02:06,364
and recursively you progress through the data until you end up with a final sorted data set.

31
00:02:06,364 --> 00:02:09,598
>> So 1 of the demos you guys showed when you launched this

32
00:02:09,598 --> 00:02:12,435
was N body simulation interstellar,

33
00:02:12,435 --> 00:02:18,372
a bunch of stars moving around, being attracted to each other with gravity.

34
00:02:18,372 --> 00:02:25,249
And so, with dynamic parallelism, you were able to write that in a way that you hadn't written it before.

35
00:02:25,249 --> 00:02:28,686
So how did that come about--like, what was the cool thing you could do with it?

36
00:02:28,686 --> 00:02:31,922
>> I mentioned octree spatial partitioning just now,

37
00:02:31,922 --> 00:02:34,824
and that is a key component of an N body simulation.

38
00:02:34,824 --> 00:02:39,798
So the way that you approach an N body simulation with a very large number of bodies

39
00:02:39,798 --> 00:02:42,932
is instead of doing an all to all comparison

40
00:02:42,932 --> 00:02:46,600
where you just calculate the gravity between all the bodies--

41
00:02:46,600 --> 00:02:49,003
so for N bodies that's an N squared problem.

42
00:02:49,003 --> 00:02:51,474
You can cut down the complexity of the problem

43
00:02:51,474 --> 00:02:54,804
to an N log N or an order of an N problem

44
00:02:54,804 --> 00:03:01,252
by partitioning things into space, doing a local interaction of gravity between your close neighbors,

45
00:03:01,252 --> 00:03:05,155
and doing an approximation to a center of mass at a more distant neighbor.

46
00:03:05,155 --> 00:03:11,384
To do this, you build an octree, partitioning your bodies up into small octans, little cubes.

47
00:03:11,384 --> 00:03:15,104
Everyone inside your cube, you do the N squared problem,

48
00:03:15,104 --> 00:03:21,567
and for all of the other cubes you then only have an order of an N expansion for.

49
00:03:21,567 --> 00:03:26,576
So what we did with dynamic parallelism in this N4 body problem

50
00:03:26,576 --> 00:03:32,249
was we optimize the tree build which is about half of the time in the whole simulation.

51
00:03:32,249 --> 00:03:35,895
We optimize the tree build by using this recursive property

52
00:03:35,895 --> 00:03:39,456
by using this irregular parallelism ability

53
00:03:39,456 --> 00:03:44,591
where the tree might--in the case of a galaxy of stars, for example, might be very, very dense in some regions

54
00:03:44,591 --> 00:03:48,129
and very, very sparse in others to much more efficiently build the tree.

55
00:03:48,129 --> 00:03:50,941
So instead of building the tree level by level by level

56
00:03:50,941 --> 00:03:57,070
so that you're wasting work building the tree for areas of where the bodies are sparse,

57
00:03:57,070 --> 00:04:00,343
you focus the compute performance on the area where you need it.

58
00:04:00,343 --> 00:04:02,977
>> Could you have done this without dynamic parallelism?

59
00:04:02,977 --> 00:04:06,516
>> Yes, I guess you could,

60
00:04:06,516 --> 00:04:10,820
but the overhead of moving backwards and forwards between the CPU and GPU

61
00:04:10,820 --> 00:04:14,000
would probably have negated the performance gain that we got.
