1
00:00:00,180 --> 00:00:02,772
We know that there are going to be N source elements,

2
00:00:02,772 --> 00:00:05,428
and we're going to have the same N destination elements.

3
00:00:05,428 --> 00:00:09,016
So for any particular source element, say X here,

4
00:00:09,016 --> 00:00:15,425
we must fetch that source element for each individual computation for every destination element,

5
00:00:15,425 --> 00:00:17,721
and for a particular destination element,

6
00:00:17,721 --> 00:00:22,627
we know that we have to fetch the parameters for each individual source element.

7
00:00:22,627 --> 00:00:27,478
So overall we have to fetch each element N times as the source and N times as the destination,

8
00:00:27,478 --> 00:00:31,574
or if we assume that an object does not exert any force on itself,

9
00:00:31,574 --> 00:00:34,879
then we'd fetch each element N minus 1 for each of the source or destination.

10
00:00:34,879 --> 00:00:40,125
The answer should be either 2N or 2N minus 2 times; This is quite expensive.

11
00:00:40,125 --> 00:00:44,681
We'd really like to organize the computation in such a way that we consume less global memory bandwidth,

12
00:00:44,681 --> 00:00:48,318
and we're going to try to do this by storing and reusing some of these memory fetches,

13
00:00:48,318 --> 00:00:51,605
and in particular, we'd like to be able to take advantage of the GPU's ability

14
00:00:51,605 --> 00:00:54,487
to share data between neighboring threads.
