1
00:00:00,120 --> 00:00:05,230
There're several ways of how we can deal with visuospatial knowledge.

2
00:00:05,230 --> 00:00:08,460
In fact in your projects you've already come across some of them. So imagine

3
00:00:08,460 --> 00:00:13,190
there is a figure here. Here is a triangle with the apex facing to the right.

4
00:00:13,190 --> 00:00:17,400
Here is another triangle with the apex facing to the left. So in one view,

5
00:00:17,400 --> 00:00:22,550
the AI agent can extract propositional representations out of figures like this.

6
00:00:22,550 --> 00:00:25,680
And similarly propositional representations out of figures like this. So

7
00:00:25,680 --> 00:00:29,180
this is a propositional representation, this is a propositional representation.

8
00:00:29,180 --> 00:00:33,150
And then, the AI agent can work on these propositional representations to

9
00:00:33,150 --> 00:00:37,070
produce new propositional representations. So some AI agent can

10
00:00:37,070 --> 00:00:41,840
use a logic engine or a production rule to say that this particular triangle,

11
00:00:41,840 --> 00:00:46,740
which was rotated 90 degrees, has not been rotated to 270 degrees. So

12
00:00:46,740 --> 00:00:51,140
although the input wasn't in formula's figures, the action here was at the level

13
00:00:51,140 --> 00:00:55,850
of propositional representations of these figures. The agent may extract

14
00:00:55,850 --> 00:00:59,410
propositional representations like this through image processing, through image

15
00:00:59,410 --> 00:01:04,038
segmentation, perhaps using some techniques like constraint propagation as well.

16
00:01:04,038 --> 00:01:08,610
Alternatively, the agent may have analogical representations.

17
00:01:08,610 --> 00:01:10,440
In these analogical representations,

18
00:01:10,440 --> 00:01:13,930
it is a structural correspondence between the representation and

19
00:01:13,930 --> 00:01:17,900
the external figure. So the external world headed triangle like this, and

20
00:01:17,900 --> 00:01:22,650
the analogical representation will also have a triangle like this. Notice that

21
00:01:22,650 --> 00:01:25,640
I'm using the term Analogical Representation, we use a separate thing from

22
00:01:25,640 --> 00:01:29,465
analogical reasoning. We are not talking about analogical reasoning right now.

23
00:01:29,465 --> 00:01:33,370
We're talking about analogical representation and analogical representation is

24
00:01:33,370 --> 00:01:37,630
one, which is some structural correspondence with the external world that is

25
00:01:37,630 --> 00:01:42,490
being represented. Give a certain analogical representation, then I might want

26
00:01:42,490 --> 00:01:46,910
affine transformations or set transformations to get this. So I may say that I

27
00:01:46,910 --> 00:01:50,510
got this triangle out of that one, simply by the operation of reflection or

28
00:01:50,510 --> 00:01:55,130
rotation. So these proposed representations in the previous view are A model.

29
00:01:55,130 --> 00:02:00,120
They are separated from, divorced from the perceptual modality.

30
00:02:00,120 --> 00:02:02,220
These analogical representations on the other hand,

31
00:02:02,220 --> 00:02:06,910
are modal representations. They're very close to the perceptual modality.

32
00:02:06,910 --> 00:02:13,370
And human cognition, mental imagery, appears to use analogical representations.

33
00:02:13,370 --> 00:02:16,640
What would be an equally intuitive of computational imagery?

34
00:02:16,640 --> 00:02:20,850
Human cognition is very good at using both propositional representations and

35
00:02:20,850 --> 00:02:25,110
analogical representations. Computers however, are not yet

36
00:02:25,110 --> 00:02:29,020
good at using analogical representations. Most computers, most of the time,

37
00:02:29,020 --> 00:02:33,730
use only prepositional presentations. The same kind of analysis may apply to

38
00:02:33,730 --> 00:02:38,240
other perceptual modalities, not just to our visual images. So here are two

39
00:02:38,240 --> 00:02:42,350
measures and we can either extract proposed representations out of them and

40
00:02:42,350 --> 00:02:46,590
then analyze those propositional representations. Or, we could think directly

41
00:02:46,590 --> 00:02:50,080
with the relationship in these two particular measures. There is a question for

42
00:02:50,080 --> 00:02:53,870
building queries of human cognition. When you're driving a car, and

43
00:02:53,870 --> 00:02:57,930
you listen to a melody on your radio and you're reminded of something.

44
00:02:57,930 --> 00:03:00,840
Reminded of a similar melody that you had heard earlier.

45
00:03:00,840 --> 00:03:04,093
What exactly is happening? Are you extracting a purpose for

46
00:03:04,093 --> 00:03:08,050
your presentation out of the melody that you just heard? And then

47
00:03:08,050 --> 00:03:12,710
the proposition representation reminds you of the proposition representation for

48
00:03:12,710 --> 00:03:18,300
a previously heard melody. Or, does a new melody somehow directly remind

49
00:03:18,300 --> 00:03:22,490
you of a previously heard melody without any intermediate propositional

50
00:03:22,490 --> 00:03:26,980
representation? These are our open issues in cognitive science,

51
00:03:26,980 --> 00:03:31,660
as well as in knowledge based AI. In cognitive science, it is by now,

52
00:03:31,660 --> 00:03:37,230
significant agreement that human cognition does use mental imagery at least

53
00:03:37,230 --> 00:03:41,750
with visual images. But we don't know how to do mental imagery in computers.
