1
00:00:00,240 --> 00:00:02,300
So we have two threads, T1 and T2.

2
00:00:02,300 --> 00:00:08,640
They need to perform some operation involving some variables, A and B.

3
00:00:08,640 --> 00:00:11,710
And, in fact, the two threads don't even need to perform the same

4
00:00:11,710 --> 00:00:13,810
operation on A and B.

5
00:00:13,810 --> 00:00:18,250
But let's say they both need to access these shared variables, A and B.

6
00:00:18,250 --> 00:00:20,770
Before performing these operations,

7
00:00:20,770 --> 00:00:24,970
they must lock mutexes that protect the shared variables A and B.

8
00:00:26,030 --> 00:00:32,299
And let's say T1 first locks the mutex for A and then locks the mutex for B.

9
00:00:33,340 --> 00:00:34,750
And in the case of T2,

10
00:00:34,750 --> 00:00:39,280
T2 first locks the mutex for B and then locks the mutex for A.

11
00:00:39,280 --> 00:00:41,130
And this is where the problem is.

12
00:00:41,130 --> 00:00:45,280
The two threads are waiting on each other in a cycle.

13
00:00:45,280 --> 00:00:48,920
Neither one of them will be able to get to the foo operation.

14
00:00:48,920 --> 00:00:50,200
Neither one of them, in fact,

15
00:00:50,200 --> 00:00:53,160
will be able to execute this second lock operation.

16
00:00:53,160 --> 00:00:55,050
They'll keep waiting on each other.

17
00:00:55,050 --> 00:00:56,390
And we'll have a dead lock.

18
00:00:56,390 --> 00:00:58,900
So how can we avoid these situations?

19
00:00:58,900 --> 00:01:03,130
One way to avoid this situation would be to unlock the mutex for

20
00:01:03,130 --> 00:01:06,120
A before locking the mutex for B, or the other way around.

21
00:01:06,120 --> 00:01:09,130
We would call this fine-grained locking.

22
00:01:09,130 --> 00:01:11,270
The problem with this is that,

23
00:01:11,270 --> 00:01:15,260
it won't work in this case since the threads need both A and B.

24
00:01:15,260 --> 00:01:18,150
So, they have to have both locks.

25
00:01:18,150 --> 00:01:20,280
They need both variables, after all.

26
00:01:20,280 --> 00:01:23,800
Another possibility would be to get all the locks up front and

27
00:01:23,800 --> 00:01:26,180
then release them at the very end.

28
00:01:26,180 --> 00:01:31,640
Or maybe we just end up using one mega-lock, some mutex m sub A,B.

29
00:01:31,640 --> 00:01:34,530
This solution may work for some applications.

30
00:01:34,530 --> 00:01:38,363
However, in other cases it can be very restrictive because it

31
00:01:38,363 --> 00:01:43,154
limits the level of parallelism that can exist in the system, and the last and

32
00:01:43,154 --> 00:01:47,700
the really most accepted solution is to maintain a lock order.

33
00:01:47,700 --> 00:01:52,600
If we force everyone to first get the mutex for A and then the lock for

34
00:01:52,600 --> 00:01:55,240
B, the problem will not occur.

35
00:01:55,240 --> 00:01:57,760
If we investigate this a little bit more,

36
00:01:57,760 --> 00:02:03,690
we see that the problem is that T1 is waiting on something that T2 has.

37
00:02:03,690 --> 00:02:06,120
And T2's waiting on something that T1 has.

38
00:02:06,120 --> 00:02:09,490
So we have a cycle basically.

39
00:02:09,490 --> 00:02:12,730
And in this case, we have two threads, so

40
00:02:12,730 --> 00:02:18,260
it's easy to reason about the situation and to determine that the order

41
00:02:18,260 --> 00:02:23,080
in which these locks are being acquired can result potentially in a cycle.

42
00:02:23,080 --> 00:02:27,230
In principle, this type of analysis is a little bit more difficult to illustrate

43
00:02:27,230 --> 00:02:33,370
than to determine, but what we're trying to really show is that if there is

44
00:02:33,370 --> 00:02:40,080
a cycle in this kind of wave graph in which we draw a line between two threads.

45
00:02:40,080 --> 00:02:44,310
If one thread is waiting on a resource that the other thread has,

46
00:02:44,310 --> 00:02:47,700
then a cycle indicates a dead lock.

47
00:02:47,700 --> 00:02:52,920
Maintaining a lock order will prevent such cycles from occurring.

48
00:02:52,920 --> 00:02:57,560
So will ensure that there will be no deadlocks in the code.

49
00:02:57,560 --> 00:03:03,880
So to enforce this kind of maintain lock order principle in the example before,

50
00:03:03,880 --> 00:03:08,480
T2 would have to get the mutexes, the mutex for A first and then the mutex for

51
00:03:08,480 --> 00:03:13,200
B, and there no way that in that, in this code a cycle would occur.

52
00:03:13,200 --> 00:03:15,490
There's no way that a deadlock can happen.

53
00:03:15,490 --> 00:03:16,665
So, consider this.

54
00:03:16,665 --> 00:03:22,630
If thread 1 is waiting on the lock, is about to execute the operation lock

55
00:03:22,630 --> 00:03:28,768
m of B, it means it already has acquire the mutex m of A.

56
00:03:28,768 --> 00:03:33,280
If thread 1 already has this mutex then thread two cannot have it.

57
00:03:33,280 --> 00:03:39,360
So, thread two must be somewhere before this lock operation and its execution.

58
00:03:39,360 --> 00:03:44,060
That also means that thread 2 could not have acquired the m_b mutex,

59
00:03:44,060 --> 00:03:46,850
it doesn't have it, and therefore there's no cycle.

60
00:03:46,850 --> 00:03:51,020
Thread 1 is not going to end up in a situation in which it has to

61
00:03:51,020 --> 00:03:53,960
wait on thread 2 for that particular lock.

62
00:03:53,960 --> 00:03:56,320
So it will be able to acquire it and continue.

63
00:03:56,320 --> 00:03:59,020
So this type of technique will always work.

64
00:03:59,020 --> 00:04:03,400
The only potential challenge is that in complex programs that

65
00:04:03,400 --> 00:04:07,490
use many shared variables and potentially many synchronization variables, so

66
00:04:07,490 --> 00:04:12,740
lots of mutexes, take some effort to make sure that these are indeed ordered.

67
00:04:12,740 --> 00:04:14,920
And everywhere used in the same order.

68
00:04:14,920 --> 00:04:16,870
But as a technique this is foolproof.

69
00:04:16,870 --> 00:04:20,240
And it guarantees that it will prevent deadlocks from happening.
