1
00:00:00,168 --> 00:00:02,732
Now that we have seen
what DRAM looks like,

2
00:00:02,732 --> 00:00:06,590
let's briefly look at how to
connect the DRAM to the processor.

3
00:00:06,590 --> 00:00:08,112
So we have our processor.

4
00:00:08,112 --> 00:00:12,783
It sends its requests to level one
cache, which sends its misses and write

5
00:00:12,783 --> 00:00:17,604
back requests to the larger level two
cache, which might send its misses and

6
00:00:17,604 --> 00:00:21,295
write back requests to in even
larger level three cache and

7
00:00:21,295 --> 00:00:25,320
let's say that these are all
on our processor chip.

8
00:00:25,320 --> 00:00:27,420
Now what happens is the misses and

9
00:00:27,420 --> 00:00:32,409
the write back requests from the L3
cache would be made over and

10
00:00:32,409 --> 00:00:37,180
external connection, so
we need processor pins here.

11
00:00:37,180 --> 00:00:43,110
And traditionally, this data would go
over what is called a front-side bus.

12
00:00:43,110 --> 00:00:45,808
Now you want to design
the processor chip, so

13
00:00:45,808 --> 00:00:48,865
that you can connect it to
many possible memories.

14
00:00:48,865 --> 00:00:53,495
So you don't design the front-side bus,
such that it supplies

15
00:00:53,495 --> 00:00:58,222
the row address and a column address and
so on to the memory chips.

16
00:00:58,222 --> 00:01:03,167
What you have instead is another chip
that contains the memory controller and

17
00:01:03,167 --> 00:01:08,114
that memory controller will have what's
called a memory channel connecting

18
00:01:08,114 --> 00:01:09,423
it to a DRAM module.

19
00:01:09,423 --> 00:01:13,578
And over this channel,
it will issue things like open a row,

20
00:01:13,578 --> 00:01:15,786
read something, get the data.

21
00:01:15,786 --> 00:01:17,369
Write something, supply the data.

22
00:01:17,369 --> 00:01:19,836
Close or open another one and so on and

23
00:01:19,836 --> 00:01:23,585
it will usually have more
than one such memory channel.

24
00:01:23,585 --> 00:01:28,382
So the memory latency is seen by
the level three cache is not only

25
00:01:28,382 --> 00:01:31,820
the access time of
the memory are right here,

26
00:01:31,820 --> 00:01:36,182
it includes sending the request
over a front-side bus.

27
00:01:36,182 --> 00:01:39,493
Having the memory
controller figure it out,

28
00:01:39,493 --> 00:01:42,991
sending the page open to
the appropriate DRAM.

29
00:01:42,991 --> 00:01:48,598
Sending a request to read, supplying
the column addresses and everything.

30
00:01:48,598 --> 00:01:51,470
Getting the data over
the memory channel,

31
00:01:51,470 --> 00:01:54,429
know that you have
a level three cache miss.

32
00:01:54,429 --> 00:01:58,962
That means you want a whole cache
line worth of data to read, so

33
00:01:58,962 --> 00:02:02,109
it takes a while to
transfer the data here.

34
00:02:02,109 --> 00:02:06,335
Then the memory controller reads
it from the memory channel,

35
00:02:06,335 --> 00:02:09,018
which usually has one bus frequency and

36
00:02:09,018 --> 00:02:14,462
sends it at a different data rate over
to front-side bus to the processor chip,

37
00:02:14,462 --> 00:02:18,626
which then puts the line together and
puts it into L3 cache.

38
00:02:18,626 --> 00:02:25,163
So the latency includes all of this
here in addition to just the memory

39
00:02:25,163 --> 00:02:32,054
access and this can be a significant
part of the overall memory latency.

40
00:02:32,054 --> 00:02:38,261
So recent processor chips integrate
the memory controller, which means that

41
00:02:38,261 --> 00:02:44,383
the memory controller is put on the same
chip as the processor and the caches.

42
00:02:44,383 --> 00:02:49,703
Now we no longer need the front-side
bus, we can use lots of unshaped

43
00:02:49,703 --> 00:02:54,307
wiring to communicate with
the on chip memory controller.

44
00:02:54,307 --> 00:02:58,327
So this can be plenty of bandwidth and
very, very close.

45
00:02:58,327 --> 00:03:02,751
This whole thing is something
like two by two centimeters and

46
00:03:02,751 --> 00:03:08,145
then we just send requests directly
through the memory channels to DRAM.

47
00:03:08,145 --> 00:03:12,294
So now the processor chip directly
knows how to talk to DRAM's and

48
00:03:12,294 --> 00:03:17,282
open pages and so on, which dramatically
can reduce this part of the latency.

49
00:03:17,282 --> 00:03:21,427
And because it's not a negligible
part of the overall latency,

50
00:03:21,427 --> 00:03:24,353
we get our data from
dram a little bit faster.

51
00:03:24,353 --> 00:03:29,258
Actually, 10,
20 maybe 30% faster than before,

52
00:03:29,258 --> 00:03:31,958
but the cost of that is that now,

53
00:03:31,958 --> 00:03:37,082
we design a processor chip to
talk to a specific kind of DRAM.

54
00:03:37,082 --> 00:03:38,605
And because of that,

55
00:03:38,605 --> 00:03:43,606
we need a relatively high degree of
standardization of DRAM modules.

56
00:03:43,606 --> 00:03:48,470
So that, for example, when we go from 2
gigabytes to 4 gigabyte memory modules,

57
00:03:48,470 --> 00:03:50,979
we don't have to
redesign our whole chip.

58
00:03:50,979 --> 00:03:55,778
So the protocols here, got a lot
more standardized and uniform and

59
00:03:55,778 --> 00:03:57,501
flexible than before.

60
00:03:57,501 --> 00:04:01,526
But in exchange, we get to transfer data
very quickly between the processor and

61
00:04:01,526 --> 00:04:03,140
the memory controller.

62
00:04:03,140 --> 00:04:06,280
We can make the memory
controller now very smart and

63
00:04:06,280 --> 00:04:08,850
then access memory in
a more efficient way.
