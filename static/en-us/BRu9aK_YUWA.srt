1
00:00:00,350 --> 00:00:06,730
I mentioned that any system design should be simple. And power of simplicity

2
00:00:06,730 --> 00:00:12,000
is the key for adoption. So in this case, let's revisit the sequential program

3
00:00:12,000 --> 00:00:13,740
for video analytics that I showed

4
00:00:13,740 --> 00:00:17,530
you earlier. Converting the sequential program for

5
00:00:17,530 --> 00:00:21,250
video analytics into a distributed program, using

6
00:00:21,250 --> 00:00:25,550
the get put primitives, provided by PTS,

7
00:00:25,550 --> 00:00:28,660
is fairly straightforward. What you do

8
00:00:28,660 --> 00:00:34,190
is, you interpose between these computations,

9
00:00:34,190 --> 00:00:39,860
that are there in the original pipeline, channels that are named entities

10
00:00:39,860 --> 00:00:45,030
that can be used to hold the temporal evolution of output

11
00:00:45,030 --> 00:00:50,460
from a particular computation. So in this case, camera capture is a thread,

12
00:00:50,460 --> 00:00:54,280
and this capture computation captures images from

13
00:00:54,280 --> 00:00:56,900
a camera with a certain periodicity. And

14
00:00:56,900 --> 00:00:59,090
places it into a name channel called

15
00:00:59,090 --> 00:01:03,002
frames, and so the frames channel abstraction is

16
00:01:03,002 --> 00:01:05,850
going to contain the temporal evolution of

17
00:01:05,850 --> 00:01:09,570
output produced by this capture computation. And

18
00:01:09,570 --> 00:01:13,340
the detector can discover where this frame

19
00:01:13,340 --> 00:01:16,390
channel is, connect to it, and get images

20
00:01:16,390 --> 00:01:21,060
from this channel, process them and produce

21
00:01:21,060 --> 00:01:25,030
blobs that characterize the objects that it

22
00:01:25,030 --> 00:01:28,780
sees in any particular given frame. So

23
00:01:28,780 --> 00:01:31,220
this is a temporal evolution of the detector's

24
00:01:31,220 --> 00:01:33,320
output corresponding to the frames that it

25
00:01:33,320 --> 00:01:36,880
sees. And the tracker takes these blobs.

26
00:01:36,880 --> 00:01:38,980
And interesting blobs from that are the

27
00:01:38,980 --> 00:01:42,430
objects that it is tracking and it produces

28
00:01:42,430 --> 00:01:47,420
a temporal evolution of the location of objects that it sees and

29
00:01:47,420 --> 00:01:52,560
places it in its output channel and a recognizer may then look at these

30
00:01:52,560 --> 00:01:57,740
objects and consults. A database of known objects to see

31
00:01:57,740 --> 00:02:02,690
whether any of those objects that are being continuously

32
00:02:02,690 --> 00:02:08,050
captured, detected, and tracked, correspond to anything

33
00:02:08,050 --> 00:02:11,000
that may indicate that there's an anomalous

34
00:02:11,000 --> 00:02:13,600
situation. And those are the events that it

35
00:02:13,600 --> 00:02:16,225
produces, and those events may trigger an

36
00:02:16,225 --> 00:02:18,840
alarm. So basically, what, what I'm showing you

37
00:02:18,840 --> 00:02:23,970
here is converting the sequential program for video analytics into a

38
00:02:23,970 --> 00:02:28,920
distributed program using the channel abstraction and the get/put primitive

39
00:02:28,920 --> 00:02:34,100
available in the PTS programming model. So the ovals

40
00:02:34,100 --> 00:02:39,670
are the threads of the PTS abstraction and these rectangles

41
00:02:39,670 --> 00:02:45,020
are the channels that are there between any two computational entities.
