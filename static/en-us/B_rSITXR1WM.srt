1
00:00:00,070 --> 00:00:03,350
Okay, answer number one, it's not, this is a trick question. It's actually

2
00:00:03,350 --> 00:00:07,080
not a trick question. Multiple app servers means multiple caches, and so we

3
00:00:07,080 --> 00:00:10,100
have to keep them in sync. Yes, that is one source of problems

4
00:00:10,100 --> 00:00:12,670
we are going to face. You know, we have multiple app servers, let's

5
00:00:12,670 --> 00:00:15,880
draw a picture, and we've got our database. And say both of these

6
00:00:15,880 --> 00:00:18,350
guys have their little caches here, you know, let's say both of these

7
00:00:18,350 --> 00:00:21,590
caches are, are, both of these caches are one, they've got their stuff.

8
00:00:21,590 --> 00:00:25,440
Let's say, a database, you know, a POST comes in here that, the results

9
00:00:25,440 --> 00:00:28,890
in a database write, which results in a, in a refreshing of

10
00:00:28,890 --> 00:00:31,910
the cache. Now we got one up server with an up-to-date cache and

11
00:00:31,910 --> 00:00:34,260
another up server with an out-of-date cache. And so if the read

12
00:00:34,260 --> 00:00:38,520
comes in to here We're going to get stale cache. And that's no good.

13
00:00:38,520 --> 00:00:40,640
So we gotta figure figure out a way of keeping these caches

14
00:00:40,640 --> 00:00:43,360
in sync. Each app server may have to hit the database to update

15
00:00:43,360 --> 00:00:46,380
its cache. You know, this is a problem. Let's say the situation

16
00:00:46,380 --> 00:00:50,570
is neither, both of these caches are cold, they're empty. And two read

17
00:00:50,570 --> 00:00:54,010
requests come in, or many read requests come in. This is similar

18
00:00:54,010 --> 00:00:56,820
to the cache stampede problem, where Each of these app servers is

19
00:00:56,820 --> 00:00:58,900
going to want to update its cache which means it's going to have to

20
00:00:58,900 --> 00:01:02,600
hit the database. So that's problematic as well. Now of course we can

21
00:01:02,600 --> 00:01:06,065
alleviate, you know, some of these problems by updating the cache on

22
00:01:06,065 --> 00:01:08,470
writes, but we'd still have to find a way of, you know,

23
00:01:08,470 --> 00:01:12,290
keeping these guys in sync with one another which is a little

24
00:01:12,290 --> 00:01:13,660
tedious. And the final answer we'll

25
00:01:13,660 --> 00:01:15,800
be caching data redundantly. I'm not accepting

26
00:01:15,800 --> 00:01:19,410
that one in this quiz as a bad thing because very often

27
00:01:19,410 --> 00:01:22,200
you do cache data redundantly. That's kind of what a cache is. Right?

28
00:01:22,200 --> 00:01:25,260
You're storing data redundantly and, and I'm actually torn and, and whether

29
00:01:25,260 --> 00:01:27,420
this should be considered a down time or a plus side or kind

30
00:01:27,420 --> 00:01:30,350
of neutral. But, for our purposes, we want to focus on, on these

31
00:01:30,350 --> 00:01:33,440
problems, which is keeping these caches in sync and limiting the number of

32
00:01:33,440 --> 00:01:37,640
database requests we do. Now, the solution we're going to approach here is

33
00:01:37,640 --> 00:01:38,900
going to change this architecture a little

34
00:01:38,900 --> 00:01:40,850
bit. Instead of each app server having

35
00:01:40,850 --> 00:01:43,890
its own cache, we're going to move caching into its

36
00:01:43,890 --> 00:01:48,000
own process. And so now, both these app servers will

37
00:01:48,000 --> 00:01:51,790
use a shared cache. And so, this cache actually behaves

38
00:01:51,790 --> 00:01:53,740
very similar to the database except the queries are much

39
00:01:53,740 --> 00:01:57,110
simpler. They're just key value pairs, and it's probably only

40
00:01:57,110 --> 00:02:00,790
in memory, and there's technology designed. Specifically to solve this

41
00:02:00,790 --> 00:02:03,420
problem. Which is to be fast and used as a

42
00:02:03,420 --> 00:02:06,080
cache. Which is different from a database which is designed

43
00:02:06,080 --> 00:02:07,680
to you know run complex queries on huge

44
00:02:07,680 --> 00:02:10,484
amounts of data. This piece of technology is called

45
00:02:10,484 --> 00:02:12,848
memchached. And we're going to be spending basically the

46
00:02:12,848 --> 00:02:14,780
rest of this lecture learning how to use memchached.
