1
00:00:00,000 --> 00:00:03,000
So let's really think about what we're doing when we're executing

2
00:00:03,000 --> 00:00:05,000
the active TD learning algorithm.

3
00:00:05,000 --> 00:00:09,000
First, we're keeping track of the optimal policy we've found so far;

4
00:00:09,000 --> 00:00:11,000
and that gets updated as we go,

5
00:00:11,000 --> 00:00:13,000
and replaced with new policies.

6
00:00:13,000 --> 00:00:17,000
Secondly, we're keeping track of the utilities of states--

7
00:00:17,000 --> 00:00:20,000
and those, too, get updated as we go along.

8
00:00:20,000 --> 00:00:23,000
And third, we're keeping track of the number

9
00:00:23,000 --> 00:00:26,000
of times that we visited each state.

10
00:00:26,000 --> 00:00:28,000
And that gets incremented on each trial.

11
00:00:28,000 --> 00:00:30,000
Now, what could happen? What could go wrong?

12
00:00:30,000 --> 00:00:32,000
There are really 2 reasons

13
00:00:32,000 --> 00:00:36,000
why our utility estimates could be off.

14
00:00:36,000 --> 00:00:39,000
First, we haven't sampled enough.

15
00:00:39,000 --> 00:00:42,000
The end values are too low for that state

16
00:00:42,000 --> 00:00:44,000
and the utilities that we got were just some

17
00:00:44,000 --> 00:00:46,000
random fluctuations and weren't

18
00:00:46,000 --> 00:00:48,000
a very good, true estimate.

19
00:00:48,000 --> 00:00:51,000
And secondly, we could get a bad utility

20
00:00:51,000 --> 00:00:53,000
because our policy was off.

21
00:00:53,000 --> 00:00:57,000
The policy was telling us to do something that wasn't really the best thing,

22
00:00:57,000 --> 00:01:00,000
and so the utility wasn't as high as it could be.

23
00:01:00,000 --> 00:01:02,000
So let's do a little quiz.

24
00:01:02,000 --> 00:01:06,000
I want you to tell me, for the 2 sources of possible error--

25
00:01:06,000 --> 00:01:09,000
too little sampling and wrong policy--

26
00:01:09,000 --> 00:01:13,000
I want you to tell me, is it True or False--each of these statements:

27
00:01:13,000 --> 00:01:19,000
One: Could the error--either the sampling error or the policy error--

28
00:01:19,000 --> 00:01:23,000
could that make the utility estimates too low?

29
00:01:23,000 --> 00:01:29,000
And secondly, could it make utility too high?

30
00:01:29,000 --> 99:59:59,999
And third, could it be improved with higher N values--that is, more trials?
