1
00:00:00,000 --> 00:00:02,490
you might think of GPUs as devices built

2
00:00:02,490 --> 00:00:04,169
for rendering graphically intensive

3
00:00:04,169 --> 00:00:06,839
video games and that's true but gpus

4
00:00:06,839 --> 00:00:08,160
have also become extraordinarily

5
00:00:08,160 --> 00:00:10,949
important for deep learning GPUs are

6
00:00:10,949 --> 00:00:12,058
optimized for high-throughput

7
00:00:12,058 --> 00:00:15,179
computation whereas CPUs are mostly

8
00:00:15,179 --> 00:00:17,609
optimized for latency running a single

9
00:00:17,609 --> 00:00:19,050
threat of instructions as quickly as

10
00:00:19,050 --> 00:00:20,100
possible

11
00:00:20,100 --> 00:00:21,809
GPUs are optimized for throughput

12
00:00:21,809 --> 00:00:23,460
running as many simultaneous

13
00:00:23,460 --> 00:00:25,859
computations as possible throughput

14
00:00:25,859 --> 00:00:27,449
computing is important for computer

15
00:00:27,449 --> 00:00:29,399
graphics because we want to update lots

16
00:00:29,399 --> 00:00:30,989
of pixels on the screen at the same time

17
00:00:30,989 --> 00:00:32,880
and it turns out that throughput

18
00:00:32,880 --> 00:00:34,770
computing is also important for deep

19
00:00:34,770 --> 00:00:36,539
learning because the computations

20
00:00:36,539 --> 00:00:38,280
fundamental to deep learning have a lot

21
00:00:38,280 --> 00:00:40,170
of parallelism what level of

22
00:00:40,170 --> 00:00:42,179
acceleration do you typically see when

23
00:00:42,179 --> 00:00:43,829
you move from training a network on a

24
00:00:43,829 --> 00:00:46,890
cpu to a GPU it depends on a lot of

25
00:00:46,890 --> 00:00:48,780
factors including how the software

26
00:00:48,780 --> 00:00:50,820
running has been designed and the

27
00:00:50,820 --> 00:00:53,820
precise cpu and GPU are comparing for

28
00:00:53,820 --> 00:00:55,770
example the low-power processor in your

29
00:00:55,770 --> 00:00:57,929
laptop is going to be much slower than a

30
00:00:57,929 --> 00:01:00,420
big server processor but a rule of thumb

31
00:01:00,420 --> 00:01:02,280
would be that Network strain about five

32
00:01:02,280 --> 00:01:04,500
times faster on a GPU that on a cpu

33
00:01:04,500 --> 00:01:07,200
that's similar to what I've seen and I

34
00:01:07,200 --> 00:01:08,909
know from my own experience that it's

35
00:01:08,909 --> 00:01:11,188
just so much faster and easier to make

36
00:01:11,188 --> 00:01:13,469
progress when my network is training 5

37
00:01:13,469 --> 00:01:15,930
or 10 times faster and I have all that

38
00:01:15,930 --> 00:01:17,579
extra time to experiment with new

39
00:01:17,579 --> 00:01:19,739
approaches and get fast feedback on how

40
00:01:19,739 --> 00:01:20,849
they work

41
00:01:20,849 --> 00:01:22,680
another good approach for getting fast

42
00:01:22,680 --> 00:01:24,810
feedback is to use transfer learning to

43
00:01:24,810 --> 00:01:26,159
take advantage of networks that have

44
00:01:26,159 --> 00:01:28,259
already been trained instead of just

45
00:01:28,259 --> 00:01:34,700
starting from scratch every time

