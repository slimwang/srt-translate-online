1
00:00:00,690 --> 00:00:04,300
Now I'll be walk you through how
I built out this decision tree.

2
00:00:04,300 --> 00:00:07,950
The first thing we should do is go grab
our data set with an input data tool.

3
00:00:09,170 --> 00:00:13,120
I'm going to grab
the Employees_TransportationData.yxdb.

4
00:00:13,120 --> 00:00:15,628
[BLANK_AUDIO]

5
00:00:15,628 --> 00:00:19,171
After bringing in this data set, the
first thing that I want to do is bring

6
00:00:19,171 --> 00:00:21,860
in a field summary tool to
check the health of our data.

7
00:00:21,860 --> 00:00:26,337
What I want to see is first, are there
any null records within our data set?

8
00:00:27,450 --> 00:00:31,650
And, from looking at the green ticker
bars below each of the different fields

9
00:00:31,650 --> 00:00:33,320
within this interactive browser,

10
00:00:33,320 --> 00:00:38,880
the field summary tool, it looks that
100% of each of the fields are valid,

11
00:00:38,880 --> 00:00:42,860
meaning that there are no null
values within our data set.

12
00:00:42,860 --> 00:00:45,630
The other thing that I notice is that

13
00:00:45,630 --> 00:00:50,180
all of our fields seem evenly
distributed, and there's no skewed data.

14
00:00:51,250 --> 00:00:56,660
So for example, there seems to be a
normal distribution of the age category,

15
00:00:56,660 --> 00:01:00,850
the drive distances miles is
pretty normal, besides for

16
00:01:00,850 --> 00:01:05,349
only a few number of records of people
driving between 10 and 12 miles to work.

17
00:01:06,920 --> 00:01:10,520
And as well, our categorical
variables has only two or

18
00:01:10,520 --> 00:01:13,380
three different categories within them.

19
00:01:13,380 --> 00:01:17,430
And this all seems very logical and
our data seems pretty healthy.

20
00:01:17,430 --> 00:01:20,630
So, I'm happy with the field
summary tools results.

21
00:01:20,630 --> 00:01:25,950
So what I'm going to do is I'm
going to deselect this tool and what

22
00:01:25,950 --> 00:01:28,915
I'm going to do is I'm going to create
different samples of our data set,

23
00:01:28,915 --> 00:01:33,880
70% in the estimation sample, and
the 30% in the validation sample.

24
00:01:35,130 --> 00:01:40,660
As we can see, we have about 70% of
raw data in estimation sample with

25
00:01:40,660 --> 00:01:43,570
almost 2700 number of
records over there.

26
00:01:43,570 --> 00:01:48,720
With only 1100 in the validation sample
and nothing in the hold out sample.

27
00:01:50,070 --> 00:01:52,900
So now what I am going to do is I am
going to go straight to our decision

28
00:01:52,900 --> 00:01:53,820
tree tool.

29
00:01:55,360 --> 00:01:57,340
First thing I'm going to do is
I'm going to name the model.

30
00:01:57,340 --> 00:02:01,590
So Dt for decision tree underscore and

31
00:02:01,590 --> 00:02:06,660
I'm going to say transportation since
that's what we're trying to predict.

32
00:02:06,660 --> 00:02:10,509
Then our target variable is going to
be that mode of transportation.

33
00:02:10,509 --> 00:02:13,140
And then my different predictor
variables is I'm going to choose

34
00:02:13,140 --> 00:02:18,050
the gender, age, marital status and
drive distance in miles.

35
00:02:18,050 --> 00:02:21,320
Since we can't choose the mode since
that's what we're trying to predict.

36
00:02:21,320 --> 00:02:25,640
In the first field,
the employee ID is simply an ID field.

37
00:02:25,640 --> 00:02:29,220
I'm now going to bring in a browse
tool after interactive result and

38
00:02:29,220 --> 00:02:29,840
run this model.

39
00:02:32,020 --> 00:02:35,860
What I'm able to see first of all is
that the drive distance in mile and

40
00:02:35,860 --> 00:02:39,400
the age are the only two variables
that are actually important at

41
00:02:39,400 --> 00:02:40,890
all in this model.

42
00:02:40,890 --> 00:02:43,520
Therefore, the other
variables that we put

43
00:02:43,520 --> 00:02:47,170
into the model were not used at
all to build this decision tree.

44
00:02:48,860 --> 00:02:52,250
The next thing I see is that we
have many different splits within

45
00:02:52,250 --> 00:02:56,610
this data set to go to our three
different possible terminal nodes,

46
00:02:56,610 --> 00:03:01,250
public transportation, bike and car.

47
00:03:01,250 --> 00:03:04,680
But instead of going to interpret these
results what I'm going to do is go over

48
00:03:04,680 --> 00:03:06,900
to our confusion matrix and

49
00:03:06,900 --> 00:03:12,480
view that 96% of our different
variables were classified correctly.

50
00:03:12,480 --> 00:03:17,570
This is very strong but again this
is the estimation sample against

51
00:03:17,570 --> 00:03:20,290
the data that was used
to build that model.

52
00:03:20,290 --> 00:03:24,640
So we need to definitely go and validate
or model verses and independent data set

53
00:03:25,980 --> 00:03:30,950
but I'm able to see that bikes where
predicted correctly 100% of the time.

54
00:03:30,950 --> 00:03:35,120
Cars where as well but public
transportation was quiet lower at 86%.

55
00:03:35,120 --> 00:03:41,410
So overall this looks very promising so
far but as we know

56
00:03:41,410 --> 00:03:46,950
decision trees have a high likelihood
to possibly over fit a data set.

57
00:03:46,950 --> 00:03:50,972
So what we should do is we should really
test this model out against a validation

58
00:03:50,972 --> 00:03:54,740
data set, to determine how
strong this model actually is.
