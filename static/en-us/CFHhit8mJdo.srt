1
00:00:00,260 --> 00:00:03,107
All right Michael, last example
I want to give you is something

2
00:00:03,107 --> 00:00:06,100
that comes from the world of
what's called drama management.

3
00:00:06,100 --> 00:00:08,630
And the way I'm going to
introduce this to you

4
00:00:08,630 --> 00:00:12,360
is I'm going to point out what we've
actually been talking about so far.

5
00:00:12,360 --> 00:00:13,710
So I'm cheating a little bit for

6
00:00:13,710 --> 00:00:16,480
you in helping you with what have
we learned part of the lesson.

7
00:00:16,480 --> 00:00:19,120
So I'm going to claim
that if you think about

8
00:00:19,120 --> 00:00:21,880
at least the last few things
about communication and

9
00:00:21,880 --> 00:00:25,430
coaching particularly on the coaching
thing with human beings we've kind of

10
00:00:25,430 --> 00:00:29,750
talked about three different ways that
a human can communicate to an agent.

11
00:00:29,750 --> 00:00:32,299
The first is demonstrations.

12
00:00:32,299 --> 00:00:37,900
You show the example of one
particular drawing through

13
00:00:37,900 --> 00:00:41,110
a grid world to do inverse reinforcement
learning and that was a demonstration.

14
00:00:41,110 --> 00:00:43,290
And I can give you
multiple demonstrations.

15
00:00:43,290 --> 00:00:47,610
And we talked a little bit about rewards
and that what a human can give you is

16
00:00:47,610 --> 00:00:51,160
rewards for various things that you do
and that's a kind of reward shaping way.

17
00:00:51,160 --> 00:00:53,780
And then last thing we talked
about was policy shaping where

18
00:00:53,780 --> 00:00:56,680
the human is communicating to
you is not demonstrations and

19
00:00:56,680 --> 00:00:59,250
not reward values, but
actually telling you

20
00:00:59,250 --> 00:01:02,310
what the correct policy thing is in
response to things that you've done.

21
00:01:02,310 --> 00:01:05,780
And the last policies is different from
the first demonstrations in that in

22
00:01:05,780 --> 00:01:08,850
the first case you would actually
demonstrate what the right action is.

23
00:01:08,850 --> 00:01:12,270
But here with the policy shaping
you're just giving critique that

24
00:01:12,270 --> 00:01:15,560
gives information about whether
a particular policy is correct or not.

25
00:01:15,560 --> 00:01:16,420
Does that make sense?

26
00:01:16,420 --> 00:01:19,312
>> Yeah, that's interesting there's
these different kind of mechanisms for

27
00:01:19,312 --> 00:01:20,240
giving feedback.

28
00:01:20,240 --> 00:01:25,230
>> Right, so I want to talk
about another sort of model and

29
00:01:25,230 --> 00:01:26,510
way of doing coordination.

30
00:01:26,510 --> 00:01:28,310
This time between a human and

31
00:01:28,310 --> 00:01:31,760
an agent who's interacting
with another human, right?

32
00:01:31,760 --> 00:01:34,360
So in the cases we described
before there were two.

33
00:01:34,360 --> 00:01:36,640
There was the human and
there was an agent, but

34
00:01:36,640 --> 00:01:38,400
here I'm going to say
there's a third person.

35
00:01:38,400 --> 00:01:42,865
So I'm going to replace the human
with what I'm going to call a Player.

36
00:01:42,865 --> 00:01:45,552
For example,
a player of a game like Pac-Man.

37
00:01:45,552 --> 00:01:48,770
The Agent,
which in this case would be Pac-Man, and

38
00:01:48,770 --> 00:01:51,750
a third human,
I'm going to call the Author.

39
00:01:51,750 --> 00:01:54,810
So in the world of drama managment
there's this basic idea that

40
00:01:54,810 --> 00:01:58,274
there are these things like Choose
Your Own Adventure stories there's

41
00:01:58,274 --> 00:02:00,945
ways of seeing tasks in the world
as if they are a games.

42
00:02:00,945 --> 00:02:05,092
Where there's some Author, someone who
designs the game designs the system

43
00:02:05,092 --> 00:02:07,449
whether it be Pac-Man or
a story or a movie or

44
00:02:07,449 --> 00:02:11,020
anything if you can imagine any sort
of interaction in the world and

45
00:02:11,020 --> 00:02:13,888
wants to build an Agent,
which is actually a system,

46
00:02:13,888 --> 00:02:17,650
which interferes with the third agent so
to speak which is the Player,

47
00:02:17,650 --> 00:02:21,540
the person that's controlling
what's going on in this world.

48
00:02:21,540 --> 00:02:24,390
So, in this Pac-Man example the Author

49
00:02:24,390 --> 00:02:25,910
would be the person
that created Pac-Man.

50
00:02:25,910 --> 00:02:28,670
The Player would be

51
00:02:28,670 --> 00:02:32,486
the person controlling Pac-Man running
around in this world and eating.

52
00:02:32,486 --> 00:02:35,950
And then the Agent would be
the actual Pac-Man game itself, and

53
00:02:35,950 --> 00:02:41,980
that Agent might have the ability
to change the way the ghost behave.

54
00:02:41,980 --> 00:02:46,290
To set up another level that
has different properties or

55
00:02:46,290 --> 00:02:47,120
whatever it wants.

56
00:02:47,120 --> 00:02:52,660
And the goal of the Agent is
to create an experience for

57
00:02:52,660 --> 00:02:56,800
the player that is consistent with
whatever it is the Author wants.

58
00:02:56,800 --> 00:02:57,939
Does that make any sense at all?

59
00:02:57,939 --> 00:02:59,240
>> At a high level.

60
00:02:59,240 --> 00:03:02,800
I mean, how does the Author
express what he or she wants?

61
00:03:02,800 --> 00:03:03,710
>> That's a good point.

62
00:03:03,710 --> 00:03:06,070
So, he Author wants to
the Agent something,

63
00:03:06,070 --> 00:03:08,510
the Player is going to be
interacting with the Agent and

64
00:03:08,510 --> 00:03:10,200
the Author never gets to
play with the Player.

65
00:03:10,200 --> 00:03:12,380
How does the Author express
to the Agent what it wants?

66
00:03:12,380 --> 00:03:14,290
Well, that's what I'm
going to talk about but

67
00:03:14,290 --> 00:03:15,680
let me just kind of give
you a little preview.

68
00:03:15,680 --> 00:03:19,330
Imagine that the Author
says to the Agent.

69
00:03:19,330 --> 00:03:24,090
I want the Player to be able
to win every level, but

70
00:03:24,090 --> 00:03:29,760
only after they died several
times in that level.

71
00:03:29,760 --> 00:03:34,530
I want the Player to feel like they
have to learn how to play better.

72
00:03:34,530 --> 00:03:37,080
So the game has to be hard,
but it can be so

73
00:03:37,080 --> 00:03:39,520
hard that the Player can never win.

74
00:03:39,520 --> 00:03:41,020
>> Okay.
>> Now I haven't told you how to

75
00:03:41,020 --> 00:03:42,820
communicate that with numbers, but

76
00:03:42,820 --> 00:03:45,640
you can imagine that that's
an objective function.

77
00:03:45,640 --> 00:03:49,955
It's a thing I could write
down that I keep track of

78
00:03:49,955 --> 00:03:53,475
how quickly a Player
can go through a level.

79
00:03:53,475 --> 00:03:54,735
Whether it gets better over time.

80
00:03:54,735 --> 00:03:58,125
I could come up with a function that
tries to capture elements of that

81
00:03:58,125 --> 00:03:59,745
either directly through
the experience or

82
00:03:59,745 --> 00:04:04,235
by describing properties of the game,
properties of the Pac-Man level

83
00:04:04,235 --> 00:04:07,220
that need to be traded off one another
in terms of things like difficulty.

84
00:04:07,220 --> 00:04:08,887
>> Good.
>> So there's lots of ways of

85
00:04:08,887 --> 00:04:12,766
doing it and people have been solving,
worrying about this problem for many,

86
00:04:12,766 --> 00:04:13,607
many years now.

87
00:04:13,607 --> 00:04:18,081
And I want to describe a particular
mechanism that combines this notion of

88
00:04:18,081 --> 00:04:21,966
demonstrations and rewards so
that you can come up with a way for

89
00:04:21,966 --> 00:04:24,973
this Author to convey
information to the Agent so

90
00:04:24,973 --> 00:04:30,200
that the Player has an experience that
is consistent with the Author's intent.

91
00:04:30,200 --> 00:04:30,726
Okay?

92
00:04:30,726 --> 00:04:32,856
>> Neat yeah, that seems to fit with
a couple of things we've been talking

93
00:04:32,856 --> 00:04:33,750
about in this lesson.

94
00:04:33,750 --> 00:04:35,140
>> Excellent, so let's dive in.
