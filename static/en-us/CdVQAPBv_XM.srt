1
00:00:00,360 --> 00:00:05,153
So we mentioned, a number of complete
technologies that are used in cloud

2
00:00:05,153 --> 00:00:09,794
computing and also we mentioned
a number of types of functionality that

3
00:00:09,794 --> 00:00:12,914
cloud computing technology
needs to provide.

4
00:00:12,914 --> 00:00:16,939
Again, let me offer a birds eye
view of two popular stack for

5
00:00:16,939 --> 00:00:21,085
big data that are used in
cloud computing platforms.

6
00:00:21,085 --> 00:00:25,490
The two concrete stacks I want to show
you is the Hadoop Big Data Stack,

7
00:00:25,490 --> 00:00:30,732
it's an open source stack and then also
the Berkeley Data Analytics Stack, BDAS.

8
00:00:30,732 --> 00:00:32,900
This is another open source stack.

9
00:00:32,900 --> 00:00:34,921
These are by the way,
not the only options.

10
00:00:34,921 --> 00:00:37,926
There are number of both
propriety stacks and

11
00:00:37,926 --> 00:00:41,480
also a number of other
open source stacks.

12
00:00:41,480 --> 00:00:47,570
For instance, one example is
the so-called HPCC stack by LexisNexis.

13
00:00:47,570 --> 00:00:51,040
This actually, even predates Hadoop.

14
00:00:51,040 --> 00:00:54,368
However, it wasn't
necessarily popular or

15
00:00:54,368 --> 00:00:58,318
widely used outside of
the LexisNexis environment.

16
00:00:58,318 --> 00:01:01,580
When it comes to the overall
popularity and adoption rate,

17
00:01:01,580 --> 00:01:05,168
both in commercial and
academic settings or research settings,

18
00:01:05,168 --> 00:01:08,510
these two are probably the dominant
stacks out there today.

19
00:01:10,370 --> 00:01:13,120
The Hadoop architecture looks like this.

20
00:01:13,120 --> 00:01:16,650
At the bottom layer,
there is the data storage layer,

21
00:01:16,650 --> 00:01:21,370
the Hadoop file system and this takes
care of taking large amounts of data and

22
00:01:21,370 --> 00:01:25,680
somehow, splitting them and replicating
and making sure the data doesn't get

23
00:01:25,680 --> 00:01:29,330
lost and making sure that there
are no hot spots in the system, etc.

24
00:01:29,330 --> 00:01:33,820
Then there is a processing framework
that can allow computation to

25
00:01:33,820 --> 00:01:38,630
operate on such data and deals with
the scheduling of what are the specific

26
00:01:38,630 --> 00:01:43,530
notes that particular data manipulation
operations need to be scheduled.

27
00:01:43,530 --> 00:01:46,853
Ideally, the scheduling
should be done in such a way,

28
00:01:46,853 --> 00:01:51,260
so that you don't have to constantly
move data from one note to another,

29
00:01:51,260 --> 00:01:54,599
depending on what is the task
that needs to process it.

30
00:01:54,599 --> 00:01:59,180
We're really not going to talk in more
detail about the Map Reduce framework.

31
00:01:59,180 --> 00:02:02,965
The intent of these is just as
an illustration to provide you with

32
00:02:02,965 --> 00:02:06,412
an overview of the breadth of
technologies in this space.

33
00:02:06,412 --> 00:02:11,459
There's a component Hbase and
this provides a table like view

34
00:02:11,459 --> 00:02:16,895
of the stored data that is more
similar to with what we're familiar

35
00:02:16,895 --> 00:02:22,621
with in the context of databases, but
it is not the same as the relation

36
00:02:22,621 --> 00:02:28,861
of database representation of the data
as were used in the SQL environment.

37
00:02:28,861 --> 00:02:31,586
In order to support data processing and

38
00:02:31,586 --> 00:02:35,550
data query operations like
what SQL databases support,

39
00:02:35,550 --> 00:02:40,009
there's a language front end hive
that will take an SQL query and

40
00:02:40,009 --> 00:02:45,060
then translate it into a number
of these Map Reduce operations.

41
00:02:45,060 --> 00:02:49,880
That will then operate on top of
the data that's stored in this Hbase

42
00:02:49,880 --> 00:02:53,080
tables on top of
the distributed file system.

43
00:02:53,080 --> 00:02:57,666
Order number of higher levels services
that would also provide the same kind of

44
00:02:57,666 --> 00:02:58,230
things.

45
00:02:58,230 --> 00:03:03,070
So end users can use the R environment
in order to describe certain

46
00:03:03,070 --> 00:03:07,206
rules about how data should
be processed and analyzed or

47
00:03:07,206 --> 00:03:12,574
we can use machine learning algorithms,
one of a collection of many that

48
00:03:12,574 --> 00:03:18,570
are supported in the Mahout component
that's part of the Hadoop stack.

49
00:03:18,570 --> 00:03:22,940
And a number of other technologies
that provide more specialized

50
00:03:22,940 --> 00:03:27,750
type soft functionality or different
kinds of interfaces to the end users.

51
00:03:27,750 --> 00:03:29,360
At the lowest level, however,

52
00:03:29,360 --> 00:03:33,850
all of these end up being a number of
these more primitive operations that can

53
00:03:33,850 --> 00:03:38,110
execute on top of the distributed
file system where the data is stored.

54
00:03:38,110 --> 00:03:41,750
And there are a number of supporting
services that are needed in order to

55
00:03:41,750 --> 00:03:47,710
deal with locker or coordination or
to provide the streaming of data into

56
00:03:47,710 --> 00:03:53,550
this distributed environment and this
is what the Berkeley BDAS looks like.

57
00:03:53,550 --> 00:03:58,100
There's similarly a component
that's the data storage layer and

58
00:03:58,100 --> 00:04:03,210
then there is a in memory component
that is the in memory file system,

59
00:04:03,210 --> 00:04:06,240
so that you can avoid the caches.

60
00:04:06,240 --> 00:04:11,137
You can run the regular Hadoop Map
Reduce engines on top of this layer or

61
00:04:11,137 --> 00:04:14,458
you can run another type
of programming model,

62
00:04:14,458 --> 00:04:17,712
another processing
framework called Spark.

63
00:04:17,712 --> 00:04:22,510
There are a number of front-ends for
the Spark in terms of the kinds of

64
00:04:22,510 --> 00:04:27,809
execution models that are supported,
so whether it's in SQLite queries or

65
00:04:27,809 --> 00:04:32,528
stream processing or graph processing or
machine learning types of

66
00:04:32,528 --> 00:04:38,150
operations that should be executed
on top of this processing framework.

67
00:04:38,150 --> 00:04:43,006
Another component that's important
to mention is this Mesos component

68
00:04:43,006 --> 00:04:47,465
that's the lowest level scheduling
framework, the lowest level

69
00:04:47,465 --> 00:04:51,844
resource manager that allows
the resources to be partitioned and

70
00:04:51,844 --> 00:04:54,884
then used by different
types of frameworks.

71
00:04:54,884 --> 00:04:57,570
You may have a partition
that's a Hadoop partition.

72
00:04:57,570 --> 00:04:59,673
A partition that's a Spark partition.

73
00:04:59,673 --> 00:05:02,200
A partition that's an MPI partition.

74
00:05:02,200 --> 00:05:03,650
And using this stack,

75
00:05:03,650 --> 00:05:08,280
the two will be able to basically
coordinate and negotiate among them and

76
00:05:08,280 --> 00:05:12,415
then you'll have elasticity across these
very different types of framework.
