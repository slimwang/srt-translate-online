1
00:00:00,230 --> 00:00:06,090
Now we're going to look at two main concepts in ROC analysis.

2
00:00:06,090 --> 00:00:09,650
The first one is the Iso Performance Lines.

3
00:00:09,650 --> 00:00:12,140
The idea here is very simple.

4
00:00:12,140 --> 00:00:17,770
If you draw a line through ROC space, then the points

5
00:00:17,770 --> 00:00:23,210
in the ROC Cuves that intersect with the straight line have the same

6
00:00:23,210 --> 00:00:28,930
performance and this performance is measured by the slope of this line.

7
00:00:28,930 --> 00:00:33,280
The gray line that I drew, intersected the ROC curves in one,

8
00:00:33,280 --> 00:00:35,355
two, three, four, five, points.

9
00:00:36,610 --> 00:00:41,580
All these points have the same performance and

10
00:00:41,580 --> 00:00:45,240
that's the fall on iso performance line.

11
00:00:45,240 --> 00:00:50,780
So you see these lines can be determined by the objective of optimization,

12
00:00:50,780 --> 00:00:57,530
such as the lines that can give maximum accuracy or specificity or sensitivity.

13
00:00:57,530 --> 00:01:02,500
Another important concept is the concept of the area under the curve.

14
00:01:02,500 --> 00:01:07,700
An ROC curve with a larger area under it performs better on

15
00:01:07,700 --> 00:01:12,490
average than and ROC curves that has a smaller area.

16
00:01:12,490 --> 00:01:16,320
In our case here you see the green line has

17
00:01:16,320 --> 00:01:20,240
a lesser area than the red line under it.

18
00:01:20,240 --> 00:01:25,730
Thus, the SVC performs better than the logistic regression.

19
00:01:25,730 --> 00:01:32,160
Since a greater AUC, or area under the curve, implies better performance.

20
00:01:32,160 --> 00:01:36,200
In our case we choose the random forest classifier as it

21
00:01:36,200 --> 00:01:41,990
performs best on average given the area under the curve is the greatest.

22
00:01:41,990 --> 00:01:47,250
One very interesting property of the ROC curve is that is

23
00:01:47,250 --> 00:01:52,790
invariant under the class distribution, and thus the results are applicable

24
00:01:52,790 --> 00:01:57,650
to a dataset with different proportion of class instances.

25
00:01:57,650 --> 00:02:02,950
What this means is that it doesn't matter, as far as the ROC analysis goes,

26
00:02:02,950 --> 00:02:06,730
as to which class has how many points to train upon.
