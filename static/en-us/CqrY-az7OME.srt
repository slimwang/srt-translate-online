1
00:00:00,130 --> 00:00:03,550
Okay so I think that was almost it,
was there anything else?

2
00:00:03,550 --> 00:00:07,640
>> Yes, we then made a leap
to Monte Carlo tree search.

3
00:00:07,640 --> 00:00:08,970
>> I wouldn't say it was a leap.

4
00:00:08,970 --> 00:00:11,710
>> We climbed a Monte Carlo tree.

5
00:00:11,710 --> 00:00:13,300
>> Yes, and did some search, and

6
00:00:13,300 --> 00:00:15,430
what did we learn about
Monte Carlo tree search?

7
00:00:15,430 --> 00:00:19,320
>> So it's really important to help
with scaling because it lets you

8
00:00:19,320 --> 00:00:22,860
have computation that's independent
of the size of the state space

9
00:00:22,860 --> 00:00:27,720
Even though it depends very possibly
badly on the length of the horizon.

10
00:00:27,720 --> 00:00:33,650
>> Right so it's got a low o on
the state space practice independent.

11
00:00:33,650 --> 00:00:40,480
But it has a big o on the horizon
which I'll just call h here.

12
00:00:40,480 --> 00:00:42,150
>> And it's exponential with m.

13
00:00:42,150 --> 00:00:43,609
>> Yeah it's exponential with m.

14
00:00:43,609 --> 00:00:46,040
>> [LAUGH]
>> It looks like hydrogen now.

15
00:00:46,040 --> 00:00:51,260
So does MCTS and
abstraction fit together in any way?

16
00:00:51,260 --> 00:00:54,740
>> We could make it if
we were abstract enough.

17
00:00:56,620 --> 00:00:59,040
If you pop back up far enough

18
00:00:59,040 --> 00:01:03,650
you can sort of think of it as a kind of
abstraction over actions and policies.

19
00:01:03,650 --> 00:01:07,780
>> But no I was thinking in particular
that the idea that in MCTS the way

20
00:01:07,780 --> 00:01:12,410
we talked about it, it was talking about
specific states ground level states.

21
00:01:12,410 --> 00:01:15,320
Like if we have a good way of
abstracting states can we use those

22
00:01:15,320 --> 00:01:17,410
abstract states in an MTCS context.

23
00:01:17,410 --> 00:01:18,086
>> Sure.
In fact,

24
00:01:18,086 --> 00:01:20,420
what I was about to say is that all
of the stuff that we learned about

25
00:01:20,420 --> 00:01:24,080
generalization up here can apply
to MCTS more easily than others.

26
00:01:24,080 --> 00:01:27,750
Doing the function approximation
is sometimes quite hard, but

27
00:01:27,750 --> 00:01:32,990
not really because of the way that we're
sort of thinking about the q functions.

28
00:01:32,990 --> 00:01:35,680
But the temple abstraction works
very well because I can use

29
00:01:35,680 --> 00:01:38,818
options instead of
actions to do my MCTS.

30
00:01:38,818 --> 00:01:40,698
>> Right, you said that.

31
00:01:40,698 --> 00:01:42,150
>> Yeah I said that.

32
00:01:42,150 --> 00:01:44,890
And as a result
the state abstraction and

33
00:01:44,890 --> 00:01:47,740
the the goal abstraction can also
follow through there if you think about

34
00:01:47,740 --> 00:01:52,660
each of the individual modules as
doing their own version of MCTS.

35
00:01:52,660 --> 00:01:54,270
But MCTS is a very general notion.

36
00:01:54,270 --> 00:01:58,440
So if I were trying to decide between
different modules that I might take,

37
00:01:58,440 --> 00:02:03,705
it will look exactly like trying to
do the sequential decision making and

38
00:02:03,705 --> 00:02:05,610
MCTS will work either way.

39
00:02:05,610 --> 00:02:09,729
But the big temporal abstraction is
a huge win for MCTS because again all of

40
00:02:09,729 --> 00:02:14,300
its difficulty lies in the link
to the horizon, right.

41
00:02:14,300 --> 00:02:18,270
So if I'm able to search
far ahead in the future,

42
00:02:18,270 --> 00:02:20,342
that lowers my effective horizon.

43
00:02:20,342 --> 00:02:20,908
>> Nice.

44
00:02:20,908 --> 00:02:22,040
>> All right.

45
00:02:22,040 --> 00:02:23,650
>> So if these ideas are so
important for

46
00:02:23,650 --> 00:02:27,200
scaling up do you do you feel like
they've contributed to, I don't know,

47
00:02:27,200 --> 00:02:30,220
the ability of reinforcement,
learning to solve some real problems.

48
00:02:30,220 --> 00:02:31,180
>> Yeah.
Absolutely.

49
00:02:31,180 --> 00:02:32,700
No, these things actually
come up quite a bit.

50
00:02:32,700 --> 00:02:35,050
They've been used in a lot of games.

51
00:02:35,050 --> 00:02:38,850
MCTS has been used, well it's all in the
papers that the students have written.

52
00:02:38,850 --> 00:02:42,870
But MCTS has been used to solve
a bunch of game problems in just my

53
00:02:42,870 --> 00:02:45,090
own work as well as in
a variety of other things.

54
00:02:45,090 --> 00:02:48,040
You probably know a few more
off the top of your head.

55
00:02:48,040 --> 00:02:52,960
But really any time you have a huge
state space, or potentially a huge

56
00:02:52,960 --> 00:02:57,540
state space, these kinds of interactions
turn out to be extremely useful.

57
00:02:57,540 --> 00:02:59,940
Some of them are easier to
think about than others.

58
00:02:59,940 --> 00:03:02,310
Function approximation is very nice, but

59
00:03:02,310 --> 00:03:05,410
does have its own problem with
picking the right features.

60
00:03:05,410 --> 00:03:07,270
Particularly, if you are going
to be non-linear about it.

61
00:03:07,270 --> 00:03:09,900
Temple abstraction is
often quite useful because

62
00:03:09,900 --> 00:03:14,270
people can help you come up with
things like options or constraints.

63
00:03:14,270 --> 00:03:16,990
Goal abstraction has kind
of a similar flavor to it.

64
00:03:16,990 --> 00:03:19,710
And because of those things,
the state abstraction helps.

65
00:03:19,710 --> 00:03:22,710
Basically, anything that lets you
lower the number of states or

66
00:03:22,710 --> 00:03:25,762
the effective horizon has to make the
reinforcement learning problem easier.

67
00:03:25,762 --> 00:03:26,316
>> Nice.

68
00:03:26,316 --> 00:03:26,994
Alright.

69
00:03:26,994 --> 00:03:28,300
So there, scalability.

70
00:03:28,300 --> 00:03:30,700
These things actually work
they actually are helpful and

71
00:03:30,700 --> 00:03:34,250
this is a huge wide open field
in reinforcement learning.

72
00:03:34,250 --> 00:03:36,950
In fact, to your point I'll just sort
of ended with this that I think that

73
00:03:38,080 --> 00:03:41,960
reinforcement learning has gotten so
good at solving.

74
00:03:41,960 --> 00:03:45,640
Kind of well thought out
grid like problems that.

75
00:03:45,640 --> 00:03:48,690
The field is really interested in, and
increasingly more interested in figuring

76
00:03:48,690 --> 00:03:50,290
out how to make it
work in the real world.

77
00:03:50,290 --> 00:03:52,560
And these kind of techniques,
these abstraction techniques,

78
00:03:52,560 --> 00:03:54,010
these scaling techniques,

79
00:03:54,010 --> 00:03:56,910
become increasingly important as you
try to move it out into the real world.

80
00:03:56,910 --> 00:03:58,090
So this is a good thing.

81
00:03:58,090 --> 00:03:59,580
>> Wow, I'm glad you told me about it.

82
00:03:59,580 --> 00:04:00,870
>> I'm about helping others.

83
00:04:00,870 --> 00:04:01,840
So I think we're good.

84
00:04:01,840 --> 00:04:03,920
So I guess, goodbye, Michael.

85
00:04:03,920 --> 00:04:04,480
Until next time.

86
00:04:04,480 --> 00:04:05,470
>> All right.

87
00:04:05,470 --> 00:04:06,050
Yeah, see you then.
