1
00:00:00,000 --> 00:00:03,000
[Thrun] This finishes my unit on clustering,

2
00:00:03,000 --> 00:00:05,000
at least so far.

3
00:00:05,000 --> 00:00:07,000
I just want to briefly summarize what we've learned.

4
00:00:07,000 --> 00:00:10,000
We talked about K-means, and we talked about expectation maximization.

5
00:00:10,000 --> 00:00:14,000
K-means is a very simple almost binary algorithm

6
00:00:14,000 --> 00:00:16,000
that allows you to find cluster centers.

7
00:00:16,000 --> 00:00:19,000
EM is a probabilistic generalization that also allows you to find clusters

8
00:00:19,000 --> 00:00:23,000
but also modifies the shapes of the clusters by modifying the covariance matrix.

9
00:00:23,000 --> 00:00:26,000
EM is probabilistically sound, and you can prove convergence

10
00:00:26,000 --> 00:00:29,000
in a log likelihood space. K-means also converges.

11
00:00:29,000 --> 00:00:31,000
Both are prone to local minima.

12
00:00:31,000 --> 00:00:34,000
In both cases you need to know the number of cluster centers, K.

13
00:00:34,000 --> 00:00:39,000
I showed you a brief trick how to estimate the K as you go,

14
00:00:39,000 --> 99:59:59,999
which also overcomes local minima to some extent.
