1
00:00:00,370 --> 00:00:05,200
The stage set for the Andrew File System, AFS, is

2
00:00:05,200 --> 00:00:10,110
the CMU campus. And the user community can access

3
00:00:10,110 --> 00:00:15,330
file servers using workstations connected to a local

4
00:00:15,330 --> 00:00:20,500
area network. And as I mentioned, local disks on the

5
00:00:20,500 --> 00:00:25,810
workstation served as efficient caches. And the vision of the designers

6
00:00:25,810 --> 00:00:30,390
of the Andrew File System and the Coda file system, both of which were built

7
00:00:30,390 --> 00:00:34,510
at CMU for enabling the student community to

8
00:00:34,510 --> 00:00:38,870
access a central file system, is as follows.

9
00:00:38,870 --> 00:00:44,820
A user walks up to any workstation and, and logs into the work station. And your

10
00:00:44,820 --> 00:00:49,170
content magically appears on this workstation from the

11
00:00:49,170 --> 00:00:51,740
central server as soon as you log in.

12
00:00:51,740 --> 00:00:56,890
In other words, in the CMU experiment, what they wanted to afford the users

13
00:00:56,890 --> 00:01:01,580
to be able to do is have this ability to walk up

14
00:01:01,580 --> 00:01:06,810
to any workstation spread out throughout the campus and be able to

15
00:01:06,810 --> 00:01:11,880
access their personal information that is stored

16
00:01:11,880 --> 00:01:17,090
in servers that are central to the entire campus. Isn't that what

17
00:01:17,090 --> 00:01:22,300
today's cloud computing and mobile devices are trying to do to your

18
00:01:22,300 --> 00:01:26,640
content? In some sense you'll see that many of the technologies that

19
00:01:26,640 --> 00:01:32,670
we take for granted today had their modest beginnings in

20
00:01:32,670 --> 00:01:37,030
experiments such as the Andrew File System and the Coda file system at CMU.
