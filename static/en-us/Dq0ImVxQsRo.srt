1
00:00:00,000 --> 00:00:04,708
So in the discussion on graphs, I made the following statement; let me quote myself.

2
00:00:04,708 --> 00:00:11,114
"If we had a graph that was just a linear chain, the last node would be node N minus 1.

3
00:00:11,114 --> 00:00:13,782
"The linear chain is very hard to paralyze.

4
00:00:13,782 --> 00:00:20,863
If we're doing a BFS here, it's going to take us order of N steps to get to the end of the graph."

5
00:00:20,863 --> 00:00:23,257
Let me state this problem another way.

6
00:00:23,257 --> 00:00:25,463
I have N nodes in a linear chain,

7
00:00:25,463 --> 00:00:28,060
and each node knows the ID of the next node in the chain.

8
00:00:28,060 --> 00:00:30,037
This is just a simple link list.

9
00:00:30,037 --> 00:00:34,205
What is the algorithm for each node, every node finding the end of the list?

10
00:00:34,205 --> 00:00:36,939
And so of course we can solve this in N steps.

11
00:00:36,939 --> 00:00:41,458
Let's say that each node has a next pointer, and I've shown those in blue,

12
00:00:41,458 --> 00:00:45,451
that points to the next node in the chain, and the last node has next equals null.

13
00:00:45,451 --> 00:00:49,484
Now we don't want to change the next pointers at all, or else we'll lose the structure of our lists.

14
00:00:49,484 --> 00:00:51,921
So we're going to assume they're read only.

15
00:00:51,921 --> 00:00:56,204
So we're also going to store a second pointer per node that we can change.

16
00:00:56,204 --> 00:00:59,396
For historical purposes, we'll call this pointer chum,

17
00:00:59,396 --> 00:01:01,798
and we're going to designate it in red.

18
00:01:01,798 --> 00:01:07,904
And at the end of the algorithm, we want each node's chum pointer to point to the last node in the chain.

19
00:01:07,904 --> 00:01:11,976
So the straightforward algorithm is on each iteration on each node,

20
00:01:11,976 --> 00:01:17,711
set chum to chum to next until we reach a node where next is null.

21
00:01:17,711 --> 00:01:22,153
So we'll start off by making all chum pointers point to their own nodes.

22
00:01:22,153 --> 00:01:27,855
That's how we are going to initialize them, and again, on each iteration, we will set chum to the next pointer.

23
00:01:27,855 --> 00:01:31,762
So on the first iteration it's going to look like this, so now we're going to do another iteration,

24
00:01:31,762 --> 00:01:35,498
so for any particular node, we look for chum and then next.

25
00:01:35,498 --> 00:01:39,836
So on the second iteration, it's going to look like this, and so on, and so on.

26
00:01:39,836 --> 00:01:45,440
So on each iteration, the length of the chum pointer is going to be 1 more than it was on the iteration before.

27
00:01:45,440 --> 00:01:49,489
So the question is--the important question is, can we do better?

28
00:01:49,489 --> 00:01:52,063
And it turns out the answer is yes,

29
00:01:52,063 --> 00:01:55,852
and this algorithm described by Danny Hillis and Guy Steele in 1986,

30
00:01:55,852 --> 00:01:58,421
not discovered by them but described very nicely,

31
00:01:58,421 --> 00:02:03,633
is so cool that it's one of the reasons that I decided to do parallel computing in the first place.

32
00:02:03,633 --> 00:02:07,063
So let's analyze the complexity of the algorithm that we just described.

33
00:02:07,063 --> 00:02:11,534
Clearly a serial processor can do this computation in N steps in order of N work.

34
00:02:11,534 --> 00:02:13,851
How about the parallel processor?

35
00:02:13,851 --> 00:02:16,148
We know that it takes N steps; how much work?

36
00:02:16,148 --> 00:02:20,148
Your choices are order of N, N log N, N square root of N, or N-squared.
