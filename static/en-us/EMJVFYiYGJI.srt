1
00:00:00,370 --> 00:00:04,480
Recall the Lemma that relates the number
of misses in an LRU cache to the number

2
00:00:04,480 --> 00:00:06,750
in one with optimal replacement.

3
00:00:06,750 --> 00:00:10,090
From this Lemma there's
a corollary about regularity.

4
00:00:10,090 --> 00:00:15,310
You can design an algorithm for an ideal
cache and if that analysis shows that

5
00:00:15,310 --> 00:00:20,480
the number of misses is regular, then
an LRU cache will perform just as well.

6
00:00:20,480 --> 00:00:22,500
So let's see how to use this.

7
00:00:22,500 --> 00:00:24,640
Suppose you design a matrix
multiply algorithm,

8
00:00:24,640 --> 00:00:30,020
assuming a conventional non stronsense
scheme and you do so for an ideal cache.

9
00:00:30,020 --> 00:00:34,310
Let's say that your analysis shows your
algorithm does n cubed over L root z,

10
00:00:34,310 --> 00:00:35,170
misses.

11
00:00:35,170 --> 00:00:39,080
For this example let's further assume
that the line size is one word.

12
00:00:39,080 --> 00:00:43,450
So will this algorithm perform well
on a machine with an LRU cache?

13
00:00:43,450 --> 00:00:45,570
Let's check the regularity condition.

14
00:00:45,570 --> 00:00:48,060
What happens when you
double the cash size?

15
00:00:48,060 --> 00:00:51,450
Well, it introduces just
a small constant factor.

16
00:00:51,450 --> 00:00:54,250
So the regularity
condition is satisfied.

17
00:00:54,250 --> 00:00:58,780
And because Qopt is regular,
QLRU will be proportional to it.

18
00:00:58,780 --> 00:01:02,660
By the Lemma, you could also evaluate
the right-hand side of this relation.

19
00:01:02,660 --> 00:01:04,060
Here's what you get.

20
00:01:04,060 --> 00:01:07,550
Basically an upper bound on
the number of LRU misses.

21
00:01:07,550 --> 00:01:10,320
This brings us to one of
life's great pleasures,

22
00:01:10,320 --> 00:01:13,640
well assuming you're a bit of a geek,
or is it nerd?

23
00:01:13,640 --> 00:01:15,900
Let's just say enthusiast, shall we?

24
00:01:15,900 --> 00:01:18,740
The pleasure is that
the Lemma is not hard to see.

25
00:01:18,740 --> 00:01:22,860
For simplicity, let's assume that
the transfer size is one word.

26
00:01:22,860 --> 00:01:25,740
Now imagine the sequence,
or trace, of all load and

27
00:01:25,740 --> 00:01:28,430
store operations performed by a program.

28
00:01:28,430 --> 00:01:30,820
Divide this trace into phases.

29
00:01:30,820 --> 00:01:33,360
Let's define these
phases in a special way.

30
00:01:33,360 --> 00:01:38,690
In particular, suppose that each phase
references exactly Z unique addresses.

31
00:01:38,690 --> 00:01:43,220
Just to be clear, each phase might
contain many more than Z loads and

32
00:01:43,220 --> 00:01:44,220
stores.

33
00:01:44,220 --> 00:01:47,020
The phases might also have widely
varying numbers of loads and

34
00:01:47,020 --> 00:01:49,560
stores as the illustration suggests, but

35
00:01:49,560 --> 00:01:54,680
the number of unique addresses is
always exactly Z in each phase.

36
00:01:54,680 --> 00:01:58,740
Now let's say the machine
has an LRU cache of size Z.

37
00:01:58,740 --> 00:02:01,870
Think about what happens during
some phase, let's say phase i.

38
00:02:01,870 --> 00:02:05,960
At the beginning of the phase,
it's possible that the cache is full.

39
00:02:05,960 --> 00:02:09,340
So, the first time each unique
address of phase i is seen,

40
00:02:09,340 --> 00:02:11,360
it could cause an eviction.

41
00:02:11,360 --> 00:02:13,320
Thus, by the definition of a phase,

42
00:02:13,320 --> 00:02:16,650
the number of cache misses
could be as high as z.

43
00:02:16,650 --> 00:02:20,040
Now think about what happens on
a cache with optimal replacement, but

44
00:02:20,040 --> 00:02:22,480
half the capacity, Z over 2.

45
00:02:22,480 --> 00:02:27,170
Remember this optimal cache can gaze
into its crystal ball to see all future

46
00:02:27,170 --> 00:02:28,330
accesses.

47
00:02:28,330 --> 00:02:30,990
So during the previous phase i- 1,

48
00:02:30,990 --> 00:02:33,930
what might the optimal
replacement policy have done?

49
00:02:33,930 --> 00:02:39,110
Well it may have arranged itself so
that the first z/2 unique addresses seen

50
00:02:39,110 --> 00:02:44,350
in phase i are exactly in cache,
that would mean no evictions.

51
00:02:44,350 --> 00:02:48,630
But since the optimal cache is
only of size z/2, then it must,

52
00:02:48,630 --> 00:02:51,280
at that point, start loading addresses.

53
00:02:51,280 --> 00:02:52,820
In other words, the smaller but

54
00:02:52,820 --> 00:02:57,440
all seeing cache has to perform
at least z over 2 transfers.

55
00:02:57,440 --> 00:03:01,180
The competitiveness Lemma then
follows from these two facts.

56
00:03:01,180 --> 00:03:04,380
One is at most Z and
twice the other is at least Z.
