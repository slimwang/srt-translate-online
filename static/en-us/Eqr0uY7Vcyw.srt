1
00:00:00,340 --> 00:00:07,020
Before we dive into the nuts and bolts of how GMS is implemented, how it is

2
00:00:07,020 --> 00:00:10,600
architected, let's first understand at the high level

3
00:00:10,600 --> 00:00:13,360
what's going on in terms of page fault

4
00:00:13,360 --> 00:00:16,900
handling now that we have this community service

5
00:00:16,900 --> 00:00:19,810
underlying GMS. In this picture, I am showing

6
00:00:19,810 --> 00:00:25,500
you two hosts, host P and host Q and you can see that the physical memory

7
00:00:25,500 --> 00:00:27,520
on this host is divided into the local and

8
00:00:27,520 --> 00:00:32,290
the global part. Similarly, the physical memory on host Q

9
00:00:32,290 --> 00:00:34,010
is divided into the local part and the global

10
00:00:34,010 --> 00:00:37,810
part. And we already mentioned that these are not fixed

11
00:00:37,810 --> 00:00:41,560
in size but the size actually fluctuates depending on

12
00:00:41,560 --> 00:00:44,180
the activity and that's what we are going to illustrate through

13
00:00:44,180 --> 00:00:47,820
a example situations. So the most common case is

14
00:00:47,820 --> 00:00:50,670
that I am running a process on P and that

15
00:00:50,670 --> 00:00:57,130
page faults on some page X. When that happens, you have to find out if this

16
00:00:57,130 --> 00:01:02,780
page X is in the global cache of some node in the cluster. Lets say that this

17
00:01:02,780 --> 00:01:09,530
page happens to be in the global cache of node Q. So what will happen in

18
00:01:09,530 --> 00:01:12,236
order to handle this page fault is the

19
00:01:12,236 --> 00:01:16,140
GMS system will locate, oh this particular page it's

20
00:01:16,140 --> 00:01:22,580
on host Q. So it'll go to host Q. And the host Q will then

21
00:01:22,580 --> 00:01:27,880
send the page X over to node P and clearly, if there there was a page fault that

22
00:01:27,880 --> 00:01:31,110
means that the memory pressure on host P

23
00:01:31,110 --> 00:01:34,670
is increasing and therefore, it is going to add X

24
00:01:34,670 --> 00:01:37,560
to it's current working set. That is it's

25
00:01:37,560 --> 00:01:41,300
local allocation of the physical memory is going to go

26
00:01:41,300 --> 00:01:43,690
up by one but it cannot go up by one

27
00:01:43,690 --> 00:01:47,320
without getting rid of something here. Because the sum of

28
00:01:47,320 --> 00:01:50,960
the local and global is the total amount of physical

29
00:01:50,960 --> 00:01:54,150
memory available in this node and therefore, what P is going

30
00:01:54,150 --> 00:01:57,030
to do is, pick the oldest page that's available in

31
00:01:57,030 --> 00:02:00,550
the global part and send it over to node Q. So,

32
00:02:00,550 --> 00:02:02,700
in other words, what we are doing so far, as

33
00:02:02,700 --> 00:02:06,470
host Q is concerned is saying, well X happens to be

34
00:02:06,470 --> 00:02:09,280
currently in the working set, then resend it to host

35
00:02:09,280 --> 00:02:11,910
P. And host P says, well, my working set is

36
00:02:11,910 --> 00:02:15,560
increasing. Therefore, I have to shrink my community service and

37
00:02:15,560 --> 00:02:17,960
we going to reduce the global part by one. Pick the

38
00:02:17,960 --> 00:02:21,250
oldest page. Lets say it's Y. Send it over to

39
00:02:21,250 --> 00:02:24,910
host Q. So that the host Q can host this

40
00:02:24,910 --> 00:02:29,260
new page Y in the global cache on this node.

41
00:02:29,260 --> 00:02:31,600
The key take away for you is that, for this

42
00:02:31,600 --> 00:02:34,120
particular common case, the memory pressure pressure

43
00:02:34,120 --> 00:02:36,340
on p is increasing, so the local

44
00:02:36,340 --> 00:02:38,910
allocation of the physical memory goes up

45
00:02:38,910 --> 00:02:41,390
by one, and the global allocation, the community

46
00:02:41,390 --> 00:02:45,750
service part goes down by one on host P. Where as on host Q, it

47
00:02:45,750 --> 00:02:50,380
remains unchanged because all that we have done is we have traded Y for X.
