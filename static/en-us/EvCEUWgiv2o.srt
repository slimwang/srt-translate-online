1
00:00:00,260 --> 00:00:02,920
So now let's talk about the virtues of this

2
00:00:02,920 --> 00:00:06,110
link list based queuing lock. Some of virtues are

3
00:00:06,110 --> 00:00:09,040
exactly similar to the Anderson's queuing lock, and that

4
00:00:09,040 --> 00:00:11,780
is it is fair. And so Anderson's lock was also

5
00:00:11,780 --> 00:00:14,300
fair, ticket lock was also fair. The linked list

6
00:00:14,300 --> 00:00:18,190
queuing lock is also fair. And again, the spin location

7
00:00:18,190 --> 00:00:22,360
is unique for every spinner, right? Every spinner has

8
00:00:22,360 --> 00:00:25,370
a unique spin location to wait on and so that

9
00:00:25,370 --> 00:00:27,150
is similar to the Anderson's queue lock as

10
00:00:27,150 --> 00:00:30,650
well. And that's good because you're not causing contention

11
00:00:30,650 --> 00:00:33,430
on the network when the lock is released. When

12
00:00:33,430 --> 00:00:36,490
one guy releases the lock, others if they're waiting,

13
00:00:36,490 --> 00:00:39,180
they don't, they don't get bothered by by the,

14
00:00:39,180 --> 00:00:43,140
by the signal. And exactly one processor gets signaled

15
00:00:43,140 --> 00:00:46,160
when the lock is released. That's also good. And

16
00:00:46,160 --> 00:00:50,610
usually, there's only one atomic operation per critical section.

17
00:00:50,610 --> 00:00:52,970
And the only thing that happens is this corner case.

18
00:00:52,970 --> 00:00:55,870
In order to implement this corner case, you have to

19
00:00:55,870 --> 00:00:59,350
use a second atomic operation. But if the link list

20
00:00:59,350 --> 00:01:02,420
has several members in this, in these examples. I'm just

21
00:01:02,420 --> 00:01:05,550
showing only two requesters at a time. But if the

22
00:01:05,550 --> 00:01:08,940
link list has a number of requesters, then if I

23
00:01:08,940 --> 00:01:12,470
am middle of the gang, have, using the lock, I

24
00:01:12,470 --> 00:01:15,960
simply signal the successor. I don't have to do anything fancy

25
00:01:15,960 --> 00:01:19,110
in terms of compare and swap. So this is something

26
00:01:19,110 --> 00:01:22,090
that needs to be done only for the corner case, not

27
00:01:22,090 --> 00:01:25,520
as a, a routine for doing the unlock operation. And

28
00:01:25,520 --> 00:01:27,740
the other good thing that we already mentioned is that the

29
00:01:27,740 --> 00:01:31,280
space complexity of this data structure is proportional to the

30
00:01:31,280 --> 00:01:34,450
number of requesters to the lock at any point of time.

31
00:01:34,450 --> 00:01:37,193
So it is dynamic. It's not statically defined as in

32
00:01:37,193 --> 00:01:41,040
the array-based queueing lock. And so that's one of the biggest

33
00:01:41,040 --> 00:01:45,110
virtues of this particular algorithm that the space

34
00:01:45,110 --> 00:01:47,940
complexity is bound by the number of dynamic

35
00:01:47,940 --> 00:01:50,370
requests to a particular lock, and not the

36
00:01:50,370 --> 00:01:53,950
size of the multi-processor itself. Now the downside

37
00:01:53,950 --> 00:01:58,430
to this link list based queuing lock of course is the fact that there is link

38
00:01:58,430 --> 00:02:01,660
list maintenance overhead that is associated with making

39
00:02:01,660 --> 00:02:06,350
a lock request or unlock request. And Anderson's [INAUDIBLE]

40
00:02:06,350 --> 00:02:08,800
queue lock because it is in a irregular structure

41
00:02:08,800 --> 00:02:13,240
can be slightly faster than this, link list based algorithm.

42
00:02:13,240 --> 00:02:14,950
And one of the things that I should mention

43
00:02:14,950 --> 00:02:18,270
to that is that both Anderson's [UNKNOWN] queue lock as

44
00:02:18,270 --> 00:02:23,300
well as the NCS link list based, queue lock.

45
00:02:23,300 --> 00:02:26,230
May result in poorer performance if the architecture does not

46
00:02:26,230 --> 00:02:28,940
support fancy instructions like this, because they have to

47
00:02:28,940 --> 00:02:32,140
be simulated using test and set, so that can be

48
00:02:32,140 --> 00:02:34,810
a little detriment to to this particular

49
00:02:34,810 --> 00:02:37,400
algorithm as well. We have discussed different

50
00:02:37,400 --> 00:02:39,545
algorithms for implementing locks in a shared

51
00:02:39,545 --> 00:02:43,790
memory multi processor. If the processor has some

52
00:02:43,790 --> 00:02:46,430
form of affection free operation, then the

53
00:02:46,430 --> 00:02:49,570
two flavors of queue based locks, both due

54
00:02:49,570 --> 00:02:57,170
to Anderson and MCS, they are good bet for scalability. If on the other hand,

55
00:02:57,170 --> 00:02:59,920
the processor only has test and set, then an

56
00:02:59,920 --> 00:03:03,400
exponential backoff algorithm would be a good bet for scalability.
