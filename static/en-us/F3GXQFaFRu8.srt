1
00:00:00,350 --> 00:00:03,370
Having defined a random variable,
it now makes sense to talk about

2
00:00:03,370 --> 00:00:05,939
a random variable's average or
expected value.

3
00:00:07,060 --> 00:00:11,720
Formally, we define the expectation
of a random variable X, like this.

4
00:00:11,720 --> 00:00:15,320
We consider the set of
values that X could take on,

5
00:00:15,320 --> 00:00:17,850
notating it as X of omega.

6
00:00:17,850 --> 00:00:22,560
The image of the sample space under X,
and we sum over all these possible

7
00:00:22,560 --> 00:00:27,360
values, giving each a weight according
to how probable the value is.

8
00:00:28,530 --> 00:00:31,080
Thus the expectation
is a weighted average

9
00:00:31,080 --> 00:00:33,680
of all the values that
a variable could take on.

10
00:00:33,680 --> 00:00:34,710
For example,

11
00:00:34,710 --> 00:00:39,870
let the random variable X be the number
of heads in three fair coin tosses.

12
00:00:39,870 --> 00:00:44,365
Then, according to this definition,
this would be 0 times one-eighth for

13
00:00:44,365 --> 00:00:48,240
getting no heads, plus 1 times
three-eighths for getting one head.

14
00:00:48,240 --> 00:00:52,330
There are three possible tosses
that could've come up heads.

15
00:00:52,330 --> 00:00:55,240
Also, 2 times three-eighths for
getting two heads.

16
00:00:55,240 --> 00:00:59,320
Similarly there are three possible
tosses that could have come up tails so

17
00:00:59,320 --> 00:01:01,180
as to give us two heads, and

18
00:01:01,180 --> 00:01:05,230
lastly there's only a one-eighth
chance of getting all three heads.

19
00:01:05,230 --> 00:01:08,420
Adding these up we get twelve-eighths or
3 over 2.

20
00:01:08,420 --> 00:01:12,200
Now if I asked you casually how
many heads will there be in three

21
00:01:12,200 --> 00:01:13,870
coin tosses on average.

22
00:01:13,870 --> 00:01:16,670
You probably would have said
three over rather quickly

23
00:01:16,670 --> 00:01:19,080
without doing all this calculation.

24
00:01:19,080 --> 00:01:22,200
Each toss should get you half a head,
so with three,

25
00:01:22,200 --> 00:01:25,110
you should get three halves,
you might have reasoned.

26
00:01:25,110 --> 00:01:29,200
In terms of our notation,
we can express the argument like this.

27
00:01:29,200 --> 00:01:33,830
We let Xi be 1 if the ith
fair coin toss is heads.

28
00:01:33,830 --> 00:01:35,760
And we let it be 0 otherwise.

29
00:01:35,760 --> 00:01:40,305
Then we say that the average
number of heads in three tosses

30
00:01:40,305 --> 00:01:43,379
is the expectation of X1 + X2 + X3.

31
00:01:43,379 --> 00:01:48,224
And this is the expectation of
X1 plus the expectation of X2

32
00:01:48,224 --> 00:01:53,310
plus the expectation of X3 and
this totals to 3 over 2.

33
00:01:53,310 --> 00:01:56,620
The key step in the proof
is this equality here,

34
00:01:56,620 --> 00:02:00,800
which says that the expectation of
the sum is the sum of the expectations.

35
00:02:01,910 --> 00:02:04,390
This is called the linearity
of expectation.

36
00:02:04,390 --> 00:02:08,030
And as we will see, this turns
out to be a very powerful idea.

37
00:02:08,030 --> 00:02:11,730
In general, for
any two random variables X and Y and

38
00:02:11,730 --> 00:02:15,470
any constant a,
we have these two equalities.

39
00:02:15,470 --> 00:02:19,850
The expectation of the sum is
the sum of the expectations, and

40
00:02:19,850 --> 00:02:23,740
we can just factor out constant
factors from expectations.

41
00:02:23,740 --> 00:02:24,540
Remember this theorem.
