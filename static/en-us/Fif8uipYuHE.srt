1
00:00:00,360 --> 00:00:03,227
Now that you've seen what
a simple convnet looks like,

2
00:00:03,227 --> 00:00:05,794
there are many things that
we can do to improve it.

3
00:00:05,794 --> 00:00:10,112
We're going to talk about three of them,
pooling, one by one convolutions and

4
00:00:10,112 --> 00:00:13,821
something a bit more advanced
called the inception architecture.

5
00:00:13,821 --> 00:00:17,740
The first improvement is a better way
to reduce the spatial extent of your

6
00:00:17,740 --> 00:00:20,790
feature maps in
the convolutional pyramid.

7
00:00:20,790 --> 00:00:25,540
Until now, we've used striding to shift
the filters by a few pixel each time and

8
00:00:25,540 --> 00:00:27,570
reduce the future map size.

9
00:00:27,570 --> 00:00:30,860
This is a very aggressive
way to downsample an image.

10
00:00:30,860 --> 00:00:32,280
It removes a lot of information.

11
00:00:33,600 --> 00:00:36,660
What if instead of skipping
one in every two convolutions,

12
00:00:36,660 --> 00:00:40,690
we still ran with a very small stride,
say for example one.

13
00:00:40,690 --> 00:00:44,980
But then took all the convolutions in a
neighborhood and combined them somehow.

14
00:00:46,540 --> 00:00:50,780
That operation is called pooling, and
there are a few ways to go about it.

15
00:00:50,780 --> 00:00:52,850
The most common is max pooling.

16
00:00:52,850 --> 00:00:56,500
At every point in the future map,
look at a small neighborhood around that

17
00:00:56,500 --> 00:01:00,910
point and compute the maximum
of all the responses around it.

18
00:01:00,910 --> 00:01:03,800
There are some advantages
to using max pooling.

19
00:01:03,800 --> 00:01:06,400
First, it doesn't add to
your number of parameters.

20
00:01:06,400 --> 00:01:08,160
So you don't risk
an increasing over fitting.

21
00:01:09,190 --> 00:01:11,660
Second, it simply often
yields more accurate models.

22
00:01:12,880 --> 00:01:16,900
However, since the convolutions that
run below run at a lower stride,

23
00:01:16,900 --> 00:01:19,290
the model then becomes a lot
more expensive to compute.

24
00:01:20,400 --> 00:01:23,480
And now you have even more hyper
parameters to worry about.

25
00:01:23,480 --> 00:01:26,850
The pooling region size, and
the pooling stride, and no,

26
00:01:26,850 --> 00:01:27,880
they don't have to be the same.

27
00:01:28,910 --> 00:01:30,480
A very typical architecture for

28
00:01:30,480 --> 00:01:33,910
a convnets is a few layers
alternating convolutions and

29
00:01:33,910 --> 00:01:37,660
max pooling, followed by a few
fully connected layers at the top.

30
00:01:38,670 --> 00:01:43,472
The first famous model to use this
architecture was LENET-5 designed by

31
00:01:43,472 --> 00:01:47,356
Yann Lecun to the character
recognition back in 1998.

32
00:01:47,356 --> 00:01:50,276
Modern convolutional networks
such as ALEXNET, which

33
00:01:50,276 --> 00:01:54,687
famously won the competitive ImageNet
object recognition challenge in 2012,

34
00:01:54,687 --> 00:01:57,559
used a very similar architecture
with a few wrinkles.

35
00:01:58,810 --> 00:02:02,250
Another notable form of
pooling is average pooling.

36
00:02:02,250 --> 00:02:04,020
Instead of taking the max,

37
00:02:04,020 --> 00:02:08,970
just take an average over the window
of pixels around a specific location.

38
00:02:08,970 --> 00:02:12,423
It's a little bit like providing
a blurred low resolution view of

39
00:02:12,423 --> 00:02:13,694
the feature map below.

40
00:02:13,694 --> 00:02:15,500
We're going to take
advantage of that shortly.
