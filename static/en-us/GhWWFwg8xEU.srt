1
00:00:00,010 --> 00:00:03,320
In this app, we see an example, 
of a defragmented network traffic

2
00:00:03,320 --> 00:00:05,210
that uses the big cookie model.

3
00:00:05,210 --> 00:00:08,160
All the repeating transfers
have been bundled together,

4
00:00:08,160 --> 00:00:10,720
and all the intermittent transfers
have been largely replaced

5
00:00:10,720 --> 00:00:12,730
with aggressive prefetching.

6
00:00:12,730 --> 00:00:17,310
Obviously, you usually can't entirely
predict what data users might need.

7
00:00:17,310 --> 00:00:20,250
Nor can you ignore either client
or service site changes

8
00:00:20,250 --> 00:00:21,750
that need to be synchronized.

9
00:00:21,750 --> 00:00:24,460
You can aim to minimize the number
of radio state transitions

10
00:00:24,460 --> 00:00:26,810
through a combination
of aggressive prefetching

11
00:00:26,810 --> 00:00:30,720
in addition to batching and queueing 
any transfers that aren't time critical

12
00:00:30,720 --> 00:00:34,480
and bundling these with
user initiated time critical transfers,

13
00:00:34,480 --> 00:00:36,620
or those initiated from the server.

14
00:00:36,620 --> 00:00:39,900
If we compare the impact 
on the radio of the big cookie model

15
00:00:39,900 --> 00:00:42,160
compared to the previous
on demand approach,

16
00:00:42,160 --> 00:00:45,770
you can see it's now idle 
nearly two thirds of the time.

17
00:00:45,770 --> 00:00:49,530
Even the active radio percentage 
has significantly dropped,

18
00:00:49,530 --> 00:00:52,573
thanks to improved download efficiency
as a result of transmitting

19
00:00:52,573 --> 00:00:54,710
more data in one shot.
