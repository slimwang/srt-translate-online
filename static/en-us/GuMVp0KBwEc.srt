1
00:00:00,103 --> 00:00:06,108
Hi, my name is Steven Jones, and I'm one of the senior engineers in the CUDA group at Nvidia.

2
00:00:06,108 --> 00:00:09,380
My job is to work on what we think about the CUDA programming model.

3
00:00:09,380 --> 00:00:11,815
I have to figure out what we should and shouldn't do to add to it,

4
00:00:11,815 --> 00:00:14,684
how it should look once we actually do decide to add something,

5
00:00:14,684 --> 00:00:19,062
and of course getting the actual engineering work done under the covers to support the new stuff that we add.

6
00:00:19,062 --> 00:00:23,848
And one of the things I've worked on most recently is what I'm here to tell you about right now.

7
00:00:23,848 --> 00:00:26,160
It's something we call dynamic parallelism.

8
00:00:26,160 --> 00:00:28,430
So, in essence, it's really simple.

9
00:00:28,430 --> 00:00:31,632
Everything you've learned so far about running programs on the GPU

10
00:00:31,632 --> 00:00:36,940
has followed sort of a code processor model where the GPU is fully under control of the CPU.

11
00:00:36,940 --> 00:00:44,281
If you think about it, the CPU can create threads for itself. It cannot work on the GPU like this.

12
00:00:44,281 --> 00:00:47,651
Or it can synchronize to wait for the GPU work to finish.

13
00:00:47,651 --> 00:00:53,230
It sounds pretty simple, but this extra little arrow allows all sorts of new types of problems to be solved on the GPU,

14
00:00:53,230 --> 00:00:54,922
and I'm going to tell you about some of those.
