1
00:00:00,053 --> 00:00:04,955
We're going to start with what is compact. And so let's consider a common problem in computing.

2
00:00:04,955 --> 00:00:09,945
We have a set of things like cards, and we want to filter that set to get a subset that we care about.

3
00:00:09,945 --> 00:00:11,752
This comes up all the time.

4
00:00:11,752 --> 00:00:17,115
We might decide that we only want to do computation on the diamonds from this set of cards,

5
00:00:17,115 --> 00:00:20,075
and take all the other cards and throw them away.

6
00:00:20,075 --> 00:00:22,678
We might select students from the roster of this class

7
00:00:22,678 --> 00:00:25,095
who have perfect scores on the programming assignments.

8
00:00:25,095 --> 00:00:27,392
My background is in computer graphics, for instance.

9
00:00:27,392 --> 00:00:30,905
So an example there, we might have a lot of objects to draw in a scene,

10
00:00:30,905 --> 00:00:34,801
but we only want to keep those that actually intersect the screen.

11
00:00:34,801 --> 00:00:38,736
We call this operation compact because we're compacting

12
00:00:38,736 --> 00:00:43,648
the large input set of potentially many items, into something smaller.

13
00:00:43,648 --> 00:00:47,020
Another word for this is filter. Now, why do we want to do this?

14
00:00:47,020 --> 00:00:49,996
Well, if we only care about a subset of the input, and we want to run

15
00:00:49,996 --> 00:00:54,713
some computation on that input, it makes more sense to throw away the items that we don't care about,

16
00:00:54,713 --> 00:00:57,661
and only compute on the objects that we do care about.

17
00:00:57,661 --> 00:01:02,455
We can rightfully assume this is both cheaper to compute and takes less space.

18
00:01:02,455 --> 00:01:08,571
We have a set of objects S 0, S 1, S 2, S 3, S 4 and so on.

19
00:01:08,571 --> 00:01:12,755
And we have what we call a predicate, and that's this line here.

20
00:01:12,755 --> 00:01:18,705
Predicate is a function that inputs an S object and returns true or false for that object.

21
00:01:18,705 --> 00:01:23,556
For instance, this predicate we're looking at here is, "is my index even?"

22
00:01:23,556 --> 00:01:30,496
So for S 0, S 2 and S 4, the predicate returns true. For S 1 and S 3, the predicate returns false and so on.

23
00:01:30,496 --> 00:01:35,052
We want to calculate S filtered by this predicate.

24
00:01:35,052 --> 00:01:40,265
So we only keep those objects in S for which the predicate is true.

25
00:01:40,265 --> 00:01:44,887
So what form do we want the output of this filter of this compact operation to be?

26
00:01:44,887 --> 00:01:50,895
We have a choice of how to do it. We can either have a sparse output, or a dense output.

27
00:01:50,895 --> 00:01:56,064
For the sparse output, each element tracks to its same position in the output,

28
00:01:56,064 --> 00:02:00,641
and if an input has a false predicate we just put some sort of nole element in there.

29
00:02:00,641 --> 00:02:06,060
Alternatively, we could have a dense output, where all the elements for which the predicate is true

30
00:02:06,060 --> 00:02:10,033
are then packed together into the output so they're all sitting right next to each other.

31
00:02:10,033 --> 00:02:12,319
There aren't any gaps in the output.

32
00:02:12,326 --> 00:02:17,278
In general, we want the output of a compact operation to be dense. And let me tell you why.

33
00:02:17,278 --> 00:02:20,259
Let's go back to one of the examples I cited earlier.

34
00:02:20,274 --> 00:02:24,699
Selecting the 13 diamonds from a deck of 52 playing cards and running

35
00:02:24,699 --> 00:02:30,586
a procedure called compute card on each of the diamonds, we can structure this code in 1 of 2 ways.

36
00:02:30,586 --> 00:02:35,339
We could either wrap our computation in a big if clause--

37
00:02:35,339 --> 00:02:39,343
so what we're doing here is on each card we check if it's a diamond,

38
00:02:39,343 --> 00:02:43,586
and if it is a diamond then we run computecard.

39
00:02:43,586 --> 00:02:46,330
Otherwise, we do nothing. This is the sparse approach.

40
00:02:46,330 --> 00:02:50,736
Or, we could run a compact on the deck of 52 cards

41
00:02:50,736 --> 00:02:57,126
to get back 13 diamonds, by running compact on the cards, using the is diamond predicate,

42
00:02:57,126 --> 00:03:03,152
and then run a map on the compacted cards, calling compute card only on the diamonds.

43
00:03:03,152 --> 00:03:09,385
So note that the sparse computation, on the left side, is going to launch 52 threads, 1 per card,

44
00:03:09,385 --> 00:03:12,748
and 39 of those threads will be idle.

45
00:03:12,748 --> 00:03:17,093
The dense computation, on the other hand, incurs the cost of the compact,

46
00:03:17,093 --> 00:03:20,962
but then in the map step, it only launches 13 threads.

47
00:03:20,962 --> 00:03:24,598
If the compute card routine is at all expensive,

48
00:03:24,598 --> 00:03:29,239
then the sparce approach loses because we have to launch 4 times as many threads.

49
00:03:29,239 --> 00:03:32,192
Three quarters of those threads are going to be idle,

50
00:03:32,192 --> 00:03:35,133
while the other quarter of the threads are actually doing useful work.

51
00:03:35,133 --> 00:03:39,387
But because both idle and non-idle threads are running in log-step,

52
00:03:39,387 --> 00:03:43,245
we're still paying the run time costs of having 4 times as many threads

53
00:03:43,245 --> 00:03:48,921
Therefore, generally, you prefer the dense approach especially when this computation is expensive.
