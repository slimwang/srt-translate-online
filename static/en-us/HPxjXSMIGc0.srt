1
00:00:00,013 --> 00:00:01,635
Let's recap what we've learned so far.

2
00:00:01,635 --> 00:00:06,444
Parallel computing is all about many threads solving a problem by working together.

3
00:00:06,444 --> 00:00:08,712
The key is this working together.

4
00:00:08,712 --> 00:00:10,848
Any books on business practices or teamwork will tell you

5
00:00:10,848 --> 00:00:13,222
that working together is really all about communication.

6
00:00:13,222 --> 00:00:16,047
In CUDA, this communication takes place through memory.

7
00:00:16,047 --> 00:00:19,769
For example, threads may need to read from the same input location.

8
00:00:19,769 --> 00:00:22,953
Threads may need to write to the same output location.

9
00:00:22,953 --> 00:00:26,258
Sometimes threads may need to exchange partial results.
