1
00:00:00,012 --> 00:00:01,905
Now we're going to talk about the memory model.

2
00:00:01,905 --> 00:00:05,010
Let's go back to our diagram and draw the threads and blocks and kernels.

3
00:00:05,010 --> 00:00:09,608
So every thread has access to something called local memory,

4
00:00:09,608 --> 00:00:13,360
and this is memory that's private to that thread, things like its local variables.

5
00:00:13,360 --> 00:00:15,852
So the thread can read and write from local memory,

6
00:00:15,852 --> 00:00:19,311
and the threads in the thread block also have access to something called shared memory.

7
00:00:19,311 --> 00:00:23,325
So all the threads in this thread block can read and write to the per block shared memory.

8
00:00:23,325 --> 00:00:26,906
It's important to understand that shared memory is shared among the threads in a block.

9
00:00:26,906 --> 00:00:30,432
This is a small amount of memory that sits on the SM directly.

10
00:00:30,432 --> 00:00:34,084
And finally, there's global memory; every thread in the entire system at any time

11
00:00:34,084 --> 00:00:36,370
can read and write to global memory.

12
00:00:36,370 --> 00:00:39,272
So threads in 1 kernel can read and write from it.

13
00:00:39,272 --> 00:00:42,008
Threads in a later kernel can also read and write from it.

14
00:00:42,008 --> 00:00:46,015
So every thread, to recap, has access to its own local memory,

15
00:00:46,015 --> 00:00:49,351
has access to shared memory

16
00:00:49,351 --> 00:00:54,089
that's also accessible to threads specifically in its thread block,

17
00:00:54,089 --> 00:00:58,027
and to global memory, which is accessible to all of the threads everywhere.

18
00:00:58,027 --> 00:01:02,837
Of course, everything we've been talking about is on the GPU, but there's also a CPU.

19
00:01:02,837 --> 00:01:06,274
The CPU thread launches the work on the GPU,

20
00:01:06,274 --> 00:01:11,579
and of course the CPU has access to its own memory which in CUDA we call host memory.

21
00:01:11,579 --> 00:01:16,479
Usually data is copied to and from this host memory into the GPU's fast global memory

22
00:01:16,479 --> 00:01:19,018
before launching a kernel to work on that data.

23
00:01:19,018 --> 00:01:23,489
We'll talk later about how CUDA threads can access host memory directly.
