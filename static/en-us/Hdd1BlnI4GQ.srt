1
00:00:00,160 --> 00:00:02,550
Now that we know what threads are,

2
00:00:02,550 --> 00:00:05,450
what is it that we need in order to support them?

3
00:00:05,450 --> 00:00:08,860
First, we must have some data structure that will allow us to

4
00:00:08,860 --> 00:00:11,090
distinguish a thread from a process.

5
00:00:11,090 --> 00:00:15,700
This data structure should allow us to identify a specific thread and

6
00:00:15,700 --> 00:00:18,170
to keep track of their resource usage.

7
00:00:18,170 --> 00:00:22,180
Then we must have some mechanisms to create and to manage threads.

8
00:00:22,180 --> 00:00:25,460
In addition, we also need mechanisms to allow threads to

9
00:00:25,460 --> 00:00:27,390
coordinate amongst each other.

10
00:00:27,390 --> 00:00:30,620
Especially when there are certain dependencies between their

11
00:00:30,620 --> 00:00:34,340
execution when these threads are executing concurrently.

12
00:00:34,340 --> 00:00:38,420
For instance, we need to make sure that threads that execute

13
00:00:38,420 --> 00:00:43,420
concurrently don't overwrite each other's inputs or each other's results.

14
00:00:43,420 --> 00:00:47,730
Or we need mechanisms that allow one thread to wait on results that should be

15
00:00:47,730 --> 00:00:49,295
produced by some other thread.

16
00:00:49,295 --> 00:00:52,340
Well, when thinking about the type of coordination that's

17
00:00:52,340 --> 00:00:54,010
needed between threads,

18
00:00:54,010 --> 00:00:58,640
we must first think about the issues associated with concurrent execution.

19
00:00:58,640 --> 00:01:01,162
Let's first start by looking at processes.

20
00:01:01,162 --> 00:01:03,242
When processes run concurrently,

21
00:01:03,242 --> 00:01:06,230
they each operate within their own address space.

22
00:01:07,240 --> 00:01:10,110
The operating system together with the underlying hardware will

23
00:01:10,110 --> 00:01:14,710
make sure that no access from one address space is allowed to

24
00:01:14,710 --> 00:01:17,950
be performed on memory that belongs to another.

25
00:01:17,950 --> 00:01:21,520
Memory is, or state that belongs to the other address space.

26
00:01:21,520 --> 00:01:26,000
For instance, consider a physical address x that belongs to

27
00:01:26,000 --> 00:01:28,330
the process one address space.

28
00:01:28,330 --> 00:01:31,910
In that case, the mapping between the virtual address for

29
00:01:31,910 --> 00:01:37,980
p1 in process one and the physical address of x will be valid.

30
00:01:37,980 --> 00:01:42,460
Since the operating system is the one that establishes these mappings,

31
00:01:42,460 --> 00:01:45,580
the operating system will not have a valid mapping for

32
00:01:45,580 --> 00:01:50,390
any address from the address space of p2 to x.

33
00:01:50,390 --> 00:01:52,220
So from the p2 address space,

34
00:01:52,220 --> 00:01:58,300
we simply will not be able to perform a valid access to this physical location.

35
00:01:58,300 --> 00:02:03,550
Threads, on the other hand, share the same virtual-to-physical address mappings.

36
00:02:03,550 --> 00:02:08,280
So both T1 and T2, concurrently running as part of an address space,

37
00:02:08,280 --> 00:02:12,430
can both legally perform access to the same physical memory.

38
00:02:12,430 --> 00:02:15,560
And using the same virtual address on top of that.

39
00:02:15,560 --> 00:02:18,000
But this introduces some problems.

40
00:02:18,000 --> 00:02:23,380
If both T1 and T2 are allowed to access the data at the same time and

41
00:02:23,380 --> 00:02:30,150
modify it at the same time, then this could end up with some inconsistencies.

42
00:02:30,150 --> 00:02:32,020
One thread may try to read the data,

43
00:02:32,020 --> 00:02:36,950
while the other one is modifying it, so we just read some garbage.

44
00:02:36,950 --> 00:02:40,260
Or both threads are trying to update the data at the same time and

45
00:02:40,260 --> 00:02:42,380
their updates sort of overlap.

46
00:02:42,380 --> 00:02:46,530
This type of data race problem where multiple threads are accessing the same

47
00:02:46,530 --> 00:02:50,540
data at the same time is common in multithreaded environments,

48
00:02:50,540 --> 00:02:52,730
where threads execute concurrently.

49
00:02:52,730 --> 00:02:56,110
To deal with these concurrency issues, we need mechanisms for

50
00:02:56,110 --> 00:02:59,060
threads to execute in an exclusive manner.

51
00:02:59,060 --> 00:03:01,210
We call this mutual exclusion.

52
00:03:01,210 --> 00:03:05,950
Mutual exclusion is a mechanism where only one thread at a time is allowed to

53
00:03:05,950 --> 00:03:07,550
perform an operation.

54
00:03:07,550 --> 00:03:08,580
The remaining threads,

55
00:03:08,580 --> 00:03:12,550
if they want to perform the same operation, must wait their turn.

56
00:03:12,550 --> 00:03:15,430
The actual operation that must be performed in

57
00:03:15,430 --> 00:03:20,820
mutual exclusion may include some update to state or, in general,

58
00:03:20,820 --> 00:03:24,733
access to some data structure that's shared among all these threads.

59
00:03:24,733 --> 00:03:30,260
For this, Birrell and other threading systems, use what, what's called mutexes.

60
00:03:30,260 --> 00:03:32,210
In addition, it is also useful for

61
00:03:32,210 --> 00:03:36,310
threads to have a mechanism to wait on one another.

62
00:03:36,310 --> 00:03:39,540
And to exactly specify what are they waiting for.

63
00:03:39,540 --> 00:03:45,050
For instance a thread that's dealing with shipment processing must wait on all

64
00:03:45,050 --> 00:03:49,860
the items in a certain order to be processed before that order can be shipped.

65
00:03:49,860 --> 00:03:52,660
So it doesn't make sense to repeatedly check whether

66
00:03:52,660 --> 00:03:56,490
the remaining threads are done filling out the order.

67
00:03:56,490 --> 00:04:00,910
The thread just might as well wait until it's explicitly notified that

68
00:04:00,910 --> 00:04:04,450
the order is finalized so that it can at that point get up,

69
00:04:04,450 --> 00:04:06,975
pick up the order, and ship the package.

70
00:04:06,975 --> 00:04:11,535
Birrell talks about using so-called condition variables to handle this type of

71
00:04:11,535 --> 00:04:13,380
inter-thread coordination.

72
00:04:13,380 --> 00:04:18,510
We refer to both of these mechanisms as synchronization mechanisms.

73
00:04:18,510 --> 00:04:21,560
For completeness, Birrell also talks about mechanisms for

74
00:04:21,560 --> 00:04:25,440
waking up other threads from a wait state, but in this lesson,

75
00:04:25,440 --> 00:04:28,430
we will focus mostly on thread creation and

76
00:04:28,430 --> 00:04:33,680
these two synchronization mechanisms, mutexes and condition variables.

77
00:04:33,680 --> 00:04:37,000
We will discuss this issue a little bit more in following lessons.
