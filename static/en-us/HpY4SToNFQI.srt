1
00:00:00,000 --> 00:00:05,000
And so in practice what we ended up with is not this idea of coming up with a good partitioning

2
00:00:05,000 --> 00:00:08,000
for the input domain rather than a notion of test coverage.

3
00:00:08,000 --> 00:00:11,000
What the test coverage is doing is to try to accomplish exact the same thing

4
00:00:11,000 --> 00:00:14,000
that partitioning was accomplishing, but it goes about in a different way.

5
00:00:14,000 --> 00:00:18,000
Test coverage is an automatic way of partitioning the input domain

6
00:00:18,000 --> 00:00:21,000
with some observed features of the source code so let me say what I mean.

7
00:00:21,000 --> 00:00:23,000
So one particular kind of test coverage that we might aim for

8
00:00:23,000 --> 00:00:26,000
that is sort of an easy kind of test coverage is called function coverage,

9
00:00:26,000 --> 00:00:30,000
and function coverage is achieved if we managed to test our system in such a way

10
00:00:30,000 --> 00:00:34,000
that every function in our source code is executed during testing.

11
00:00:34,000 --> 00:00:37,000
We will be dividing our input domain in chunks where any test case in this part

12
00:00:37,000 --> 00:00:42,000
of the input space is going to result, for example, in a call to foo.

13
00:00:42,000 --> 00:00:46,000
So now, there's going to be some different subset of our input domain

14
00:00:46,000 --> 00:00:50,000
and any point in this subset of the input domain when used as a test input

15
00:00:50,000 --> 00:00:55,000
is going to result in a different function in the system under test--let's say bar being called.

16
00:00:55,000 --> 00:00:58,000
We can keep subdividing the input domain for the software under test

17
00:00:58,000 --> 00:01:02,000
until we have split it into parts that results in every function being called.

18
00:01:02,000 --> 00:01:05,000
So now, of course, doing this in theory is easy.

19
00:01:05,000 --> 00:01:07,000
In practice, we start with a set of test of cases,

20
00:01:07,000 --> 00:01:10,000
and we run them all through the software under test.

21
00:01:10,000 --> 00:01:12,000
We see which functions are called,

22
00:01:12,000 --> 00:01:14,000
and then we're going to end up with some sort of a score.

23
00:01:14,000 --> 00:01:18,000
So, for example, some sort of a tool that is watching our software execute can say--

24
00:01:18,000 --> 00:01:22,000
we called 181/250 functions.

25
00:01:22,000 --> 00:01:25,000
And so what this kind of score is called a test coverage metric.

26
00:01:25,000 --> 00:01:29,000
It means that our test cases so far have covered 181 of the functions

27
00:01:29,000 --> 00:01:31,000
out of the 250 that we implemented.

28
00:01:31,000 --> 00:01:33,000
And so now that we have achieved this goal that we had,

29
00:01:33,000 --> 00:01:35,000
which is assigning a score to a collection of test cases.

30
00:01:35,000 --> 00:01:38,000
The next thing we have to ask is this score any good?

31
00:01:38,000 --> 00:01:42,000
Is that a good test coverage to have executed 181/250 functions?

32
00:01:42,000 --> 00:01:44,000
With this example, it's probably not.

33
00:01:44,000 --> 00:01:47,000
So, we can do is for each of the functions that wasn't covered, we can go and look at it.

34
00:01:47,000 --> 00:01:52,000
And we can try to come up with the test input that causes that function to execute.

35
00:01:52,000 --> 00:01:55,000
There is some function baz here, and we can't seem to devise an input

36
00:01:55,000 --> 00:01:58,000
that causes it to execute, then there are a couple of possibilities.

37
00:01:58,000 --> 00:02:02,000
One possibility is that it can't be called at all. It's dead code.

38
00:02:02,000 --> 00:02:04,000
Another possibility is that we simply don't understand our system

39
00:02:04,000 --> 00:02:06,000
well enough to be able to trigger it.

40
00:02:06,000 --> 99:59:59,999
Either way, there is something possibly suspicious or wrong.
