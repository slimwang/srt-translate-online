1
00:00:00,600 --> 00:00:05,540
Some of the challenges for data center networking include traffic load balance,

2
00:00:05,540 --> 00:00:08,150
support for migrating virtual machines, in

3
00:00:08,150 --> 00:00:12,090
response to changing demands. Adjusting server

4
00:00:12,090 --> 00:00:15,320
and traffic placement to save power.

5
00:00:15,320 --> 00:00:19,270
Provisioning the network, when demands fluctuate,

6
00:00:19,270 --> 00:00:22,940
and providing various security guarantees, particularly

7
00:00:22,940 --> 00:00:25,790
in scenarios that involve multiple tenants.

8
00:00:25,790 --> 00:00:31,070
To understand these challenges, in a bit more detail, let's take a look at

9
00:00:31,070 --> 00:00:34,079
a typical data center topology. A topology

10
00:00:34,079 --> 00:00:37,274
typically has three layers: an access layer, which

11
00:00:37,274 --> 00:00:41,590
connect the servers themselves. An aggregation layer

12
00:00:41,590 --> 00:00:44,640
which connects the access layer, and then the

13
00:00:44,640 --> 00:00:48,180
core. Historically, the core of the network

14
00:00:48,180 --> 00:00:51,700
has been connected with layer three, but increasingly,

15
00:00:51,700 --> 00:00:54,320
modern data centers are connected with

16
00:00:54,320 --> 00:00:58,900
an entire layer-two topology. A layer-two topology

17
00:00:58,900 --> 00:01:04,730
makes it easier to perform migration of services from one part of the topology

18
00:01:04,730 --> 00:01:11,320
to another, since these services can stay on the same layer-two network and

19
00:01:11,320 --> 00:01:16,850
hence would not need new IP addresses when they moved. It also becomes easier to

20
00:01:16,850 --> 00:01:19,220
load balance traffic. On the other hand,

21
00:01:19,220 --> 00:01:23,970
a monolithic layer-two topology makes scaling difficult, since

22
00:01:23,970 --> 00:01:30,160
now we have tens of thousands of servers on a single flat topology. In other

23
00:01:30,160 --> 00:01:33,960
words, layer-two addresses are not topological. So

24
00:01:33,960 --> 00:01:36,580
the forwarding tables in these switches can't scale

25
00:01:36,580 --> 00:01:39,180
as easily, because they can't take advantage of

26
00:01:39,180 --> 00:01:42,560
the natural hierarchy that exists in the topology.

27
00:01:42,560 --> 00:01:44,838
Other problems that exist in this type of

28
00:01:44,838 --> 00:01:48,456
topology, is that the hierarchy can potentially create single

29
00:01:48,456 --> 00:01:51,560
points of failure. And links at the top of

30
00:01:51,560 --> 00:01:55,550
the topology, in the core, can be come oversubscribed.

31
00:01:55,550 --> 00:01:59,130
Modern data center operators have observed that as you

32
00:01:59,130 --> 00:02:02,500
move from the bottom of the hierarchy up towards

33
00:02:02,500 --> 00:02:04,790
the core, that the links at the top can

34
00:02:04,790 --> 00:02:08,060
carry as much as 200 times as much traffic

35
00:02:08,060 --> 00:02:09,258
as the links at the bottom of

36
00:02:09,258 --> 00:02:13,340
the hierarchy. So there's a serious capacity mismatch

37
00:02:13,340 --> 00:02:17,980
in that the top part of the topology has to carry a whole lot more

38
00:02:17,980 --> 00:02:20,980
traffic than the bottom. We'll explore how

39
00:02:20,980 --> 00:02:24,060
modern data center network architectures address these various

40
00:02:24,060 --> 00:02:26,880
challenges, but let's first take a quick look

41
00:02:26,880 --> 00:02:29,440
at one way of solving the scale problem.
