1
00:00:00,000 --> 00:00:03,461
A linear model is not going to be helpful here, because we

2
00:00:03,461 --> 00:00:08,090
require a model that is capable of portraying a non-linear relationship.

3
00:00:08,090 --> 00:00:11,314
Now, there are several options for accomplishing this.

4
00:00:11,314 --> 00:00:17,271
We might use k-nearest neighbor or we might consider using neural networks or we

5
00:00:17,271 --> 00:00:23,237
might consider using a kernel density estimation at each point of elapsed time.

6
00:00:23,237 --> 00:00:26,962
In fact, that might be where we'd go if we did not get anywhere using any

7
00:00:26,962 --> 00:00:27,902
other features.

8
00:00:27,902 --> 00:00:34,213
To make use of our feature set, let's attempt to use a k-nearest neighbors fit.

9
00:00:34,213 --> 00:00:39,280
Before we jump into fitting our k-nearest neighbor's model.

10
00:00:39,280 --> 00:00:42,988
Lets talk briefly about preparing out data points.

11
00:00:42,988 --> 00:00:48,244
So lets talk briefly about how we collect a series of training points that

12
00:00:48,244 --> 00:00:54,032
contain intertweet time, tweet length, elapsed time and mention distance.

13
00:00:54,032 --> 00:00:55,969
So recall in the original data set.

14
00:00:57,930 --> 00:01:05,450
We're given points, such as t1 and t2 representing two succeeding tweets.

15
00:01:05,450 --> 00:01:10,745
The amount of time taken between them is considered the intertweet time, but

16
00:01:10,745 --> 00:01:14,581
we want something that's more fine grained than this.

17
00:01:14,581 --> 00:01:18,736
What we're looking for is given an amount of time that has elapsed since

18
00:01:18,736 --> 00:01:24,030
the previous tweet, how much more time do we have to go until the next one?

19
00:01:24,030 --> 00:01:28,434
We're going to produce that information for each pair of given points.

20
00:01:28,434 --> 00:01:34,142
For example, if this is the intertweet time between two given tweets,

21
00:01:34,142 --> 00:01:37,030
we can choose a point here.

22
00:01:37,030 --> 00:01:41,230
And consider the beginning to that point to be elapsed time and

23
00:01:41,230 --> 00:01:44,830
that point to the end to be the time to go.

24
00:01:44,830 --> 00:01:49,240
And we can consider putting that marker at many points,

25
00:01:49,240 --> 00:01:51,850
giving us many values of delta s and p.

26
00:01:53,000 --> 00:01:58,199
This gives us many values of elapsed time and time to go.

27
00:01:58,199 --> 00:02:00,373
And for each one of those points,

28
00:02:00,373 --> 00:02:04,411
we still know the length of the previous tweet and the number of

29
00:02:04,411 --> 00:02:09,473
seconds that has elapsed since the last time this person has been mentioned.

30
00:02:09,473 --> 00:02:12,877
In this way, we construct out training points.

31
00:02:12,877 --> 00:02:18,633
So after constructing our training points in this way,

32
00:02:18,633 --> 00:02:23,415
we get a total of 1,381,258 points.

33
00:02:23,415 --> 00:02:30,552
And we will split those points into 70% training and 30% test.

34
00:02:30,552 --> 00:02:34,392
Let's go ahead and fit the data and perform some steps of validation and

35
00:02:34,392 --> 00:02:37,537
measure the performance of using k-nearest neighbors.
