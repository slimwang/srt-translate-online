1
00:00:00,210 --> 00:00:03,690
The same brainstorming sessions there are no bad ideas. Fair enough,

2
00:00:03,690 --> 00:00:05,580
but at some point you have to call out the ones

3
00:00:05,580 --> 00:00:09,070
that some counterproductive or incoherent. The first idea here is in

4
00:00:09,070 --> 00:00:11,790
that category since it makes no sense at all. The input to

5
00:00:11,790 --> 00:00:14,900
a fragment shader is the point inside a triangle, typically produced

6
00:00:14,900 --> 00:00:18,085
by triangle set up. The application doesn't feed service points the

7
00:00:18,085 --> 00:00:21,925
GPU. It provides triangles. Even if it fed such points the

8
00:00:21,925 --> 00:00:25,270
GPU, these points would not normally be properly placed on the screen.

9
00:00:25,270 --> 00:00:28,710
That's something the vertex shader does. Transforms the triangle to screen

10
00:00:28,710 --> 00:00:32,159
coordinates, so forget idea number one. The second idea is a

11
00:00:32,159 --> 00:00:34,870
good one, if we know early on that the fragment is

12
00:00:34,870 --> 00:00:37,390
visible, then we don't have to use the fragment shader at all.

13
00:00:37,390 --> 00:00:40,734
GPUs take advantage of this and so perform the Z-depth test

14
00:00:40,734 --> 00:00:44,210
early. So, saving not executing that fragment shader's program. This type

15
00:00:44,210 --> 00:00:47,460
of speed up is called Early-Z, after the fragment is computed,

16
00:00:47,460 --> 00:00:50,520
its then put into the Z buffer and color image as usual.

17
00:00:50,520 --> 00:00:52,790
However, there's a little subtle catch with this idea, if

18
00:00:52,790 --> 00:00:56,150
the fragment shader, itself, actually changes the Z-depth value passed

19
00:00:56,150 --> 00:00:58,840
in. Then you can not safely check this Z-depth before

20
00:00:58,840 --> 00:01:03,460
running the shader program. That said, about 99.44 of all

21
00:01:03,460 --> 00:01:06,530
fragment shaders never touch the Z-depth. In fact, in web

22
00:01:06,530 --> 00:01:09,390
GL it's not currently possible. Though this has been proposed

23
00:01:09,390 --> 00:01:12,100
as an extension. This third idea of making each core

24
00:01:12,100 --> 00:01:15,250
be usable as either a vertex a fragment shader is worthwhile.

25
00:01:15,250 --> 00:01:18,390
This in fact ia how modern GP is architected. Vertex and

26
00:01:18,390 --> 00:01:21,810
fragment shaders are close enough together and functionality that a single core

27
00:01:21,810 --> 00:01:24,480
can be used as either. This is called a unified shader.

28
00:01:24,480 --> 00:01:27,970
An advantage for the fragment shader bottleneck problem is that such course

29
00:01:27,970 --> 00:01:31,150
to be allocated on-the-fly. If fragments of piling up, cores are

30
00:01:31,150 --> 00:01:34,240
assigned to them. If vertices are queued up, cores are moved to

31
00:01:34,240 --> 00:01:37,250
this area. The first solution doesn't change anything as far as the

32
00:01:37,250 --> 00:01:40,390
fragment shader goes. The same number of pixels will be covered and

33
00:01:40,390 --> 00:01:43,120
generate fragments so that the fragment shader still has

34
00:01:43,120 --> 00:01:45,650
to work as hard. Where's the end, adding more triangles

35
00:01:45,650 --> 00:01:48,080
means more strain on other parts of the pipeline, such

36
00:01:48,080 --> 00:01:51,160
as the vertex shader. So, this idea causes more overall

37
00:01:51,160 --> 00:01:51,172
[UNKNOWN],

38
00:01:51,172 --> 00:01:52,178
not less.
