1
00:00:00,300 --> 00:00:02,370
So this is the framework that we're going to be using

2
00:00:02,370 --> 00:00:05,600
through most of the discussions that we'll be having at least

3
00:00:05,600 --> 00:00:08,860
on reinforcement learning. The single

4
00:00:08,860 --> 00:00:10,730
agent reinforcement learning, and it's called

5
00:00:10,730 --> 00:00:14,850
the Markov Decision Process. This should sound familiar to you, Michael.

6
00:00:14,850 --> 00:00:17,580
>> Well, you did say we're going to talk about decisions.

7
00:00:17,580 --> 00:00:21,904
>> That's true, and we need a process for making decisions. And we're going

8
00:00:21,904 --> 00:00:24,204
to introduce something called the Markovian property

9
00:00:24,204 --> 00:00:25,400
as a part of this discussion and

10
00:00:25,400 --> 00:00:27,810
I'll tell you exactly what that means in a moment.

11
00:00:27,810 --> 00:00:30,010
So, I'm just going to write out this frame work and

12
00:00:30,010 --> 00:00:32,110
just, and tell you what it is and what the

13
00:00:32,110 --> 00:00:36,030
problem it produces for us. And then we're going to start

14
00:00:36,030 --> 00:00:39,360
talking about solutions through the rest of the discussion. So

15
00:00:39,360 --> 00:00:41,960
a Markov Decision Process tries to capture worlds like this

16
00:00:41,960 --> 00:00:45,840
one by dividing up in the following way. We say

17
00:00:45,840 --> 00:00:50,810
that there are states. And states are a set of tokens

18
00:00:50,810 --> 00:00:54,550
that somehow represent every state, for lack of a better word, that

19
00:00:54,550 --> 00:00:57,430
one could be in. So, does that make sense to you, Michael?

20
00:00:57,430 --> 00:00:58,230
>> Yeah, I think so.

21
00:00:58,230 --> 00:00:59,910
>> So what would the states be in the

22
00:00:59,910 --> 00:01:01,990
world that we've been playing around in so far?

23
00:01:01,990 --> 00:01:04,709
>> So, the only thing that differs from

24
00:01:04,709 --> 00:01:08,440
moment to moment is where, I guess, I am.

25
00:01:08,440 --> 00:01:08,470
>> Mm-hm.

26
00:01:08,470 --> 00:01:10,250
>> Like, which grid, grid position I'm in.

27
00:01:10,250 --> 00:01:10,350
>> Right.

28
00:01:10,350 --> 00:01:12,120
>> So, I feel like each different grid position I could

29
00:01:12,120 --> 00:01:16,270
be in is a state, maybe there's a state for being successfully

30
00:01:16,270 --> 00:01:18,070
done or unsuccessfully done?

31
00:01:18,070 --> 00:01:19,880
>> It's possible. But let's stick with the simple one. I

32
00:01:19,880 --> 00:01:23,360
like that one because that's really, I think, easy to grasp. So,

33
00:01:23,360 --> 00:01:26,080
there are at least, of all the states one could reach,

34
00:01:26,080 --> 00:01:29,110
there's, well let's see there's four times three minus one, since you

35
00:01:29,110 --> 00:01:31,990
can never reach this state. Although we could say it is

36
00:01:31,990 --> 00:01:35,330
a state we just happen to never reach it. So, at most

37
00:01:35,330 --> 00:01:38,350
if we just think of this grid literally as a grid there

38
00:01:38,350 --> 00:01:41,400
are something like twelve different states. And we can represent these states

39
00:01:41,400 --> 00:01:44,352
as their X,Y coordinates, say. We could call

40
00:01:44,352 --> 00:01:47,304
this, the start state as say 1,1, which

41
00:01:47,304 --> 00:01:53,450
is sort of how I described it earlier. We could describe the goal state as 4,4.

42
00:01:53,450 --> 00:01:55,670
And say this is how we describe our

43
00:01:55,670 --> 00:01:58,380
states. Or frankly, it doesn't matter. We could

44
00:01:58,380 --> 00:02:06,870
call these states 1,2,3 up to 12. Or we could name them Fred and Marcus. It

45
00:02:06,870 --> 00:02:08,620
doesn't really matter. The point is

46
00:02:08,620 --> 00:02:10,639
that they're states, they represent something, and

47
00:02:10,639 --> 00:02:14,106
we have some way of knowing which state we happen to be in. Okay?

48
00:02:14,106 --> 00:02:15,062
>> Sure.

49
00:02:15,062 --> 00:02:16,018
>> Okay.
