1
00:00:02,538 --> 00:00:05,914
Okay so here's where dynamic parallelism steps scene.

2
00:00:05,914 --> 00:00:08,373
It solves both of these problems really neatly.

3
00:00:08,373 --> 00:00:11,687
What I've got here is an example of how quicksort would sort a series of numbers.

4
00:00:11,687 --> 00:00:15,817
At the top level, a single kernel partitions the numbers into 2 groups

5
00:00:15,817 --> 00:00:20,206
then launches 2 quicksort kernels, 1 on each group, and so on down.

6
00:00:20,206 --> 00:00:24,770
It would already have all the information it needs to decide whether to launch and how many threads to use

7
00:00:24,770 --> 00:00:26,864
because it's just done the partitioning,

8
00:00:26,864 --> 00:00:29,698
so it doesn't have to communicate this back to the CPU.

9
00:00:29,698 --> 00:00:32,066
That's the first problem taken care of.

10
00:00:32,066 --> 00:00:35,374
It solves a second problem, because as these kernels run,

11
00:00:35,374 --> 00:00:38,279
they each launch as soon as they finish partitioning.

12
00:00:38,279 --> 00:00:40,885
That means my plot progresses asynchronously.

13
00:00:40,885 --> 00:00:45,807
For example, this one on the left will launch its children, while the one on the right is still working,

14
00:00:45,807 --> 00:00:48,106
because there's more work to do on the right hand side here.

15
00:00:48,106 --> 00:00:50,997
Each sort will be running independently of any others.

16
00:00:50,997 --> 00:00:54,036
I'm not waiting around for the slowest sort anymore,

17
00:00:54,036 --> 00:00:56,748
and my GPU is kept busy.

18
00:00:56,748 --> 00:00:58,915
So here's what the code looks like.

19
00:00:58,915 --> 00:01:01,581
I'm not going to get into detail about the partitioning function,

20
00:01:01,581 --> 00:01:06,316
because we're looking at dynamic launches here and you already covered partitioning in a previous lecture.

21
00:01:06,316 --> 00:01:10,421
The important thing to notice is there is no host side management of data or launchers needed.

22
00:01:10,421 --> 00:01:13,320
Everything happens inside the code itself.

23
00:01:13,320 --> 00:01:18,060
Here are my launches inside my kernel of my next quicksort kernels.

24
00:01:18,060 --> 00:01:20,181
So my code's nice and simple,

25
00:01:20,181 --> 00:01:23,741
and the kernel launches its 2 children into separate streams.

26
00:01:23,741 --> 00:01:26,803
Remember that CUDA streams run simultaneously,

27
00:01:26,803 --> 00:01:30,091
which means my 2 sub sorts will execute in parallel.

28
00:01:30,091 --> 00:01:33,125
Without these streams, everything would run sequentially,

29
00:01:33,125 --> 00:01:36,125
because both of these launches would end up in the null stream,

30
00:01:36,125 --> 00:01:40,234
and that would defeat the purpose of the parallel sort to have my program running sequentially.

31
00:01:40,234 --> 00:01:43,004
So let's have a quick look back at the sort diagram to show you what I mean.

32
00:01:43,004 --> 00:01:48,528
If each launch runs sequentially, then I would do the left side first,

33
00:01:48,528 --> 00:01:51,726
then its children,

34
00:01:51,726 --> 00:01:54,613
left side first here,

35
00:01:54,613 --> 00:01:56,644
then the right-hand side,

36
00:01:56,644 --> 00:02:01,181
then I would come back and do the right-hand side next, and then so on,

37
00:02:01,181 --> 00:02:04,150
and so what we would see

38
00:02:04,150 --> 00:02:07,640
is that each step gets run sequentially instead of in parallel,

39
00:02:07,640 --> 00:02:09,955
which defeats the purpose of the parallel sort.

40
00:02:09,955 --> 00:02:15,670
So by launching the sort into different streams, we run both the left and right sorts in parallel.

41
00:02:15,670 --> 00:02:18,266
So I would run both of these together,

42
00:02:18,266 --> 00:02:20,867
and then each of their children and so on,

43
00:02:20,867 --> 00:02:23,105
and I'd get the parallel performance I'm looking for.

44
00:02:23,105 --> 00:02:26,841
I've combined dynamic parallism with CUDA streams

45
00:02:26,841 --> 00:02:31,230
to get the parallel execution that I just would not be able to do any other way.
