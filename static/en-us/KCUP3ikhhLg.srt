1
00:00:00,025 --> 00:00:03,412
So let's summarize our breadth first search try number 1.

2
00:00:03,412 --> 00:00:05,710
So this algorithm has some great properties.

3
00:00:05,710 --> 00:00:10,277
It's completely parallel, and there's no direct communication or synchronization between threads at all.

4
00:00:10,277 --> 00:00:12,198
There's very little thread divergence.

5
00:00:12,198 --> 00:00:16,412
The memory behavior isn't ideal since it involves gathers and scatters, but it's not bad.

6
00:00:16,412 --> 00:00:20,023
Unfortunately, the host has to control the iterations, which isn't super attractive,

7
00:00:20,023 --> 00:00:24,401
though we'll look at a new feature in CUDA 5 in the next unit called Dynamic Parallelism

8
00:00:24,401 --> 00:00:26,696
that allows the GPU to control the iterations directly,

9
00:00:26,696 --> 00:00:29,405
but the real problem is the quadratic complexity.

10
00:00:29,405 --> 00:00:31,867
We're going to have perfectly data parallel work,

11
00:00:31,867 --> 00:00:34,152
but we're going to do way too much of it.

12
00:00:34,152 --> 00:00:37,240
This approach will scale poorly as we process larger and larger graphs,

13
00:00:37,240 --> 00:00:39,223
and we are not cool with that at all.
