1
00:00:00,137 --> 00:00:04,139
So remember that our goal is to maximize the amount of useful computation done per second,

2
00:00:04,139 --> 00:00:09,125
and we've been talking a lot about optimizing memory access because that's usually the bottleneck for GPU codes,

3
00:00:09,125 --> 00:00:13,317
but some codes, or some portions of codes, are limited by the actual computation,

4
00:00:13,317 --> 00:00:15,793
so let's talk about optimizing compute performance.

5
00:00:15,793 --> 00:00:22,856
This topic boils down to two simple guidelines: minimize time spent waiting at barriers and minimize thread divergence.

6
00:00:22,856 --> 00:00:26,161
Now, we've already seen an example of the first optimization.

7
00:00:26,161 --> 00:00:31,476
Too much time spent waiting at barriers prevented us, in our tile transpose code,

8
00:00:31,476 --> 00:00:35,867
from making memory accesses fast enough to saturate global memory bandwidth.

9
00:00:35,867 --> 00:00:38,074
By shrinking the number of threads in the thread block,

10
00:00:38,074 --> 00:00:42,613
we're able to minimize the number of them that were actually waiting on the barrier

11
00:00:42,613 --> 00:00:45,781
and get closer to fully utilizing the global memory.
