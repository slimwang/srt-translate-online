1
00:00:00,420 --> 00:00:02,210
All right. So Charles, what do you think would some

2
00:00:02,210 --> 00:00:06,150
reasonable resources to try to manage in a learning algorithm?

3
00:00:06,150 --> 00:00:09,480
>> Okay, well I was thinking of three. Because three is my favorite

4
00:00:09,480 --> 00:00:12,440
number. Two of them are what you already have written up there. Time and

5
00:00:12,440 --> 00:00:16,149
space. After all, at the end of the day, it's still an algorithm.

6
00:00:16,149 --> 00:00:18,490
We need to be able to analyze algorithms in terms of time and space.

7
00:00:18,490 --> 00:00:22,300
>> That's right, so if in particular we have a learning algorithm and

8
00:00:22,300 --> 00:00:25,720
they, they do more or less the same things, but one runs in n-squared

9
00:00:25,720 --> 00:00:28,580
time and the other runs in exponential time, we'd really like

10
00:00:28,580 --> 00:00:31,300
to have the one that runs in the shorter amount of

11
00:00:31,300 --> 00:00:33,660
time. Or, in particular, if there's a, if we define a

12
00:00:33,660 --> 00:00:37,120
learning problem and we say well, We could do this computation, but

13
00:00:37,120 --> 00:00:41,220
its MP hard. Then maybe that's a problematic way of defining

14
00:00:41,220 --> 00:00:44,090
the problem. So yeah, time definitely matters. Space for the same

15
00:00:44,090 --> 00:00:47,100
reason. And those are the same things that happen in in,

16
00:00:47,100 --> 00:00:51,230
or that are relevant in regular algorithms. What about anything specific to

17
00:00:51,230 --> 00:00:52,110
the machine learning setting?

18
00:00:52,110 --> 00:00:54,880
>> Okay, so that was my third one. So The only thing that

19
00:00:54,880 --> 00:00:58,400
matters in machine learning or the most important thing in machine learning is

20
00:00:58,400 --> 00:01:02,880
data. So I would think that another resource that we care about is

21
00:01:02,880 --> 00:01:07,550
the data and in particular the set of training samples that we have.

22
00:01:07,550 --> 00:01:11,100
>> Yes I like the, I like the word samples. Though data

23
00:01:11,100 --> 00:01:15,540
is probably pretty good. Thing to stick in there as well or examples.

24
00:01:17,470 --> 00:01:18,350
Those should all be okay.

25
00:01:18,350 --> 00:01:21,380
>> Yes. Indeed. Yeah. We, we want to know, can

26
00:01:21,380 --> 00:01:24,510
we learn well with a small amount of samples. In

27
00:01:24,510 --> 00:01:27,100
particular if, our learning algorithm works great in terms of

28
00:01:27,100 --> 00:01:29,200
time and space, but in order to run it you

29
00:01:29,200 --> 00:01:33,950
actually have to give Examples of every possible input, then

30
00:01:33,950 --> 00:01:36,140
that's not going to be a very useful algorithm. So,

31
00:01:36,140 --> 00:01:38,880
the fewer samples that it can use, the more that

32
00:01:38,880 --> 00:01:41,650
it's generalizing effectively, and the better it is at learning.

33
00:01:41,650 --> 00:01:42,480
>> Oh, that makes sense.
