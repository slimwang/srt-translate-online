1
00:00:00,278 --> 00:00:04,778
Given these technical trends, let's characterize the decisions that GPU designers have made.

2
00:00:04,778 --> 00:00:10,815
One, GPUs have lots of simple compute units that together can perform a large amount of computation.

3
00:00:10,815 --> 00:00:13,951
In general, the GPU is willing to trade off control for compute

4
00:00:13,951 --> 00:00:17,154
and choose simpler control complexity and more compute power.

5
00:00:17,154 --> 00:00:20,226
The consequence of this decision is that the GPU programming model,

6
00:00:20,226 --> 00:00:24,830
the programmer's view of the machine, is perhaps more restrictive than the CPU's.

7
00:00:24,830 --> 00:00:28,666
Two, GPUs have an explicitly parallel programming model.

8
00:00:28,666 --> 00:00:32,168
When we write programs for this machine, we know that we have lots of processors,

9
00:00:32,168 --> 00:00:34,174
and we have to program it in that way.

10
00:00:34,174 --> 00:00:36,278
We don't pretend that it has one processor

11
00:00:36,278 --> 00:00:40,847
and rely on a magic compiler chain to figure out how to map work onto many processors.

12
00:00:40,847 --> 00:00:43,382
This programming model is a main focus of the class.

13
00:00:43,382 --> 00:00:45,150
We'll talk a lot more about this.

14
00:00:45,150 --> 00:00:48,754
And three, GPUs optimize for throughput, not latency.

15
00:00:48,754 --> 00:00:52,790
They are willing to accept increased latency of any single individual computation

16
00:00:52,790 --> 00:00:55,559
in exchange for more computation being performed per second.

17
00:00:55,559 --> 00:01:00,364
Consequently, they're well suited for application domains where throughput is the most important metric.
