1
00:00:00,240 --> 00:00:03,280
Now, I get slightly more complicated
in the case where there can be

2
00:00:03,280 --> 00:00:04,380
only one policy.

3
00:00:04,380 --> 00:00:08,550
And that's because for the very reason
that we described in the first quiz,

4
00:00:08,550 --> 00:00:11,630
where if I know with certainty,
there's only one policy, and

5
00:00:11,630 --> 00:00:14,840
I know with certainty, the human gives
me the right answer, the moment you tell

6
00:00:14,840 --> 00:00:18,220
me that some action is correct, I now
know something about the other actions.

7
00:00:18,220 --> 00:00:20,210
So it becomes complicated.

8
00:00:20,210 --> 00:00:23,410
Somehow, what you've told me about
a second action tells me something about

9
00:00:23,410 --> 00:00:24,580
the first action.

10
00:00:24,580 --> 00:00:27,850
And when you go through all the math,
it's still a multinomial.

11
00:00:27,850 --> 00:00:30,010
And when you go through all the math and
do the derivation, and

12
00:00:30,010 --> 00:00:33,440
the derivation's available for the
students, you end up with this quantity.

13
00:00:33,440 --> 00:00:39,018
That the probability that a particular
action A is optimal given a sequence

14
00:00:39,018 --> 00:00:44,062
of labels is what we've seen before,
it's c raised to the delta sub

15
00:00:44,062 --> 00:00:50,109
a (1-c) raised to all the other evidence
that we have from the other actions.

16
00:00:50,109 --> 00:00:53,420
And then there's a normalization
factor which I don't write out here.

17
00:00:53,420 --> 00:00:56,948
And this corresponds to what
we did in the last example,

18
00:00:56,948 --> 00:01:02,368
where we wrote out 0.8, 0.2, and
0.2 and then normalized everything out.

19
00:01:02,368 --> 00:01:03,610
>> And
let me make sure I understand that.

20
00:01:03,610 --> 00:01:06,490
So we have 1.2, the delta is 1.

21
00:01:06,490 --> 00:01:07,140
>> Yes.

22
00:01:07,140 --> 00:01:09,040
>> No, but it's 0 for the other guys?

23
00:01:09,040 --> 00:01:10,550
What's delta j?

24
00:01:10,550 --> 00:01:12,040
Delta j is for the other actions.

25
00:01:12,040 --> 00:01:17,020
>> Yes, this is the difference between
the times you said yes and no for

26
00:01:17,020 --> 00:01:20,300
every other action that isn't the
particular action you're asking about.

27
00:01:20,300 --> 00:01:23,304
So this provides evidence
from the other actions.

28
00:01:23,304 --> 00:01:24,680
>> I see, and
then we're going to normalize.

29
00:01:24,680 --> 00:01:27,735
So maybe that squiggle equals
wants to be like an alpha,

30
00:01:27,735 --> 00:01:29,493
like a proportional to symbol?

31
00:01:29,493 --> 00:01:34,196
>> Yeah, sure, I usually write squiggle,
where I grew up in the South,

32
00:01:34,196 --> 00:01:36,130
that meant approximately.

33
00:01:36,130 --> 00:01:38,450
But there, that make you feel better?

34
00:01:38,450 --> 00:01:41,468
>> Much better, because it's not
really approximately, it's actually

35
00:01:41,468 --> 00:01:44,634
proportional to, which means we're
going to have to normalize afterwards,

36
00:01:44,634 --> 00:01:46,923
so that we get the 0.8,
we get a 0.2 and a 0.2.

37
00:01:46,923 --> 00:01:49,720
And then when we normalize it,
we get the 2/3, 1/6, 1/6.

38
00:01:49,720 --> 00:01:50,650
Awesome.
>> Exactly.

39
00:01:50,650 --> 00:01:52,100
And the right thing
kind of happens there.

40
00:01:52,100 --> 00:01:54,720
And you could write out what
the normalization factor is, and

41
00:01:54,720 --> 00:01:57,170
then we don't have to have an alpha
here, we can have an equals.

42
00:01:57,170 --> 00:02:01,280
But it's big, long, and hairy, and it's
just much simpler to actually ignore it,

43
00:02:01,280 --> 00:02:03,460
do this part, which is really easy.

44
00:02:03,460 --> 00:02:05,150
And then do the normalization
afterwards.

45
00:02:05,150 --> 00:02:05,830
More to the point,

46
00:02:05,830 --> 00:02:09,080
since what we care about is a policy,
we only care about which one's maximal.

47
00:02:09,080 --> 00:02:11,480
We don't actually care about
the actual probability.

48
00:02:11,480 --> 00:02:13,406
>> I'm forgetting why
we care about a policy.

49
00:02:13,406 --> 00:02:14,560
>> Remember.
>> because we're trying to,

50
00:02:14,560 --> 00:02:15,190
because ultimately,

51
00:02:15,190 --> 00:02:17,670
we're combining this information
to figure out what action to take.

52
00:02:17,670 --> 00:02:18,450
>> Right.
>> Got it.

53
00:02:18,450 --> 00:02:21,370
>> If all we're doing is listening to
human beings, then when a human tells

54
00:02:21,370 --> 00:02:25,250
us something, we want to pick the action
that's most likely to be optimal.

55
00:02:25,250 --> 00:02:27,390
And so it doesn't matter what
the actual probability is so

56
00:02:27,390 --> 00:02:28,640
long as we have the ordering right.

57
00:02:28,640 --> 00:02:30,050
And so we don't have to normalise.

58
00:02:30,050 --> 00:02:31,360
We don't have to know the probability,

59
00:02:31,360 --> 00:02:33,150
we just have to make certain
we get the maximum one right.
