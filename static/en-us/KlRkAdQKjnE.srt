1
00:00:00,008 --> 00:00:03,160
Now, in order to limit the amount of contention

2
00:00:03,160 --> 00:00:05,590
on the network when a lock is released, we're

3
00:00:05,590 --> 00:00:07,760
going to do something that we often do in real

4
00:00:07,760 --> 00:00:12,840
life. procrastination. So basically, the idea is the following.

5
00:00:14,050 --> 00:00:17,290
Each processor is going to delay asking for the

6
00:00:17,290 --> 00:00:19,900
lock, even though they observe that the lock is

7
00:00:19,900 --> 00:00:23,190
released. Then I will immediately go and try to

8
00:00:23,190 --> 00:00:25,080
get the lock. They're going to wait for a little bit

9
00:00:25,080 --> 00:00:29,010
of time. It's sort of like what happens at rush

10
00:00:29,010 --> 00:00:32,479
hour. If you find that the this traffic is too

11
00:00:32,479 --> 00:00:34,640
much, you might decide that I don't want to get on

12
00:00:34,640 --> 00:00:37,640
the highway right now. I'm going to delay a little bit

13
00:00:37,640 --> 00:00:41,330
so that I don't have to spend as much time

14
00:00:41,330 --> 00:00:43,190
on the highway. So that's sort of the same thing

15
00:00:43,190 --> 00:00:45,920
that is being proposed here, and this is what is

16
00:00:45,920 --> 00:00:50,499
called spinlocks with delay. Let's discuss two different delay alternatives.

17
00:00:51,700 --> 00:00:55,880
In the first one, you're here. You found that you

18
00:00:55,880 --> 00:00:59,000
did not get the lock and therefore, you're here locally

19
00:00:59,000 --> 00:01:03,440
spinning in your cache, waiting for the lock to be

20
00:01:03,440 --> 00:01:06,400
released. Normally what you would have done, when the lock

21
00:01:06,400 --> 00:01:08,380
is released, is go back out, break out of this

22
00:01:08,380 --> 00:01:10,710
loop and go back and check if you can get

23
00:01:10,710 --> 00:01:12,900
the lock again. But what we're going to do is,

24
00:01:12,900 --> 00:01:16,790
instead of doing that, when we break out of this loop,

25
00:01:16,790 --> 00:01:19,610
meaning that the lock has been release, I'm

26
00:01:19,610 --> 00:01:21,960
not going to immediately go and check to see

27
00:01:21,960 --> 00:01:23,850
if I can get the lock. I'm doing to

28
00:01:23,850 --> 00:01:26,600
delay myself by a certain amount of time. And

29
00:01:26,600 --> 00:01:31,810
you notice that the delay is conditioned by what processor id I

30
00:01:31,810 --> 00:01:36,570
have. So every processor is waiting for a different amount of

31
00:01:36,570 --> 00:01:42,300
delay in order to contend for the lock. So since the delay

32
00:01:42,300 --> 00:01:45,650
is being chosen differently for each processor, even though

33
00:01:45,650 --> 00:01:48,540
all of them notice that the lock has been released

34
00:01:48,540 --> 00:01:52,230
simultaneously, only one of them will go and check

35
00:01:52,230 --> 00:01:55,750
it. And so we are sort of sequentializing the order

36
00:01:55,750 --> 00:01:59,460
in which the processors that are waiting for the

37
00:01:59,460 --> 00:02:02,120
lock are going to check whether the lock is available.

38
00:02:02,120 --> 00:02:04,940
So that is one possible scheme for delaying. Now

39
00:02:04,940 --> 00:02:07,190
the problem with this is it's a static delay, right?

40
00:02:07,190 --> 00:02:09,258
So every processor has been preassigned a certain

41
00:02:09,258 --> 00:02:11,580
amount of delay, which means that even if

42
00:02:11,580 --> 00:02:14,770
the lock is available, I may not immediately

43
00:02:14,770 --> 00:02:16,890
go and check because my delay may be very

44
00:02:16,890 --> 00:02:20,530
high compared to some other processor. And that's

45
00:02:20,530 --> 00:02:24,660
always an issue when you have static decision

46
00:02:24,660 --> 00:02:27,700
making. What we can do is instead make

47
00:02:27,700 --> 00:02:31,100
the decision dynamically, and what we're going to do is,

48
00:02:32,190 --> 00:02:35,510
when we notice that we don't have the lock,

49
00:02:37,400 --> 00:02:39,250
we're going to delay ourselves by a certain amount of

50
00:02:39,250 --> 00:02:41,380
time before we try for the lock again. You

51
00:02:41,380 --> 00:02:44,930
notice that if you're going to delay checking for whether

52
00:02:44,930 --> 00:02:47,270
I have the lock or not. It's not super

53
00:02:47,270 --> 00:02:51,360
critical that, that you spin locally or go to

54
00:02:51,360 --> 00:02:54,700
memory. But in this example, I'm making it very

55
00:02:54,700 --> 00:02:57,270
simple by saying that if you don't get the

56
00:02:57,270 --> 00:02:59,700
lock, just delay a little bit before you try for

57
00:02:59,700 --> 00:03:05,260
this lock again. And the idea here is this delay

58
00:03:05,260 --> 00:03:08,470
is, is some small number to start with. But suppose

59
00:03:08,470 --> 00:03:10,800
I go and check and I find it again to

60
00:03:10,800 --> 00:03:12,630
be locked. Now, what I'm going to do is the

61
00:03:12,630 --> 00:03:16,380
next time around, I'm going to increase the delay. That's

62
00:03:16,380 --> 00:03:19,840
why it's called exponential backoff. So I'm increasing the delay,

63
00:03:19,840 --> 00:03:22,180
doubling the amount of delay that I'm going to do.

64
00:03:22,180 --> 00:03:24,610
So that the next time, if I don't find

65
00:03:24,610 --> 00:03:28,620
the lock to be available, I delay by twice

66
00:03:28,620 --> 00:03:31,530
the amount from the previous time. And this is

67
00:03:31,530 --> 00:03:36,580
essentially saying that when the lock is not highly contented

68
00:03:36,580 --> 00:03:40,550
for, I'm not going to delay myself too much. I'm

69
00:03:40,550 --> 00:03:42,640
going to immediately go and get it. But on

70
00:03:42,640 --> 00:03:45,450
the other hand, if I go back again and

71
00:03:45,450 --> 00:03:47,470
again, and every time I go and check, I find

72
00:03:47,470 --> 00:03:49,740
it is locked, I'm going to increase the amount of

73
00:03:49,740 --> 00:03:52,890
delay. Because that's saying that lot of people are contending

74
00:03:52,890 --> 00:03:55,130
for the lock at the same time. And therefore,

75
00:03:55,130 --> 00:03:58,530
in order to make sure that we are being sensitive

76
00:03:58,530 --> 00:04:01,460
to the contention that is there for the lock,

77
00:04:01,460 --> 00:04:04,880
we increase the amount of delay that we're experiencing. Now

78
00:04:04,880 --> 00:04:07,200
one nice thing about this simple algorithm that I've shown

79
00:04:07,200 --> 00:04:12,670
you is that I'm not using the caches at all.

80
00:04:12,670 --> 00:04:14,990
And, if the, if the processor happens to

81
00:04:14,990 --> 00:04:19,660
be a non-cache coherent multi-processor, this algorithm will

82
00:04:19,660 --> 00:04:22,690
still work. Because we're always using test and

83
00:04:22,690 --> 00:04:27,330
set, and not using just loading from the memory.

84
00:04:27,330 --> 00:04:30,340
Because if it is not a cache-coherent multiprocessor,

85
00:04:31,530 --> 00:04:33,620
your private cache is now going to be coherent

86
00:04:33,620 --> 00:04:35,760
with respect to memory. And so you have

87
00:04:35,760 --> 00:04:37,720
to execute test and set. But you don't want to

88
00:04:37,720 --> 00:04:42,510
do it all the time. And this delay makes sure that you can reduce the amount

89
00:04:42,510 --> 00:04:46,880
of contention on the network. Generally speaking. If

90
00:04:46,880 --> 00:04:49,720
there's a lot of contention, then static assignment

91
00:04:49,720 --> 00:04:52,500
of delay may be better than the dynamic

92
00:04:52,500 --> 00:04:57,220
exponential backoff. But in, in general any kind

93
00:04:57,220 --> 00:05:00,370
of delay, any kind of procrastination, will help

94
00:05:00,370 --> 00:05:02,960
a lock algorithm better than the naive spin lock

95
00:05:02,960 --> 00:05:03,740
that we talked about.
