1
00:00:00,300 --> 00:00:03,890
So we're going to need one more
interesting property of this operator

2
00:00:03,890 --> 00:00:07,510
B1, but this one is specific to
the context of policy iteration.

3
00:00:07,510 --> 00:00:09,230
So let's think about it this way.

4
00:00:09,230 --> 00:00:12,530
Imagine we've got some policy, Pi1,
just like we've been saying, and

5
00:00:12,530 --> 00:00:15,530
associated with Pi1 is the operator B1.

6
00:00:15,530 --> 00:00:18,940
And let's say that Q1 Is
the fixed point of B1 and

7
00:00:18,940 --> 00:00:21,950
how do we know that it
has a unique fixed point?

8
00:00:21,950 --> 00:00:23,100
>> because you proved it earlier.

9
00:00:23,100 --> 00:00:25,611
>> Yeah,
it was the contraction property of B1.

10
00:00:25,611 --> 00:00:26,249
>> Yeah.

11
00:00:26,249 --> 00:00:27,970
>> So let's imagine that's happened.

12
00:00:27,970 --> 00:00:28,590
We have solved out Q1,

13
00:00:28,590 --> 00:00:30,990
and this is sort of how policy
iteration works too, right?

14
00:00:30,990 --> 00:00:34,640
You start off with the policy, you
get the value function of that policy

15
00:00:34,640 --> 00:00:38,240
then we're going to take the greedy
policy Pi2 with respect to Q1.

16
00:00:38,240 --> 00:00:42,534
So in the last slide or so Pi1 and
Pi2 were just arbitrary policies.

17
00:00:42,534 --> 00:00:45,460
Now Pi2 is specifically
the greedy policy

18
00:00:45,460 --> 00:00:48,750
with respect to the value
function defined by Pi1.

19
00:00:48,750 --> 00:00:52,240
So then let B2 be the operator
associated with Pi2 and

20
00:00:52,240 --> 00:00:54,090
this is the thing that we want to show.

21
00:00:54,090 --> 00:00:59,432
The Q function that comes from solving,
for the the fixed point of Pi1,

22
00:00:59,432 --> 00:01:04,788
so the value function for Pi1 is less
than or equal to B2 applied to Q1.

23
00:01:04,788 --> 00:01:05,600
Does that make sense?

24
00:01:05,600 --> 00:01:08,740
So if we take whatever we end
up with after we solve for

25
00:01:08,740 --> 00:01:14,300
the value function for Pi1, we take
Pi2s greedy policy and then we do one

26
00:01:14,300 --> 00:01:20,100
Bellman backup with respect to that and
we get value function that dominates Q1.

27
00:01:20,100 --> 00:01:23,120
>> Okay, and that's because
of other stuff on the slide.

28
00:01:23,120 --> 00:01:25,140
>> Yeah so we'll just work through that.

29
00:01:25,140 --> 00:01:29,730
So intuitively what we're saying is you
do policy evaluation on Pi1 we get some

30
00:01:29,730 --> 00:01:33,620
value function Q1 and
then we do one step of

31
00:01:33,620 --> 00:01:37,510
essentially value iteration using
the greedy policy with respect to Q1 and

32
00:01:37,510 --> 00:01:40,380
that's going to make it
no worse possibly better.

33
00:01:40,380 --> 00:01:42,610
And so the reason for
that is well what is Q1.

34
00:01:42,610 --> 00:01:45,260
Q1, it's the fixed point
of the B1 operator.

35
00:01:45,260 --> 00:01:49,270
So in this particular case it's
the reward plus the discounted

36
00:01:49,270 --> 00:01:54,100
expected value for taking action Pi1 and
ending up in some new state as prime and

37
00:01:54,100 --> 00:01:57,470
taking action Pi1 of S
prime from that state.

38
00:01:57,470 --> 00:01:59,400
But think about what Pi2 is.

39
00:01:59,400 --> 00:02:01,781
We can actually substitute Pi2 for

40
00:02:01,781 --> 00:02:04,890
Pi1 in here but Pi2 is the greedy
policy with respect to this.

41
00:02:04,890 --> 00:02:05,720
In other words,

42
00:02:05,720 --> 00:02:10,210
it is the policy that causes this
exact quantity to be maximized.

43
00:02:10,210 --> 00:02:12,600
That's what the greedy policy does.

44
00:02:12,600 --> 00:02:16,020
At every state either we're going to
do no worse than we did with Pi1, or

45
00:02:16,020 --> 00:02:18,290
we might actually do better
by switching to Pi2,

46
00:02:18,290 --> 00:02:20,910
the greedy policy with respect to Q1.

47
00:02:20,910 --> 00:02:26,860
So at each state action pair we're
doing no worse by doing one step of,

48
00:02:26,860 --> 00:02:30,610
well, one Bellman backup with B2 on Q1.

49
00:02:30,610 --> 00:02:32,625
So this is exactly
the result that we get.

50
00:02:32,625 --> 00:02:35,680
That the Q function that we
had before is less than or

51
00:02:35,680 --> 00:02:40,360
equal to the Q function that we had
before pushed through the B2 operator.

52
00:02:40,360 --> 00:02:45,060
The Bellman operator with respect to
the greedy policy with respect to Q1.

53
00:02:45,060 --> 00:02:48,120
Essentially the idea is if we are going
to do one more update on Q1, and

54
00:02:48,120 --> 00:02:51,810
we are going to do that update with
respect to a policy that we know is

55
00:02:51,810 --> 00:02:55,060
greedy with respect to Q1,
then we are moving up in the world.

56
00:02:55,060 --> 00:02:56,767
>> Oh, I see, I see, I see, okay.

57
00:02:56,767 --> 00:02:58,306
>> What?

58
00:02:58,306 --> 00:03:00,915
>> Well, no, I was sitting there
thinking well shouldn't this be greater

59
00:03:00,915 --> 00:03:02,365
than or equal to and
then I think, oh no,

60
00:03:02,365 --> 00:03:04,170
I see,
I was kind of reading it backward.

61
00:03:04,170 --> 00:03:07,310
>> Yeah, I wanted to write it as,
because domination up to this point we

62
00:03:07,310 --> 00:03:09,970
used greater than or equal to, but
it just didn't feel right to put it

63
00:03:09,970 --> 00:03:13,120
this way because it would have been
B2 applied to Q1 is greater than or

64
00:03:13,120 --> 00:03:17,060
equal to Q1, which is true, but
the ordering feels backwards to me.

65
00:03:17,060 --> 00:03:19,670
So this seems better,
that we're going to take Q1, we're

66
00:03:19,670 --> 00:03:22,540
going to apply the B2 operator to it,
and it's going to make things better.

67
00:03:22,540 --> 00:03:23,878
>> Write it the other way and
see what happens.

68
00:03:23,878 --> 00:03:24,840
>> Sure.

69
00:03:24,840 --> 00:03:29,140
>> So, when I look at that,
that says that applying the greedy

70
00:03:30,520 --> 00:03:34,252
operator to Q1 makes it
better than it was before.

71
00:03:34,252 --> 00:03:35,980
>> All right, so
that is more helpful for you read,

72
00:03:35,980 --> 00:03:37,420
that's really the same thing.

73
00:03:37,420 --> 00:03:37,983
So that's great.

74
00:03:37,983 --> 00:03:38,950
>> Oh no, it is the same thing.

75
00:03:38,950 --> 00:03:40,950
I just realized the whole time
you were talking I had been

76
00:03:40,950 --> 00:03:42,890
flipping the thing in my head.

77
00:03:42,890 --> 00:03:43,500
>> Sorry about that.

78
00:03:43,500 --> 00:03:44,850
>> Oh no, no, it's not your fault.

79
00:03:44,850 --> 00:03:47,750
>> So
now we have all the pieces we need.

80
00:03:47,750 --> 00:03:49,700
We had one property,
we called it monotonicity.

81
00:03:49,700 --> 00:03:51,970
What, we should call this
property something, too.

82
00:03:51,970 --> 00:03:53,110
Value improvement.

83
00:03:53,110 --> 00:03:56,652
>> Okay.
>> So now with value improvement and

84
00:03:56,652 --> 00:04:00,987
other stuff like definition of Pi2 and
B1 and

85
00:04:00,987 --> 00:04:05,765
B2 and Q1 and Q2 and
the monotonicity property,

86
00:04:05,765 --> 00:04:10,322
we should have all the things
we need to prove that

87
00:04:10,322 --> 00:04:14,902
policy iteration moves
in the right direction.

88
00:04:14,902 --> 00:04:16,959
That it actually improves the policy.

89
00:04:16,959 --> 00:04:19,440
Or, in the case where
the policy's already optimal,

90
00:04:19,440 --> 00:04:21,450
it can't improve it, but
it doesn't break it.

91
00:04:21,450 --> 00:04:22,510
It leaves it the same.

92
00:04:22,510 --> 00:04:24,540
>> It doesn't ever make it worse.
