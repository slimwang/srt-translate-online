1
00:00:00,490 --> 00:00:03,910
Let's motivate the graph partitioning
problem through a different problem.

2
00:00:03,910 --> 00:00:08,050
Suppose I want to multiply a sparse
matrix A times a vector X.

3
00:00:08,050 --> 00:00:11,320
Remember the duality between
matrices and graphs.

4
00:00:11,320 --> 00:00:15,200
Meaning this sparse matrix has this
equivalent graph representation.

5
00:00:15,200 --> 00:00:19,680
The rows and corresponding columns
of the matrix are vertices and

6
00:00:19,680 --> 00:00:21,570
the non-zeros are edges.

7
00:00:21,570 --> 00:00:24,890
One way to do a distributed breadth
first search is to use a computational

8
00:00:24,890 --> 00:00:28,350
primitive that looks like this
linear algebra operation.

9
00:00:28,350 --> 00:00:32,581
Now, suppose you decide to distribute
the work by first dividing the matrix

10
00:00:32,581 --> 00:00:33,340
row-wise.

11
00:00:33,340 --> 00:00:36,680
You would then assign
block rows to processes.

12
00:00:36,680 --> 00:00:40,780
Note that this assignment corresponds
to a partitioning of the graph.

13
00:00:40,780 --> 00:00:44,710
This example is a vertex based or
just vertex partition.

14
00:00:44,710 --> 00:00:47,450
Observe that this partitioning
usually also implies

15
00:00:47,450 --> 00:00:50,580
a partitioning of the vectors x and y.

16
00:00:50,580 --> 00:00:53,910
That's because there's a one to one
mapping of vector entries to graph

17
00:00:53,910 --> 00:00:55,140
vertices.

18
00:00:55,140 --> 00:00:58,580
Now the amount of work in a sparse
matrix vector multiply is proportional

19
00:00:58,580 --> 00:00:59,814
to the number of non-zeroes.

20
00:01:00,930 --> 00:01:03,430
So, when you divide up the rows,
you might want to do so

21
00:01:03,430 --> 00:01:07,810
in a way that balances the number
matrix non-zeroes per partition.

22
00:01:07,810 --> 00:01:09,330
So that's one goal.

23
00:01:09,330 --> 00:01:11,960
Now, you have another goal
in choosing a partition.

24
00:01:11,960 --> 00:01:14,160
Hm, what is that goal?

25
00:01:14,160 --> 00:01:17,240
Recall that the vertex x is partitioned.

26
00:01:17,240 --> 00:01:20,430
Now suppose you want to
update the first block of Y.

27
00:01:20,430 --> 00:01:23,629
Because of these non-zeros you're
going to need these corresponding

28
00:01:23,629 --> 00:01:25,190
elements of x.

29
00:01:25,190 --> 00:01:29,820
That requires communication with the
processes that own these elements of x.

30
00:01:29,820 --> 00:01:33,100
In the language of graphs,
these communication exchanges happen

31
00:01:33,100 --> 00:01:36,020
anytime an edge crosses
a process boundary.

32
00:01:36,020 --> 00:01:39,810
For instance, these two non zeros,
correspond to this edge.

33
00:01:39,810 --> 00:01:43,940
The two processes that own the endpoints
of the edge, will need to communicate.

34
00:01:43,940 --> 00:01:46,600
This observation suggests a second goal.

35
00:01:46,600 --> 00:01:48,300
To minimize communication volume,

36
00:01:48,300 --> 00:01:51,310
you prefer to reduce
the number of edge cuts.

37
00:01:51,310 --> 00:01:55,380
This example motivates the classic
graph partitioning problem.

38
00:01:55,380 --> 00:01:58,840
You're given a graph and
a target number of partitions as input.

39
00:01:58,840 --> 00:02:03,600
Your goal is to divide the vertices
into, say, P partitions.

40
00:02:03,600 --> 00:02:06,920
You'd like this partitioning to
have the following properties.

41
00:02:06,920 --> 00:02:11,820
First, these partitions should cover all
the vertices but should be disjoint.

42
00:02:11,820 --> 00:02:14,960
The partition should also
be about equal in size.

43
00:02:14,960 --> 00:02:18,230
And the number of cut
edges should be minimized.

44
00:02:18,230 --> 00:02:20,430
That is the graph partitioning
problem in a nutshell.
