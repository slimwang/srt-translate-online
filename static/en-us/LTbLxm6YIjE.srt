1
00:00:00,780 --> 00:00:04,030
You obviously need a very good
model train on a lot of data

2
00:00:04,030 --> 00:00:05,470
to get this kind of result.

3
00:00:05,470 --> 00:00:08,500
And it's likely that the model that
you're training in the assignments

4
00:00:08,500 --> 00:00:11,290
is just not trained with
enough data to show this.

5
00:00:11,290 --> 00:00:12,960
But you can try.

6
00:00:12,960 --> 00:00:15,540
There are many other ways to learn
embeddings that I won't cover.

7
00:00:16,550 --> 00:00:19,400
Now, that we have models for
individual words,

8
00:00:19,400 --> 00:00:23,360
how do we deal with the fact that
text is actually a sequence of words?

9
00:00:23,360 --> 00:00:27,220
So far, your models have only looked
at inputs that were a fixed size.

10
00:00:27,220 --> 00:00:30,890
Fixed size means you can always
turn things into a vector, and

11
00:00:30,890 --> 00:00:32,930
feed it to your neural network.

12
00:00:32,930 --> 00:00:35,160
When you have sequences
of varying length,

13
00:00:35,160 --> 00:00:38,770
like speech or text,
you can no longer do that.

14
00:00:38,770 --> 00:00:39,270
Now what?
