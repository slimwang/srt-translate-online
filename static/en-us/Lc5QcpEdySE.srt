1
00:00:00,360 --> 00:00:02,120
Okay Michael have you thought about it? Do you know what the answer is?

2
00:00:02,120 --> 00:00:05,060
>> Yeah. I think, you know, you asked it in a

3
00:00:05,060 --> 00:00:07,520
funny way, but I think, what you're asking maybe was pretty

4
00:00:07,520 --> 00:00:09,320
simple. So let, let me, let me see if I can

5
00:00:09,320 --> 00:00:13,080
talk it through. So ,we've got n data points, each learner is

6
00:00:13,080 --> 00:00:16,100
a zeroth order polynomial. So you, you said the ensemble rule

7
00:00:16,100 --> 00:00:19,620
is that you learn over a subset, a zeroth order polynomial

8
00:00:19,620 --> 00:00:21,690
is just (no period) Well, we said that the thing that

9
00:00:21,690 --> 00:00:26,570
minimizes the average. Sorry, that minimizes the expected error, or the squared

10
00:00:26,570 --> 00:00:30,000
error [INAUDIBLE] it's just the average. So, if

11
00:00:30,000 --> 00:00:33,510
the sets are indistinct sets, with one data point

12
00:00:33,510 --> 00:00:37,530
each, then each, of the individual learners, is

13
00:00:37,530 --> 00:00:40,190
just going to learn the average. Then they get, not

14
00:00:40,190 --> 00:00:42,350
the average sorry. The actual output value of

15
00:00:42,350 --> 00:00:44,880
each individual point is the average, and then the

16
00:00:44,880 --> 00:00:48,170
combining algorithm, to combine all the pieces of

17
00:00:48,170 --> 00:00:51,580
the ensemble into one answer, combines with the mean.

18
00:00:51,580 --> 00:00:52,900
So ,it's going to combine the mean of those

19
00:00:52,900 --> 00:00:54,700
each of which is the data point, so it's

20
00:00:54,700 --> 00:00:57,270
the mean of the data points. So, the ensemble

21
00:00:57,270 --> 00:01:00,510
outputs, I don't know, I'd say average or mean?

22
00:01:00,510 --> 00:01:01,358
>> Yes.

23
00:01:01,358 --> 00:01:06,180
>> Or zeroth order polynomial of the data set,

24
00:01:06,180 --> 00:01:10,840
or, you know, one node decision tree, or ,uh.

25
00:01:10,840 --> 00:01:12,970
>> A constant? Which happens to be the

26
00:01:12,970 --> 00:01:15,870
mean of the data. Haven't we seen this before?

27
00:01:15,870 --> 00:01:16,780
>> It seems to come up a lot,

28
00:01:16,780 --> 00:01:18,930
when we are outputting very simple hypotheses.

29
00:01:18,930 --> 00:01:23,390
>> Right. And the last time we did this, if I recall correctly, this is what

30
00:01:23,390 --> 00:01:29,020
happens ,if you do an unweighted average with kNN where k is equal to n.

31
00:01:29,020 --> 00:01:35,242
>> Oh, right. Like, like, right. An N-NN.

32
00:01:35,242 --> 00:01:37,085
>> N-NN.

33
00:01:37,085 --> 00:01:37,605
>> Mm.

34
00:01:37,605 --> 00:01:39,220
>> Mm, so we should probably do

35
00:01:39,220 --> 00:01:41,800
something a little smarter than this then. And,

36
00:01:41,800 --> 00:01:45,650
I thought that we might look at some of the housing data, because, no

37
00:01:45,650 --> 00:01:46,900
one's started looking at the housing data

38
00:01:46,900 --> 00:01:49,340
yet. [LAUGH] Okay, so let's look at that

39
00:01:49,340 --> 00:01:51,340
right quick and see if we can figure out how this works. And then

40
00:01:51,340 --> 00:01:54,040
see if we can do something a little bit better, even better than that. Okay?
