1
00:00:00,120 --> 00:00:03,260
So the question that
we have to address is

2
00:00:03,260 --> 00:00:06,560
if we've got these sort of thousands
of features per image, and

3
00:00:06,560 --> 00:00:09,460
maybe millions or hundreds of
millions of images or patches.

4
00:00:09,460 --> 00:00:12,820
You know, what's an efficient
way to search to figure out

5
00:00:12,820 --> 00:00:15,880
which image had about
the same sets of patches or

6
00:00:15,880 --> 00:00:20,030
at least has a high overlap in the set
of patches that I find in a new image.

7
00:00:20,030 --> 00:00:23,890
And what we do is we take a little bit
of inspiration from other systems that

8
00:00:23,890 --> 00:00:27,350
have lots of little instances in them,
namely things like words and

9
00:00:27,350 --> 00:00:28,790
indices, right.

10
00:00:28,790 --> 00:00:33,780
So if I've got a book, it would be
really hard to find all the examples of

11
00:00:33,780 --> 00:00:38,240
where it says Karl Marx in that
book by flipping through that book.

12
00:00:38,240 --> 00:00:40,850
So what do we do instead,
we build an index.

13
00:00:40,850 --> 00:00:43,050
Right?
There's an index in the back,

14
00:00:43,050 --> 00:00:47,770
it's an efficient way to find all the
pages that contain a particular word.

15
00:00:47,770 --> 00:00:48,580
Okay?

16
00:00:48,580 --> 00:00:53,500
So what we want to do is we want to
find all the images from a known

17
00:00:53,500 --> 00:00:56,850
database that have a particular
feature that we find.

18
00:00:56,850 --> 00:00:59,759
So now what's going to happen is I'm
going to find a bunch of features

19
00:01:00,770 --> 00:01:03,240
that are in a, new image.

20
00:01:03,240 --> 00:01:06,740
I'm going to look up the different
images that have those features and

21
00:01:06,740 --> 00:01:10,810
maybe if I find an image that has a lot
of the same features as my new image,

22
00:01:10,810 --> 00:01:13,880
then I say, aha,
maybe it's the same kind of thing.

23
00:01:13,880 --> 00:01:17,380
And this comes to the notion
of what we call visual words.

24
00:01:17,380 --> 00:01:19,180
Okay?
So, the featured descriptors

25
00:01:19,180 --> 00:01:21,780
we sometimes refer to
as visual words and

26
00:01:21,780 --> 00:01:23,910
we're going to get to
code words in a minute.

27
00:01:23,910 --> 00:01:26,990
But the idea is that, and
I think really this notion of words

28
00:01:26,990 --> 00:01:30,420
comes from this whole
analogy with text processing.

29
00:01:30,420 --> 00:01:31,555
Right?
So we've got words

30
00:01:31,555 --> 00:01:35,690
are the local features and
documents are the entire image.
