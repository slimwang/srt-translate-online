1
00:00:00,640 --> 00:00:05,480
Okay you now have all the pieces you
need to finish the parallel algorithm.

2
00:00:05,480 --> 00:00:08,730
The only piece that's left
is this process level.

3
00:00:08,730 --> 00:00:11,170
Remember that bag splits
are very efficient.

4
00:00:11,170 --> 00:00:14,900
Therefore we should try to use our
favorite scheme, divide and conquer.

5
00:00:14,900 --> 00:00:17,850
So here's some pseudo code that
implements exactly a divide and

6
00:00:17,850 --> 00:00:19,180
conquer scheme.

7
00:00:19,180 --> 00:00:20,690
It's got two parts,

8
00:00:20,690 --> 00:00:24,060
first the input bag is big enough
then we do divide and conquer.

9
00:00:24,060 --> 00:00:25,350
Using splitting.

10
00:00:25,350 --> 00:00:29,420
If the bag is not big enough,
then we just fall back, essentially,

11
00:00:29,420 --> 00:00:31,210
to the sequential code.

12
00:00:31,210 --> 00:00:34,120
Now, the one difference is
this parallel for loop.

13
00:00:34,120 --> 00:00:35,290
So let's see how that works.

14
00:00:36,390 --> 00:00:38,240
So again, given a bag at level L,

15
00:00:38,240 --> 00:00:41,300
the first step is to split
it if the bag is big enough.

16
00:00:42,340 --> 00:00:45,050
Since we can process the elements
in any order we can use divide and

17
00:00:45,050 --> 00:00:46,420
conquer on the two halves.

18
00:00:47,420 --> 00:00:50,410
And I said the base case was the same
as the sequential algorithm, but

19
00:00:50,410 --> 00:00:52,680
I planned out this one difference.

20
00:00:52,680 --> 00:00:54,100
The difference is this neighbor loop.

21
00:00:55,180 --> 00:00:58,240
Notice that i'm iterating over
the neighbors using a parallel

22
00:00:58,240 --> 00:00:59,820
four instead of a conventional four.

23
00:00:59,820 --> 00:01:03,910
Now that might give you pause because
there might be tasks trying to update

24
00:01:03,910 --> 00:01:09,270
the same neighbor W, but since were
using a level synchronize album

25
00:01:09,270 --> 00:01:12,260
all those updates are going to be
doing this exact same thing which

26
00:01:12,260 --> 00:01:16,230
is writing the value of L
plus 1 into the D of W.

27
00:01:16,230 --> 00:01:19,910
So even though there's a data race here,
it's actually perfectly safe.

28
00:01:19,910 --> 00:01:22,780
Now the bag inserts are trickier.

29
00:01:22,780 --> 00:01:23,580
And for those,

30
00:01:23,580 --> 00:01:28,840
we're going to have to exploit the fact
that bags are logically associative, and

31
00:01:28,840 --> 00:01:33,550
therefore we can use these reducer hyper
objects that we talked about earlier.

32
00:01:33,550 --> 00:01:34,990
Okay, we're almost done.

33
00:01:34,990 --> 00:01:38,340
The last thing we need to do,
is analyze the cost.

34
00:01:38,340 --> 00:01:40,440
Now, the cost analysis is really tricky,
so

35
00:01:40,440 --> 00:01:44,750
if you want all of the gory details, I
refer you to the paper by Lyzer-shin and

36
00:01:44,750 --> 00:01:47,950
Shettle, which we posted
on the instructor's notes.

37
00:01:47,950 --> 00:01:50,990
For now, let's just sketch the analysis.

38
00:01:50,990 --> 00:01:54,270
First, I'm going to claim that
the algorithm is work-optimal.

39
00:01:54,270 --> 00:01:57,560
If you want to go into details again,
please see the paper.

40
00:01:57,560 --> 00:01:58,550
Now what about the span?

41
00:01:59,860 --> 00:02:02,795
The The span is effected by
a couple different factors.

42
00:02:02,795 --> 00:02:05,245
The first factor is
the number of levels,

43
00:02:05,245 --> 00:02:07,335
that's essentially
the outer most while loop.

44
00:02:07,335 --> 00:02:09,865
Of course the while
loop is not shown here

45
00:02:09,865 --> 00:02:13,375
that was the pseudo code that was on
the left side of the screen earlier.

46
00:02:13,375 --> 00:02:16,965
The second factor is
the span of process level.

47
00:02:16,965 --> 00:02:21,130
Now the first factor we said was
bounded by the diameter of the graph.

48
00:02:21,130 --> 00:02:22,720
let's call it little d.

49
00:02:22,720 --> 00:02:26,240
The span of process
level has three parts.

50
00:02:26,240 --> 00:02:30,660
There's the depth of the recursion,
there's the cost of splitting and

51
00:02:30,660 --> 00:02:32,350
then there's the cost of the base case.

52
00:02:33,490 --> 00:02:38,210
Now the recursion will be
logarithmic in the size of Fl.

53
00:02:38,210 --> 00:02:41,710
And since Fl can only be
the total number of vertices,

54
00:02:41,710 --> 00:02:45,790
in the worst case the depth of
recursion should be log in.

55
00:02:45,790 --> 00:02:50,070
The splitting we argue was log in,
now what about the base case?

56
00:02:50,070 --> 00:02:52,860
Now in the base case,
the size of Fl is a constant,

57
00:02:52,860 --> 00:02:56,380
because we have a constant cut-off
built in as we usually do,

58
00:02:56,380 --> 00:02:59,100
therefore we can bound
this by a constant.

59
00:02:59,100 --> 00:03:00,310
So let's put that all together.

60
00:03:00,310 --> 00:03:05,410
It will turn out that the cost is
basically bounded by the diameter and

61
00:03:05,410 --> 00:03:09,750
something that's polylogrithmic
in the size of the graph.

62
00:03:09,750 --> 00:03:11,740
And we love polylogrithmic,
so we're done.

63
00:03:13,630 --> 00:03:14,264
>> Yay.
[APPLAUSE]
