1
00:00:00,560 --> 00:00:03,240
Welcome to lesson five. This may be shocking to hear,

2
00:00:03,240 --> 00:00:05,050
but thus far, all of the data that we've used in

3
00:00:05,050 --> 00:00:08,420
this course has been relatively manageable. What do I mean by

4
00:00:08,420 --> 00:00:12,140
that? Well, we can fit it onto one machine pretty easily,

5
00:00:12,140 --> 00:00:14,670
we can load it into memory and we can run all

6
00:00:14,670 --> 00:00:18,450
of our analysis in a serial fashion. But imagine that we

7
00:00:18,450 --> 00:00:21,560
are working with some very large data set. I'm not talking

8
00:00:21,560 --> 00:00:24,880
hundreds of gigabytes here, I mean terabytes, or maybe even petabytes.

9
00:00:26,090 --> 00:00:27,950
At this point, it would make sense to introduce something

10
00:00:27,950 --> 00:00:31,000
like the MapReduce programming model, which allows us to take

11
00:00:31,000 --> 00:00:34,270
our data, distribute it across many different machines, and run

12
00:00:34,270 --> 00:00:38,280
our computations in parallel. If you spent any amount of time

13
00:00:38,280 --> 00:00:40,800
around data science circles, you've probably heard tons of crazy

14
00:00:40,800 --> 00:00:44,633
terms like hadoop or hive. Or a MapReduce or distributed file

15
00:00:44,633 --> 00:00:48,010
systems. More generically, you've probably heard a lot about big

16
00:00:48,010 --> 00:00:51,490
data. During this lesson, we'll discuss how to use the MapReduce

17
00:00:51,490 --> 00:00:52,910
programming models to solve some very

18
00:00:52,910 --> 00:00:56,440
simple problems. We'll also discuss other big

19
00:00:56,440 --> 00:01:00,640
data tools like Hive at a high level. That way, next time when

20
00:01:00,640 --> 00:01:03,450
you find yourself at a data science cocktail party, you'll be able to

21
00:01:03,450 --> 00:01:07,150
keep up with the conversation. Alright, well why don't we get started then.
