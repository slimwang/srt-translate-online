1
00:00:00,000 --> 00:00:05,000
A visualization of our Standford racing car, Junior,

2
00:00:05,000 --> 00:00:10,000
in action, applying that exact same algorithm for actual driving.

3
00:00:10,000 --> 00:00:17,000
You can see here that a right turn is being executed, followed by a lane shift.

4
00:00:17,000 --> 00:00:20,000
These are discrete actions, and the car actually performs those

5
00:00:20,000 --> 00:00:23,000
to reach a goal location at the orange circle.

6
00:00:23,000 --> 00:00:28,000
But if we make a lane shift prohibitively expensive,

7
00:00:28,000 --> 00:00:31,000
just as we made a left turn expensive before,

8
00:00:31,000 --> 00:00:34,000
then the car chooses a different path.

9
00:00:34,000 --> 00:00:41,000
It goes straight, then takes a left turn, which right now isn't that expensive.

10
00:00:41,000 --> 00:00:46,000
It takes a left turn and a left turn again to find itself

11
00:00:46,000 --> 00:00:51,000
in the lane where the goal location is located.

12
00:00:51,000 --> 00:00:57,000
That is a result of modifying cost functions in our dynamic programming algorithm

13
00:00:57,000 --> 00:01:02,000
in the same 3D regime we just studied and that you just programmed.

14
00:01:02,000 --> 00:01:07,000
Your program could effectively drive this car, and by changing these cost function,

15
00:01:07,000 --> 00:01:11,000
as you can see over here, the car would be able to attain its goal

16
00:01:11,000 --> 00:01:16,000
in the optimal way, relative to the cost that you have given him.

17
00:01:16,000 --> 00:01:19,000
Congratulations. You made it through my first motion class.

18
00:01:19,000 --> 00:01:22,000
Today we assumed that the world is discrete,

19
00:01:22,000 --> 00:01:28,000
and we looked at 2 planning algorithms--A-star, which uses a heuristic to find a path,

20
00:01:28,000 --> 00:01:33,000
and dynamic programming, which finds an entire policy that has a plan for every location.

21
00:01:33,000 --> 00:01:35,000
We implemented both of them.

22
00:01:35,000 --> 00:01:40,000
In fact, in the policy case, even in 3D, which is quite an achievement.

23
00:01:40,000 --> 00:01:42,000
I want to congratulate you to get here.

24
00:01:42,000 --> 00:01:45,000
You really now understand two of the main paradigms

25
00:01:45,000 --> 00:01:48,000
by which our robots make motion decisions,

26
00:01:48,000 --> 00:01:52,000
and they are are also some very major paradigms for artificial intelligence in general.

27
00:01:52,000 --> 00:01:58,000
In the next class we talk about how to turn this into actual robot motion.

28
00:01:58,000 --> 00:02:04,000
We'll talk about continuous state spaces, and we'll talk about what's called "control,"

29
00:02:04,000 --> 00:02:08,000
in which we make a robot move. I'll see you next week.
