1
00:00:00,290 --> 00:00:02,320
Let's think about the binary
search algorithm.

2
00:00:02,320 --> 00:00:07,400
We're given a sorted array, A,
containing let's say n unique elements.

3
00:00:07,400 --> 00:00:09,070
Then, given a target value, v,

4
00:00:09,070 --> 00:00:13,950
you want to find the largest index
i such that a sub i is at most v.

5
00:00:13,950 --> 00:00:16,560
You can find this index
by binary search.

6
00:00:16,560 --> 00:00:20,380
To compute the number of cache misses,
you'd set up recurrence, like so.

7
00:00:20,380 --> 00:00:22,910
Once the search interval
falls within a cache line,

8
00:00:22,910 --> 00:00:25,340
there would be just one cache miss.

9
00:00:25,340 --> 00:00:26,980
Otherwise, you'd pay for one miss,

10
00:00:26,980 --> 00:00:30,690
plus any additional misses to search
the remaining half of the array.

11
00:00:30,690 --> 00:00:33,000
Solving the recurrence,
you'd find the following.

12
00:00:33,000 --> 00:00:35,000
Big O of log n over l.

13
00:00:35,000 --> 00:00:37,490
Compare this to the lower bound.

14
00:00:37,490 --> 00:00:41,980
Binary search differs from the lower
bound by about a factor of log L.

15
00:00:41,980 --> 00:00:43,260
So it's not optimal, but

16
00:00:43,260 --> 00:00:47,650
one nice thing about binary search is
that it's already cache oblivious.

17
00:00:47,650 --> 00:00:51,330
It makes no references to the cache
size Z or the line size L.

18
00:00:51,330 --> 00:00:54,280
But it begs the question,
how do we get to the lower bound?

19
00:00:54,280 --> 00:00:56,200
In fact, there's a way to do it.

20
00:00:56,200 --> 00:00:58,990
Leave the logic of the binary
search algorithm intact, but

21
00:00:58,990 --> 00:01:00,940
change the data layout.

22
00:01:00,940 --> 00:01:05,620
Remember that a binary search tree
maintains some ordering of its elements.

23
00:01:05,620 --> 00:01:09,220
Let's number this tree according
to an in-order traversal.

24
00:01:09,220 --> 00:01:12,530
If you interpret these numbers
as addresses or index positions,

25
00:01:12,530 --> 00:01:16,480
then the layout of the tree nodes
is equivalent to sorted order.

26
00:01:16,480 --> 00:01:19,170
But there's nothing
sacred about this layout.

27
00:01:19,170 --> 00:01:20,050
In fact let's consider

28
00:01:20,050 --> 00:01:23,210
a different ordering which is
called the Vanamdebos layout.

29
00:01:23,210 --> 00:01:25,210
Iâ€™ll sketch this now but
if you want some details,

30
00:01:25,210 --> 00:01:27,480
see the nice tutorial by Erik Demaine.

31
00:01:27,480 --> 00:01:30,870
The idea is to use
the following recursive layout.

32
00:01:30,870 --> 00:01:34,050
Suppose you start with
a complete binary search tree.

33
00:01:34,050 --> 00:01:37,640
If it has about n nodes it
should have log n levels.

34
00:01:37,640 --> 00:01:39,820
Now divide the levels in half.

35
00:01:39,820 --> 00:01:43,350
So there would be about one half
log n levels above the cut line and

36
00:01:43,350 --> 00:01:45,500
about one half log n below.

37
00:01:45,500 --> 00:01:49,430
This also means the upper subtree
will have about root n nodes.

38
00:01:49,430 --> 00:01:54,850
Below the cut line, there will about
root n subtrees, each of size root n.

39
00:01:54,850 --> 00:01:56,690
Here's the Van Emde Boas layout idea.

40
00:01:56,690 --> 00:02:01,850
You have a binary search tree that you'd
like to lay out linearly in slow memory.

41
00:02:01,850 --> 00:02:03,390
After partitioning the levels,

42
00:02:03,390 --> 00:02:06,270
lay out all of the upper
sub-tree elements together.

43
00:02:06,270 --> 00:02:09,810
And then concatenate them with
the lower sub-tree elements.

44
00:02:09,810 --> 00:02:11,850
And when I say lay out
the elements together,

45
00:02:11,850 --> 00:02:16,550
I mean recursively apply the Van
Emde Boas layout to each sub-tree.

46
00:02:16,550 --> 00:02:17,700
So, what does this buy you?

47
00:02:18,730 --> 00:02:20,020
Let's zoom in on the tree,

48
00:02:20,020 --> 00:02:24,390
looking at the point where
the sub-trees fit within cache lines.

49
00:02:24,390 --> 00:02:28,950
That is, in the figure the elements in
each of the smallest sub trees shown

50
00:02:28,950 --> 00:02:31,750
fit within a cache line size hole.

51
00:02:31,750 --> 00:02:36,210
A binary search in this tree takes
some path from the root to the leaf.

52
00:02:36,210 --> 00:02:38,040
Since the sub trees are a size L,

53
00:02:38,040 --> 00:02:42,340
you only generate a cache miss when you
hit the root of one of the sub trees.

54
00:02:42,340 --> 00:02:45,930
Now the maximum height of one of these
little cache line size sub trees is

55
00:02:45,930 --> 00:02:47,230
log L.

56
00:02:47,230 --> 00:02:49,000
So, starting at the root of the tree,

57
00:02:49,000 --> 00:02:52,150
how many of these size L
sub trees will you visit?

58
00:02:52,150 --> 00:02:54,280
Well, the height of the tree is log-n.

59
00:02:54,280 --> 00:02:56,370
So, on any path from root to leaf,

60
00:02:56,370 --> 00:03:00,860
you'll encounter log-n
over log-l sub-trees.

61
00:03:00,860 --> 00:03:03,580
That's totally awesome
because that is optimal.

62
00:03:03,580 --> 00:03:04,450
Woot!

63
00:03:04,450 --> 00:03:07,610
The important lesson is
that data layout matters.

64
00:03:07,610 --> 00:03:10,710
What we did hear that was so
cool is we took the standard binary

65
00:03:10,710 --> 00:03:14,640
search algorithm, reshuffled how we
stored the data in order to get an IO

66
00:03:14,640 --> 00:03:18,384
optimal algorithm, and
the layout is itself cache-oblivious.
