1
00:00:00,370 --> 00:00:04,338
Lately there's been a huge growth
in using infrared structured light.

2
00:00:04,338 --> 00:00:07,460
All right, and infrared structured
light, one of the nice things about it

3
00:00:07,460 --> 00:00:11,740
is you and I can't see it, so
it's doing all this stuff out there but

4
00:00:11,740 --> 00:00:14,750
it's not,
sort of interfering with our vision.

5
00:00:14,750 --> 00:00:19,300
And the main reason,
that IR structured light has become so

6
00:00:19,300 --> 00:00:22,900
big is because of this puppy right here,
the Microsoft Kinect, all right?

7
00:00:24,100 --> 00:00:28,440
Kudos to my friends and colleagues
in in England and Cambridge who

8
00:00:28,440 --> 00:00:32,380
helped take the technology, and it was,
the 3-D technology that I'll tell

9
00:00:32,380 --> 00:00:36,770
you about was actually developed by
PrimeSense which was a Israel company.

10
00:00:36,770 --> 00:00:41,110
And then Microsoft leveraged
it in a way to go from

11
00:00:41,110 --> 00:00:42,990
the depth to recovering skeleton,

12
00:00:42,990 --> 00:00:46,570
which is a whole other interesting piece
of work that we won't talk about here.

13
00:00:46,570 --> 00:00:47,740
But if we did it in machine learning,

14
00:00:47,740 --> 00:00:49,110
since they used machine
learning methods for

15
00:00:49,110 --> 00:00:51,728
doing it,
we could talk more about doing that.

16
00:00:51,728 --> 00:00:56,450
But the Kinect is really, I mean it was
$150, so all of a sudden you could put

17
00:00:56,450 --> 00:01:00,950
depth sensors on little experimental
robots for very little money.

18
00:01:00,950 --> 00:01:03,060
So, how does the Kinect work?

19
00:01:03,060 --> 00:01:05,730
Well, it's not public, all right?

20
00:01:05,730 --> 00:01:08,160
So there are people who know
exactly how the Kinect works,

21
00:01:08,160 --> 00:01:11,030
people from PrimeSense,
etc., but it's not public.

22
00:01:11,030 --> 00:01:14,010
Lots and lots of this stuff is known.

23
00:01:14,010 --> 00:01:16,910
But the exact implementations
are not known.

24
00:01:16,910 --> 00:01:20,620
The PrimeSense patents
describe at least two ways.

25
00:01:20,620 --> 00:01:24,590
And I will tell you about
both of those ways.

26
00:01:25,880 --> 00:01:28,850
Conventional wisdom is that one of
the ways is actually used in the Kinect

27
00:01:28,850 --> 00:01:29,700
and one is not.

28
00:01:29,700 --> 00:01:32,540
I don't really care,
they're both kind of interesting.

29
00:01:32,540 --> 00:01:38,750
So, the two methods, that they use,
one is a very, very clever optics trick.

30
00:01:38,750 --> 00:01:41,955
In fact, it's so clever I don't totally
understand exactly how it works,

31
00:01:41,955 --> 00:01:43,410
because I have to get more into detail.

32
00:01:43,410 --> 00:01:46,370
But essentially, it projects a pattern
with two different kinds of lenses, and

33
00:01:46,370 --> 00:01:47,560
we'll talk more about it in a minute,

34
00:01:47,560 --> 00:01:51,900
that allows you to go directly
from the image to the depth.

35
00:01:51,900 --> 00:01:53,110
We'll explain that.

36
00:01:53,110 --> 00:01:56,890
And then the much more standard way,
which is just like light striping,

37
00:01:56,890 --> 00:01:59,900
is that you're essentially using
something about the projected image from

38
00:02:00,990 --> 00:02:03,470
the projection of a particular pattern,
and

39
00:02:03,470 --> 00:02:05,750
what it's observed like in the,
in the other camera.

40
00:02:06,800 --> 00:02:09,800
So, you're about to see some
drawings that look kind of funky.

41
00:02:09,800 --> 00:02:10,660
They don't look like, you know,

42
00:02:10,660 --> 00:02:13,810
the high quality drawings that
Megan always insists that I use.

43
00:02:13,810 --> 00:02:16,700
But that's because these are actually
taken directly from the patent and

44
00:02:16,700 --> 00:02:17,850
the patent applications.

45
00:02:17,850 --> 00:02:19,340
I think it's cool to just see those.

46
00:02:19,340 --> 00:02:22,790
So the key to the Kinect sorry,

47
00:02:22,790 --> 00:02:26,570
the key to PrimeSense focus method
are these cylindrical lenses.

48
00:02:26,570 --> 00:02:29,130
So cylindrical lenses,
if you take two of them and

49
00:02:29,130 --> 00:02:31,650
you have one that goes one way and
I think on the next thing,

50
00:02:31,650 --> 00:02:37,370
you have one goes the other way, you
end up with this funny situation where

51
00:02:37,370 --> 00:02:42,250
you have different focal lengths
depending upon which way you move.

52
00:02:42,250 --> 00:02:44,910
So you have a,
one focal length horizontally and

53
00:02:44,910 --> 00:02:47,410
a different focal length vertically,
and of course,

54
00:02:47,410 --> 00:02:50,680
slightly different focal length as
you were to sort of, rotate around.

55
00:02:51,810 --> 00:02:55,300
What this allows them to do is
to project out speckles, and

56
00:02:55,300 --> 00:03:00,040
they, now,
what happens when a dot is out of focus?

57
00:03:00,040 --> 00:03:03,780
Well, in a normal lens, right,
it becomes a blurry circle.

58
00:03:04,960 --> 00:03:07,660
When you have one of these,
what are called, astigmatic or asym,

59
00:03:07,660 --> 00:03:12,350
asymmetric lenses, it becomes
an ellipse because the, the lenses

60
00:03:12,350 --> 00:03:15,680
are different in one direction than
they are in another direction.

61
00:03:15,680 --> 00:03:18,070
And what's cool about the way
they did this geometry, and

62
00:03:18,070 --> 00:03:21,080
this is the part that I'd have to work
through the math more to understand,

63
00:03:21,080 --> 00:03:25,430
is that depending upon the depth,
so here the hand is at one z and

64
00:03:25,430 --> 00:03:28,470
here is at another z,
again these are from the patent.

65
00:03:28,470 --> 00:03:32,130
These ellipses, well they have different
thickness, but more importantly,

66
00:03:32,130 --> 00:03:34,810
they have different orientations.

67
00:03:34,810 --> 00:03:39,550
So you can just take a look at
the orientation in a little local area,

68
00:03:39,550 --> 00:03:42,790
of these little dots that
have been smeared, and

69
00:03:42,790 --> 00:03:45,260
the orientation tells you the depth.

70
00:03:45,260 --> 00:03:47,220
This is really, really cool.

71
00:03:47,220 --> 00:03:49,755
But I think it's so
cool that they probably don't use it.

72
00:03:49,755 --> 00:03:53,080
because I think it requires some pretty
precise lensing and some other things.

73
00:03:53,080 --> 00:03:54,410
I'm not, not really sure.

74
00:03:54,410 --> 00:03:58,220
But this is the,
the one method of how the Kinect works.

75
00:03:58,220 --> 00:04:01,170
And if you go in their patent, you'll
see figures that talk about like this,

76
00:04:01,170 --> 00:04:03,160
that you capture this test image and

77
00:04:03,160 --> 00:04:06,560
then you find the range base
upon the pattern orientation.

78
00:04:06,560 --> 00:04:09,630
And then you build this 3D map.

79
00:04:09,630 --> 00:04:12,700
Although you notice this says
based on offsets between test and

80
00:04:12,700 --> 00:04:13,910
reference pattern.

81
00:04:13,910 --> 00:04:16,380
So that's the method
I'm about to tell you.

82
00:04:16,380 --> 00:04:18,680
Here's the one that just talks
about the, the, orientation.
