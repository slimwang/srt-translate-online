1
00:00:00,000 --> 00:00:06,000
By now, you might have recognized what we're really building up is a Bayes network

2
00:00:06,000 --> 00:00:10,000
where the parameters of the Bayes networks are estimated using supervised learning

3
00:00:10,000 --> 00:00:15,000
by a maximum likelihood estimator based on training data.

4
00:00:15,000 --> 00:00:20,000
The Bayes network has at its root an unobservable variable called spam,

5
00:00:20,000 --> 00:00:28,000
which is binary, and it has as many children as there are words in a message,

6
00:00:28,000 --> 00:00:33,000
where each word has an identical conditional distribution

7
00:00:33,000 --> 00:00:39,000
of the word occurrence given the class spam or not spam.

8
00:00:39,000 --> 00:00:42,000
If you write on our dictionary over here,

9
00:00:42,000 --> 00:00:48,000
you might remember the dictionary had 12 different words,

10
00:00:48,000 --> 00:00:52,000
so here is 5 of the 12, offer, is, secret, click and sports.

11
00:00:52,000 --> 00:00:59,000
Then for the spam class, we found the probability of secret given spam is 1/3,

12
00:00:59,000 --> 00:01:05,000
and we also found that the probability of secret given ham is 1/15,

13
00:01:05,000 --> 00:01:07,000
so here's a quiz.

14
00:01:07,000 --> 00:01:12,000
Assuming a vocabulary size of 12, or put differently,

15
00:01:12,000 --> 00:01:16,000
the dictionary has 12 words, how many parameters

16
00:01:16,000 --> 99:59:59,999
do we need to specify this Bayes network?
