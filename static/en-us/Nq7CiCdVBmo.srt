1
00:00:00,330 --> 00:00:04,760
That all we're going to say about Model
Based Reinforcement Learning in POMDPs

2
00:00:04,760 --> 00:00:07,866
and now we're going to talk a little bit
about Model Free Reinforcement Learning

3
00:00:07,866 --> 00:00:08,758
in POMDPS.

4
00:00:08,758 --> 00:00:09,540
>> Okay.
>> And

5
00:00:09,540 --> 00:00:11,560
particular we're going to focus
on memory loss policies and

6
00:00:11,560 --> 00:00:14,120
what I'd like to show actually is not so
much about learning, but

7
00:00:14,120 --> 00:00:15,450
more about planning.

8
00:00:15,450 --> 00:00:16,530
So here's a little POMDP.

9
00:00:17,690 --> 00:00:20,570
This is a POMDP that has
four underlying states.

10
00:00:20,570 --> 00:00:23,160
Two observations there's this
sort of clear blue thing and

11
00:00:23,160 --> 00:00:24,780
there's a green thing.

12
00:00:24,780 --> 00:00:27,610
Two actions, black and red.

13
00:00:27,610 --> 00:00:30,060
Black takes you to the right and

14
00:00:30,060 --> 00:00:32,470
red takes you to the left
back around the other way.

15
00:00:32,470 --> 00:00:36,010
And the way that this is set up, I think
of it as a one dimensional hallway.

16
00:00:37,170 --> 00:00:39,140
And we don't know exactly
where we are in the hallway.

17
00:00:39,140 --> 00:00:44,170
But we're trying to get to you know
say my office along the hallway.

18
00:00:44,170 --> 00:00:48,180
If we're to the left of my hallway,
we should go right to go to my office.

19
00:00:48,180 --> 00:00:50,180
But if we just keep going left and
left and left and left and

20
00:00:50,180 --> 00:00:53,600
left we're just going to go and get
stuck and It's infinitely long hallway,

21
00:00:53,600 --> 00:00:54,800
it feels like an infinitely long.

22
00:00:54,800 --> 00:00:56,340
We just going to get stuck at the end.

23
00:00:56,340 --> 00:00:59,770
Whereas if we're to the right of
my office and we go to the right,

24
00:00:59,770 --> 00:01:02,740
we also kind of get stuck, we need to go
to the left to get where we're going.

25
00:01:02,740 --> 00:01:05,765
Once we actually get to the office,
we have a reset action, the black action

26
00:01:05,765 --> 00:01:08,515
resets us with equal probability
to one of those three states.

27
00:01:08,515 --> 00:01:10,495
because I don't know we're drunk and

28
00:01:10,495 --> 00:01:13,495
then we get to go again try
to get back to the office.

29
00:01:13,495 --> 00:01:14,355
>> Okay, good.

30
00:01:14,355 --> 00:01:15,385
>> First, I want to point out.

31
00:01:15,385 --> 00:01:17,645
I think we talked about an example
just like this before and

32
00:01:17,645 --> 00:01:22,022
we said that probably the right thing
to do is to go like left, right,

33
00:01:22,022 --> 00:01:23,932
right, that sort of thing.

34
00:01:23,932 --> 00:01:28,022
Because each time we reset we're in one
of these states which we go left hoping

35
00:01:28,022 --> 00:01:30,572
that it's going to take us out of here,
but that doesn't seem to work so

36
00:01:30,572 --> 00:01:33,742
we go right to take us
from this side back out.

37
00:01:33,742 --> 00:01:35,552
Actually right, right,
left is probably even better.

38
00:01:35,552 --> 00:01:37,620
Just keep doing this over and
over and over again.

39
00:01:37,620 --> 00:01:38,720
All right.
But now what we're talking about

40
00:01:38,720 --> 00:01:39,690
are memoryless policies.

41
00:01:39,690 --> 00:01:41,760
So memoryless policy has the form.

42
00:01:41,760 --> 00:01:43,150
When you're in the green state.

43
00:01:43,150 --> 00:01:45,250
Well, there's only one action choice so
you take it.

44
00:01:45,250 --> 00:01:46,710
When you're in the clear blue state.

45
00:01:46,710 --> 00:01:48,430
You have to go either left or right.

46
00:01:48,430 --> 00:01:51,320
Or maybe you can choose
probabilistically among left and right.

47
00:01:51,320 --> 00:01:53,975
But you can't do these sequences
because it's memoryless.

48
00:01:53,975 --> 00:01:55,751
[SOUND] You need memory
to do a sequence.

49
00:01:55,751 --> 00:01:57,095
>> Right, that's a problem.

50
00:01:57,095 --> 00:02:00,535
Okay I see, I see why this is a problem
or you could just invent memory.

51
00:02:00,535 --> 00:02:01,890
>> POMPDP's do invent memory.

52
00:02:01,890 --> 00:02:03,920
If you're going to learn
the POMDP model of this,

53
00:02:03,920 --> 00:02:07,570
it captures the memory that you need
to actually make optimal decisions.

54
00:02:07,570 --> 00:02:08,210
>> All right, fair enough.
