1
00:00:00,000 --> 00:00:04,000
[Sebastian:] Let me talk about dynamic programming with stochastic actions.

2
00:00:04,000 --> 00:00:08,000
At the end of this assignment, you'll be able to program this.

3
00:00:08,000 --> 00:00:10,000
The motivation to study this is as follows:

4
00:00:10,000 --> 00:00:13,000
suppose we have a robot, and we have an obstacle and a goal state.

5
00:00:13,000 --> 00:00:19,000
Then this robot might be tempted to scratch the wall over here and head towards the goal.

6
00:00:19,000 --> 00:00:24,000
In practice this is a bad idea, because robots that get really close to obstacles are frightening.

7
00:00:24,000 --> 00:00:30,000
In fact, if their actions aren't quite perfect they might actually hit the obstacle, which is no good.

8
00:00:30,000 --> 00:00:33,000
In practice, what we tend to do is we go more like this.

9
00:00:33,000 --> 00:00:36,000
We maintain a certain clearance to obstacles.

10
00:00:36,000 --> 00:00:40,000
Now we're going to modify our dynamic programming planner to do just that--

11
00:00:40,000 --> 00:00:45,000
to find paths that are a little bit safer and lead a little bit away from obstacles.

12
00:00:45,000 --> 00:00:49,000
The way we will do this is we will model actions as stochastic,

13
00:00:49,000 --> 00:00:53,000
and we have not done this before, but you'll learn how to do it.

14
00:00:53,000 --> 00:00:56,000
Take the action of going north from the from the cell over here.

15
00:00:56,000 --> 00:01:01,000
In a deterministic action, it obviously succeeds, unless of course we run into a wall.

16
00:01:01,000 --> 00:01:05,000
In the stochastic case, it succeeds with a certain probability--say 50%--

17
00:01:05,000 --> 00:01:11,000
whereas with 25% chance, it might accidentally go left or right

18
00:01:11,000 --> 00:01:14,000
even though we commanded it to go up.

19
00:01:14,000 --> 00:01:19,000
This is a stochastic action, and it's exactly the type of action I want you to program later on.

20
00:01:19,000 --> 00:01:23,000
If, for example, there was a wall over here and the robot decided to go up,

21
00:01:23,000 --> 00:01:27,000
there'd be a 25% chance it would hit the wall, which is not good.

22
00:01:27,000 --> 00:01:32,000
So staying away from the wall is a good idea in a stochastic situation.

23
00:01:32,000 --> 00:01:37,000
I will now show you how the backup works without asking or quizzes.

24
00:01:37,000 --> 00:01:42,000
Suppose we study the action of going up over here, and we have a 50% of success.

25
00:01:42,000 --> 00:01:46,000
Suppose at the time we do the backup, the value over here is 10,

26
00:01:46,000 --> 00:01:50,000
20 over here, and 40 on the right.

27
00:01:50,000 --> 00:01:56,000
Then the value of the state for the action "go up" would be obtained as follows.

28
00:01:56,000 --> 00:02:06,000
It's a 50% chance times 10, 25% times 20, and 25% chance times 40 plus 1,

29
00:02:06,000 --> 00:02:16,000
which is our motion cost, which together gives me 5 plus 5 plus 10 plus 1 equals 21.

30
00:02:16,000 --> 00:02:19,000
That is the backed up value over here for the action go up,

31
00:02:19,000 --> 00:02:23,000
and you can do the same with go right, go left, go down.

32
00:02:23,000 --> 00:02:27,000
The interesting case in your implementation is the one for an action

33
00:02:27,000 --> 00:02:30,000
that either runs off the grid or into a wall.

34
00:02:30,000 --> 00:02:34,000
Let's study the case of going north from this cell over here

35
00:02:34,000 --> 00:02:39,000
where there is a 25% chance of falling off the grid.

36
00:02:39,000 --> 00:02:43,000
Then the value for the cell and the action of going north

37
00:02:43,000 --> 00:02:52,000
is 50% times 20, which is 10, 25% chance times 40, which is also 10,

38
00:02:52,000 --> 00:02:54,000
and then we have this case where we fall off the wall.

39
00:02:54,000 --> 00:03:00,000
Let's define the penalty for falling off the grid or for hitting an obstacle as 100.

40
00:03:00,000 --> 00:03:04,000
So we add 25% chance times 100 plus 1, 1,

41
00:03:04,000 --> 00:03:10,000
hence the new value is 10 plus 10 plus 25 plus, which is 46.

42
00:03:10,000 --> 00:03:16,000
I want your update to produce for the cell over here 46 for this specific action of going up.

43
00:03:16,000 --> 00:03:19,000
Of course, the value might be smaller because there might be a better action

44
00:03:19,000 --> 00:03:21,000
like the action of going right.

45
00:03:21,000 --> 00:03:25,000
But for this specific calculation you should receive 46.

46
00:03:25,000 --> 00:03:30,000
Your programming assignment looks as follows. I will give you a grid.

47
00:03:30,000 --> 00:03:33,000
In this case it's a grid that's entirely unoccupied.

48
00:03:33,000 --> 00:03:37,000
As before, I give you a goal state and a set of actions.

49
00:03:37,000 --> 00:03:41,000
I want you to program dynamic programming all the way to the end,

50
00:03:41,000 --> 00:03:45,000
so when I run it, the values I get are 0 for the goal state,

51
00:03:45,000 --> 00:03:49,000
37 for the 2 adjacent states, and 44, 16, and 63.

52
00:03:49,000 --> 00:03:53,000
If I go right to the goal, there is a 50% chance of hitting the goal,

53
00:03:53,000 --> 00:03:56,000
in which case my cost is just one, which is the cost of motion.

54
00:03:56,000 --> 00:04:00,000
There is 25% chance of running into the wall,

55
00:04:00,000 --> 00:04:04,000
which costs me 100 plus, of course, 1 for the robot motion,

56
00:04:04,000 --> 00:04:09,000
and there's a 25% chance I find myself down here, which costs us 44.

57
00:04:09,000 --> 00:04:14,000
If I put this into mathematics, we get 50% chance for reaching the goal,

58
00:04:14,000 --> 00:04:18,000
25% for hitting a wall, which costs me 100,

59
00:04:18,000 --> 00:04:25,000
25% for going south, and the value here is 44.77 plus the cost of motion is 1.

60
00:04:25,000 --> 00:04:33,000
If you add this all up, you get exactly the 37.193 that this value over here constitutes.

61
00:04:33,000 --> 00:04:38,000
After conversions for this grid, I want the value function to look just like this.

62
00:04:38,000 --> 00:04:42,000
Here is the corresponding policy.

63
00:04:42,000 --> 00:04:45,000
If I modify the grid to insert an obstacle over here,

64
00:04:45,000 --> 00:04:50,000
then I get a value function like this. One thousand is my initial value for each cell.

65
00:04:50,000 --> 00:04:54,000
It's unmodified for the obstacle cell, and these are the values I receive--

66
00:04:54,000 --> 00:04:58,000
94, 86, 73, and 44.

67
00:04:58,000 --> 00:05:00,000
You can check whether these values are correct.

68
00:05:00,000 --> 00:05:03,000
Let me pick a slightly bigger grid

69
00:05:03,000 --> 00:05:09,000
with a goal position in the top right corner and two obstacles down here--size 4 x 4.

70
00:05:09,000 --> 00:05:13,000
Here is my output for the value function. I can read those values.

71
00:05:13,000 --> 00:05:16,000
They happen to be 1000 for the two obstacles.

72
00:05:16,000 --> 00:05:18,000
What's remarkable is the policy.

73
00:05:18,000 --> 00:05:21,000
When I'm close to the wall, you can see that I'm being pulled away

74
00:05:21,000 --> 00:05:25,000
from those wall elements to stay in free space.

75
00:05:25,000 --> 00:05:28,000
I will eventually reach the goal, but I never am willing to drive in a way

76
00:05:28,000 --> 00:05:32,000
that crashes me into a wall if it's not avoidable.

77
00:05:32,000 --> 00:05:36,000
What you have to do with the code we provide is to modify

78
00:05:36,000 --> 00:05:39,000
the dynamic programming routine that assumes a deterministic action

79
00:05:39,000 --> 00:05:41,000
with the one for a stochastic action.

80
00:05:41,000 --> 00:05:46,000
Specifically, what this routine should do is it should incorporate

81
00:05:46,000 --> 00:05:49,000
the probability of successful action and the collision costs.

82
00:05:49,000 --> 00:05:54,000
For example, if I modify the probability of success into a deterministic function,

83
00:05:54,000 --> 00:05:56,000
then my value function will look as follows.

84
00:05:56,000 --> 00:06:00,000
It's just a number of steps in the usual way--1, 2, 3--as before,

85
00:06:00,000 --> 00:06:03,000
and the policy drives me straight to the goal as shown over here.

86
00:06:03,000 --> 00:06:06,000
In your final submission, please exclude any printouts

87
00:06:06,000 --> 00:06:11,000
so we can modify the grid and these values for success probabiilty and collision cost,

88
00:06:11,000 --> 00:06:13,000
and we can see what your code generates.

89
00:06:13,000 --> 99:59:59,999
In the initial value function, please initialize your value function with 1000.
