1
00:00:00,280 --> 00:00:02,430
So let's look at what a network on chip

2
00:00:02,430 --> 00:00:04,760
might look like. Let's say we have some sort

3
00:00:04,760 --> 00:00:07,630
of a squarish style, that has a core, and

4
00:00:07,630 --> 00:00:11,520
maybe a level one cache. And such styles normally will

5
00:00:11,520 --> 00:00:15,110
be connected to a shared bus. Now let's say

6
00:00:15,110 --> 00:00:18,630
that these four cores are using half of the available

7
00:00:18,630 --> 00:00:21,530
tuples on the bus. Because their cache misses and

8
00:00:21,530 --> 00:00:25,110
coherence need to be taken care of through the bus.

9
00:00:25,110 --> 00:00:26,770
Now let's say we had another set of

10
00:00:26,770 --> 00:00:29,860
those cores pretty much the same thing just replicated.

11
00:00:29,860 --> 00:00:32,764
Now we have an even longer thus possibly

12
00:00:32,764 --> 00:00:36,108
a slower bus, that all traffic from all these

13
00:00:36,108 --> 00:00:38,570
eight cores goes to. So we got a

14
00:00:38,570 --> 00:00:41,980
slower bus probably with less throughput than the original

15
00:00:41,980 --> 00:00:45,600
small one had, yet it has twice the demand

16
00:00:45,600 --> 00:00:49,810
for traffic. So very quickly, it will get saturated.

17
00:00:49,810 --> 00:00:55,170
Now, let's consider a type of on chip network that is called a mesh.

18
00:00:55,170 --> 00:00:59,730
So here, what we have is this quartiles are individually

19
00:00:59,730 --> 00:01:05,280
connected like this, for example. Now there is no more broadcast, but

20
00:01:05,280 --> 00:01:07,270
this core can still send the message to any

21
00:01:07,270 --> 00:01:10,140
other core. If we send the message to this,

22
00:01:10,140 --> 00:01:12,600
this the link that gets used. Meanwhile, this core

23
00:01:12,600 --> 00:01:14,890
could be sending a message here. If we need to

24
00:01:14,890 --> 00:01:17,073
send a message from here to here, then these

25
00:01:17,073 --> 00:01:20,570
two links get used. Meanwhile, we can get these two

26
00:01:20,570 --> 00:01:24,023
links used independently. So as you can see, the total

27
00:01:24,023 --> 00:01:27,857
available throughput in the entire network is several times the

28
00:01:27,857 --> 00:01:31,382
throughput of this individual link. And because it's a

29
00:01:31,382 --> 00:01:34,547
short link we can have a very large throughput. Now

30
00:01:34,547 --> 00:01:37,573
I'm going to take this two by two mesh and

31
00:01:37,573 --> 00:01:40,243
copy it so that I get four of those and

32
00:01:40,243 --> 00:01:46,760
create a four by four mesh that now supports 16 cores, twice as many as here.

33
00:01:46,760 --> 00:01:50,041
Note how many new links are there. Now

34
00:01:50,041 --> 00:01:53,176
if you have neighbor-to-neighbor communication, we can have

35
00:01:53,176 --> 00:01:55,570
these two talking, these two talking, these two

36
00:01:55,570 --> 00:01:59,130
talking all over independent links. So as I

37
00:01:59,130 --> 00:02:02,100
increase the number of cores, I also increase

38
00:02:02,100 --> 00:02:05,270
the number of these links, naturally. So that the

39
00:02:05,270 --> 00:02:08,240
total throughput available in this network grows with

40
00:02:08,240 --> 00:02:11,154
the number of cores. So the number of cores

41
00:02:11,154 --> 00:02:14,040
grows, the number of links grows, and that

42
00:02:14,040 --> 00:02:17,784
allows the available throughput to grow, and that means

43
00:02:17,784 --> 00:02:22,870
that I can have many more cores than I could on the bus. There many of types

44
00:02:22,870 --> 00:02:26,850
of these so-called point to point networks. A mesh

45
00:02:26,850 --> 00:02:30,480
is one of those that is very good for

46
00:02:30,480 --> 00:02:33,810
chip building because none of these links

47
00:02:33,810 --> 00:02:36,727
intersect each other. So because chips are

48
00:02:36,727 --> 00:02:39,567
basically made by printing things on silicon,

49
00:02:39,567 --> 00:02:42,336
it's naturally good to have something that is

50
00:02:42,336 --> 00:02:48,580
kind of flat like this, and doesn't have links going across different nodes. But

51
00:02:48,580 --> 00:02:55,490
we can build chips with some amount of links crossing each other and thus we can

52
00:02:55,490 --> 00:02:58,480
have a mesh which is kind of like what

53
00:02:58,480 --> 00:03:01,420
we have seen. We can have a torus network.

54
00:03:01,420 --> 00:03:03,950
You build the torus by taking the mesh and

55
00:03:03,950 --> 00:03:07,900
connecting the end points to each other so the

56
00:03:07,900 --> 00:03:10,990
torus really takes the link and kind of wraps

57
00:03:10,990 --> 00:03:13,970
it around and then wraps it around and so

58
00:03:13,970 --> 00:03:16,020
on. And then you do that in the other

59
00:03:16,020 --> 00:03:21,156
dimension too. You can think of these processors as basically

60
00:03:21,156 --> 00:03:25,290
things on a donut. You would take this wrap it around,

61
00:03:25,290 --> 00:03:28,112
you get a cylinder. Then you take the end points of the

62
00:03:28,112 --> 00:03:30,704
cylinder, bend it and create a donut so that's why it's

63
00:03:30,704 --> 00:03:34,080
called a taurus. But in reality what you really do. Is you

64
00:03:34,080 --> 00:03:37,580
do this, have a long link that crosses here, and a

65
00:03:37,580 --> 00:03:40,860
long link that crosses here, and so on. And then you also

66
00:03:40,860 --> 00:03:43,320
take this and create a long link that goes here, so

67
00:03:43,320 --> 00:03:46,568
that's how you create a taurus. And then there are even fancier

68
00:03:46,568 --> 00:03:49,277
networks that are still reasonably good for on chip

69
00:03:49,277 --> 00:03:53,785
implementation, such as flattened butterfly. If you're interested in

70
00:03:53,785 --> 00:03:56,060
how these work, a very good place to start

71
00:03:56,060 --> 00:03:59,050
would be an advanced class on on chip interconnects.
