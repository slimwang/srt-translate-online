1
00:00:00,200 --> 00:00:05,950
As we mentioned previously, in journal, the editors may lie in the knowledge,

2
00:00:05,950 --> 00:00:09,890
in the reasoning, or the architecture of a nation. And therefore, learning and

3
00:00:09,890 --> 00:00:14,030
correcting errors might be applicable to any one of those.

4
00:00:14,030 --> 00:00:17,690
However, in this lesson, we will be focusing only on errors and

5
00:00:17,690 --> 00:00:21,660
knowledge. In fact, in particular, we'll be focusing on errors and

6
00:00:21,660 --> 00:00:24,500
classification knowledge. Classification, of course,

7
00:00:24,500 --> 00:00:27,590
is a topic that we have considered this class repeatedly. Let us

8
00:00:27,590 --> 00:00:32,870
consider an air agent that has two examples of executing an action in the world.

9
00:00:32,870 --> 00:00:36,620
In the first experience, the agent will use this object as a cup and

10
00:00:36,620 --> 00:00:41,470
gets the feedback, this indeed was a cup. So this was a positive experience.

11
00:00:41,470 --> 00:00:45,080
This, on the other hand, is a negative example. Here, the agent viewed this as

12
00:00:45,080 --> 00:00:49,070
a cup and got the feedback that this should not have been viewed as a cup.

13
00:00:49,070 --> 00:00:54,870
We can visualize the problem of identifying what knowledge element led the agent

14
00:00:54,870 --> 00:01:01,470
to incorrectly classify this as a cup. As follows. This left circle here consist

15
00:01:01,470 --> 00:01:07,350
of all features that describe the positive example. The circle on the right

16
00:01:07,350 --> 00:01:12,910
consist of all features that describe the negative example. So features in this

17
00:01:12,910 --> 00:01:17,640
left circle might be things like this is a handle, there is a question mark,

18
00:01:17,640 --> 00:01:22,450
there is a blue interior and so on. The circle on the right consist of features.

19
00:01:22,450 --> 00:01:26,210
That characterize a negative example. It has a movable handle.

20
00:01:26,210 --> 00:01:30,060
It has a red interior. It has red and white markings on the outside.

21
00:01:30,060 --> 00:01:34,940
There's some features that characterize only the positive experience and

22
00:01:34,940 --> 00:01:38,370
not the negative experience. There are those that characterize only,

23
00:01:38,370 --> 00:01:40,750
the negative experience, and not the positive experience.

24
00:01:40,750 --> 00:01:43,990
There are also many features that characterize both the positive and

25
00:01:43,990 --> 00:01:47,840
the negative example. For example they are both concave, they both have handles,

26
00:01:47,840 --> 00:01:53,490
and so on. In this example, it is these features that are specially important.

27
00:01:53,490 --> 00:01:58,670
We'll call them fault suspicious features. We call them fault suspicious

28
00:01:58,670 --> 00:02:04,990
features because first they identify only the negative experience. Secondly,

29
00:02:04,990 --> 00:02:09,990
one or more of these features may be responsible for the fact that the agent

30
00:02:09,990 --> 00:02:14,340
classified this as a positive example when in fact it was a negative example.

31
00:02:14,340 --> 00:02:19,550
As an example suppose that this features corresponds to a movable handle. This

32
00:02:19,550 --> 00:02:25,900
is a false suspicious feature. It is false because this experience was false.

33
00:02:25,900 --> 00:02:31,170
It is suspicious because it does not characterize the positive experience.

34
00:02:31,170 --> 00:02:34,940
And thus it may be one of the features responsible for the fact that this was

35
00:02:34,940 --> 00:02:40,104
a negative example. But now there's an additional problem. There are number

36
00:02:40,104 --> 00:02:44,122
of false suspicious features here. So how will the agent decide which false

37
00:02:44,122 --> 00:02:49,370
suspicious feature to focus on? We've encountered this problem earlier,

38
00:02:49,370 --> 00:02:52,690
when we were talking about incremental costs of learning. At that point we had

39
00:02:52,690 --> 00:02:56,960
said that we wanted to give examples in an order, such that each succeeding

40
00:02:56,960 --> 00:03:01,540
example referred to the current constant definition, and exactly one feature.

41
00:03:01,540 --> 00:03:04,340
So that the agent knows exactly what the focus that feature is on.

42
00:03:04,340 --> 00:03:09,660
The same kind of problem occurs again how might the agent know which feature to

43
00:03:09,660 --> 00:03:14,780
focus on. One possible idea is that it could try on of the feature at a time and

44
00:03:14,780 --> 00:03:19,570
see if it will work. That is it could select this feature to repeat the process

45
00:03:19,570 --> 00:03:24,291
get more feedback and either is accepted or eliminated. An alternate method is

46
00:03:24,291 --> 00:03:29,880
that the agent perceived not just two experiences. But many such experiences. So

47
00:03:29,880 --> 00:03:35,050
there were other positive experiences that covered this part of the circle.

48
00:03:35,050 --> 00:03:39,480
That would leave only this as a false suspicious feature, and then the agent can

49
00:03:39,480 --> 00:03:43,680
focus attention on this feature. As an example, just like this circle may

50
00:03:43,680 --> 00:03:48,290
correspond to a movable handle, this may correspond to red interior. Because red

51
00:03:48,290 --> 00:03:52,070
interior is one of the features that characterizes a negative example and

52
00:03:52,070 --> 00:03:56,540
not a positive example. But later on, there might be another positive example

53
00:03:56,540 --> 00:04:00,070
that comes of a cup, which had a red interior in which case agent can

54
00:04:00,070 --> 00:04:05,050
exclude this particular feature. The reverse of this situation is also possible.

55
00:04:05,050 --> 00:04:09,020
Let us suppose that the agent decides that this is not a cup,

56
00:04:09,020 --> 00:04:12,720
perhaps because its definition says that something with a blue interior is

57
00:04:12,720 --> 00:04:17,200
not a cup. And therefore, it doesn't bring water to you inside this cup and

58
00:04:17,200 --> 00:04:21,029
tells you there is no cup available in the kitchen. You go to the kitchen.

59
00:04:21,029 --> 00:04:26,010
You see it and you say, well, this is the cup. Now, the agent must learn

60
00:04:26,010 --> 00:04:30,860
why did they decide that it was not a cup. In this case, the relevant features

61
00:04:30,860 --> 00:04:35,880
are these three features. These are the three features that define this cup, but

62
00:04:35,880 --> 00:04:39,740
do not define the other experiences. So this dot may correspond to a blue

63
00:04:39,740 --> 00:04:43,810
interior, this dot may correspond to a question mark on the exterior, we'll call

64
00:04:43,810 --> 00:04:47,800
this feature true suspicious, just like we call them false suspicious.

65
00:04:49,050 --> 00:04:53,700
These are the features that prevented the agent from deciding that this was

66
00:04:53,700 --> 00:04:58,790
a positive example of a cup. One or more of these features may be

67
00:04:58,790 --> 00:05:02,650
responsible for the agent's failure to recognize that this was a cup
