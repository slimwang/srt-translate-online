1
00:00:00,360 --> 00:00:01,450
>> Okay Michael, so we've done our little

2
00:00:01,450 --> 00:00:05,390
example. I want to ask you a quick question

3
00:00:05,390 --> 00:00:07,260
and try to talk something through with you

4
00:00:07,260 --> 00:00:09,270
and then we can start to wrap up. Okay.

5
00:00:09,270 --> 00:00:09,720
>> Awesome.

6
00:00:09,720 --> 00:00:14,880
>> Alright, so, here is my quick question. Now, in the reading, which I know

7
00:00:14,880 --> 00:00:20,100
you've read, there's a proof. That shows that boosting not

8
00:00:20,100 --> 00:00:25,610
only, you know, does pretty things with axis of line semi-planes, but also

9
00:00:25,610 --> 00:00:29,210
that it will converge to good answers and that it will

10
00:00:29,210 --> 00:00:33,390
find good combined hypotheses. You know, we could go look at

11
00:00:33,390 --> 00:00:36,110
the reading and write down a proof that shows that boosting

12
00:00:36,110 --> 00:00:38,892
does well. Umm. And there's one in the reading. Or we

13
00:00:38,892 --> 00:00:41,380
could talk about an intuition. So if someone were to come

14
00:00:41,380 --> 00:00:44,172
up to you. If a student were to find you somewhere

15
00:00:44,172 --> 00:00:47,592
and said, I read the proof, I'm kind of getting it,

16
00:00:47,592 --> 00:00:50,632
but do you have a good sort of intuition about why

17
00:00:50,632 --> 00:00:54,450
boosting tends will do well? What do you think you would tell them?

18
00:00:54,450 --> 00:00:57,240
Could you think of something simple? I've been struggling with this for a while.

19
00:00:57,240 --> 00:00:59,400
>> No. [LAUGH].

20
00:00:59,400 --> 00:01:01,870
>> Okay, well, then let me try something on you and you can tell

21
00:01:01,870 --> 00:01:05,074
me if it sort of makes sense. So this is just an intuition for why,

22
00:01:05,074 --> 00:01:10,000
for why boosting pins will do well. Okay, so what does boosting do? Okay.

23
00:01:10,000 --> 00:01:13,090
Boosting basically says, if I have some

24
00:01:13,090 --> 00:01:15,990
examples that I haven't been able to classify

25
00:01:15,990 --> 00:01:21,210
well, I'm going to re-rate all my examples. So that the ones

26
00:01:21,210 --> 00:01:23,030
I don't do well become increasingly

27
00:01:23,030 --> 00:01:25,160
important. Right, that's what boosting does. Yes?

28
00:01:25,160 --> 00:01:25,480
>> Yes.

29
00:01:25,480 --> 00:01:30,965
>> Right, that's what this whole, whole bit of D is all about. It's all about

30
00:01:30,965 --> 00:01:36,560
re-weighting based on difficulty and hardest. And we know that

31
00:01:36,560 --> 00:01:41,040
we have the notion of a weak learner. That no matter what happens for

32
00:01:41,040 --> 00:01:45,160
whatever distribution, we're always going to be able to find

33
00:01:45,160 --> 00:01:48,280
some hypothesis that does well. So, if I'm trying to

34
00:01:48,280 --> 00:01:51,980
understand why boosting in the end, why the final hypothesis

35
00:01:51,980 --> 00:01:54,620
that I get at the end, is going to do well.

36
00:01:54,620 --> 00:01:56,330
I can try to get a feeling for that by

37
00:01:56,330 --> 00:02:00,250
asking, well. Under what circumstances would it not do well? So,

38
00:02:00,250 --> 00:02:02,990
if it doesn't do well, then that means there has

39
00:02:02,990 --> 00:02:07,170
to be a bunch of examples that it's getting wrong, right?

40
00:02:07,170 --> 00:02:07,830
>> Mm hm.

41
00:02:07,830 --> 00:02:09,800
>> That's what it would mean not to do well, agreed?

42
00:02:09,800 --> 00:02:10,288
>> Yeah.

43
00:02:10,288 --> 00:02:16,670
>> Okay. So how many things could it not get right? How many things could it

44
00:02:16,670 --> 00:02:19,640
misclassify? How many things could it get incorrect?

45
00:02:19,640 --> 00:02:21,780
Well, I'm going to argue Michael, that, that

46
00:02:21,780 --> 00:02:25,780
number has to be small. There cannot be a lot of examples that it gets wrong.

47
00:02:25,780 --> 00:02:27,920
So do you want to know why? Do you want to know my reasoning for why?

48
00:02:27,920 --> 00:02:29,170
>> Yeah.

49
00:02:29,170 --> 00:02:32,400
>> So, here's my reasoning, let's imagine I had a

50
00:02:32,400 --> 00:02:35,230
number of examples at the end of this whole process.

51
00:02:35,230 --> 00:02:38,150
I've done it T times. I've gone through this many times

52
00:02:38,150 --> 00:02:40,020
and I have some number of examples that I'm getting

53
00:02:40,020 --> 00:02:43,610
wrong. If I were getting those examples wrong, then I was

54
00:02:43,610 --> 00:02:47,080
getting them wrong in the last time step, right? And,

55
00:02:47,080 --> 00:02:51,170
since I have a distribution and I re-normalize, and it has

56
00:02:51,170 --> 00:02:54,880
to be the case that at least half of the time,

57
00:02:54,880 --> 00:02:57,750
more than half of the time I am correct, that number

58
00:02:57,750 --> 00:03:00,230
of things I'm getting wrong has to be getting smaller over

59
00:03:00,230 --> 00:03:02,720
time. Because let's imagine that was at a stage where I

60
00:03:02,720 --> 00:03:05,000
had a whole bunch of them wrong. Well, then I would

61
00:03:05,000 --> 00:03:09,680
naturally renormalize them with a distribution so that all of those things

62
00:03:09,680 --> 00:03:12,270
are important. But if they were all important, the ones that

63
00:03:12,270 --> 00:03:14,930
I was getting wrong, the next time I run a learner, I

64
00:03:14,930 --> 00:03:16,690
am going to have to get at least half of them

65
00:03:16,690 --> 00:03:19,086
right, more than half of them are right. Is that make sense?

66
00:03:19,086 --> 00:03:22,810
>> It does, but it, but what scares me is, okay, why can't

67
00:03:22,810 --> 00:03:25,810
it just be the case that the previous ones which were getting right

68
00:03:25,810 --> 00:03:29,910
start to get more wrong as we shift our energy towards the errors.

69
00:03:29,910 --> 00:03:30,910
>> Yeah, why is that?

70
00:03:30,910 --> 00:03:36,080
>> I don't know. But did you wanna, are we, we working up to some kind of you

71
00:03:36,080 --> 00:03:39,880
know, log n kind of thing where each time

72
00:03:39,880 --> 00:03:42,100
you are knocking off half of them and therefore.

73
00:03:42,100 --> 00:03:43,820
>> I don't know. Do you remember the proof.

74
00:03:43,820 --> 00:03:44,130
>> The proof.

75
00:03:44,130 --> 00:03:45,050
>> I mean what goes on is that

76
00:03:45,050 --> 00:03:48,380
you get, sort of, this exponentially aggressive weighting over

77
00:03:48,380 --> 00:03:49,200
examples, right?

78
00:03:49,200 --> 00:03:50,270
>> Yeah.

79
00:03:50,270 --> 00:03:53,520
>> And you're driving down the number of things you get wrong. Sort of

80
00:03:53,520 --> 00:03:55,980
exponentially quickly, over time. That's why boosting

81
00:03:55,980 --> 00:03:57,200
works so well and works so fast.

82
00:03:57,200 --> 00:04:01,410
>> I get that we're, the we're quickly ramping up the weights on the hard

83
00:04:01,410 --> 00:04:05,710
ones. I don't get why that's causing us to get fewer things wrong over time.

84
00:04:05,710 --> 00:04:10,300
So like, when you should, in your, in your example that you worked through, that

85
00:04:10,300 --> 00:04:13,500
had the error in the alphas and the errors kept going down and the alphas

86
00:04:13,500 --> 00:04:14,180
kept going up.

87
00:04:14,180 --> 00:04:15,050
>> Right.

88
00:04:15,050 --> 00:04:18,120
>> Like, is that necessarily the case?

89
00:04:18,120 --> 00:04:20,540
>> Well, what would be the circumstances under

90
00:04:20,540 --> 00:04:22,300
which it isn't the case? How would you

91
00:04:22,300 --> 00:04:24,880
ever go back and forth between examples? Well,

92
00:04:24,880 --> 00:04:26,430
certainly it's the case that if you keep getting

93
00:04:26,430 --> 00:04:31,120
something, right, you will, get them. Well, so

94
00:04:31,120 --> 00:04:32,660
here's what happens over time, right. Is that over

95
00:04:32,660 --> 00:04:36,040
time, every new hypothesis, it gets to get

96
00:04:36,040 --> 00:04:38,680
a vote, based upon how well it does on

97
00:04:38,680 --> 00:04:43,470
the last, difficult let's say, distribution. So the

98
00:04:43,470 --> 00:04:47,810
ones that are even if the ones that

99
00:04:47,810 --> 00:04:49,420
you were getting right you start to get

100
00:04:49,420 --> 00:04:52,480
wrong, they are going to, if you get them

101
00:04:52,480 --> 00:04:55,720
increasingly wrong, that error's going to go down and

102
00:04:55,720 --> 00:04:59,130
you're going to get less of a vote, right.

103
00:04:59,130 --> 00:05:00,990
Because e sub T is over the current

104
00:05:00,990 --> 00:05:03,842
distribution. And it's not over the sum of the

105
00:05:03,842 --> 00:05:07,500
voted, over all the examples you've ever seen.

106
00:05:07,500 --> 00:05:08,080
>> Understand.

107
00:05:08,080 --> 00:05:11,020
>> So does that make sense? Is that right?

108
00:05:11,020 --> 00:05:13,872
>> I don't know. I don't have the intuition, it seems like

109
00:05:13,872 --> 00:05:16,620
it could be, you know, could we keep shifting the distribution. It

110
00:05:16,620 --> 00:05:18,820
could be that the error is going up. Like if the error

111
00:05:18,820 --> 00:05:21,680
could be low, why can't we just make it low from the beginning.

112
00:05:21,680 --> 00:05:22,340
>> Right.

113
00:05:22,340 --> 00:05:24,030
>> Like, I feel like the error should be going up,

114
00:05:24,030 --> 00:05:26,810
because we're, we're asking it harder and harder questions as we go.

115
00:05:26,810 --> 00:05:29,090
>> No, no, no, because we're asking it harder and

116
00:05:29,090 --> 00:05:32,160
harder questions, but even though we're

117
00:05:32,160 --> 00:05:34,140
asking it harder and harder questions, it's

118
00:05:34,140 --> 00:05:37,770
forced to be able to do well on those hard questions. It's forced

119
00:05:37,770 --> 00:05:41,600
to, because it's a weak learner. I mean that's why having, being able

120
00:05:41,600 --> 00:05:44,610
to always, that's why having a weak learner is such a powerful thing.

121
00:05:44,610 --> 00:05:46,690
>> But why couldn't we like on, on

122
00:05:46,690 --> 00:05:50,350
iteration 17, have something where the weak learner works

123
00:05:50,350 --> 00:05:51,890
right at the edge of it's abilities, and

124
00:05:51,890 --> 00:05:54,240
it just comes back with something that's a half

125
00:05:54,240 --> 00:05:55,720
minus epsilon.

126
00:05:55,720 --> 00:05:58,020
>> That's fine. But it has to always be able to do that. If it's

127
00:05:58,020 --> 00:05:59,480
a half minus epsilon, the things it's getting

128
00:05:59,480 --> 00:06:01,800
wrong will have to go back down again.

129
00:06:01,800 --> 00:06:03,140
>> No, no I understand that. What I'm saying

130
00:06:03,140 --> 00:06:06,620
is that, why would the error go down each iteration.

131
00:06:06,620 --> 00:06:08,537
>> Well, it doesn't have to, but it shouldn't be getting bigger.

132
00:06:08,537 --> 00:06:09,488
>> Why shouldn't it be getting bigger?

133
00:06:09,488 --> 00:06:11,227
>> So, imagine, imagine, imagine the case that you're

134
00:06:11,227 --> 00:06:13,960
getting, right. You, you are working at the edge of

135
00:06:13,960 --> 00:06:16,910
your abilities. You get half of them right. Roughly and

136
00:06:16,910 --> 00:06:19,290
half of them wrong, the ones you got wrong would

137
00:06:19,290 --> 00:06:21,200
become more important, so the next time round you're going

138
00:06:21,200 --> 00:06:24,180
to get those right, versus the other ones. So you could

139
00:06:24,180 --> 00:06:26,510
cycle back and forth I suppose, in the worst case,

140
00:06:26,510 --> 00:06:29,000
but then you're just going to be sitting around, always having

141
00:06:29,000 --> 00:06:31,120
a little bit more information. So your error will not

142
00:06:31,120 --> 00:06:33,910
get worse, you'll just have different ones that are able to

143
00:06:33,910 --> 00:06:37,520
vote on that do well on different parts of the space.

144
00:06:37,520 --> 00:06:40,090
Right? Because you're always forced to do better than chance. So.

145
00:06:40,090 --> 00:06:42,070
>> Yeah but that, that's not the same as saying

146
00:06:42,070 --> 00:06:44,500
that we're forced to get better and better each iteration.

147
00:06:44,500 --> 00:06:45,240
>> That's right, it's not.

148
00:06:45,240 --> 00:06:49,380
>> So it's, yeah again, I don't see that, that property just falling out.

149
00:06:49,380 --> 00:06:51,310
>> Well, I don't see it falling out either, but then

150
00:06:51,310 --> 00:06:54,154
I haven't read the proof in like seven, eight, nine years.

151
00:06:54,154 --> 00:06:56,780
>> Well, I feel like it should be, it should be something like, look we

152
00:06:56,780 --> 00:07:01,130
had, look at what the, so okay, so we generate a new distribution, what is

153
00:07:01,130 --> 00:07:03,370
the previous, what's the previous classified error

154
00:07:03,370 --> 00:07:05,880
on this distribution, it better be the case.

155
00:07:05,880 --> 00:07:09,870
I mean if it were the case that we always return the best classifier that

156
00:07:09,870 --> 00:07:11,870
I could imagine trying to use that but.

157
00:07:11,870 --> 00:07:13,808
>> Well we, well we don't, we don't require that.

158
00:07:13,808 --> 00:07:15,800
>> Yeah, I mean, it's just finding one

159
00:07:15,800 --> 00:07:20,370
that's epsilon minus, or a half minus epsilon.

160
00:07:20,370 --> 00:07:22,300
>> Right, so let's, let's see if we can take the simple case,

161
00:07:22,300 --> 00:07:27,040
we got three examples, right, and you're bouncing back and forth and you want

162
00:07:27,040 --> 00:07:30,112
to construct something so that you always do well on two of them.

163
00:07:30,112 --> 00:07:34,750
And then poorly on one, kind of a thing, and that you keep bouncing

164
00:07:34,750 --> 00:07:38,410
back and forth. So let's imagine that you have one-third, one-third, one-third,

165
00:07:38,410 --> 00:07:41,100
and your first thing gets the first two right and the last one

166
00:07:41,100 --> 00:07:44,460
wrong. So you have an error of a third. And you make that

167
00:07:44,460 --> 00:07:49,770
last one more likely and the other two less likely. Suitably normalized, right?

168
00:07:49,770 --> 00:07:50,760
>> Yep.

169
00:07:50,760 --> 00:07:53,570
>> So now, your next one, you want to somehow

170
00:07:53,570 --> 00:07:56,430
bounce back and have it decide that it can miss,

171
00:07:56,430 --> 00:07:58,160
so lets say you missed the third one. So you,

172
00:07:58,160 --> 00:07:59,930
you get the third one right. You get the second

173
00:07:59,930 --> 00:08:03,000
one right but you get the first one wrong. What's going

174
00:08:03,000 --> 00:08:06,540
to happen? Well, three is going to go down. You're still going to,

175
00:08:06,540 --> 00:08:09,780
well you won't have a third error actually. You'll have less than

176
00:08:09,780 --> 00:08:12,190
a third error because you had to get one of the ones

177
00:08:12,190 --> 00:08:13,990
you were getting right wrong, you had to get the one

178
00:08:13,990 --> 00:08:17,330
you were getting wrong right. So your error is going to be

179
00:08:17,330 --> 00:08:21,860
at least an example I just gave. Less than a third. So,

180
00:08:21,860 --> 00:08:25,260
if your error is less and a third, then the weighting goes

181
00:08:25,260 --> 00:08:28,980
up more. And so, the one that you just got wrong

182
00:08:28,980 --> 00:08:31,340
goes up, doesn't go back to where it was before. It

183
00:08:31,340 --> 00:08:33,876
becomes even more important than it was when you had a

184
00:08:33,876 --> 00:08:38,480
uniform distribution. So the next time around, you have to get

185
00:08:38,480 --> 00:08:41,940
that one right, but it's not enough to break a half.

186
00:08:41,940 --> 00:08:44,750
So you're going to have to get something else right as well,

187
00:08:44,750 --> 00:08:46,550
and the one in the middle that you were getting right

188
00:08:46,550 --> 00:08:49,830
isn't enough. So you'll have to get number three right as well.

189
00:08:49,830 --> 00:08:50,610
>> Interesting.

190
00:08:50,610 --> 00:08:54,980
>> Right? And so, it's really hard to cycle

191
00:08:54,980 --> 00:08:59,475
back and forth between different examples, because you're exponentially

192
00:08:59,475 --> 00:09:02,160
weighting how important they are. Which means, you're always

193
00:09:02,160 --> 00:09:04,140
going to have to pick up something along the way.

194
00:09:05,210 --> 00:09:07,790
Because the ones that you, coicidentally, got right two

195
00:09:07,790 --> 00:09:10,710
times in a row. Become so unimportant. It doesn't

196
00:09:10,710 --> 00:09:12,950
help you to get those right. Whereas, the ones

197
00:09:12,950 --> 00:09:15,430
that you've gotten wrong, in the past. You've got to,

198
00:09:15,430 --> 00:09:19,940
on these cycles. Pick up some of them in order to get you over a half.

199
00:09:19,940 --> 00:09:20,490
>> Mmm

200
00:09:20,490 --> 00:09:22,850
>> And so, it is very difficult for you to cycle back and forth.

201
00:09:22,850 --> 00:09:24,660
>> Interesting.

202
00:09:24,660 --> 00:09:26,570
>> And that kind of makes sense, right? If

203
00:09:26,570 --> 00:09:28,520
you think about it in kind of an information gain

204
00:09:28,520 --> 00:09:31,180
sense, because what's going on there is you're, you're

205
00:09:31,180 --> 00:09:34,590
basically saying you must pick up information all the time.

206
00:09:34,590 --> 00:09:38,020
>> Hm. And then your non uni. Well uniform is

207
00:09:38,020 --> 00:09:40,001
the wrong word but you are kind of. You know,

208
00:09:40,001 --> 00:09:43,680
non-linearly using that information in some way. So that kind of

209
00:09:43,680 --> 00:09:47,910
works. It makes some sense to me, but I think that

210
00:09:47,910 --> 00:09:51,650
in the end what has to happen is you. You, there

211
00:09:51,650 --> 00:09:54,920
must be just a few examples in a kind of weighted sense

212
00:09:54,920 --> 00:09:57,920
that you're getting wrong. And so if I'm right, that as

213
00:09:57,920 --> 00:10:00,410
you, as you move through each of these cycles, you're weighting

214
00:10:00,410 --> 00:10:02,490
in such a way that you have to be picking up

215
00:10:02,490 --> 00:10:04,880
things you've gotten wrong in the past. So in other words,

216
00:10:04,880 --> 00:10:07,380
it's not enough to say, only the things that are

217
00:10:07,380 --> 00:10:10,560
hard in the last set, are the ones that I

218
00:10:10,560 --> 00:10:12,840
have to do better. You must also be picking up

219
00:10:12,840 --> 00:10:17,160
some of the things that you've gotten wrong earlier more

220
00:10:17,160 --> 00:10:19,980
than you were getting right. Because there's just not enough

221
00:10:19,980 --> 00:10:21,750
information in the one's that you're getting right all the

222
00:10:21,750 --> 00:10:24,890
time, because by the time you get that far along,

223
00:10:24,890 --> 00:10:26,690
the weight on them is near zero and they don't matter.

224
00:10:26,690 --> 00:10:28,850
>> Interesting.

225
00:10:28,850 --> 00:10:29,930
>> And then if you say, well, Charles,

226
00:10:29,930 --> 00:10:32,230
I could cycle back by always getting those wrong,

227
00:10:32,230 --> 00:10:34,450
yes, but then if you're getting those wrong, they're going to

228
00:10:34,450 --> 00:10:35,860
pull up and you're going to have to start getting

229
00:10:35,860 --> 00:10:38,440
those right too. And so, over time, you've gotta not

230
00:10:38,440 --> 00:10:39,860
just pick out things that do better than a

231
00:10:39,860 --> 00:10:42,218
half. But things that do well on a lot of

232
00:10:42,218 --> 00:10:45,710
the data. Because there's no way for all of the

233
00:10:45,710 --> 00:10:48,780
possible distributions for you to do better than chance otherwise.

234
00:10:48,780 --> 00:10:49,340
>> Cool.
