1
00:00:00,180 --> 00:00:05,150
File systems use several techniques to
try to minimize the access to disk and

2
00:00:05,150 --> 00:00:07,910
to improve the file access overheads.

3
00:00:07,910 --> 00:00:12,390
Much like hardware caches are used to
temporarily hold recently used data and

4
00:00:12,390 --> 00:00:16,900
avoid accessing main memory,
file systems rely on buffer caches,

5
00:00:16,900 --> 00:00:20,400
except these buffer caches
are present in main memory and

6
00:00:20,400 --> 00:00:24,620
they're used in order to reduce
the number of necessary disk accesses.

7
00:00:24,620 --> 00:00:29,260
With caching the file will be read or
written to from the cache and

8
00:00:29,260 --> 00:00:33,130
periodically any changes to the file
that have not been backed up on

9
00:00:33,130 --> 00:00:38,190
permanent storage will be flushed
from memory to disc, by forcing these

10
00:00:38,190 --> 00:00:42,890
flushes to happen only periodically,
we can amortize the cost of performing

11
00:00:42,890 --> 00:00:48,380
a disc access over multiple intermittent
rights that will hit the cache.

12
00:00:48,380 --> 00:00:52,590
File systems support this operation
using the fsync system call,

13
00:00:52,590 --> 00:00:56,715
another component that helps reduce the
file access overheads is what we call

14
00:00:56,715 --> 00:01:00,610
I/O scheduling,
this is the component that orders how

15
00:01:00,610 --> 00:01:03,720
disk access operations
will be scheduled.

16
00:01:03,720 --> 00:01:08,470
The intent is to reduce the diskette
movement that's a slow operation and we

17
00:01:08,470 --> 00:01:13,230
can do that by maximizing the number of
sequential accesses, which are needed,

18
00:01:13,230 --> 00:01:17,560
so, for sequential access, this kind of
movement is not expensive It's expensive

19
00:01:17,560 --> 00:01:20,430
for these random accesses, so
that's what we want to avoid.

20
00:01:20,430 --> 00:01:24,320
What that means is, let's say we have
two operations that have been issued,

21
00:01:24,320 --> 00:01:29,880
write block 25 followed by write block
17 and if the disk head is at position,

22
00:01:29,880 --> 00:01:34,990
let's say 15, these operations will
be reordered by the I/O scheduler so

23
00:01:34,990 --> 00:01:39,870
that they're issues as write
first block 17 and then block 25,

24
00:01:39,870 --> 00:01:43,060
and this will achieve this objective
of maximizing sequential and

25
00:01:43,060 --> 00:01:45,090
minimizing random accesses.

26
00:01:45,090 --> 00:01:49,250
Another useful technique is prefetching,
since for many workloads there is a lot

27
00:01:49,250 --> 00:01:53,960
of locality in how the file is accessed,
it is likely that if one

28
00:01:53,960 --> 00:01:57,900
data block is accessed, the subsequent
blocks will be accessed as well.

29
00:01:57,900 --> 00:02:01,710
File systems can take advantage
of this feature by prefetching

30
00:02:01,710 --> 00:02:05,440
more than one block of a file
whenever a single block is accessed,

31
00:02:05,440 --> 00:02:09,070
this does use up more disk
bandwidth to move larger,

32
00:02:09,070 --> 00:02:13,040
in this case, three x worth of
data from disk into main memory.

33
00:02:13,040 --> 00:02:15,590
But it can significantly impact,
or reduce,

34
00:02:15,590 --> 00:02:19,650
the access latency,
by increasing the cache hit rate

35
00:02:19,650 --> 00:02:23,760
because more of the accesses will be
served out of cache, potentially.

36
00:02:23,760 --> 00:02:28,400
Finally, another useful technique is
journaling, I/O scheduling reduces

37
00:02:28,400 --> 00:02:32,990
the random access, but
it still keeps the data in memory, so,

38
00:02:32,990 --> 00:02:36,810
these blocks, 17 and 25,
are still in memory waiting for

39
00:02:36,810 --> 00:02:40,030
the I/O scheduler to interleave
them in the right way.

40
00:02:40,030 --> 00:02:42,310
That means that,
if something happens and

41
00:02:42,310 --> 00:02:45,970
the system crashes,
these data blocks will be lost, so,

42
00:02:45,970 --> 00:02:49,860
we want to make sure that the data ends
up on disk, but we still want to make

43
00:02:49,860 --> 00:02:54,160
sure that we reduce the level of
random access that's required.

44
00:02:54,160 --> 00:02:55,910
This is where journaling helps,

45
00:02:55,910 --> 00:02:59,620
as opposed to writing out the data
in the proper disk location,

46
00:02:59,620 --> 00:03:05,490
which will require a lot of random
access we write updates in a log, so,

47
00:03:05,490 --> 00:03:10,340
the log will contain some description of
the write that's supposed to take place.

48
00:03:10,340 --> 00:03:13,940
If we specify the block,
the offset, and the value,

49
00:03:13,940 --> 00:03:18,330
that essentially describes an individual
write, now, I'm over trivializing

50
00:03:18,330 --> 00:03:21,910
this there is a little bit more that
goes into it, but this is overall,

51
00:03:21,910 --> 00:03:25,260
the nature of the journal link or
the logging base systems.

52
00:03:25,260 --> 00:03:28,260
The following file systems to
execute called the ext3 and

53
00:03:28,260 --> 00:03:32,040
the ext4 they're also part
of current Linux versions,

54
00:03:32,040 --> 00:03:35,430
they use journaling as well
as many other file systems.

55
00:03:35,430 --> 00:03:38,770
Note that a journal has to
be periodically updated

56
00:03:38,770 --> 00:03:42,190
into a proper disk location, otherwise
it will just grow indefinitely and

57
00:03:42,190 --> 00:03:44,380
it will be really hard to find anything.

58
00:03:44,380 --> 00:03:48,410
So if we look at these four techniques
and summary, every single one of

59
00:03:48,410 --> 00:03:52,990
them contributes to reducing the file
system overheads and latencies.

60
00:03:52,990 --> 00:03:57,230
This is done by increasing the
likelihood of accessing data from memory

61
00:03:57,230 --> 00:04:01,490
by not having to wait on
slow disk head movements,

62
00:04:01,490 --> 00:04:04,870
by reducing the overall number
of accesses to disk and

63
00:04:04,870 --> 00:04:08,310
definitely the number of
random accesses to disk.

64
00:04:08,310 --> 00:04:11,640
These techniques are commonly used
in current file system solutions.
