1
00:00:00,000 --> 00:00:01,867
Okay, and that's Stratton's Taxonomy.

2
00:00:01,867 --> 00:00:06,488
Data layout transformation, transforming scatter patterns to gather patterns.

3
00:00:06,488 --> 00:00:10,433
Tiling, so that we can share input upon multiple threads.

4
00:00:10,433 --> 00:00:14,384
Privatization, so that we can avoid sharing output, as long as possible.

5
00:00:14,384 --> 00:00:19,001
Binning and spatial data structures, so that we can reduce the amount of input

6
00:00:19,001 --> 00:00:21,938
that's necessary to look at for given output.

7
00:00:21,938 --> 00:00:25,770
Compaction, so that we can avoid processing inactive

8
00:00:25,770 --> 00:00:29,709
inputs and process more efficiently on a sparse set of inputs.

9
00:00:29,740 --> 00:00:37,340
And regularization, where we can extract regular parallelism from irregular parallelism,

10
00:00:37,340 --> 00:00:43,424
often in the face of strategies like binning and spatial data structures or the scatter to gather transformation.

11
00:00:43,424 --> 00:00:45,922
Now you've encountered most of these ideas already in the class.

12
00:00:45,922 --> 00:00:48,602
But I do hope this overview helps you think consciously

13
00:00:48,602 --> 00:00:51,768
about the strategies you can employ to optimize parallel programs.

14
00:00:51,768 --> 00:00:55,392
I definitely recommend that you read the original papers if you're interested in learning more.

15
00:00:55,392 --> 00:00:57,934
They give examples from much different bench marks

16
00:00:57,934 --> 00:01:00,161
and describe case studies for some of these techniques.

17
00:01:00,161 --> 00:01:06,422
I find them useful to help me be principled in my thinking about Parallel Optimization.

18
00:01:06,422 --> 00:01:10,712
I'll include, again, links to those papers in the instructor's notes and on the wiki and so forth.
