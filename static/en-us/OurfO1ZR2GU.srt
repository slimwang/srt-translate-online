1
00:00:00,130 --> 00:00:03,030
Let's dig in a little more to see how the number of features that you use in

2
00:00:03,030 --> 00:00:06,480
your algorithm is connected to the bias-variance dilemma.

3
00:00:06,480 --> 00:00:10,190
Remember what we said before is that a high bias algorithm is one

4
00:00:10,190 --> 00:00:14,310
that pays little attention to the training data and is kind of oversimplified.

5
00:00:14,310 --> 00:00:16,050
It just does the same thing over and

6
00:00:16,050 --> 00:00:20,380
over again regardless of what the data might be trying to tell it to do.

7
00:00:20,380 --> 00:00:23,420
On the other hand an algorithm that's too high variance,

8
00:00:23,420 --> 00:00:25,310
pays too much attention to the data.

9
00:00:25,310 --> 00:00:29,690
It doesn't generalize well to new situations that it hasn't quite seen before.

10
00:00:29,690 --> 00:00:32,270
It's basically just memorizing the training examples.

11
00:00:32,270 --> 00:00:35,310
And as soon as it gets a new example or a new data point that's not

12
00:00:35,310 --> 00:00:39,280
exactly like one of the training examples, it doesn't really know what to do.

13
00:00:39,280 --> 00:00:42,330
Another way to think about this is that it's overfitting to the data.

14
00:00:42,330 --> 00:00:46,010
Another thing that would be fair to say is that high biased algorithms tend to

15
00:00:46,010 --> 00:00:48,290
have high error on the training set.

16
00:00:48,290 --> 00:00:51,116
So in the case of a regression, for example, would be mean a low

17
00:00:51,116 --> 00:00:55,580
r-squared value or a large sum of the squared residual errors.

18
00:00:55,580 --> 00:01:00,620
High variance on the other hand might have a very, very good fit to the training

19
00:01:00,620 --> 00:01:06,500
data but a bad fit to the test data because it's not generalizing very well.

20
00:01:06,500 --> 00:01:09,170
So as soon as you give it something new it starts to run into

21
00:01:09,170 --> 00:01:10,740
problems right away.

22
00:01:10,740 --> 00:01:13,410
You usually expect to do a little bit better on the training set than you do

23
00:01:13,410 --> 00:01:14,660
on the test set.

24
00:01:14,660 --> 00:01:18,650
But high variance means that your doing much better on the training set.

25
00:01:18,650 --> 00:01:21,201
But high variance is when your over fitting to the training set,

26
00:01:21,201 --> 00:01:23,450
you get much worse performance on the test set.

27
00:01:23,450 --> 00:01:24,830
So, here's a quiz question for you.

28
00:01:24,830 --> 00:01:29,530
Let's suppose you have an algorithm that's only using a few features in it.

29
00:01:29,530 --> 00:01:32,520
Out of, say, very many that you have available to you.

30
00:01:32,520 --> 00:01:35,190
So maybe one or two out of dozens, potentially.

31
00:01:35,190 --> 00:01:37,670
Without knowing anything more about the exact problem or

32
00:01:37,670 --> 00:01:41,530
the exact features that you're using, do you think that this would

33
00:01:41,530 --> 00:01:46,270
be more inclined to be a high bias situation, or a high variance situation?

34
00:01:46,270 --> 00:01:47,590
Click which one sounds right to you.
