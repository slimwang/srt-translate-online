1
00:00:00,290 --> 00:00:01,970
>> Okay Michael, what have we learned.

2
00:00:03,260 --> 00:00:06,270
>> Well, we learned the definition for feature selection,

3
00:00:06,270 --> 00:00:10,280
which was getting a subset of the features to feed

4
00:00:10,280 --> 00:00:13,090
to some, I think we also talked about supervised training

5
00:00:13,090 --> 00:00:16,990
algorithms, or learning algorithms after the selection has taken place.

6
00:00:16,990 --> 00:00:17,740
>> Right.

7
00:00:17,740 --> 00:00:26,456
>> We made a distinction between [NOISE] rapping and filtering.

8
00:00:29,614 --> 00:00:30,670
>> Was that supposed to be filtering?

9
00:00:30,670 --> 00:00:32,409
>> Yeah, I didn't know how the filtering sounds.

10
00:00:32,409 --> 00:00:33,725
>> It sounded more like slurping.

11
00:00:33,725 --> 00:00:36,490
>> Yeah, I'm not sure that my raping actually sounded like rapping either.

12
00:00:36,490 --> 00:00:39,050
>> It didn't, but I wasn't going to say anything. So what else

13
00:00:39,050 --> 00:00:42,330
did we learn? Besides, you like sound effects. So we learned about feature

14
00:00:42,330 --> 00:00:43,870
selection, we defined that. We discussed

15
00:00:43,870 --> 00:00:45,580
the difference between filtering methods for feature

16
00:00:45,580 --> 00:00:47,750
selection and wrapping methods for feature

17
00:00:47,750 --> 00:00:50,150
selection. What did we learn about them?

18
00:00:50,150 --> 00:00:52,860
>> That wrapping is slow, but actually

19
00:00:52,860 --> 00:00:55,030
seems like it solves the problem that matters.

20
00:00:55,030 --> 00:00:58,890
>> Yeah. So let's call that slow but useful.

21
00:00:58,890 --> 00:01:03,532
>> Is that useful in the sense that you defined it?

22
00:01:03,532 --> 00:01:04,700
>> Yes. Mm Hm.

23
00:01:04,700 --> 00:01:07,900
>> Boy these can be useful words. Filtering

24
00:01:07,900 --> 00:01:13,710
is simpler, possibly faster, but maybe misses the point.

25
00:01:13,710 --> 00:01:19,670
>> Probably faster, yeah, but ignores bias. Okay, so what else? Is that it?

26
00:01:19,670 --> 00:01:20,030
>> Well so

27
00:01:20,030 --> 00:01:22,040
we, and we specifically learned about the distinction

28
00:01:22,040 --> 00:01:27,020
between features being useful versus them being relevant.

29
00:01:27,020 --> 00:01:30,990
>> That's right. so, relevant things are things that give

30
00:01:30,990 --> 00:01:35,350
you information about the classification problem, or the regression problem

31
00:01:35,350 --> 00:01:39,260
that you care about. But useful, features are things that

32
00:01:39,260 --> 00:01:41,840
help you to actually do the learning, given some specific algorithm.

33
00:01:41,840 --> 00:01:44,890
>> Right. And you reminded what a Bayes optimal class

34
00:01:44,890 --> 00:01:48,040
fucker was. [LAUGH]. Which I guess I should have known already.

35
00:01:48,040 --> 00:01:53,365
But somehow, I did not understand how it fit into this context.

36
00:01:53,365 --> 00:01:55,310
>> The, the main power Bayes optimal classifiers is

37
00:01:55,310 --> 00:01:57,450
that it is sort of the gold standard, it

38
00:01:57,450 --> 00:01:59,190
is the ultimate that you could do if you

39
00:01:59,190 --> 00:02:01,010
had everything and all the time in the world.

40
00:02:01,010 --> 00:02:02,690
>> Could I say that relevance is

41
00:02:02,690 --> 00:02:06,600
usefulness with regard to the Bayes optimal classifier?

42
00:02:06,600 --> 00:02:09,610
>> Yes, actually you could, I like that. It is a special case [UNKNOWN].

43
00:02:09,610 --> 00:02:11,690
>> Oh wait,

44
00:02:11,690 --> 00:02:13,540
there's something else that you talk, that you talked about.

45
00:02:13,540 --> 00:02:13,630
>> Yes.

46
00:02:13,630 --> 00:02:15,670
>> Which was, strong and weak relevance.

47
00:02:15,670 --> 00:02:16,478
>> Right.

48
00:02:16,478 --> 00:02:19,150
>> And in a sense that relevant features

49
00:02:19,150 --> 00:02:20,690
have a kind of kryptonite, in the sense

50
00:02:20,690 --> 00:02:22,450
that you can make them not strong just

51
00:02:22,450 --> 00:02:24,200
by putting a copy of them into this space.

52
00:02:24,200 --> 00:02:29,250
>> Right. I like that, the kryptonite is copy. Well done.

53
00:02:29,250 --> 00:02:32,820
That's because you're no longer indispensable. If I have a copy you.

54
00:02:32,820 --> 00:02:33,600
>> That's right, you and now your

55
00:02:33,600 --> 00:02:36,320
evil twin now resides in your parallel universe.

56
00:02:36,320 --> 00:02:36,940
>> So what

57
00:02:36,940 --> 00:02:38,165
do you think that means for us? Are

58
00:02:38,165 --> 00:02:43,829
we, strongly relevant, weakly relevant or useless? [Laughs]

59
00:02:43,829 --> 00:02:47,430
>> And those are your choices. [Laughs]. I am,

60
00:02:47,430 --> 00:02:49,520
I'm going to say I am weakly relevant because I

61
00:02:49,520 --> 00:02:53,050
think I correlate with truth, assuming the subset of

62
00:02:53,050 --> 00:02:54,980
other people in the world is the empty set.

63
00:02:54,980 --> 00:02:56,480
>> Hm. . Fair enough, fair enough. So then

64
00:02:56,480 --> 00:02:58,780
by that definition, do I get to be weakly relevant?

65
00:02:58,780 --> 00:03:00,409
>> You are atleast weakly relevant.

66
00:03:01,510 --> 00:03:02,040
>> Very good.

67
00:03:02,040 --> 00:03:03,620
Very good. But are we useful.

68
00:03:03,620 --> 00:03:08,110
>> We're going to say yes. As far as our students know.

69
00:03:08,110 --> 00:03:10,510
>> [LAUGH] Well I guess that's the way we will

70
00:03:10,510 --> 00:03:12,960
find out ultimately is how well they do on the course.

71
00:03:12,960 --> 00:03:16,580
>> It's true. It's in some sense completely in their hands.

72
00:03:16,580 --> 00:03:18,430
>> Right. So in fact, this course is a

73
00:03:18,430 --> 00:03:23,040
wrapper method over features and this is the first iteration.

74
00:03:23,040 --> 00:03:24,300
>> Interesting.

75
00:03:24,300 --> 00:03:26,990
>> Wow, that was deep. I feel like we should end on that.

76
00:03:26,990 --> 00:03:27,430
>> I

77
00:03:27,430 --> 00:03:27,920
do too.

78
00:03:27,920 --> 00:03:29,880
>> Okay, well then I will see you

79
00:03:29,880 --> 00:03:32,890
next time when we will talk about feature transformation.

80
00:03:32,890 --> 00:03:34,630
>> Transformation.

81
00:03:34,630 --> 00:03:36,480
>> Well done. Bye.

82
00:03:36,480 --> 00:03:37,010
>> Bye.
