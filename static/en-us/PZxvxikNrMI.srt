1
00:00:00,140 --> 00:00:01,640
Notice I've changed
nothing about states.

2
00:00:01,640 --> 00:00:04,440
I've said nothing about function
approximation over states.

3
00:00:04,440 --> 00:00:08,150
I'm talking about abstraction over
this set of actions that you have.

4
00:00:08,150 --> 00:00:10,840
>> Well, you did implicitly talk
a little bit about states when you said

5
00:00:10,840 --> 00:00:16,340
that all the states in say the northeast
room end up being sort of equivalent.

6
00:00:16,340 --> 00:00:20,370
>> Right, equivalent with respect to
the action that you want to take, yes.

7
00:00:20,370 --> 00:00:21,100
>> Yeah.

8
00:00:21,100 --> 00:00:24,680
>> Right, which is its own kind of
approximation, its own kind of a track.

9
00:00:24,680 --> 00:00:26,270
All of these are different
kinds of abstraction.

10
00:00:27,300 --> 00:00:27,810
>> Okay.

11
00:00:27,810 --> 00:00:28,970
>> And will allow us to do scale.

12
00:00:28,970 --> 00:00:32,700
So let me just add one more thing to
this before we move on to the next line.

13
00:00:32,700 --> 00:00:35,110
And what I want to point out is
that this isn't just a way for

14
00:00:35,110 --> 00:00:38,130
you to think about this problem or
to sort of in a compact and

15
00:00:38,130 --> 00:00:41,430
efficient way explain how you would
accomplish a particular goal.

16
00:00:41,430 --> 00:00:43,930
It actually has other
computational benefits.

17
00:00:43,930 --> 00:00:46,870
So if we think in this sort
of southeast room here

18
00:00:46,870 --> 00:00:49,980
about how value propagation works,
right.

19
00:00:49,980 --> 00:00:51,560
You took a bunch of actions in here.

20
00:00:51,560 --> 00:00:53,130
You got to this good space.

21
00:00:53,130 --> 00:00:55,430
Then you start backing up values, right.

22
00:00:55,430 --> 00:00:57,970
So I know this is worth a lot,

23
00:00:57,970 --> 00:01:01,290
because one is the biggest number in
the universe without loss of generality.

24
00:01:01,290 --> 00:01:02,630
Assume one is the largest number.

25
00:01:02,630 --> 00:01:05,280
And then I'm going to learn
that being in this state and

26
00:01:05,280 --> 00:01:08,460
taking this particular
action is also good.

27
00:01:08,460 --> 00:01:10,280
I'll just draw a little dot here.

28
00:01:10,280 --> 00:01:13,960
The big size thing,
that's really good, and a smaller dot,

29
00:01:13,960 --> 00:01:15,810
a slightly smaller dog.

30
00:01:15,810 --> 00:01:19,520
And so the value of the states
around here are nice and

31
00:01:19,520 --> 00:01:24,920
big because I can easily get
from here to the goal state.

32
00:01:24,920 --> 00:01:29,360
And as I move farther
away the value gets to be

33
00:01:30,600 --> 00:01:35,540
a little bit less and then a little
bit less and a little bit less,

34
00:01:35,540 --> 00:01:40,920
and it sort of propagates
out into the other room.

35
00:01:40,920 --> 00:01:43,880
And the way that you propagate
this information is actually kind

36
00:01:43,880 --> 00:01:44,660
of slow, right.

37
00:01:44,660 --> 00:01:47,360
You have to get to the state and
sort of back it up a little bit.

38
00:01:47,360 --> 00:01:51,370
Your horizon is such that the value
seems relatively small and

39
00:01:51,370 --> 00:01:52,280
you kind of keep going.

40
00:01:52,280 --> 00:01:55,390
And you have to visit this often,
very often actually,

41
00:01:55,390 --> 00:01:58,300
to back up the information to
tell you sort of what the value

42
00:01:58,300 --> 00:02:01,110
of the states are, what the Q
values of state-action pairs are.

43
00:02:01,110 --> 00:02:06,580
And that's fine,
that's how we learn in MDPs.

44
00:02:06,580 --> 00:02:11,410
But, because I have this abstract
action, I have this go to doorway,

45
00:02:11,410 --> 00:02:16,470
I can actually from here, from this
particular state at the doorway,

46
00:02:16,470 --> 00:02:19,870
back up information all the way to here.

47
00:02:19,870 --> 00:02:24,510
Wherever it is I executed that
particular action in sort of one step.

48
00:02:24,510 --> 00:02:29,000
So I learned a lot about the value
of being in this state immediately

49
00:02:29,000 --> 00:02:30,480
from having taken that and got here.

50
00:02:30,480 --> 00:02:35,820
So soon as information from my little
plus one box here gets me to here,

51
00:02:35,820 --> 00:02:38,570
I can back that information
all the way up to where

52
00:02:38,570 --> 00:02:41,190
initially executed the go to doorway x.

53
00:02:41,190 --> 00:02:43,360
And similarly,
now that I've got information here,

54
00:02:43,360 --> 00:02:46,200
I can back it all the way up to
the value of being in this state.

55
00:02:46,200 --> 00:02:49,380
And so I can back up information
in value much more quickly

56
00:02:49,380 --> 00:02:53,180
without having to back it up sort
of one little state at a time.

57
00:02:53,180 --> 00:02:55,660
So there's a lot of advantages
here sort of computational and

58
00:02:55,660 --> 00:02:58,830
otherwise that will hopefully
allow us to learn faster.

59
00:02:58,830 --> 00:03:01,700
>> Cool, and I think that's
helping me understand why it's

60
00:03:01,700 --> 00:03:02,750
temporal abstraction, right.

61
00:03:02,750 --> 00:03:07,210
So state obstruction is treating a whole
bunch of states sort of equivalently.

62
00:03:07,210 --> 00:03:10,823
This is actually treating a whole bunch
of time steps equivalently, right,

63
00:03:10,823 --> 00:03:12,580
that can just kind of align over them.

64
00:03:12,580 --> 00:03:13,690
>> All right, and

65
00:03:13,690 --> 00:03:17,290
now you'll notice that it will have
the side effect of allowing us to treat

66
00:03:17,290 --> 00:03:23,050
a bunch of states similarly, because
we know that one way of thinking about

67
00:03:23,050 --> 00:03:27,500
similarity between states is how their
features are similar to one another.

68
00:03:27,500 --> 00:03:29,100
That's what you talked about.

69
00:03:29,100 --> 00:03:33,250
Another way to think about similarity
among states is to think about whether

70
00:03:33,250 --> 00:03:35,350
you should take the same
action when you're in them.

71
00:03:35,350 --> 00:03:40,000
And so every single state in this
room is the same in the sense that

72
00:03:40,000 --> 00:03:42,540
the optimal action is the same,
go to this doorway.
