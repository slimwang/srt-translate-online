1
00:00:00,570 --> 00:00:04,080
Dynamic memory allocation is another important service that

2
00:00:04,080 --> 00:00:06,990
is part of memory management. It's important, once

3
00:00:06,990 --> 00:00:10,870
again, to make sure that memory allocation scales

4
00:00:10,870 --> 00:00:13,260
with the size of the system. And in order

5
00:00:13,260 --> 00:00:15,750
to do that, one possibility is to take

6
00:00:15,750 --> 00:00:19,080
the heap space of the process and break it

7
00:00:19,080 --> 00:00:21,150
up. So this is the logical address space

8
00:00:21,150 --> 00:00:25,710
of a multi-threaded application. And in the logical address

9
00:00:25,710 --> 00:00:28,600
space, everything is shared. But what we're going to do

10
00:00:28,600 --> 00:00:30,920
is we're going to take this heap portion of the

11
00:00:30,920 --> 00:00:34,000
address space and break it up into the portion

12
00:00:34,000 --> 00:00:37,220
of physical memories that are associated with the nodes on

13
00:00:37,220 --> 00:00:40,530
which these threads are executing. Suppose the mapping of

14
00:00:40,530 --> 00:00:43,950
the threads of this particular application is such that

15
00:00:43,950 --> 00:00:47,920
T1 and T2 are executing on N1. And T3

16
00:00:47,920 --> 00:00:51,280
and T4 are executing N2, and it's a [INAUDIBLE] machine,

17
00:00:51,280 --> 00:00:53,250
so there's a physical memory that is local to this

18
00:00:53,250 --> 00:00:57,020
node N1. And therefore what I'm going to do is dynamic

19
00:00:57,020 --> 00:01:00,430
memory allocation requests. If it is centralized, it'll be a

20
00:01:00,430 --> 00:01:04,209
huge bottleneck. Instead, we're going to break up the heap and

21
00:01:04,209 --> 00:01:06,970
say that this portion of the heap fits in the

22
00:01:06,970 --> 00:01:10,270
physical memory that is close to N1. This portion of

23
00:01:10,270 --> 00:01:12,480
the heap fits in the physical memory that is close

24
00:01:12,480 --> 00:01:16,920
to N2, so dynamic memory allocation requests from these threads,

25
00:01:16,920 --> 00:01:21,815
satisfied from here. From these threads, satisfied from here. That allows for

26
00:01:21,815 --> 00:01:25,910
scale-able implementation of dynamic memory allocation.

27
00:01:25,910 --> 00:01:27,490
The other side benefit that you

28
00:01:27,490 --> 00:01:32,500
get by breaking up the heap space into these distinct physical memories

29
00:01:32,500 --> 00:01:37,590
that it can avoid full shading across nodes of the paddling machine.
