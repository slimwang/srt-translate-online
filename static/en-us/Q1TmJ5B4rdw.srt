1
00:00:00,140 --> 00:00:04,059
So, we need one more thing to
finish mean shift tracking.

2
00:00:04,059 --> 00:00:05,400
You remember before,

3
00:00:05,400 --> 00:00:09,380
when I was showing you the mean shift
example we were plopping down a circle,

4
00:00:09,380 --> 00:00:11,910
right, and I said we'll worry
later about the shape of that?

5
00:00:11,910 --> 00:00:16,140
Well that circle can be thought
of as a uniform kernel.

6
00:00:16,140 --> 00:00:20,200
What I mean by uniform is that its
height is the same everywhere around and

7
00:00:20,200 --> 00:00:24,210
it happens to have a circular shape and
it would be written like that.

8
00:00:24,210 --> 00:00:27,650
That's not such a great kernel, what
do you think a better kernel might be?

9
00:00:27,650 --> 00:00:32,299
Well, instead of using uniform kernel
we could use something that is

10
00:00:32,299 --> 00:00:35,980
differentiable, we'll use that in
a minute, isotropic, all that means is

11
00:00:35,980 --> 00:00:41,310
that it's the same in every direction,
monotonically decreasing kernel and

12
00:00:41,310 --> 00:00:43,560
there's a certain convexity property
we're not going to worry about that.

13
00:00:43,560 --> 00:00:46,200
So, so what's our favorite

14
00:00:46,200 --> 00:00:50,440
differential isotropic monotonically
decreasing always positive kernel?

15
00:00:50,440 --> 00:00:52,180
Yes, it's the Gaussian.

16
00:00:52,180 --> 00:00:55,440
Okay.
So here it's written just as a constant

17
00:00:55,440 --> 00:00:58,990
proportional to a fall off by
the square of the distance, okay?

18
00:00:58,990 --> 00:01:01,120
You can also have a scale factor, right?

19
00:01:01,120 --> 00:01:04,280
So if you wanted you could talk
about like, the sigma, sort of the,

20
00:01:04,280 --> 00:01:06,190
the scale of the kernel.

21
00:01:06,190 --> 00:01:11,380
What's really cool about this is that,
unlike the uniform kernel, which goes

22
00:01:11,380 --> 00:01:16,960
straight and then falls off on the edge,
this is differentiable, okay?

23
00:01:16,960 --> 00:01:20,110
You can know how much it's changing, and

24
00:01:20,110 --> 00:01:22,940
it also means that it goes
down to zero at the edges.

25
00:01:22,940 --> 00:01:29,360
So as you slide that kernel along a new
point, it just has a very, very small

26
00:01:29,360 --> 00:01:32,320
weight, in fact, an infinitesimally
small weight, and then it grows.

27
00:01:33,380 --> 00:01:38,070
Likewise, points that are right near the
top, their weight doesn't change very

28
00:01:38,070 --> 00:01:41,920
much, right, because as you slide it
along, the weight stays about the same.

29
00:01:41,920 --> 00:01:44,410
The points that are going to have
the greatest value are the ones that

30
00:01:44,410 --> 00:01:45,470
are along the slope.

31
00:01:46,590 --> 00:01:50,890
What that means is,
you can know how your function

32
00:01:50,890 --> 00:01:54,940
changes as you move,
that is your overall function.

33
00:01:54,940 --> 00:02:00,306
So, your coefficient for example,
and what you can do is, you can use

34
00:02:00,306 --> 00:02:05,776
this gradient to essentially hill climb
up your similarity function, right?

35
00:02:05,776 --> 00:02:09,749
So you can, by computing this, you
don't have to sort of blindly search,

36
00:02:09,749 --> 00:02:13,044
you actually follow that gradient and
get to a local maximum.

37
00:02:13,044 --> 00:02:14,494
All right?

38
00:02:14,494 --> 00:02:17,945
And that was the basis
of mean shift tracking.

39
00:02:17,945 --> 00:02:22,892
So now, going back to our, our previous
example here of the ping pong, right,

40
00:02:22,892 --> 00:02:25,495
we start with the, the current frame.

41
00:02:25,495 --> 00:02:26,575
We want to search, but

42
00:02:26,575 --> 00:02:31,035
now our search can actually climb
to the maximum of this function,

43
00:02:31,035 --> 00:02:34,467
using that gradient information,
and that's mean shift tracking.
