1
00:00:49,210 --> 00:00:52,710
>> Let us build on David's answers, let us suppose that the robot goes to

2
00:00:52,710 --> 00:00:56,870
the kitchen and finds this pail in the kitchen. It looks the pail and

3
00:00:56,870 --> 00:01:01,160
decides that this pail meets this definition of a cup, denoted here by the solid

4
00:01:01,160 --> 00:01:06,130
circle. The robot brings water to you in this pail. You look at the pail, and

5
00:01:06,130 --> 00:01:10,750
you say to the robot, no robot, this is not a cup. At this point you would

6
00:01:10,750 --> 00:01:15,810
expect a robot to learn from its failure. Cognitive agents do a lot of learing

7
00:01:15,810 --> 00:01:20,990
from failures. Failures are opportunities for learning. We would expect robots,

8
00:01:20,990 --> 00:01:24,480
and intelligent agents more generally, to learn from their failures as well.

9
00:01:24,480 --> 00:01:29,540
How then may a robot learn form the failure of considering this fail as a cup.

10
00:01:29,540 --> 00:01:32,940
Note that the problem is not limited to this particular fail.

11
00:01:32,940 --> 00:01:36,480
We can take a different example connecting with this particular cup.

12
00:01:36,480 --> 00:01:40,290
Imagine that the definition of cup included a statement that it must have

13
00:01:40,290 --> 00:01:45,350
a handle. In which case, the robot may not recognize that this is a cup.

14
00:01:45,350 --> 00:01:48,310
Later on you may teach the robot, this in fact is a good example for

15
00:01:48,310 --> 00:01:52,580
cup, because it's liftable. In that case, the robot will want to understand from

16
00:01:52,580 --> 00:01:57,210
that failure. It will want to understand why did it not consider it to be a cup?

17
00:01:57,210 --> 00:01:59,190
It should have considered it to be a cup.

18
00:01:59,190 --> 00:02:04,200
So the problem is not just about successes that turned out to be failures. But

19
00:02:04,200 --> 00:02:06,710
also about failures that should have been successes.
