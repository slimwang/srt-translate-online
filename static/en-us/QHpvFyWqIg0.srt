1
00:00:00,203 --> 00:00:03,468
One of the questions I ask the students in the classes that I teach is,

2
00:00:03,468 --> 00:00:05,955
"What are you going to do with 100 times more compute?"

3
00:00:05,955 --> 00:00:07,895
And sometimes that's a really hard question for them.

4
00:00:07,895 --> 00:00:13,866
There's a lot of head scratching both in terms of what can we do with a super computer that's 100 times more powerful

5
00:00:13,866 --> 00:00:16,973
and what can you do with something on your desk or in your pocket?

6
00:00:16,973 --> 00:00:22,816
-Where do you see us going in this direction? 
-Yeah, well I I have an insatiable appetite for FLOPs.

7
00:00:22,816 --> 00:00:27,847
I would have no trouble using 100 or even 1,000 or even 10,000 times more compute.

8
00:00:27,847 --> 00:00:31,031
A lot of what I do is designing computers,

9
00:00:31,031 --> 00:00:35,200
and a lot of that involves prototyping and simulation new computer designs.

10
00:00:35,200 --> 00:00:37,914
I'm always frustrated about how those simulations run.

11
00:00:37,914 --> 00:00:43,042
So of I could run RTL simulations of a new computer 100 times faster,

12
00:00:43,042 --> 00:00:47,745
it would enable me to be much more productive in trying out new ideas for computer design.

13
00:00:47,745 --> 00:00:48,945
Same for circuit simulations.

14
00:00:48,945 --> 00:00:51,885
I spend a lot of time waiting for circuit simulation to converge.

15
00:00:51,885 --> 00:00:57,519
If I could run it 100 times faster, I could not just run one simulation but run whole parameter sweeps at once

16
00:00:57,519 --> 00:01:02,241
and do optimizations the same time I'm simulating.

17
00:01:02,241 --> 00:01:04,962
Another thing is also you look at the computers in your car.

18
00:01:04,962 --> 00:01:08,520
I mean our Tegra processors are actually designed into lots of different automobiles,

19
00:01:08,520 --> 00:01:13,015
including the Tesla Model S, the Motor Trend Car of the Year,

20
00:01:13,015 --> 00:01:21,247
but also Audis and BMWs and all sorts of Fords have Tegras in them.

21
00:01:21,247 --> 00:01:25,818
And the applications people are starting to use for these mobile processors in cars

22
00:01:25,818 --> 00:01:30,221
involve having lots of computer vision to look at what people inside the car are doing,

23
00:01:30,221 --> 00:01:31,888
look at what people outside of the car are doing.

24
00:01:31,888 --> 00:01:37,013
And in many ways it makes your cars much safer by having the car aware of what's going on around it.

25
00:01:37,013 --> 00:01:41,264
It can in many ways compensate for the driver not being completely alert

26
00:01:41,264 --> 00:01:43,968
or perhaps texting or doing something they shouldn't be doing.

27
00:01:43,968 --> 00:01:47,871
And in mobile devices I think there are a lot of compelling applications

28
00:01:47,871 --> 00:01:51,731
in both computational photography and augmented reality.

29
00:01:51,731 --> 00:01:56,216
If your mobile device is constantly aware of what's around you, it can be informing you.

30
00:01:56,216 --> 00:01:57,738
Oh, I think you're hungry.

31
00:01:57,738 --> 00:02:01,186
Here's a place that has gyros that I know you like

32
00:02:01,186 --> 00:02:07,746
because I have your profile of your likes and dislikes. Maybe you should stop for lunch.

33
00:02:07,746 --> 00:02:10,461
Or a block away is this guy who you really don't like.

34
00:02:10,461 --> 00:02:13,998
Maybe you should turn right at this corner and avoid running into him.

35
00:02:13,998 --> 00:02:19,504
In many ways, I think it sort of evolved to having your computing devices becoming your personal assistant.

36
00:02:19,504 --> 00:02:22,674
I always liked Jeeves in the Iron Man movies.

37
00:02:22,674 --> 00:02:25,945
I would like to have a device I can kind of talk to that is aware

38
00:02:25,945 --> 00:02:30,384
of the environment around me and can be basically a brain amplifier for me.

39
00:02:30,384 --> 00:02:33,659
It can sort of remember things that I forget

40
00:02:33,659 --> 00:02:39,691
and tell me about things in my environment and basically assist me in going through my day,

41
00:02:39,691 --> 00:02:42,340
both on professional and personal bases.

42
00:02:42,340 --> 00:02:46,648
So one of the goals of the supercomputer industry is to get up to—the term they use is exascale

43
00:02:46,648 --> 00:02:50,315
that they'd like to do 10 ^ 18 FLOPs per second.

44
00:02:50,315 --> 00:02:55,178
Certainly, Nvidia is going to be interested in being in those computers. What are we going to use that for?

45
00:02:55,178 --> 00:02:58,588
Well, I think first of all, there's nothing magical about an exascale.

46
00:02:58,588 --> 00:03:00,354
It's like, you know, when we first made

47
00:03:00,354 --> 00:03:02,888
petascale machines, which is just a few years ago,

48
00:03:02,888 --> 00:03:07,285
it wasn't like breaking the sound barrier or anything really qualitatively changed,

49
00:03:07,285 --> 00:03:10,991
but enabled better science and there's always—

50
00:03:10,991 --> 00:03:14,724
You look at sort of the fidelity of simulations we're able to do today

51
00:03:14,724 --> 00:03:18,675
to, say, simulate a more efficient engine for automobiles to improve gas mileage,

52
00:03:18,675 --> 00:03:23,472
and we're making lots of approximations to fit them on the supercomputers we have today.

53
00:03:23,472 --> 00:03:26,939
As we can get to higher fidelity by resolving grids finer

54
00:03:26,939 --> 00:03:29,877
and modeling a bunch of effects like turbulence more directly

55
00:03:29,877 --> 00:03:33,855
rather than using macro models to model them, we'll get more accurate simulations.

56
00:03:33,855 --> 00:03:39,860
And that will enable a better understanding of combustion in some of the you biotech applications

57
00:03:39,860 --> 00:03:45,051
of how proteins fold, various other climate—

58
00:03:45,051 --> 00:03:46,786
-Climate modeling.
-Sure.

59
00:03:46,786 --> 00:03:48,260
Climate evolves.

60
00:03:48,260 --> 00:03:52,829
Basically as we get better computing capacity—

61
00:03:52,829 --> 00:03:56,275
and it's not you're reaching magic exascale and wonderful things happen,

62
00:03:56,275 --> 00:03:59,034
but at every step along the way, we get better science,

63
00:03:59,034 --> 00:04:01,572
we are able to design better products.

64
00:04:01,572 --> 00:04:05,059
And computing is a big driver of both scientific understanding

65
00:04:05,059 --> 00:04:08,241
and economic progress across across the board.

66
00:04:08,241 --> 00:04:11,377
And I think it's very important that we maintain that steady march forward,

67
00:04:11,377 --> 00:04:14,347
and exascale is just one milestone along that march.

68
00:04:14,347 --> 00:04:21,091
And my understanding is that power is really an enormously crucial thing for them to get right

69
00:04:21,091 --> 00:04:24,058
to be able to enable the exascale that we don't want machines

70
00:04:24,058 --> 00:04:27,204
that are going to cost $2 million a month just to plug in.
-Right.

71
00:04:27,204 --> 00:04:28,368
It's really an economic argument.

72
00:04:28,368 --> 00:04:31,334
I mean if you really wanted an exascale machine today, you could build one.

73
00:04:31,334 --> 00:04:35,345
You just have to write a really big check and locate it right next to the nuclear power plant,

74
00:04:35,345 --> 00:04:38,008
the entire output of which it will consume.

75
00:04:38,008 --> 00:04:40,783
But I think if there was some application that was so compelling

76
00:04:40,783 --> 00:04:46,383
they were willing to really write the multi-billion dollar check required to do that, you would do it.

77
00:04:46,383 --> 00:04:50,016
I think that the real question of exascale is an economical exascale,

78
00:04:50,016 --> 00:04:56,959
and because on total cost of ownership the power bill is a tremendous fraction.

79
00:04:56,959 --> 00:04:59,762
So it's not actually an economical exascale machine

80
00:04:59,762 --> 00:05:02,604
unless you can do it for reasonable power level,

81
00:05:02,604 --> 00:05:06,908
and the number that's been thrown out is 20 megawatts.

82
00:05:06,908 --> 00:05:07,943
So that's $20 million a year.

83
00:05:07,943 --> 00:05:12,871
Yeah, $20 million a year power bill if you're paying roughly $10 a kilowatt hour.

84
00:05:12,871 --> 00:05:16,529
In fact, the bill actually winds up usually being a little bit higher than that

85
00:05:16,529 --> 00:05:22,916
because the cost of provisioning energy amortized over, say, a 30-year lifetime of the facility,

86
00:05:22,916 --> 00:05:27,565
usually is about equal to the annual bill for the energy.

87
00:05:27,565 --> 00:05:29,401
There is also something called the PUE,

88
00:05:29,401 --> 00:05:31,650
which is basically the efficiency of providing the energy.

89
00:05:31,650 --> 00:05:37,429
Even for a very good installation today maybe on the order of 1.1 to 1.2.

90
00:05:37,429 --> 00:05:43,238
So you pay another, say, 20% to run the air conditioners and fans and things like that in the facility,

91
00:05:43,238 --> 00:05:47,508
and basically energy you're consuming isn't being consumed by the computer.

92
00:05:47,508 --> 00:05:52,210
But it's a big challenge for us to get from, say, Sandy Bridge today—

93
00:05:52,210 --> 00:05:58,572
that's 1.5 nanojoules per instruction—to if you wanted to do exa instructions per second,

94
00:05:58,572 --> 00:06:02,157
to do an exa FLOP you might have to do more than an exa instruction per second.

95
00:06:02,157 --> 00:06:05,292
But even if you take that as a thing at 20 megawatts,

96
00:06:05,292 --> 00:06:07,527
that's 20 picojoules per instruction.

97
00:06:07,527 --> 00:06:09,852
And that's not just the processor; that's everything.

98
00:06:09,852 --> 00:06:14,558
That's the memory system, that's the network, that's the io storage system.

99
00:06:14,558 --> 00:06:16,935
It's the whole ball of wax that to do it.

100
00:06:16,935 --> 00:06:20,964
So you mainly get 10 picojoules per instruction to actually use in the processor.

101
00:06:20,964 --> 00:06:24,373
And so even in Nvidia it's not quite close enough to that.

102
00:06:24,373 --> 00:06:27,100
Yeah, well compared to Sandy Bridge, that's a factor of 150 down,

103
00:06:27,100 --> 00:06:29,804
and process isn't going to help you much.

104
00:06:29,804 --> 00:06:32,740
So that's why conventional CPUs are not going to get there.

105
00:06:32,740 --> 00:06:35,328
It's going to require a hybrid multi-core approach

106
00:06:35,328 --> 00:06:40,961
with most of the work being done in a GPU like throughput processor to get there.

107
00:06:40,961 --> 00:06:43,724
But even we have a ways to go.

108
00:06:43,724 --> 00:06:48,812
We're probably close to over-magnitude, and we might get a factor of three from process.

109
00:06:48,812 --> 00:06:52,434
We need to be very clever to come up with the other factor of 3 or 4 that we need.

110
00:06:52,434 --> 00:06:55,682
-Titan does have CPUs in it, yes?
-That's correct.

111
00:06:55,682 --> 00:06:58,667
So is there a vision where that won't even be the case?

112
00:06:58,667 --> 00:07:01,424
No I think there are always pieces of the code

113
00:07:01,424 --> 00:07:06,460
where you have a critical path, you have a piece of single thread code that you need to run very quickly.

114
00:07:06,460 --> 00:07:10,340
And so you always need a latency optimized processor around to do that,

115
00:07:10,340 --> 00:07:16,845
but most of the work it's one of these things, it's kind of like a cache memory, where most of your acesses

116
00:07:16,845 --> 00:07:20,843
are to this little memory that runs really fast but you still need the capacity

117
00:07:20,843 --> 00:07:22,885
of the big memory sitting behind it, right?

118
00:07:22,885 --> 00:07:25,912
And so it's, it's the same thing on throughput versus latency.

119
00:07:25,912 --> 00:07:28,420
Most of your work is done in the throughput processors,

120
00:07:28,420 --> 00:07:32,254
but when you do have a latency critical thing, you run it in on the latency optimized processors.

121
00:07:32,254 --> 00:07:36,258
And so you wind up getting the critical path performance of the CPU

122
00:07:36,258 --> 00:07:39,234
with the bulk of the energy consumption of the GPU.

123
00:07:39,234 --> 00:07:42,164
-And the bulk of the FLOPs and Titan is certainly going to the GPU's. 
-Right.

124
00:07:42,164 --> 00:07:45,000
The bulk of the FLOPs will be in the GPU's.
