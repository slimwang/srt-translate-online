1
00:00:00,200 --> 00:00:05,460
We will discuss later some of the implications on implementation that

2
00:00:05,460 --> 00:00:09,320
are there because of the interactions between the user-level threads and

3
00:00:09,320 --> 00:00:11,130
the kernel-level threads.

4
00:00:11,130 --> 00:00:14,480
But for now, you need to understand that there are different levels at

5
00:00:14,480 --> 00:00:19,660
which multi-threading is supported, at the entire system or within a process.

6
00:00:19,660 --> 00:00:24,620
And that each level affects the scope of the thread management system.

7
00:00:24,620 --> 00:00:28,160
At the kernel level we have system-wide thread

8
00:00:28,160 --> 00:00:33,150
management that's supported by the operating system-level thread managers.

9
00:00:33,150 --> 00:00:34,160
What this means is,

10
00:00:34,160 --> 00:00:39,520
that the operating system thread managers will look at the entire platform we're

11
00:00:39,520 --> 00:00:44,560
making decisions, as to how to allocate resources to the threads.

12
00:00:44,560 --> 00:00:46,350
This is the system scope.

13
00:00:46,350 --> 00:00:50,990
On the other end at user level, a user-level thread library that's linked to

14
00:00:50,990 --> 00:00:57,030
the process manages all of the threads that are within that single process only.

15
00:00:57,030 --> 00:00:59,800
So the management scope is process wide.

16
00:00:59,800 --> 00:01:04,610
Different processes will be managed by different instances of the same library.

17
00:01:04,610 --> 00:01:09,400
Or even different processes may link entirely different user-level libraries.

18
00:01:09,400 --> 00:01:11,890
To illustrate the effects of having a different scope,

19
00:01:11,890 --> 00:01:14,540
let's take a look at the following situation.

20
00:01:14,540 --> 00:01:17,848
Let's say the web server has twice as many threads as the database.

21
00:01:17,848 --> 00:01:21,990
If the user-level threads have a process scope,

22
00:01:21,990 --> 00:01:24,360
the operating system doesn't see all of them.

23
00:01:24,360 --> 00:01:29,360
So at the operating system level, the available resources will be

24
00:01:29,360 --> 00:01:33,720
maybe managed 50/50 among the two different processes.

25
00:01:33,720 --> 00:01:36,480
That means that both the web server and the database will be

26
00:01:36,480 --> 00:01:41,360
allocated equal share of the the kernel level threads, so two each.

27
00:01:41,360 --> 00:01:46,770
And then the OS level scheduler will manage these threads by

28
00:01:46,770 --> 00:01:49,840
splitting the underlying CPUs amongst them.

29
00:01:49,840 --> 00:01:51,590
The end result of that however,

30
00:01:51,590 --> 00:01:56,450
is that the webserver's user level threads, will have half of

31
00:01:56,450 --> 00:02:00,990
the amount of the CPU cycles that's allocated to the database threads.

32
00:02:00,990 --> 00:02:04,110
Now if we have a System Scope, the user-level threads all of them,

33
00:02:04,110 --> 00:02:06,560
will be visible at the kernel level.

34
00:02:06,560 --> 00:02:10,370
So the kernel will allocate to every one of its kernel-level threads.

35
00:02:10,370 --> 00:02:14,030
And therefore, to every one of the user-level threads across the two

36
00:02:14,030 --> 00:02:17,720
applications, in equal portion of the CPU.

37
00:02:17,720 --> 00:02:21,050
If that happens to be the policy that the kernel implements.

38
00:02:21,050 --> 00:02:24,750
As a result, if we have a situation in which one process has

39
00:02:24,750 --> 00:02:29,100
more user-level threads than the other, this process will end up

40
00:02:29,100 --> 00:02:33,830
receiving a larger share of the underlying physical resources.

41
00:02:33,830 --> 00:02:37,670
Since very one of its user level threads will get equal share of

42
00:02:37,670 --> 00:02:41,350
the physical resources as the user level threads in the other process.
