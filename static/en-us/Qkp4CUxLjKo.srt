1
00:00:00,660 --> 00:00:03,860
Now that we understand abduction, and now that we know the diagnosis is

2
00:00:03,860 --> 00:00:08,470
an instance of abduction, let us ask ourselves, how does this understanding help

3
00:00:08,470 --> 00:00:13,950
us in choosing hypotheses? So the first principle for choosing a hypothesis is

4
00:00:13,950 --> 00:00:18,775
explanatory coverage. A hypotheses must cover as much of the data as possible.

5
00:00:18,775 --> 00:00:23,880
Here's an example, hypotheses H3 explain data items D1 through D8.

6
00:00:25,160 --> 00:00:28,860
Hypothesis H7 explains data item D5 to D9.

7
00:00:30,000 --> 00:00:34,482
Assuming that all of these data elements are equally important or

8
00:00:34,482 --> 00:00:39,127
equally salient, we may prefer H3 over H7 because it explains for

9
00:00:39,127 --> 00:00:42,103
of the data than does H7. The second principle for

10
00:00:42,103 --> 00:00:46,550
choosing between competing hypotheses is called the principle of Parsimony.

11
00:00:46,550 --> 00:00:51,470
All things being equal, we want to pick the simplest explanation for the data.

12
00:00:51,470 --> 00:00:56,760
So consider the following scenario. H2 explains data elements D1 to D3.

13
00:00:58,380 --> 00:01:03,570
H4 explains data elements D1 through D8. H6 explains data

14
00:01:03,570 --> 00:01:09,690
elements D4 to D6 and H8 explains data elements D7 to D9.

15
00:01:09,690 --> 00:01:15,390
Now if you went by the criteria of explanatory coverage, then we might pick H2,

16
00:01:15,390 --> 00:01:20,540
plus H6, plus H8, because the three of them combined, explain more than just H4.

17
00:01:21,866 --> 00:01:26,010
However, the criteria of Parsimony would suggest if you pick H4,

18
00:01:26,010 --> 00:01:29,990
because H4 alone, explains almost all the data, and

19
00:01:29,990 --> 00:01:34,280
we don't need the other three hypothesis. In general this is a balancing act

20
00:01:34,280 --> 00:01:38,550
between these two principles. We want to both maximize the coverage, and

21
00:01:38,550 --> 00:01:44,120
maximize the parsimony. Based on this particular example, we may go with H4 and

22
00:01:44,120 --> 00:01:48,430
H8. The two together explain all the data and in addition,

23
00:01:48,430 --> 00:01:54,050
the set of these two hypotheses is smaller than these set of hypotheses H2,

24
00:01:54,050 --> 00:01:59,010
H6, and H8. The [UNKNOWN] criteria for choosing between competing hypotheses is

25
00:01:59,010 --> 00:02:02,810
that we want to pick those hypotheses in which we have more confidence.

26
00:02:02,810 --> 00:02:06,330
Some hypotheses are more likely than others. You may have more confidence in

27
00:02:06,330 --> 00:02:12,080
some hypotheses than in others. As an example, in this particular scenario,

28
00:02:12,080 --> 00:02:16,670
H3 may explain data items D1 to D8 and H5 may explain more data

29
00:02:16,670 --> 00:02:22,850
elements from D1 to D9. So H5 also explains D9 that H3 doesn't.

30
00:02:22,850 --> 00:02:27,660
However, we may have more confidence in H3, and so we may pick H3 instead of H5.

31
00:02:27,660 --> 00:02:32,540
Once again this is a balancing act between these three criteria for

32
00:02:32,540 --> 00:02:37,370
choosing between competing diagnostic hypotheses. A quick point to note here,

33
00:02:37,370 --> 00:02:41,310
these three criteria are useful for choosing between competing hypotheses even

34
00:02:41,310 --> 00:02:44,490
if the task is not diagnosis. The same problem occurs for

35
00:02:44,490 --> 00:02:48,620
example in intelligence analysis. Imagine that you have some data that needs to

36
00:02:48,620 --> 00:02:52,295
be explained and your competing hypothesis for explaining that particular data,

37
00:02:52,295 --> 00:02:56,920
well, you may pick between the competing hypothesis based on this criteria.

38
00:02:56,920 --> 00:03:01,060
All of the task is not a diagnostic task. These three criteria are useful for

39
00:03:01,060 --> 00:03:06,536
explanation. Diagnosis simply happens to be an example of this [UNKNOWN] task.
