1
00:00:00,100 --> 00:00:02,310
So, as I mentioned in
sort of a conventional or

2
00:00:02,310 --> 00:00:04,180
traditional tracking approach,

3
00:00:04,180 --> 00:00:08,210
what you do is you build a model
before something starts moving, right?

4
00:00:08,210 --> 00:00:09,690
So you might cut out a patch,

5
00:00:09,690 --> 00:00:13,938
find a contour,
some method of describing the object.

6
00:00:13,938 --> 00:00:15,570
And then you do one of,

7
00:00:15,570 --> 00:00:18,950
remember we talked about optic flow
where you essentially connect the dots.

8
00:00:18,950 --> 00:00:22,410
You do patch tracking with particles,
which if you're in the OMS class,

9
00:00:22,410 --> 00:00:23,870
you did as a problem set.

10
00:00:23,870 --> 00:00:25,980
Or you might even solve some
interesting, complicated,

11
00:00:25,980 --> 00:00:27,670
optimization problem.

12
00:00:27,670 --> 00:00:31,760
And then you somehow try to
incorporate some invariance.

13
00:00:31,760 --> 00:00:36,190
So you might use edges, because you
know that those don't change a lot

14
00:00:36,190 --> 00:00:40,090
depending upon how the illumination
changes, let's say, all right?

15
00:00:40,090 --> 00:00:44,010
But the problem is, if I'm going to
track an object over an extended period

16
00:00:44,010 --> 00:00:46,920
of time, the object and
the environment tend to change.

17
00:00:46,920 --> 00:00:50,610
And what I would like to do is I would
like to not just track the object but

18
00:00:50,610 --> 00:00:52,560
in some sense track the changes,

19
00:00:52,560 --> 00:00:56,630
incorporate the changes
slowly as the object moves.

20
00:00:56,630 --> 00:00:59,740
So some work that we're
going to talk about and

21
00:00:59,740 --> 00:01:02,410
these are some slides taken from,
from Yang.

22
00:01:02,410 --> 00:01:05,550
Who showed a piece,
who did a piece of work that I'll talk

23
00:01:05,550 --> 00:01:09,690
about along with Ross and Edal they
took some inspiration from two places.

24
00:01:09,690 --> 00:01:14,060
First of all Michael Black and
Allen Jepson way back in 1996 did

25
00:01:14,060 --> 00:01:18,230
something called Eigen tracking, so
you guys know all about Eigen faces.

26
00:01:18,230 --> 00:01:22,150
Well, Eigen tracking was the same
idea but the idea is so, here we have

27
00:01:22,150 --> 00:01:28,350
Coca Cola cans and here we have these
Eigen images, up this one's a 7 Up can.

28
00:01:28,350 --> 00:01:29,570
How did that get in there?

29
00:01:29,570 --> 00:01:33,410
Okay, we have Eigen images of
these different objects and

30
00:01:33,410 --> 00:01:38,410
the idea was we're going to track
this thing by finding the places

31
00:01:38,410 --> 00:01:42,750
we can represent well by
using those Eigen images.

32
00:01:42,750 --> 00:01:46,530
But one of the cool things they did was,
they said, you know ,remember what

33
00:01:46,530 --> 00:01:51,130
didn't work so well in eigen analysis,
the eigen face, was the alignment?

34
00:01:51,130 --> 00:01:53,160
Things had to be aligned perfectly?

35
00:01:53,160 --> 00:01:58,100
Well, suppose we decompose
the problem into the geometric part.

36
00:01:58,100 --> 00:02:01,140
That is, how is my object moving,
maybe rotating,

37
00:02:01,140 --> 00:02:04,590
scaling, to what does it look like.

38
00:02:04,590 --> 00:02:06,230
Now we've already seen this, right?

39
00:02:06,230 --> 00:02:08,820
When we were doing the good
features to track, we talked a bit.

40
00:02:08,820 --> 00:02:12,150
In fact, there was an image of of
a speed limit sign getting bigger and

41
00:02:12,150 --> 00:02:13,310
bigger and it was being tracked and

42
00:02:13,310 --> 00:02:17,460
the idea was it's the same image patch,
it just deforms.

43
00:02:17,460 --> 00:02:20,010
Well, there they were using
a single image patch.

44
00:02:20,010 --> 00:02:25,360
In the eigen tracking, the idea was that
we're going to look for a deformation.

45
00:02:25,360 --> 00:02:27,970
So could be affine,
could be otherwise, where we got,

46
00:02:27,970 --> 00:02:32,120
where we have remote translation,
rotation, scaling maybe even shearing.

47
00:02:32,120 --> 00:02:34,770
But now instead of just
taking a single patch,

48
00:02:34,770 --> 00:02:39,400
we actually have a set of eigen
vectors that describe the coke can.

49
00:02:39,400 --> 00:02:43,830
So for example, maybe if I rotate
the coke can a little bit or maybe some,

50
00:02:43,830 --> 00:02:47,850
some other change, I could represent
all those different appearances.

51
00:02:47,850 --> 00:02:52,190
When they did it, it was done in sort of
a non linear optimization way and they,

52
00:02:52,190 --> 00:02:54,370
but more importantly they
took a fixed basis set.

53
00:02:54,370 --> 00:02:57,530
So it took a whole bunch of images
of coke cans, created a basis set,

54
00:02:57,530 --> 00:03:00,550
said that's our Coca Cola basis set.

55
00:03:00,550 --> 00:03:02,500
So we're going to need to do
some improvement on that.

56
00:03:02,500 --> 00:03:05,440
The other inspiration here is also
something that we've covered,

57
00:03:05,440 --> 00:03:07,490
which was particle filtering.

58
00:03:07,490 --> 00:03:11,820
Remember Isard and Blake,
they instead of having a single

59
00:03:11,820 --> 00:03:14,050
proposal the idea is that you'd
have a bunch of particles and

60
00:03:14,050 --> 00:03:17,580
each particle would represent
a possible location.

61
00:03:17,580 --> 00:03:21,510
And that allowed us to handle sort
of non parametric densities, right?

62
00:03:21,510 --> 00:03:23,320
Use the sampling based approach and

63
00:03:23,320 --> 00:03:25,330
there what they were using
were like contours, right?

64
00:03:25,330 --> 00:03:27,430
And they would propagate this over time,

65
00:03:27,430 --> 00:03:29,170
they would,
they would move the particles forward.
