1
00:00:00,230 --> 00:00:03,030
I'm going to suggest three different algorithms to you.

2
00:00:03,030 --> 00:00:06,850
These are all examples of supervised classification algorithms and

3
00:00:06,850 --> 00:00:08,360
you should pick one.

4
00:00:08,360 --> 00:00:15,970
Your choices are k nearest neighbors, adaboost and random forest.

5
00:00:15,970 --> 00:00:17,640
You don't know what any of these are right now,

6
00:00:17,640 --> 00:00:19,349
of course, but that's sort of the point.

7
00:00:20,740 --> 00:00:23,660
Here's a tiny bit of information on each one to maybe help you

8
00:00:23,660 --> 00:00:24,730
start making your decision.

9
00:00:25,830 --> 00:00:29,130
If you're brand new to machine learning, you've never done it before, or

10
00:00:29,130 --> 00:00:32,270
it's still kind of a challenge for you to understand the algorithms that

11
00:00:32,270 --> 00:00:35,800
we've talked about so far, I would suggest trying k nearest neighbors.

12
00:00:35,800 --> 00:00:37,680
This is a classic algorithm.

13
00:00:37,680 --> 00:00:40,900
It's very simple and easy to understand, which is a big advantage in

14
00:00:40,900 --> 00:00:44,060
a machine learning algorithm, that you know what's going on.

15
00:00:44,060 --> 00:00:46,090
If you're down with everything we've done so far and

16
00:00:46,090 --> 00:00:50,330
you're ready for a really interesting challenge, I would suggest adaboost or

17
00:00:50,330 --> 00:00:53,730
random forest, which are both examples of what we call ensemble methods.

18
00:00:54,800 --> 00:00:58,000
The name ensemble methods gives you a little bit of a hint of what these two

19
00:00:58,000 --> 00:00:59,270
might be doing.

20
00:00:59,270 --> 00:01:03,610
They're meta classifiers that are built from many, usually, decision trees, so

21
00:01:03,610 --> 00:01:05,120
you have many classifiers and

22
00:01:05,120 --> 00:01:09,140
you sort of have them all working together to come up with a single decision.

23
00:01:09,140 --> 00:01:12,480
It's a little bit like how we choose the president by voting.

24
00:01:12,480 --> 00:01:16,220
There's a single decision of who's the president going to be, and there are many

25
00:01:16,220 --> 00:01:19,780
different people who have different opinions on what that answer should be.

26
00:01:19,780 --> 00:01:22,620
And so what you have to do is you ask the question of many different people and

27
00:01:22,620 --> 00:01:25,140
all together you come up with a single answer.

28
00:01:25,140 --> 00:01:27,240
That's a little bit like what these two algorithms do, but

29
00:01:27,240 --> 00:01:29,630
they do it in slightly different ways.

30
00:01:29,630 --> 00:01:32,480
However, any of the algorithms that you pick should all be

31
00:01:32,480 --> 00:01:36,500
supported in SK-learn so you can rely on SK-learn having something that you can

32
00:01:36,500 --> 00:01:37,710
use straight out of the box.
