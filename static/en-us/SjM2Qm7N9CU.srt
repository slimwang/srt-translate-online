1
00:00:00,260 --> 00:00:01,390
Okay Michael you got answers for me?

2
00:00:01,390 --> 00:00:02,400
>> Think so.

3
00:00:02,400 --> 00:00:04,750
>> Okay good. Alright so lets look at the first one.

4
00:00:04,750 --> 00:00:10,240
Mutually orthogonal. Does that apply to PCA, ICA, both, or neither?

5
00:00:10,240 --> 00:00:14,120
>> So, it was one of the defining properties in PCA, so I would say PCA.

6
00:00:14,120 --> 00:00:17,740
>> Okay that's fair enough. That is actually correct. What about ICA?

7
00:00:17,740 --> 00:00:19,900
>> I don't, I don't know. It's not one of

8
00:00:19,900 --> 00:00:22,710
the defining features. It wasn't, it wasn't even thinking about orthugonality.

9
00:00:22,710 --> 00:00:26,160
>> That's right. And in fact ICA by finding independent.

10
00:00:26,160 --> 00:00:30,530
Projections are almost all but guaranteed to find ones that are not mutually

11
00:00:30,530 --> 00:00:34,010
arthugoial, it doesn't care at all. So in fact this is what makes PCA

12
00:00:34,010 --> 00:00:35,820
a global algorithm since it has

13
00:00:35,820 --> 00:00:38,430
this global constraint of mutual arthugoality. Where

14
00:00:38,430 --> 00:00:42,910
ICA really in its definition that cares about that, so this should be unchecked.

15
00:00:42,910 --> 00:00:43,820
>> Okay.

16
00:00:43,820 --> 00:00:47,310
>> I'm going to put an X there to represent unchecked. Okay, got it?

17
00:00:47,310 --> 00:00:48,000
>> Yeah.

18
00:00:48,000 --> 00:00:50,420
>> Okay. What about mutually independent?

19
00:00:50,420 --> 00:00:51,360
>> So,

20
00:00:51,360 --> 00:00:54,780
that was how ICA was trying to construct its, I don't

21
00:00:54,780 --> 00:00:57,600
want to say features, yeah I guess the, the transformed features.

22
00:00:57,600 --> 00:00:58,050
>> That's right.

23
00:00:58,050 --> 00:00:59,150
>> It was trying to create them to

24
00:00:59,150 --> 00:01:01,330
be mutually independent, so I would check ICA in

25
00:01:01,330 --> 00:01:04,450
that case. And, PCA didn't use that language

26
00:01:04,450 --> 00:01:06,110
at all, so I would just not do that.

27
00:01:06,110 --> 00:01:08,880
>> Okay. That's fair. I will point out though,

28
00:01:08,880 --> 00:01:10,740
that it turns out that PCA is trying to do

29
00:01:10,740 --> 00:01:14,300
something that sometimes will create things that are mutually independent.

30
00:01:14,300 --> 00:01:16,740
But we'll see that when we answer the next question.

31
00:01:16,740 --> 00:01:19,010
But you're right, PCA does not care about mutually

32
00:01:19,010 --> 00:01:23,530
independents. Okay, what about the third phrase, maximal variance?

33
00:01:23,530 --> 00:01:26,280
>> Alright. Again, I feel like this was one of the defining

34
00:01:26,280 --> 00:01:32,190
features of PCA. So it was trying to choose dimensions that maximize variance.

35
00:01:32,190 --> 00:01:34,500
>> That's right, and what about ICA?

36
00:01:34,500 --> 00:01:36,340
>> In terms of variance? Again, the, the,

37
00:01:36,340 --> 00:01:39,190
there, it wasn't really discussed in that context.

38
00:01:39,190 --> 00:01:41,810
>> Right. ICA is specifically interested

39
00:01:41,810 --> 00:01:45,211
in notions of independence, statistical independence. Not inpu,

40
00:01:45,211 --> 00:01:48,710
not in issues of varience. So in fact

41
00:01:48,710 --> 00:01:51,060
ICA does not care about maximizing varients. Now

42
00:01:51,060 --> 00:01:52,250
that we have gotten this far let me point

43
00:01:52,250 --> 00:01:55,020
something out, it turns out that because of

44
00:01:55,020 --> 00:01:58,400
this arthugonal deconstraint this lack of independent contraint,

45
00:01:58,400 --> 00:02:01,460
but this gold and maximizing varience, there are

46
00:02:01,460 --> 00:02:06,710
cases under which PCA happens to find independent projections.

47
00:02:06,710 --> 00:02:09,130
What's really going on here with these three constraints

48
00:02:09,130 --> 00:02:10,508
or, or lack of at least one in this

49
00:02:10,508 --> 00:02:12,920
case, is that PCA is tending to find things

50
00:02:12,920 --> 00:02:18,613
that are uncorrelated. By maximizing variance along arthogonal dimensions is

51
00:02:18,613 --> 00:02:23,800
finding uncorrelated dimensions. And that makes some sens given

52
00:02:23,800 --> 00:02:26,060
what it's trying to do. But that is not the

53
00:02:26,060 --> 00:02:28,600
same thing as finding things that are statistically independent.

54
00:02:29,610 --> 00:02:32,050
Again there is this particular case, there is a specific

55
00:02:32,050 --> 00:02:34,210
case where that does work out, and that's

56
00:02:34,210 --> 00:02:36,180
when all of your data is in fact Gaussian.

57
00:02:36,180 --> 00:02:37,420
>> Oh, interesting.

58
00:02:37,420 --> 00:02:39,250
>> And why Gaussian? Because it

59
00:02:39,250 --> 00:02:41,860
turns out that the distribution that maximizes

60
00:02:41,860 --> 00:02:44,420
variance is in fact the normal

61
00:02:44,420 --> 00:02:47,390
distribution. That's my interpretation of a normal

62
00:02:47,390 --> 00:02:51,980
distribution. So maximizing variance means that what PCA is doing is it's trying

63
00:02:51,980 --> 00:02:56,730
to find a bunch of orthogonal Gaussians. More or less. Does that make sense?

64
00:02:56,730 --> 00:02:57,610
>> Yeah

65
00:02:57,610 --> 00:03:00,640
but, you were saying that it, and it aligns with ICA in that case?

66
00:03:00,640 --> 00:03:04,130
>> In that case yes, because it turns out that uncorrelated ends up being

67
00:03:04,130 --> 00:03:07,230
independent under very specific distributions. But that's

68
00:03:07,230 --> 00:03:09,880
a coincidence it's not a normal fact.

69
00:03:09,880 --> 00:03:10,940
>> Ha, ha.

70
00:03:10,940 --> 00:03:13,870
>> But by the way this, this is probably worth

71
00:03:13,870 --> 00:03:16,110
pointing out here something that at least I think is

72
00:03:16,110 --> 00:03:18,970
kind of interesting here. Which is since ICA is only

73
00:03:18,970 --> 00:03:23,120
trying to find things that are. Independent of one another.

74
00:03:23,120 --> 00:03:25,910
Here's our little symbol for independence. As opposed

75
00:03:25,910 --> 00:03:28,205
to things that are uncorrelated, things that are

76
00:03:28,205 --> 00:03:30,890
[INAUDIBLE], it turns out that whatever it is

77
00:03:30,890 --> 00:03:33,220
PCA is doing, it is not working under

78
00:03:33,220 --> 00:03:39,000
the same underlying model as ICA. Lets think about what ICA is trying to do. ICA

79
00:03:39,000 --> 00:03:40,390
is trying to find a bunch of these

80
00:03:40,390 --> 00:03:44,088
prjections all of which are statically independnet. RIght?

81
00:03:44,088 --> 00:03:45,213
>> Mm-hm.

82
00:03:45,213 --> 00:03:48,540
>> What happens if I take a whole bunch of statically

83
00:03:48,540 --> 00:03:52,350
independent variables and I add them together? In other words

84
00:03:52,350 --> 00:03:54,740
I create linear combination of them. What am I going to

85
00:03:54,740 --> 00:03:57,430
>> get? A bunch of sums of things that are

86
00:03:57,430 --> 00:04:01,260
independent? Right and what does that tend towards in the limit?

87
00:04:01,260 --> 00:04:05,830
>> I want to say that the law of large numbers tells us that it turns normal.

88
00:04:05,830 --> 00:04:09,810
>> That's exactly right. If I take a bunch of independent variables and

89
00:04:09,810 --> 00:04:13,770
I sum them together, that is, I create a linear combination, I in fact

90
00:04:14,890 --> 00:04:19,490
end up with a gouache. And that is

91
00:04:19,490 --> 00:04:21,970
the central limit theorem. So one argument you might

92
00:04:21,970 --> 00:04:23,540
make is that if you believe in a

93
00:04:23,540 --> 00:04:27,410
world where there are independent causes giving rise to

94
00:04:27,410 --> 00:04:30,070
observables, which is what ICA believes, then whatever

95
00:04:30,070 --> 00:04:32,980
you do, you should not be maximizing variance, becasue

96
00:04:32,980 --> 00:04:36,750
you're guaranting the summing together otherwise independant variables.

97
00:04:36,750 --> 00:04:40,110
Oh, I see. I see, I see. So by

98
00:04:40,110 --> 00:04:42,640
trying to find things that are maximal variants it's trying to

99
00:04:42,640 --> 00:04:45,370
mix together through the central unit theorem all these things that

100
00:04:45,370 --> 00:04:49,190
are independent, so it's, it's, it's, it's, specifically not teasing apart

101
00:04:49,190 --> 00:04:52,770
the independent things, it's trying to smush together the independent things.

102
00:04:52,770 --> 00:04:53,910
>> Right. Under certain assumptions

103
00:04:53,910 --> 00:04:55,880
about the distributions of these individual

104
00:04:55,880 --> 00:04:59,160
variables. So another assumption that I see us making is not just

105
00:04:59,160 --> 00:05:02,080
that these variables are independent, but that they are hightly non-normally

106
00:05:02,080 --> 00:05:05,250
distributed. And if that's the case, then ending up with things that

107
00:05:05,250 --> 00:05:08,630
look like gaussians, has got to be exactly the wrong thing to do.

108
00:05:08,630 --> 00:05:09,820
If that assumption holds to be

109
00:05:09,820 --> 00:05:12,990
true. Okay. What about maximum mutual information?

110
00:05:12,990 --> 00:05:17,230
>> My understanding of what you describe for ICA said that this is

111
00:05:17,230 --> 00:05:21,780
what it's trying to do. It's trying to find a new feature space

112
00:05:21,780 --> 00:05:24,820
where the features are maximally. The

113
00:05:24,820 --> 00:05:26,880
mutual information between them is large as

114
00:05:26,880 --> 00:05:29,880
possible. So I would check the ICA in that case and not the PCA.

115
00:05:29,880 --> 00:05:30,640
>> Let

116
00:05:30,640 --> 00:05:34,660
me be Let me clarify soething you said. How can it be trying to

117
00:05:34,660 --> 00:05:37,010
maximize mutual information while also trying to

118
00:05:37,010 --> 00:05:39,070
make things that are mutually independent. I

119
00:05:39,070 --> 00:05:42,510
think you would describe them both in the same language. So what is it

120
00:05:42,510 --> 00:05:45,890
trying to make mutual independent? Different features.

121
00:05:45,890 --> 00:05:48,090
The, the new, the new transform features.

122
00:05:48,090 --> 00:05:51,990
>> Right. So each of the new transform features is independent with all the

123
00:05:51,990 --> 00:05:54,430
other new transform features. So what is

124
00:05:54,430 --> 00:05:56,180
it trying to maximize mutual information between?

125
00:05:56,180 --> 00:06:01,970
>> Oh, the, I see. The the information that

126
00:06:01,970 --> 00:06:04,760
content of the original features and the new features.

127
00:06:04,760 --> 00:06:07,870
>> Right. So this is about joint mutual information between

128
00:06:07,870 --> 00:06:11,480
all the original features together and All of the transform features.

129
00:06:11,480 --> 00:06:14,640
There it's trying to maximize mutual information. But inside the

130
00:06:14,640 --> 00:06:18,360
new transform features it's trying to make them pair-wise mutually independent.

131
00:06:18,360 --> 00:06:21,210
>> Alright. I think I said that wrong because I understood

132
00:06:21,210 --> 00:06:22,630
it wrong. So thank you for clarifying.

133
00:06:22,630 --> 00:06:24,200
>> You're welcome. But now you understand it right.

134
00:06:24,200 --> 00:06:25,295
>> Maybe.

135
00:06:25,295 --> 00:06:27,040
>> Okay, let's go with that because

136
00:06:27,040 --> 00:06:28,830
you got the checkmark right. What about PCA?

137
00:06:28,830 --> 00:06:33,090
>> Just X that. I don't understand what that would mean.

138
00:06:33,090 --> 00:06:35,110
>> Right. So if I were to put something here that it

139
00:06:35,110 --> 00:06:39,180
could get a check mark for, what I put down is maximal reconstruction.

140
00:06:40,770 --> 00:06:40,950
>> right.

141
00:06:40,950 --> 00:06:43,870
>> Right. And notice that maximal reconstruction of your

142
00:06:43,870 --> 00:06:46,720
original data is not the same thing as maximizing

143
00:06:46,720 --> 00:06:49,780
mutual information. Thought of course in the limit they work out to be the same.

144
00:06:49,780 --> 00:06:51,090
>> Interesting, okay.

145
00:06:51,090 --> 00:06:55,170
>> But the one project that maximizes variance is not

146
00:06:55,170 --> 00:06:58,670
necessarily the same as the first projection you find for

147
00:06:58,670 --> 00:07:02,660
maximizing mutual information. So these things really are doing two

148
00:07:02,660 --> 00:07:05,819
completely different things. Okay, last two what about ordered features?

149
00:07:05,819 --> 00:07:11,500
>> So, in PCA, it was actually assigning, you know,

150
00:07:11,500 --> 00:07:15,220
taking the maximum variant to dimension first and then the next,

151
00:07:15,220 --> 00:07:15,521
>> Mm-hm

152
00:07:15,521 --> 00:07:18,080
>> You know, after that's been subtracted out, whatever

153
00:07:18,080 --> 00:07:20,830
has the largest remaining variance and so forth. So

154
00:07:20,830 --> 00:07:22,640
that the features end up coming out in, in

155
00:07:22,640 --> 00:07:25,700
a very specific order. And it has the property that

156
00:07:25,700 --> 00:07:29,080
you could drop the, the last group of features

157
00:07:29,080 --> 00:07:30,920
if you want to still have as high a

158
00:07:30,920 --> 00:07:33,500
reconstruction area as possible, given the number of features

159
00:07:33,500 --> 00:07:36,670
that you keep. So I would check PCA for that.

160
00:07:36,670 --> 00:07:38,570
>> Okay, good. What about ICA?

161
00:07:40,210 --> 00:07:42,080
>> You didn't say anything about the ordering or

162
00:07:42,080 --> 00:07:45,790
how you'd actually find features. It seemed like in the

163
00:07:45,790 --> 00:07:48,680
blind source separation example you gave It just, came

164
00:07:48,680 --> 00:07:52,060
out with the three, so I'm going to say not ordered.

165
00:07:52,060 --> 00:07:53,790
>> That's right and in fact, if you

166
00:07:53,790 --> 00:07:56,570
think about the blind source separation example, how

167
00:07:56,570 --> 00:07:59,100
in the world would you order people anyway.

168
00:07:59,100 --> 00:08:00,700
I mean, other than in the obvious way.

169
00:08:01,800 --> 00:08:03,600
It just doesn't really mean anything. I say it doesn't

170
00:08:03,600 --> 00:08:07,410
have a notion of causes being more important than other

171
00:08:07,410 --> 00:08:10,450
causes merely that they're independent. So, it doesn't really worry

172
00:08:10,450 --> 00:08:14,030
about ordered features. It turns out in practice That you

173
00:08:14,030 --> 00:08:16,960
can actually try to order the features by using something

174
00:08:16,960 --> 00:08:20,190
called kertosis. Which is the fourth central moment of a

175
00:08:20,190 --> 00:08:23,460
distribution. But that's really just something that's useful in some

176
00:08:23,460 --> 00:08:27,320
specific cases, almost by coincidence. ICA, itself, does not particularly

177
00:08:27,320 --> 00:08:29,730
care, about ordering. At least not classical ICA.

178
00:08:30,840 --> 00:08:32,549
Okay, what about the last one, bag of features?

179
00:08:32,549 --> 00:08:38,990
>> So, I. Would view what you just said about ICA as implying that

180
00:08:38,990 --> 00:08:42,840
what ICA produces is a bag of features. There's no particular ordering to them.

181
00:08:42,840 --> 00:08:43,539
>> That's right.

182
00:08:43,539 --> 00:08:44,670
>> It's just a collection of things that

183
00:08:44,670 --> 00:08:47,280
make up the whole. I guess, you know,

184
00:08:47,280 --> 00:08:49,840
PCA, after you've thrown away whichever features you

185
00:08:49,840 --> 00:08:52,270
don't want. The features that remains are just features.

186
00:08:52,270 --> 00:08:54,740
They could be treated as a bag, I guess. So I don't know if

187
00:08:54,740 --> 00:08:59,100
I would check that or not. I. For symmetry I guess I would say not.

188
00:08:59,100 --> 00:09:01,100
>> Okay, but I'm going to say yes because

189
00:09:01,100 --> 00:09:02,580
in ordered set of features is still a

190
00:09:02,580 --> 00:09:04,860
bag of features. But we would accept either.

191
00:09:04,860 --> 00:09:06,260
Either a check or an x, both are sort

192
00:09:06,260 --> 00:09:10,130
of fine. So then, what do we really learn from this, Michael? I think what we've

193
00:09:10,130 --> 00:09:13,730
learned is these things have fundamentally different assumptions

194
00:09:13,730 --> 00:09:16,510
and are really trying to do completely different things.

195
00:09:16,510 --> 00:09:16,680
>> Okay.

196
00:09:16,680 --> 00:09:17,410
>> The

197
00:09:17,410 --> 00:09:19,110
only thing they have in common is that

198
00:09:19,110 --> 00:09:21,950
they're still trying to capture the original data somehow.

199
00:09:21,950 --> 00:09:24,810
>> Alright. I understand that, but I also learned the opposite, which is

200
00:09:24,810 --> 00:09:28,090
that they are really closely related and are trying to do very similar things.

201
00:09:28,090 --> 00:09:30,520
>> Yeah. But their underlying models

202
00:09:30,520 --> 00:09:31,600
are different. So maybe that, that's actually

203
00:09:31,600 --> 00:09:34,170
a good point, Michael. So maybe a better way of saying it is,

204
00:09:34,170 --> 00:09:36,010
their sort of fundamental assumptions are

205
00:09:36,010 --> 00:09:38,580
different. Even though they're trying to do

206
00:09:38,580 --> 00:09:43,190
the same thing, which is capture the original data in some new transform space

207
00:09:43,190 --> 00:09:48,780
that is somehow better. But if you think about it that way, there

208
00:09:48,780 --> 00:09:51,400
are two different optimization functions, two different

209
00:09:51,400 --> 00:09:54,110
fitness functions, two different cost functions. So

210
00:09:54,110 --> 00:09:54,890
even though they're trying to do

211
00:09:54,890 --> 00:09:58,380
the same thing. Reconstructing. Keeping the data

212
00:09:58,380 --> 00:10:00,900
around. Their basic assumptions about the way

213
00:10:00,900 --> 00:10:02,860
that data is constructed is very different.

214
00:10:02,860 --> 00:10:03,420
>> Okay.

215
00:10:03,420 --> 00:10:04,240
>> Okay.
