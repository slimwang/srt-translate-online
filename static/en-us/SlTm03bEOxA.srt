1
00:00:00,187 --> 00:00:05,351
It's called an inception module, it's
going to look a little more complicated.

2
00:00:05,351 --> 00:00:07,924
And you can skip this
section if you'd like,

3
00:00:07,924 --> 00:00:10,647
it's not essential to
the rest of the lecture.

4
00:00:10,647 --> 00:00:13,945
The idea is that at each
layer of your convnet,

5
00:00:13,945 --> 00:00:18,861
you can make a choice have a pooling
operation, have a convolution.

6
00:00:18,861 --> 00:00:24,942
And then you need to decide,
it is a 1x1 or a 3x3 or a 5x5.

7
00:00:24,942 --> 00:00:29,393
All of these are actually beneficial to
the modeling power of your network, so

8
00:00:29,393 --> 00:00:30,429
why choose?

9
00:00:30,429 --> 00:00:32,170
Let's use them all.

10
00:00:32,170 --> 00:00:34,590
Here is what an inception
module looks like.

11
00:00:34,590 --> 00:00:36,355
Instead of having a single convolution,

12
00:00:36,354 --> 00:00:40,979
you have a composition of average
pooling followed by 1 x 1,

13
00:00:40,979 --> 00:00:46,689
then a 1 x 1 convolution then
a 1 x 1 followed by 3 x 3.

14
00:00:46,689 --> 00:00:48,549
Then a 1x1 followed by a 5x5.

15
00:00:48,549 --> 00:00:52,869
And at the top, you simply concatenate
the output of each of them.

16
00:00:52,869 --> 00:00:54,460
It looks complicated.

17
00:00:54,460 --> 00:00:58,600
But what's interesting is that you can
chose these parameters in such a way

18
00:00:58,600 --> 00:01:02,395
that the total number of parameters
in your model is very small.

19
00:01:02,395 --> 00:01:05,659
Yet the model performs better than
if you had a simple convolution.

