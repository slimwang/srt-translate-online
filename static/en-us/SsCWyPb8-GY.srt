1
00:00:00,440 --> 00:00:04,290
To apply this to the segmentation
problem of vision,

2
00:00:04,290 --> 00:00:07,939
we have to think a little bit about what
feature space we do this in, all right?

3
00:00:07,939 --> 00:00:11,810
And it turns out for an awful lot
of what we do in clustering and

4
00:00:11,810 --> 00:00:14,810
segmentation, and frankly just about
everything in computer vision,

5
00:00:14,810 --> 00:00:17,270
the feature space you
use is what matters.

6
00:00:17,270 --> 00:00:20,180
So here, I'm showing you that single
line, with the idea being that

7
00:00:20,180 --> 00:00:24,200
we're just a grouping along a single,
intensity space.

8
00:00:24,200 --> 00:00:25,940
So if I were to cluster,

9
00:00:25,940 --> 00:00:30,890
using just this simple intensity space
what would it do to this panda picture,

10
00:00:30,890 --> 00:00:35,970
and Professor Grauman in Texas,
she's got these, this thing for pandas.

11
00:00:35,970 --> 00:00:37,660
Actually I think she got
these pictures somewhere.

12
00:00:38,820 --> 00:00:40,250
Well, so let's see.

13
00:00:40,250 --> 00:00:41,800
So here's our panda.

14
00:00:41,800 --> 00:00:46,300
If I tell it that there's
going to be two centers, okay,

15
00:00:46,300 --> 00:00:48,880
then I would get a division
that looks like this, right?

16
00:00:48,880 --> 00:00:54,030
So you can see that basically, the
lighter pixels have been turned into one

17
00:00:54,030 --> 00:00:59,420
region, and the darker pixels have been
turned into another region, all right?

18
00:00:59,420 --> 00:01:02,870
Now, if I told it instead
there were three clusters,

19
00:01:02,870 --> 00:01:05,480
you might look at something that
looks like this, all right?

20
00:01:05,480 --> 00:01:08,790
And here you can see there's the bright,
the dark, and the grey, all right?

21
00:01:08,790 --> 00:01:10,000
kind of like the good,
the bad and the ugly.

22
00:01:11,105 --> 00:01:12,905
So what you're seeing here right away,

23
00:01:12,905 --> 00:01:15,765
is one of the problems in
doing K means clustering.

24
00:01:15,765 --> 00:01:19,875
We'll talk more about this, is that you
have to tell it how many clusters there

25
00:01:19,875 --> 00:01:23,285
are, and there are methods for then
trying to figure that out beyond that,

26
00:01:23,285 --> 00:01:27,125
but fundamental to K means is you
already know the number of clusters.

27
00:01:27,125 --> 00:01:28,645
When you do this type of clustering,

28
00:01:28,645 --> 00:01:32,410
you can think of this as quantizing
the feature space, right?

29
00:01:32,410 --> 00:01:34,880
So those of you familiar
with vector quantization,

30
00:01:34,880 --> 00:01:37,930
if you do it in multi-dimensional space,
the idea is you essentially carve

31
00:01:37,930 --> 00:01:40,660
a continuous space up
into a set of buckets.

32
00:01:40,660 --> 00:01:44,560
So this segment, this clustering is
a quantization of our feature space.
