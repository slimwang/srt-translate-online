1
00:00:00,190 --> 00:00:02,610
The other alternative, or
another big alternative,

2
00:00:02,610 --> 00:00:05,900
is actually top Q-learning
which is what you described.

3
00:00:05,900 --> 00:00:10,400
>> You basically take whichever thing
had the most associated with it.

4
00:00:10,400 --> 00:00:10,970
>> The most value.

5
00:00:10,970 --> 00:00:11,740
Okay, yeah.

6
00:00:11,740 --> 00:00:13,290
Good.
>> The most value.

7
00:00:13,290 --> 00:00:15,910
And that works pretty well, again those
are the kind of things that you would

8
00:00:15,910 --> 00:00:20,260
probably come up with,
if you just spend a little bit of time.

9
00:00:20,260 --> 00:00:22,120
Just say well what are the obvious
things that you could do,

10
00:00:22,120 --> 00:00:23,510
both of those make sense.

11
00:00:23,510 --> 00:00:28,460
It of course also has a problem and
that problem is that the agent,

12
00:00:28,460 --> 00:00:31,970
well, there are several problems but
one that isn't necessarily obvious, is

13
00:00:31,970 --> 00:00:36,810
the agent that happens to have given the
most Q-value to a particular action may

14
00:00:36,810 --> 00:00:41,500
also give very nearly the same Q-value
to all the other actions as well.

15
00:00:41,500 --> 00:00:43,700
So it doesn't actually
have a strong preference,

16
00:00:43,700 --> 00:00:46,680
it just happens to put
high value on everything.

17
00:00:46,680 --> 00:00:49,940
And so you're not really doing much for
it either.

18
00:00:49,940 --> 00:00:55,890
Meanwhile, make every other agent might,
for example, like the second action.

19
00:00:55,890 --> 00:00:57,350
For that particular agent.

20
00:00:57,350 --> 00:01:00,970
And so it makes a lot more sense to take
the second action but you can't because

21
00:01:02,080 --> 00:01:05,400
by a quirk of fate the other action
got slightly more value to it for

22
00:01:05,400 --> 00:01:06,770
just that one agent.pericardial sac
>> So

23
00:01:06,770 --> 00:01:09,000
it starts to feel a little
bit like a negotiation.

24
00:01:09,000 --> 00:01:12,282
>> Right, which is why there's
something called negotiated W-learning.

25
00:01:12,282 --> 00:01:16,210
>> [LAUGH] W-learning.

26
00:01:16,210 --> 00:01:19,080
>> So,
this is a lot more complicated and

27
00:01:19,080 --> 00:01:23,180
I can't write it down in just
a fancy little equation like that.

28
00:01:23,180 --> 00:01:27,410
But what negotiated W-learning
basically boils down to is,

29
00:01:27,410 --> 00:01:33,230
the agent with the most to loose gets
to figure out what the action is.

30
00:01:33,230 --> 00:01:38,330
So you sort of minimize loss
rather than maximize an average or

31
00:01:38,330 --> 00:01:39,480
pick the best thing.

32
00:01:39,480 --> 00:01:43,630
So you look at the the subagent that,

33
00:01:43,630 --> 00:01:46,380
basically what you do instead of looking
at the things that everyone thinks might

34
00:01:46,380 --> 00:01:50,960
be good an average of them are doing a
max over them, if you look at the things

35
00:01:50,960 --> 00:01:55,660
where the difference between
the maximum choice and

36
00:01:55,660 --> 00:01:59,960
the minimum choice are really large and
let that agent make a decision.

37
00:01:59,960 --> 00:02:02,150
And just sort of weighted
across all of the actions.

38
00:02:02,150 --> 00:02:03,780
It can be arbitrarily complicated but

39
00:02:03,780 --> 00:02:07,450
basically you don't want any agent to
lose as opposed to having agents win.

40
00:02:07,450 --> 00:02:12,000
And all of these have their strings and
all these have their weaknesses And

41
00:02:12,000 --> 00:02:15,140
they're all very kind of cool and
under different circumstances.

42
00:02:15,140 --> 00:02:18,060
Greatest mass makes sense,
in other circumstances top makes sense,

43
00:02:18,060 --> 00:02:20,390
and negotiated is good for
other situations.

44
00:02:20,390 --> 00:02:21,860
And you can come up with
lots of other things,

45
00:02:21,860 --> 00:02:24,870
the key thing is that you
need to do arbitration.

46
00:02:24,870 --> 00:02:27,580
The problem with all of these though,
all of these methods and

47
00:02:27,580 --> 00:02:32,820
any other methods that you come up with
is that they're terrible, and in fact,

48
00:02:32,820 --> 00:02:33,860
They're impossible.

49
00:02:33,860 --> 00:02:35,250
What does that mean, you say.

50
00:02:35,250 --> 00:02:36,750
>> What does that mean?

51
00:02:36,750 --> 00:02:39,560
>> I'm going to
summarize it simply this.

52
00:02:39,560 --> 00:02:43,190
The very first example you gave,
you said, or

53
00:02:43,190 --> 00:02:46,505
the very first response that you gave
to me when I described greatest mass

54
00:02:46,505 --> 00:02:50,650
Q-learning is you said, what you're
really doing is you're voting.

55
00:02:50,650 --> 00:02:52,770
>> And
voting is definitely not impossible.

56
00:02:52,770 --> 00:02:56,490
But as you know,
there is an impossibility result for

57
00:02:56,490 --> 00:02:59,750
voting and
that is arrows impossibility result.

58
00:02:59,750 --> 00:03:02,670
And if you don't know what arrows
impossibility result is for voting,

59
00:03:02,670 --> 00:03:05,210
then you need to stop what you're
doing right now and go look it up.
