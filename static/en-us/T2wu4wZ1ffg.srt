1
00:00:00,220 --> 00:00:04,100
For the rest of this, and next, and
next, we're going to be talking about

2
00:00:04,100 --> 00:00:07,890
discriminative methods for
doing recognition or classification.

3
00:00:07,890 --> 00:00:11,340
By the way, I'll probably use those
words interchangeably, classification,

4
00:00:11,340 --> 00:00:12,460
recognition.

5
00:00:12,460 --> 00:00:15,126
Probably a little sloppy of me
because we talked a little bit about

6
00:00:15,126 --> 00:00:16,250
the difference.

7
00:00:16,250 --> 00:00:18,760
I'm just basically talking about
classifying something as being

8
00:00:18,760 --> 00:00:19,980
an A or a B.

9
00:00:19,980 --> 00:00:21,905
Or even more precisely, an A or a not-A.

10
00:00:23,090 --> 00:00:25,820
Before we go forward, we're going to
make some assumptions, okay?

11
00:00:25,820 --> 00:00:27,150
Our first assumption.

12
00:00:27,150 --> 00:00:32,051
We're going to assume that there's
a fixed number of known classes, right?

13
00:00:32,051 --> 00:00:33,151
So I'm going to tell you,

14
00:00:33,151 --> 00:00:36,071
there are four things in this
universe you have to worry about.

15
00:00:36,071 --> 00:00:40,790
Now, they might be As, Bs,
Cs, and none of the above.

16
00:00:40,790 --> 00:00:43,770
But it's not like later I'm
going to give you some Ds or

17
00:00:43,770 --> 00:00:45,130
later I'm going to give you some Es.

18
00:00:45,130 --> 00:00:48,940
No, I'm going to tell you
the classes that exist a priori.

19
00:00:48,940 --> 00:00:52,980
So when I train this system and
I'm defining the boundaries, I'm only

20
00:00:52,980 --> 00:00:56,430
worrying about the classes that you
tell me in advance that I know about.

21
00:00:56,430 --> 00:00:59,780
The other thing I'm going to assume
is that I've got plenty of data.

22
00:00:59,780 --> 00:01:03,020
I've got training examples
that come from this class, and

23
00:01:03,020 --> 00:01:05,750
it might not be,
shall we say, that data hard.

24
00:01:05,750 --> 00:01:08,570
You know, I've got an exponential
amount, but I've got lots of data.

25
00:01:08,570 --> 00:01:13,600
So it's possible for me to typically
find points that tend to be,

26
00:01:13,600 --> 00:01:17,160
you know, might get confused
with some other class.

27
00:01:17,160 --> 00:01:22,060
For the conversations we're going to
have today and the next time,

28
00:01:22,060 --> 00:01:25,120
we're going to assume
an equal cost of mistakes.

29
00:01:25,120 --> 00:01:28,190
So it costs you just as
much to call an A a not-A

30
00:01:28,190 --> 00:01:30,150
as it does to call a not-A an A.

31
00:01:30,150 --> 00:01:32,150
In fact,
one of the methods we'll talk about,

32
00:01:32,150 --> 00:01:36,950
the fact that some of the distributions
might be quite asymmetric, right?

33
00:01:36,950 --> 00:01:39,210
So you might be looking for,
say, I don't know, faces.

34
00:01:39,210 --> 00:01:40,260
We're going to do that one.

35
00:01:40,260 --> 00:01:43,650
In an image, you may know that most
places in an image, in most images,

36
00:01:43,650 --> 00:01:44,990
are not faces.

37
00:01:44,990 --> 00:01:48,700
So you might take advantage of that fact
in terms of how you search for them.

38
00:01:48,700 --> 00:01:50,810
But we're not going to worry
about the relative cost.

39
00:01:50,810 --> 00:01:54,230
Remember that loss function between
making the two kinds of mistakes.

40
00:01:54,230 --> 00:01:56,660
And the other thing is,
that we're going to assume, is that,

41
00:01:56,660 --> 00:01:59,040
and this is actually
good because it's true.

42
00:01:59,040 --> 00:02:01,040
It's always good to assume true things.

43
00:02:01,040 --> 00:02:03,260
We need to build a representation
of each instance.

44
00:02:03,260 --> 00:02:05,040
So we're going to build a description.

45
00:02:05,040 --> 00:02:09,280
But we don't know a priori
what features actually matter.

46
00:02:09,280 --> 00:02:12,950
So we're going to write down a whole
bunch of things about each instance.

47
00:02:12,950 --> 00:02:15,000
And then we're going to train a discri,

48
00:02:15,000 --> 00:02:20,230
a discriminative classifier to make
the distinction, the the classification,

49
00:02:20,230 --> 00:02:23,640
and it'll have to figure out where
the information is in the feature.

50
00:02:23,640 --> 00:02:26,590
All right, so that's a lot of assuming,
but I'm good at making assumptions.
