1
00:00:00,540 --> 00:00:03,690
So Katie, you told everybody about training and

2
00:00:03,690 --> 00:00:06,700
test sets, and I hope people exercise it quite a bit.

3
00:00:06,700 --> 00:00:08,510
Is that correct? >> Yes, that's right.

4
00:00:08,510 --> 00:00:11,900
>> So now I'm going to talk about something that slightly generalizes this

5
00:00:11,900 --> 00:00:13,790
called cross validation.

6
00:00:13,790 --> 00:00:17,360
And to get into cross validation, let's first talk about problems with

7
00:00:17,360 --> 00:00:20,950
splitting a data set into training and testing data.

8
00:00:20,950 --> 00:00:22,580
Suppose this is your data.

9
00:00:22,580 --> 00:00:25,000
By doing what Katie told you,

10
00:00:25,000 --> 00:00:29,330
you now have to say what fraction of data is testing and what is training.

11
00:00:29,330 --> 00:00:33,710
And the dilemma you're running into is you like to maximize both of the sets.

12
00:00:33,710 --> 00:00:36,458
You want to have as many data points in the training sets to

13
00:00:36,458 --> 00:00:40,241
get the best learning results, and you want the maximum number of data items in

14
00:00:40,241 --> 00:00:42,500
your test set to get the best validation.

15
00:00:42,500 --> 00:00:46,230
But obviously, there's an inherent trade-off here, which is every data point you

16
00:00:46,230 --> 00:00:50,180
take out of the training set into the test is lost for the training set.

17
00:00:50,180 --> 00:00:52,070
So we had to reset this trade-off.

18
00:00:52,070 --> 00:00:54,950
And this is where cross validation comes into the picture.

19
00:00:54,950 --> 00:01:01,540
The basic idea is that you partition the data set into k bins of equal size.

20
00:01:01,540 --> 00:01:04,700
So example, if you have 200 data points.

21
00:01:04,700 --> 00:01:06,580
And you have ten bins.

22
00:01:06,580 --> 00:01:07,430
Very quickly.

23
00:01:07,430 --> 00:01:09,003
What's the number of data points per bin?

24
00:01:09,003 --> 00:01:10,391
Quite obviously, it's 20.

25
00:01:10,391 --> 00:01:14,490
So you will have 20 data points in each of the 10 bins.

26
00:01:14,490 --> 00:01:15,630
So here's the picture.

27
00:01:15,630 --> 00:01:19,946
Whereas in the work that Katie showed you, you just pick one of those bins as

28
00:01:19,946 --> 00:01:22,454
a testing bin and the other then as a training bin.

29
00:01:22,454 --> 00:01:27,550
In k-fold cross validation, you run k separate learning experiments.

30
00:01:27,550 --> 00:01:32,380
In each of those, you pick one of those k subsets as your testing set.

31
00:01:32,380 --> 00:01:36,336
The remaining k minus one bins are put together into the training set,

32
00:01:36,336 --> 00:01:39,153
then you train your machine learning algorithm and

33
00:01:39,153 --> 00:01:43,370
just like before, you'll test the performance on the testing set.

34
00:01:43,370 --> 00:01:46,710
The key thing in cross validation is you run this multiple times.

35
00:01:46,710 --> 00:01:51,310
In this case ten times, and then you average the ten different testing set

36
00:01:51,310 --> 00:01:53,731
performances for the ten different hold out sets, so

37
00:01:53,731 --> 00:01:57,460
you average the test results from those k experiments.

38
00:01:57,460 --> 00:02:00,430
So obviously, this takes more compute time because you now have to run

39
00:02:00,430 --> 00:02:02,700
k separate learning experiments, but

40
00:02:02,700 --> 00:02:05,940
the assessment of the learning algorithm will be more accurate.

41
00:02:05,940 --> 00:02:08,240
And in a way, you've kind of used all your data for

42
00:02:08,240 --> 00:02:11,820
training and all your data for testing, which is kind of cool.

43
00:02:11,820 --> 00:02:13,320
Say we just ask one question.

44
00:02:13,320 --> 00:02:17,060
Suppose you have a choice to do the static train test methodology that Katie

45
00:02:17,060 --> 00:02:21,630
told you about, or you do say 10-fold cross validation, C.V., and

46
00:02:21,630 --> 00:02:24,070
you really care about minimizing training time.

47
00:02:24,070 --> 00:02:27,700
Minimize run time after training using your machine learning algorithm

48
00:02:27,700 --> 00:02:30,870
to output past the training time and maximize accuracy.

49
00:02:30,870 --> 00:02:34,438
In each of these three situations, you might pick either train/test or

50
00:02:34,438 --> 00:02:36,210
10-fold cross validation.

51
00:02:36,210 --> 00:02:37,140
Give me your best guess.

52
00:02:37,140 --> 00:02:38,140
Which one would you pick?

53
00:02:38,140 --> 00:02:39,760
So for each minimum training time,

54
00:02:39,760 --> 00:02:41,180
pick one of the two over here on the right side.
