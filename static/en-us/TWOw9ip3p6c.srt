1
00:00:00,330 --> 00:00:02,880
All right, so let's open up Ultrix.

2
00:00:02,880 --> 00:00:08,760
Drag in an input data tool and connect
to the HotelLoyaltyData.csv file.

3
00:00:08,760 --> 00:00:12,080
The data has been aggregated
to a customer level and

4
00:00:12,080 --> 00:00:14,620
has many variables
about these customers.

5
00:00:14,620 --> 00:00:17,620
The first thing I'm going to
do is connect to a select tool

6
00:00:17,620 --> 00:00:20,960
that allows me to view the structure
of all my different fields.

7
00:00:22,130 --> 00:00:26,480
Since this data came in as a CSV,
they all were read in as word types or

8
00:00:26,480 --> 00:00:28,740
strings, but as we know,

9
00:00:28,740 --> 00:00:31,600
we have a few different variables
that are actually numeric.

10
00:00:31,600 --> 00:00:34,520
So we should change those
field types to numeric types.

11
00:00:35,620 --> 00:00:40,685
The other fields are find to leave as
categorical variables as word types or

12
00:00:40,685 --> 00:00:41,950
strings.

13
00:00:41,950 --> 00:00:45,380
After this, I want to go to my
data preparation category and

14
00:00:45,380 --> 00:00:50,920
build estimation and validation samples,
using a create samples tool.

15
00:00:50,920 --> 00:00:54,840
Within this tool, you choose how many
records, or the percent of records,

16
00:00:54,840 --> 00:00:59,560
that you want to have in your estimation
sample, your validation sample and

17
00:00:59,560 --> 00:01:02,170
the residual is the holdout sample.

18
00:01:03,410 --> 00:01:08,430
So by default, I typically choose
70% for my estimation sample to

19
00:01:08,430 --> 00:01:15,440
build my model off of, and 30% of my
data to then validate my model off of.

20
00:01:15,440 --> 00:01:20,580
Anything left over that is less than
100% goes into my holdout sample.

21
00:01:20,580 --> 00:01:25,570
As you can see 100% of my records
were consumed with the estimation and

22
00:01:25,570 --> 00:01:30,010
validation samples, so nothing is going
to be within this holdout sample.

23
00:01:30,010 --> 00:01:33,810
I'm going to run this workload right
now, so you're able to see it yourself.

24
00:01:33,810 --> 00:01:38,268
What we can see is we have almost 1,600
records in our estimation sample.

25
00:01:38,268 --> 00:01:40,570
So that's 70% of our records.

26
00:01:40,570 --> 00:01:44,500
While the other 30% is in
our validation sample,

27
00:01:44,500 --> 00:01:47,730
which is about almost 700 records.

28
00:01:47,730 --> 00:01:51,180
And like I mentioned before, nothing
should be in our holdout sample, but

29
00:01:51,180 --> 00:01:52,980
let me just confirm that now.

30
00:01:52,980 --> 00:01:57,430
So now that we've changed field types as
well as creating different samples of

31
00:01:57,430 --> 00:02:01,010
our dataset I want to bring in
a logistic regression tool now

32
00:02:01,010 --> 00:02:04,120
to build up my first
logistic regression.

33
00:02:04,120 --> 00:02:05,570
Let's first name the model.

34
00:02:05,570 --> 00:02:08,051
We can name this whatever we want, but

35
00:02:08,051 --> 00:02:11,629
I'll call it Hotel _Log.for
logistic regression.

36
00:02:12,880 --> 00:02:15,858
And then I'm going to select my target
variable, and remember, the target

37
00:02:15,858 --> 00:02:19,040
variables are what we're trying to
predict, so that's our redeemer field.

38
00:02:20,120 --> 00:02:24,210
And then lastly, we'll select the
different potential predictor variables.

39
00:02:24,210 --> 00:02:28,270
So, for this first run of the logistic
regression, I'm going to choose all

40
00:02:28,270 --> 00:02:32,740
my different fields minus the customer
ID field since that's unique for

41
00:02:32,740 --> 00:02:34,560
all my different customers.

42
00:02:34,560 --> 00:02:39,425
The first name and last names, since I
highly doubt [SOUND] those have any sort

43
00:02:39,425 --> 00:02:43,532
of predictive ability to my redeemer
field, as well as we need to

44
00:02:43,532 --> 00:02:47,129
deselect our target field
which is the redeemer field.

45
00:02:47,129 --> 00:02:52,078
I'm now going to bring out the browse
tool after our R, our report output,

46
00:02:52,078 --> 00:02:56,100
so I'm able to view the results and
run the workflow down.

47
00:02:56,100 --> 00:02:59,650
The other result is the O
which is the model object.

48
00:02:59,650 --> 00:03:02,220
This is going to be use layer
to validate our model and

49
00:03:02,220 --> 00:03:03,120
to score our model.

50
00:03:04,270 --> 00:03:08,040
Now let's notice that the results
look exactly the same as they did for

51
00:03:08,040 --> 00:03:09,720
our linear regression.

52
00:03:09,720 --> 00:03:12,620
And they're used in
the exact same way actually.

53
00:03:12,620 --> 00:03:16,480
The first thing I typically do,
is I go down to my R-squared value.

54
00:03:16,480 --> 00:03:22,042
As you can see my R-square value
is at 0.6243, which is quite high.

55
00:03:22,042 --> 00:03:26,826
Now, if we look a little closer at these
results, we notice that almost none of

56
00:03:26,826 --> 00:03:31,850
the different variables are listed as
significant for our predictor variables.

57
00:03:31,850 --> 00:03:36,530
We can see this because there's almost
no asterisks in the last column.

58
00:03:36,530 --> 00:03:42,430
This is an indicator that this variable
is not very important to the model.

59
00:03:42,430 --> 00:03:45,710
And it likely should not
be included at all or

60
00:03:45,710 --> 00:03:49,890
it needs to be modified before it can
be effectively used within this model.
