1
00:00:00,090 --> 00:00:02,640
We have seen that
virtually accessed caches

2
00:00:02,640 --> 00:00:06,530
can overlap the latency of the TLB
lookup and the cache lookup.

3
00:00:06,530 --> 00:00:12,570
However, virtually accessed caches
have a big problem called aliasing.

4
00:00:12,570 --> 00:00:15,190
The problem of aliasing occurs

5
00:00:15,190 --> 00:00:19,050
because in the virtual address
space of the application,

6
00:00:19,050 --> 00:00:24,120
we can have one page mapped to some
part of the physical address space.

7
00:00:24,120 --> 00:00:28,020
For example, we can use
the mmap function in Linux and

8
00:00:28,020 --> 00:00:31,530
other operating systems
to map part of a file so

9
00:00:31,530 --> 00:00:34,899
that it appears in a range of
memory that we can address.

10
00:00:35,920 --> 00:00:39,830
The problem occurs when another page
in our virtual address space is

11
00:00:39,830 --> 00:00:43,160
also mapped to the same
physical addresses.

12
00:00:43,160 --> 00:00:43,840
For example,

13
00:00:43,840 --> 00:00:49,770
when doing an mmap of the same part
of the same file to another address.

14
00:00:49,770 --> 00:00:53,290
So now what we have is
two virtual addresses

15
00:00:53,290 --> 00:00:57,040
will actually refer to
the same physical location.

16
00:00:57,040 --> 00:01:00,270
To see why this is a problem
in a virtually accessed cache,

17
00:01:00,270 --> 00:01:01,960
let's look at two specific addresses.

18
00:01:01,960 --> 00:01:07,595
So let's say that A and
B are 12345000 and ABCDE000,

19
00:01:07,595 --> 00:01:12,513
and let's say that we have
a 64 kB direct-mapped cache

20
00:01:12,513 --> 00:01:18,050
with a 16 byte block size and
that is virtually accessed.

21
00:01:18,050 --> 00:01:21,324
So let's say that this
is our 64 kB cache.

22
00:01:21,324 --> 00:01:26,022
For this cache,
we have a four bit offset part of

23
00:01:26,022 --> 00:01:30,844
the address because of
the 16 byte block size.

24
00:01:30,844 --> 00:01:33,291
It's a 64 kB cache, so

25
00:01:33,291 --> 00:01:39,133
the next 12 bits are going to
be the index into this cache.

26
00:01:39,133 --> 00:01:43,640
64 kB divided by 16 bytes
is four kilo entries, so

27
00:01:43,640 --> 00:01:49,261
we need 2 to the 12th index bits
to tell us which index do we have.

28
00:01:50,340 --> 00:01:53,170
And the rest of the bits
in the addresses are tags.

29
00:01:53,170 --> 00:01:56,450
So this is how the aliasing
problem occurs.

30
00:01:56,450 --> 00:02:01,490
Let's say that the processor
writes a value of 16 to A.

31
00:02:01,490 --> 00:02:09,130
It breaks down the address, indexes into
the cache, using the index of hex 500.

32
00:02:09,130 --> 00:02:11,110
Let's say that this is a cache miss.

33
00:02:11,110 --> 00:02:15,020
So we go to memory, and from
the physical location where this data is

34
00:02:15,020 --> 00:02:20,620
mapping to, we fetch a value, and
let's say that this value is four.

35
00:02:20,620 --> 00:02:25,680
Once we fetch the cache block,
we now put 16 there, and

36
00:02:25,680 --> 00:02:27,690
the new content of
the cache block is 16.

37
00:02:27,690 --> 00:02:31,637
Let's say this is a write-back cache,
so this 16 just stays there.

38
00:02:31,637 --> 00:02:34,770
Now, let's see what happens
when we try to read B.

39
00:02:34,770 --> 00:02:39,800
We index into the cache using
the index for B, which is E00 hex,

40
00:02:39,800 --> 00:02:45,450
and because what we are looking for
is not here, we go to memory and

41
00:02:45,450 --> 00:02:50,620
fetch the value, and this maps with
the same physical memory location, so

42
00:02:50,620 --> 00:02:53,600
we are going to get four again.

43
00:02:53,600 --> 00:02:55,450
And now we're going to read that.

44
00:02:55,450 --> 00:02:58,810
Note that this problem is not just
a problem on the cache misses.

45
00:02:58,810 --> 00:03:03,520
From now on, whenever we write to A, we
will be changing this cache block, and

46
00:03:03,520 --> 00:03:06,760
whenever we read from B,
we will be reading this cache block, so

47
00:03:06,760 --> 00:03:10,450
they never really end up sharing
the data as they should.

48
00:03:10,450 --> 00:03:14,445
What should've happened is because A and
B are really the same data,

49
00:03:14,445 --> 00:03:19,450
when we write to A and read B,
we should be getting the same data.

50
00:03:19,450 --> 00:03:21,960
And this problem results

51
00:03:21,960 --> 00:03:25,810
in incorrect execution whenever
we have such a mapping.

52
00:03:25,810 --> 00:03:29,690
Unfortunately, such mappings are
perfectly legal to do in most operating

53
00:03:29,690 --> 00:03:36,300
systems, so virtually accessed caches
need additional support for this.

54
00:03:36,300 --> 00:03:40,700
Every time we write to any virtual
location, we would have to do a check

55
00:03:40,700 --> 00:03:46,540
for aliases or different versions of
the same physical data in the cache and

56
00:03:46,540 --> 00:03:51,230
either invalidate them, remove them
from the cache, or update them so

57
00:03:51,230 --> 00:03:53,740
that they would see the new value.

58
00:03:53,740 --> 00:03:55,480
And this is really expensive to do, and

59
00:03:55,480 --> 00:03:58,530
it kind of defeats the purpose
of virtually accessed caches,

60
00:03:58,530 --> 00:04:02,360
which are all about the latency and
not needing to do translation.

61
00:04:02,360 --> 00:04:05,820
Now, when we write here,
we would need to do translation

62
00:04:05,820 --> 00:04:10,370
in order to check where else
do we have the same mapping.

63
00:04:10,370 --> 00:04:14,970
To summarize this, we like virtually
accessed caches because they allow us to

64
00:04:14,970 --> 00:04:20,279
overlap, tabulate, and see with cache
latency, but we cannot use them because

65
00:04:20,279 --> 00:04:24,310
of the aliasing problem that seriously
complicates their implementation.
