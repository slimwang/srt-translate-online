1
00:00:00,000 --> 00:00:05,000
So in lecture, we spent a lot of time learning about context-free grammars and languages.

2
00:00:05,000 --> 00:00:07,000
Can context-free grammars be used

3
00:00:07,000 --> 00:00:10,000
to do anything other than parsing a programming language?

4
00:00:10,000 --> 00:00:14,000
That's a good point, Peter, and the answer is yes.

5
00:00:14,000 --> 00:00:18,000
In fact, there are a large number of applications for language formalisms

6
00:00:18,000 --> 00:00:20,000
or context-free grammars.

7
00:00:20,000 --> 00:00:22,000
I'll just list 4 or 5 of them.

8
00:00:22,000 --> 00:00:25,000
One of the first is security.

9
00:00:25,000 --> 00:00:29,000
We saw last time that regular expressions can be used in virus checkers.

10
00:00:29,000 --> 00:00:32,000
And in fact, that's how the vast majority of virus checkers work.

11
00:00:32,000 --> 00:00:34,000
They're like a big lexer.

12
00:00:34,000 --> 00:00:38,000
It turns out that these days the most common attacks or exploits

13
00:00:38,000 --> 00:00:42,000
or vulnerabilities reported involve cross-site scripting

14
00:00:42,000 --> 00:00:46,000
or SQL--database--code injection vulnerabilities.

15
00:00:46,000 --> 00:00:52,000
Both of these involve an application, a web application like Udacity's servers,

16
00:00:52,000 --> 00:00:57,000
reading in a string from the user and treating it as if it were part of another important language

17
00:00:57,000 --> 00:01:01,000
like HTML or SQL, the language of database queries.

18
00:01:01,000 --> 00:01:04,000
It turns out that there a number of techniques available

19
00:01:04,000 --> 00:01:11,000
for using context-free grammars to detect if a string from a user is normal

20
00:01:11,000 --> 00:01:15,000
or if it's trying to take advantage of some special system structure

21
00:01:15,000 --> 00:01:17,000
if it's one of these attacks.

22
00:01:17,000 --> 00:01:22,000
And essentially, the way to do that is we pretend to parse the final string

23
00:01:22,000 --> 00:01:24,000
given the context that the user has provided.

24
00:01:24,000 --> 00:01:28,000
And if the user's changes, the string provided by the user

25
00:01:28,000 --> 00:01:33,000
ends up influencing a large part of the parse tree, of the abstract syntax tree,

26
00:01:33,000 --> 00:01:37,000
in essence, if the high watermark of the changes or the tainted information from the user

27
00:01:37,000 --> 00:01:41,000
reaches very, very high, then we know it's a SQL code injection

28
00:01:41,000 --> 00:01:45,000
or cross-site scripting attack because those attacks are based on destroying

29
00:01:45,000 --> 00:01:50,000
or conflicting or deforming the essential structure of the output language.

30
00:01:50,000 --> 00:01:53,000
So 1 possible use for them is in security.

31
00:01:53,000 --> 00:01:56,000
Some of the best ways to figure out if something is SQL code injection

32
00:01:56,000 --> 00:01:59,000
or cross-site scripting, let's say, before you actually run it and find out,

33
00:01:59,000 --> 00:02:02,000
involve the use of grammars.

34
00:02:02,000 --> 00:02:05,000
Another is in the world of optimization.

35
00:02:05,000 --> 00:02:11,000
A production compiler or interpreter is often very interested in getting the same results

36
00:02:11,000 --> 00:02:15,000
but faster or using less memory or--and this is a big one these days--

37
00:02:15,000 --> 00:02:17,000
using less power.

38
00:02:17,000 --> 00:02:20,000
If you're running a program on your smartphone or some other mobile device,

39
00:02:20,000 --> 00:02:24,000
you really want it to last as long as possible.

40
00:02:24,000 --> 00:02:28,000
Later on in the class, around Unit 6, we'll actually cover some basic optimizations.

41
00:02:28,000 --> 00:02:31,000
I'll teach some of them to you, and you'll get a chance to use them

42
00:02:31,000 --> 00:02:34,000
in your JavaScript interpreter for the web browser.

43
00:02:34,000 --> 00:02:36,000
But for now, just take my word for it.

44
00:02:36,000 --> 00:02:41,000
In order to do optimizations, we have to figure out what the values and variables are.

45
00:02:41,000 --> 00:02:45,000
For example, if I can figure out that X is always 0

46
00:02:45,000 --> 00:02:48,000
and you have a line in your program that says Y gets Y + X,

47
00:02:48,000 --> 00:02:51,000
I don't have to bother interpreting that line

48
00:02:51,000 --> 00:02:54,000
because I know that adding 0 to something doesn't change its value.

49
00:02:54,000 --> 00:02:58,000
That sort of thing is called a data flow analysis or an optimization,

50
00:02:58,000 --> 00:03:02,000
because if I can reason about how numbers flow through your program,

51
00:03:02,000 --> 00:03:06,000
then I can make them faster, higher, stronger, use less power.

52
00:03:06,000 --> 00:03:08,000
It's a really nice idea.

53
00:03:08,000 --> 00:03:12,000
It's going to turn out that the best known research idea for figuring out values

54
00:03:12,000 --> 00:03:16,000
as they flow through various functions in your program

55
00:03:16,000 --> 00:03:21,000
is related to context-free grammars or, more formally, context-free language reachability.

56
00:03:21,000 --> 00:03:26,000
It turns out that interprocedural data flow analysis is the same problem as,

57
00:03:26,000 --> 00:03:29,000
in a theoretical sense, context-free language reachability,

58
00:03:29,000 --> 00:03:34,000
which is the same problem as could I generate a string in a context-free grammar.

59
00:03:34,000 --> 00:03:37,000
It turns out all of you are experts at figuring out if we could generate a string

60
00:03:37,000 --> 00:03:39,000
in the language of a context-free grammar,

61
00:03:39,000 --> 00:03:43,000
and exactly that sort of knowledge is one of the things program optimizers use

62
00:03:43,000 --> 00:03:47,000
to squeeze every last drop of goodness out of a program.

63
00:03:47,000 --> 00:03:51,000
Third possibility is in linguistics or computational linguistics.

64
00:03:51,000 --> 00:03:54,000
There are a number of references to these underneath the lecture videos,

65
00:03:54,000 --> 00:03:57,000
but it turns out that a lot of these notions of context-free grammars

66
00:03:57,000 --> 00:04:01,000
or generative grammars or universal grammars actually came out of psychology

67
00:04:01,000 --> 00:04:04,000
or linguistics or computational linguistics

68
00:04:04,000 --> 00:04:06,000
to help us understand human and natural language.

69
00:04:06,000 --> 00:04:08,000
And it's a really important use.

70
00:04:08,000 --> 00:04:10,000
But let me skip past that one since it's too easy in some sense.

71
00:04:10,000 --> 00:04:12,000
I'll give you 2 more.

72
00:04:12,000 --> 00:04:17,000
One more--near and dear to my heart--is specification mining.

73
00:04:17,000 --> 00:04:21,000
It turns out that often we want to figure out what a program should be doing

74
00:04:21,000 --> 00:04:23,000
just by looking at its source code.

75
00:04:23,000 --> 00:04:25,000
And this is super tricky.

76
00:04:25,000 --> 00:04:27,000
It's like trying to learn the rules of English grammar

77
00:04:27,000 --> 00:04:29,000
by reading a bunch of high school student essays

78
00:04:29,000 --> 00:04:32,000
and looking at what they get right and get wrong in common.

79
00:04:32,000 --> 00:04:35,000
As you can imagine, it's very difficult to get this perfectly

80
00:04:35,000 --> 00:04:38,000
because just because a number of students say something

81
00:04:38,000 --> 00:04:40,000
doesn't necessarily mean that they're following the rules.

82
00:04:40,000 --> 00:04:42,000
They might all get it wrong the same way.

83
00:04:42,000 --> 00:04:44,000
And if you've seen people post on forums,

84
00:04:44,000 --> 00:04:46,000
maybe not everyone has perfect grammar.

85
00:04:46,000 --> 00:04:49,000
So just taking samples might not be the right way to do it.

86
00:04:49,000 --> 00:04:55,000
It turns out that the output of specification mining often takes the form of a formal grammar

87
00:04:55,000 --> 00:04:58,000
or some sort of state machine: You should always call open

88
00:04:58,000 --> 00:05:00,000
and then you should call close.

89
00:05:00,000 --> 00:05:03,000
A lot of important security or software engineering policies

90
00:05:03,000 --> 00:05:06,000
can be described in terms of some sort of grammar.

91
00:05:06,000 --> 00:05:10,000
It turns out that learning grammars from examples is really, really difficult.

92
00:05:10,000 --> 00:05:15,000
Both that and this notion I mentioned earlier of interprocedural data flow analysis

93
00:05:15,000 --> 00:05:19,000
are the sorts of things that one might get into in a subsequent course after this one

94
00:05:19,000 --> 00:05:22,000
but where you'd build on the knowledge you learned here.

95
00:05:22,000 --> 00:05:25,000
Here's my last example, and this one is perhaps the farthest from the norm,

96
00:05:25,000 --> 00:05:29,000
but I think students may appreciate it.

97
00:05:29,000 --> 00:05:32,000
It turns out that if you're using a cellular phone,

98
00:05:32,000 --> 00:05:37,000
people might be able to intercept what you're saying if they just listen very hard.

99
00:05:37,000 --> 00:05:42,000
So these days, modern cell phones or mobile phones might try to encrypt the data packets

100
00:05:42,000 --> 00:05:45,000
that they send containing your vocal information so that, in theory,

101
00:05:45,000 --> 00:05:48,000
eavesdroppers can't figure out what's going on.

102
00:05:48,000 --> 00:05:51,000
However, if I've used a lot of that computational linguistic information,

103
00:05:51,000 --> 00:05:55,000
if I've studied the world, it turns out that in different spoken languages

104
00:05:55,000 --> 00:06:01,000
or with different accents we have different patterns of speech and then pauses.

105
00:06:01,000 --> 00:06:04,000
And some of the initial implementations of phone encryption tried to be smart

106
00:06:04,000 --> 00:06:06,000
and save power.

107
00:06:06,000 --> 00:06:11,000
They would only send information when you actually said something.

108
00:06:11,000 --> 00:06:16,000
So this meant that attackers could listen in and, using linguistic analysis information,

109
00:06:16,000 --> 00:06:20,000
even if they couldn't tell what you were saying, even if it was all scrambled,

110
00:06:20,000 --> 00:06:24,000
just by doing a statistical analysis of how long you said and then how long you paused

111
00:06:24,000 --> 00:06:29,000
and then how long you said again, we can reliably identify what language you're speaking

112
00:06:29,000 --> 00:06:33,000
and, worse than that, regional accents--say you're speaking English--

113
00:06:33,000 --> 00:06:36,000
whether you're speaking with some sort of New York/Brooklyn accent or from the South

114
00:06:36,000 --> 00:06:38,000
or from California.

115
00:06:38,000 --> 00:06:42,000
We can tell based just on the patterns of how long you speak and how long the pauses are.

116
00:06:42,000 --> 00:06:48,000
That has very unfortunate Orwellian implications for some sort of surveillance state.

117
00:06:48,000 --> 00:06:53,000
Conveniently, it is more or less totally defeated by encrypting the silence as well--

118
00:06:53,000 --> 00:06:56,000
using more power to just get rid of that side channel,

119
00:06:56,000 --> 00:06:59,000
prevent people from figuring out when you're speaking and when you're not.

120
00:06:59,000 --> 00:07:02,000
But that's an example of an application that also uses this sort of linguistic analysis--

121
00:07:02,000 --> 00:07:06,000
perhaps a little less related to context-free grammars but still in the same vein.

122
00:07:06,000 --> 00:07:10,000
All in all, context-free grammars, context-free languages

123
00:07:10,000 --> 99:59:59,999
come up in significantly more of computer science than just parsing.
