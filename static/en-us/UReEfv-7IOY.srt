1
00:00:00,160 --> 00:00:01,630
So let's just summarize.

2
00:00:03,300 --> 00:00:06,250
Using SVMs for say recognition, okay?

3
00:00:06,250 --> 00:00:09,150
So you have to define your
representation that is you need some

4
00:00:09,150 --> 00:00:10,910
base feature space, all right?

5
00:00:10,910 --> 00:00:12,710
Some feature vector in
which you're representing.

6
00:00:12,710 --> 00:00:15,760
So whether you're doing HoG or,
or whatever it is.

7
00:00:15,760 --> 00:00:18,120
You select a kernel function.

8
00:00:18,120 --> 00:00:21,410
I'm not going to tell you at
the moment yet how you do that.

9
00:00:21,410 --> 00:00:27,250
Given a kernel function, you can compute
the kernel between all your inputs,

10
00:00:27,250 --> 00:00:29,820
all Xi's and all the Xj's.

11
00:00:29,820 --> 00:00:35,190
That matrix is what you can then
use to find your support vectors.

12
00:00:35,190 --> 00:00:37,870
Remember to, to find the support
vectors, it has to be able to compute

13
00:00:37,870 --> 00:00:41,880
the dot product of Xi and Xj, but in
this case, we're going to use the kernel

14
00:00:41,880 --> 00:00:45,470
of Xi and Xj because it's
the dot product in some space.

15
00:00:46,560 --> 00:00:50,230
And what's cool is you'll notice
here that there's a boundary

16
00:00:51,540 --> 00:00:53,250
that's not a line.

17
00:00:53,250 --> 00:00:58,020
It's a line or hyperplane in
some high dimensional space, but

18
00:00:58,020 --> 00:01:02,060
back in the original space
the boundary is whatever it is.

19
00:01:02,060 --> 00:01:05,740
And in fact if you use RBF,
a radial basis functions,

20
00:01:05,740 --> 00:01:09,360
you can sort of see it move
around your points elegantly.

21
00:01:09,360 --> 00:01:13,240
And that's part of what gave the power
of SVM, is that you can essentially bend

22
00:01:13,240 --> 00:01:17,200
the surface where you need to
near your support vectors.

23
00:01:17,200 --> 00:01:17,980
So, training.

24
00:01:17,980 --> 00:01:19,610
This is how you do the training.

25
00:01:19,610 --> 00:01:23,060
And then at recognition,
to classify, it's very simple.

26
00:01:23,060 --> 00:01:24,750
You take a new example.

27
00:01:24,750 --> 00:01:29,700
You compute the kernel values between
it, and only the support vectors.

28
00:01:29,700 --> 00:01:31,870
Multiply by the weights, the alphas.

29
00:01:31,870 --> 00:01:34,910
And if it's positive, it's a,
it's a positive example, negative net.

30
00:01:34,910 --> 00:01:37,340
So, here, it's sort of faces and
non faces.
