1
00:00:00,000 --> 00:00:02,627
Now we're going to take a completely different approach to sorting.

2
00:00:02,627 --> 00:00:05,533
Generally, most sorting algorithms are data dependent.

3
00:00:05,533 --> 00:00:08,785
Based on the values of the data, we choose to do different things.

4
00:00:08,785 --> 00:00:12,726
And if we sort 2 different sequences, we'd probably take a different path through the code.

5
00:00:12,726 --> 00:00:17,876
Instead, now we're going to consider a set of sorting algorithms that we call oblivious.

6
00:00:17,876 --> 00:00:22,670
No matter what input we choose, the sorting algorithm proceeds the exact same way.

7
00:00:22,670 --> 00:00:27,538
In fact, the only data dependence we will have in the whole algorithm is a swap operation

8
00:00:27,538 --> 00:00:31,007
that inputs 2 elements and outputs them in the correct order.

9
00:00:31,007 --> 00:00:33,254
Let me take a brief digression.

10
00:00:33,258 --> 00:00:38,216
Why is an oblivious algorithm a good algorithm for a parallel processor like a GPU?

11
00:00:38,216 --> 00:00:41,122
So when I talk about an oblivious algorithm, what I mean

12
00:00:41,122 --> 00:00:45,329
is that its behavior is independent of some particular aspect of the problem.

13
00:00:45,329 --> 00:00:47,899
In this case we're talking about a sorting algorithm

14
00:00:47,899 --> 00:00:51,907
that always does the exact same steps no matter what the input is.

15
00:00:51,907 --> 00:00:55,837
Good CPU sorting algorithms are generally more clever.

16
00:00:55,837 --> 00:01:00,483
They have more complex control flow and a lot of data-dependent decisions to run fast.

17
00:01:00,483 --> 00:01:03,574
GPUs aren't so great at complex control flow.

18
00:01:03,574 --> 00:01:07,347
Instead, they're great at simple control flow and massive parallelism,

19
00:01:07,347 --> 00:01:12,030
and oblivious algorithms are generally a good match for massively parallel approaches to problems.

20
00:01:12,030 --> 00:01:14,031
Okay. Let's return to sorting.

21
00:01:14,031 --> 00:01:16,739
Clearly, an example will help show what I mean.

22
00:01:16,739 --> 00:01:19,306
This structure that I'm showing here is called a sorting network.

23
00:01:19,306 --> 00:01:22,485
The input is placed on the lines at the left.

24
00:01:22,485 --> 00:01:25,447
So this will input 4 elements--1, 2, 3, 4.

25
00:01:25,447 --> 00:01:30,145
Each time 2 values are on either side of a shared vertical line,

26
00:01:30,145 --> 00:01:33,500
these values are swapped if they are in the wrong order.

27
00:01:33,500 --> 00:01:36,177
So let's put some numbers on there and give it a shot.

28
00:01:36,177 --> 00:01:39,495
So we're going to start with the input sequence 4, 2, 1, 3.

29
00:01:39,495 --> 00:01:43,989
And so each time 2 elements are connected by 1 green line,

30
00:01:43,989 --> 00:01:46,283
we will swap them if they are out of order.

31
00:01:46,283 --> 00:01:48,599
So first we'll swap 2 and 4.

32
00:01:48,599 --> 00:01:51,805
But we won't swap 1 and 3 because they're in the right order.

33
00:01:51,805 --> 00:01:58,096
Now we will look at 2 and 3, and we don't have to swap them but we do have to swap 1 and 4.

34
00:01:58,096 --> 00:02:00,471
And finally we have 2 more swaps to do.

35
00:02:00,471 --> 00:02:03,518
1 and 2 are in the wrong order, so we'll swap them.

36
00:02:03,518 --> 00:02:06,006
4 and 3 are also in the wrong order, so we will swap them.

37
00:02:06,006 --> 00:02:11,321
And, voila, now we've moved from an unsorted sequence to a sorted sequence.

38
00:02:11,321 --> 00:02:15,339
Fortunately, this bitonic sorting network scales in a straightforward

39
00:02:15,339 --> 00:02:17,482
and easily programmable way.

40
00:02:17,482 --> 00:02:20,379
So we had a little sorting network that would sort 4 items.

41
00:02:20,379 --> 00:02:24,214
It's fairly straightforward to expand it so that now it can sort 8.

42
00:02:24,214 --> 00:02:26,895
So let me try to give you a little intuition about how that works.

43
00:02:26,895 --> 00:02:32,454
So a bitonic sequence is a sequence that only changes direction a maximum of once.

44
00:02:32,454 --> 00:02:36,195
So if we look at this sequence here, we're going up for a little while

45
00:02:36,195 --> 00:02:40,667
and then down for a little while, but we only change direction right here.

46
00:02:40,667 --> 00:02:43,125
So this is bitonic. How about this sequence here?

47
00:02:43,125 --> 00:02:48,116
Well, we're going down and then up. 753 goes down, then we change direction and go back up.

48
00:02:48,116 --> 00:02:52,013
So sort of the trace of the sequence looks like that and that is also bitonic.

49
00:02:52,013 --> 00:02:55,025
But we might have a sequence that looks like this--1324--

50
00:02:55,025 --> 00:02:58,675
where we go up and then down and then up again.

51
00:02:58,675 --> 00:03:02,226
This, however, is not bitonic. Now why do we care?

52
00:03:02,226 --> 00:03:07,055
It turns out that it's particularly easy to sort a bitonic sequence, and let me tell you how.

53
00:03:07,055 --> 00:03:12,188
So let's say we have this bitonic sequence or, alternatively, 2 monotonic sequences

54
00:03:12,188 --> 00:03:15,139
that we can turn into 1 bitonic sequence.

55
00:03:15,139 --> 00:03:16,569
Here is what we are going to do.

56
00:03:16,569 --> 00:03:18,645
We're going to take the first half of this bitonic sequence

57
00:03:18,645 --> 00:03:22,179
and we're going to lay it on top of the second half of this bitonic sequence.

58
00:03:22,179 --> 00:03:27,654
Then what we're going to do is do a pairwise comparison of each element here.

59
00:03:27,654 --> 00:03:31,588
And we're going to take the larger element and we're going to put it in this set here,

60
00:03:31,588 --> 00:03:35,375
and we're going to take the smaller element and we're going to put it in this size here.

61
00:03:35,375 --> 00:03:41,457
So what we've done is we've partitioned this bitonic sequence into 2 bitonic sequences,

62
00:03:41,457 --> 00:03:45,025
one of which is bigger and one of which is smaller.

63
00:03:45,025 --> 00:03:50,239
And so then we can recurse and do the bitonic sort on each one of these subsequences

64
00:03:50,239 --> 00:03:53,511
and continue until we have a completely sorted sequence.

65
00:03:53,511 --> 00:03:56,352
The overall algorithm is generally to sort 2 sequences,

66
00:03:56,352 --> 00:04:00,359
we reverse 1, we append it to the other to create a bitonic sequence,

67
00:04:00,359 --> 00:04:05,866
we split that bitonic sequence into the larger and smaller halves, and then we sort each half.

68
00:04:05,866 --> 00:04:13,601
So if we look at this big picture here, these 2 boxes here sort to input sequences of size 4,

69
00:04:13,601 --> 00:04:19,269
this segment here splits 2 sorted sequences into a larger half and a smaller half,

70
00:04:19,269 --> 00:04:24,143
and then these 2 boxes here will sort 2 bitonic sequences

71
00:04:24,143 --> 00:04:27,312
that result for the smaller half and the bigger half.

72
00:04:27,312 --> 00:04:31,791
So if we actually did the analysis here, we would find that for an input set of size n

73
00:04:31,791 --> 00:04:35,421
it requires something proportional to log n stages overall.

74
00:04:35,421 --> 00:04:40,890
If we actually looked here, we would find that's 1, 2, 3, 4, 5, 6.

75
00:04:40,890 --> 00:04:43,955
And the first stage compares and swaps all elements once,

76
00:04:43,955 --> 00:04:46,603
the next stage does 2 swaps, and so on.

77
00:04:46,603 --> 00:04:52,269
And so the total complexity here is that we have n(log^n) swaps overall.

78
00:04:52,269 --> 00:04:55,124
Well, that's all nice theory, but here's the best part.

79
00:04:55,124 --> 00:04:59,275
What should immediately draw your eye is that within any set of swaps

80
00:04:59,275 --> 00:05:02,490
every swap is completely in parallel.

81
00:05:02,490 --> 00:05:04,838
So if you look at this stage here, for instance,

82
00:05:04,838 --> 00:05:07,961
we have 4 swaps but each of them can proceed in parallel.

83
00:05:07,961 --> 00:05:12,448
We have 4 swaps in this particular stage. Each of those can proceed in parallel.

84
00:05:12,448 --> 00:05:17,528
Here's a different permutation of swaps, and again these can all be pursued in parallel.

85
00:05:17,528 --> 00:05:21,877
And this obviously makes a GPU programmer very, very happy.

86
00:05:21,877 --> 00:05:23,929
Now that we know how this sorting network works,

87
00:05:23,929 --> 00:05:27,204
let's think about its performance when given different inputs.

88
00:05:27,204 --> 00:05:29,986
For each of the following possibilities with the same number of elements,

89
00:05:29,986 --> 00:05:33,324
what are the comparative runtimes in units of time?

90
00:05:33,324 --> 00:05:36,448
So a completely sorted sequence, how long does it take,

91
00:05:36,448 --> 00:05:40,531
an almost sorted sequence--just about sorted, maybe a couple elements off--

92
00:05:40,531 --> 00:05:44,756
a completely reversed sequence, or a completely random sequence?

93
00:05:44,756 --> 00:05:50,607
So here this would indicate that A would be the fastest, then B, then D, then C.

94
00:05:50,607 --> 00:05:53,445
So our choices are A, B, D, C;

95
00:05:53,445 --> 00:05:55,692
C is fastest, then D, B, A;

96
00:05:55,692 --> 00:05:57,862
A is fastest, then B, C, D;

97
00:05:57,862 --> 00:05:59,726
or they'll all take the same amount of time.
