1
00:00:00,000 --> 00:00:02,000
[Narrator] There are other problems with

2
00:00:02,000 --> 00:00:04,000
the search paradigm.

3
00:00:04,000 --> 00:00:08,000
The second one is that the tree could be very deep,

4
00:00:08,000 --> 00:00:10,000
and the reason is we might be able to

5
00:00:10,000 --> 00:00:13,000
circle forever in the area over here

6
00:00:13,000 --> 00:00:15,000
without reaching the goal state, and

7
00:00:15,000 --> 00:00:17,000
that makes for a very deep tree, and until

8
00:00:17,000 --> 00:00:20,000
we reach the goal state, we won't even know

9
00:00:20,000 --> 00:00:22,000
it's the best possible action.

10
00:00:22,000 --> 00:00:24,000
So conventional planning might have difficulties

11
00:00:24,000 --> 00:00:27,000
with basically infinite loops.

12
00:00:27,000 --> 00:00:30,000
The third problem is that many states

13
00:00:30,000 --> 00:00:32,000
recur in the search.

14
00:00:32,000 --> 00:00:34,000
In a star, we were careful

15
00:00:34,000 --> 00:00:37,000
to visit each state only once,

16
00:00:37,000 --> 00:00:40,000
but here because the actions might

17
00:00:40,000 --> 00:00:42,000
carry you back here to the same state,

18
00:00:42,000 --> 00:00:45,000
C1 is, for example, over here and over here.

19
00:00:45,000 --> 00:00:47,000
You might find that many states in the tree

20
00:00:47,000 --> 00:00:50,000
might be visited many, many different times.

21
00:00:50,000 --> 00:00:53,000
Now if you had a state it doesn't really matter how you got there.

22
00:00:53,000 --> 00:00:55,000
Yet, the tree doesn't understand this, and it

23
00:00:55,000 --> 00:00:58,000
might expand states more than once.

24
00:00:58,000 --> 00:01:00,000
These are the 3 problems

25
00:01:00,000 --> 00:01:04,000
that are overcome by our policy method,

26
00:01:04,000 --> 00:01:07,000
and this motivates in part by calculating policies

27
00:01:07,000 --> 00:01:09,000
is so much better of an idea than using

28
00:01:09,000 --> 00:01:12,000
conventional planning and still casting environments.

29
00:01:12,000 --> 99:59:59,999
So let's get back to the policy case.
