1
00:00:00,001 --> 00:00:03,537
Okay, so we've got these three little
bits of machine learning here.

2
00:00:03,537 --> 00:00:06,005
And there are a lot of tools and
techniques that are inside that.

3
00:00:06,005 --> 00:00:07,550
>> Mm-hm.
>> And I think that's great.

4
00:00:07,550 --> 00:00:09,870
And we're going to be trying to
teach you a lot of those tools and

5
00:00:09,870 --> 00:00:11,979
techniques and
sort of ways to connect them together.

6
00:00:11,979 --> 00:00:13,476
So by the way,
as Michael was pointing out,

7
00:00:13,476 --> 00:00:15,584
there are kind of ways that these
things might help each other,

8
00:00:15,584 --> 00:00:17,585
unsupervised learning might
help supervised learning.

9
00:00:17,585 --> 00:00:19,080
It's actually much deeper than that.

10
00:00:19,080 --> 00:00:21,817
It turns out you, even though
unsupervised learning is clearly not

11
00:00:21,817 --> 00:00:24,507
the same as supervised learning at
the level that we described it,

12
00:00:24,507 --> 00:00:26,394
in some ways they're
exactly the same thing.

13
00:00:26,394 --> 00:00:28,530
Supervised learning you have some bias.

14
00:00:28,530 --> 00:00:31,232
Oh, it's a quadratic function,
induction make sense.

15
00:00:31,232 --> 00:00:32,920
All these kind of assumptions you make.

16
00:00:32,920 --> 00:00:36,643
And in unsupervised learning, I told you
that we don't know whether this clusters

17
00:00:36,643 --> 00:00:40,258
is better than this cluster, dividing by
sex is better than dividing by height,

18
00:00:40,258 --> 00:00:41,709
or, or hair color or whatever.

19
00:00:41,709 --> 00:00:42,977
>> Mm.

20
00:00:42,977 --> 00:00:46,285
>> But ultimately you make some
decision about how to cluster, and

21
00:00:46,285 --> 00:00:49,050
that means implicitly
there's some assume signal.

22
00:00:49,050 --> 00:00:50,790
There's some assume set of labels
that you think make sense.

23
00:00:50,790 --> 00:00:54,722
Oh, I think things that look alike
should somehow be clustered together.

24
00:00:54,722 --> 00:00:55,289
>> Mm.

25
00:00:55,289 --> 00:00:57,810
>> Or things that are near one
another should cluster together.

26
00:00:57,810 --> 00:00:59,695
So in some ways it's still kind
of like supervised learning.

27
00:00:59,695 --> 00:01:00,694
You can certainly turn any

28
00:01:00,694 --> 00:01:03,481
supervised learning problem into
an unsupervised learning problem.

29
00:01:03,481 --> 00:01:04,031
>> Mm, mm.
>> Right?

30
00:01:04,031 --> 00:01:07,250
So in fact, all of these problems
are really the same kind of problem.

31
00:01:07,250 --> 00:01:08,536
>> Yeah, well there's two things
that I'd want to add to that.

32
00:01:08,536 --> 00:01:10,800
One is that in some sense,
in many cases,

33
00:01:10,800 --> 00:01:15,580
you can formulate all these different
problems as some form of optimization.

34
00:01:15,580 --> 00:01:17,778
In supervised learning
you want something that,

35
00:01:17,778 --> 00:01:21,178
that labels data well and so you're,
the thing you're trying to optimize is

36
00:01:21,178 --> 00:01:23,818
find me a function that,
that does that scores it.

37
00:01:23,818 --> 00:01:27,290
In reinforcement learning we're trying
to find a behavior that scores well.

38
00:01:27,290 --> 00:01:30,396
And unsu, unsupervised learning we
usually have to make up some kind of

39
00:01:30,396 --> 00:01:32,982
a criterion, and then we find
a way of clustering the data,

40
00:01:32,982 --> 00:01:34,929
organizing the data so
that it scores well.

41
00:01:34,929 --> 00:01:36,490
So that was the first
point I wanted to make.

42
00:01:36,490 --> 00:01:39,508
The other one is if you
divide things by sex and

43
00:01:39,508 --> 00:01:43,571
your a virgin then there's
numerical instability issues.

44
00:01:46,210 --> 00:01:48,409
>> Do you learn about
that on the street?

45
00:01:48,409 --> 00:01:50,011
>> I learned it in a Math book.

46
00:01:50,011 --> 00:01:54,281
>> Yes you [NOISE] I'm, I'm going to
move on And so here's the thing.

47
00:01:54,281 --> 00:01:55,722
>> All right.
>> Everything just Michael just

48
00:01:55,722 --> 00:01:57,800
said except the last part is true.

49
00:01:57,800 --> 00:01:59,887
But there's actually a sort of
deeper thing going on here.

50
00:01:59,887 --> 00:02:03,523
To me, if you think about the
commonalities of everything we've just

51
00:02:03,523 --> 00:02:07,420
said, it boils down to one thing data,
data, data, data, data, data.

52
00:02:07,420 --> 00:02:08,461
Data is king in machine learning.

53
00:02:08,461 --> 00:02:10,600
Now Michael would call
himself a computer scientist.

54
00:02:10,600 --> 00:02:11,429
>> Oh, yeah.
>> And I would call

55
00:02:11,429 --> 00:02:13,185
myself a computationalist.

56
00:02:13,185 --> 00:02:14,258
>> What?
>> What if I'm in a college of

57
00:02:14,258 --> 00:02:16,470
computing at a department
of computer science?

58
00:02:16,470 --> 00:02:19,940
I believe in computing and
computation as being the ultimate thing.

59
00:02:19,940 --> 00:02:22,073
So I would call myself
a computationalist, and

60
00:02:22,073 --> 00:02:25,980
Michael would probably agree with that
just to keep this discussion moving.

61
00:02:25,980 --> 00:02:26,747
>> Let's say.

62
00:02:26,747 --> 00:02:27,650
>> Right.

63
00:02:27,650 --> 00:02:28,450
So we're computationalists.

64
00:02:28,450 --> 00:02:29,880
We believe in computing.

65
00:02:29,880 --> 00:02:31,180
That's a good thing.
>> Sure.

66
00:02:31,180 --> 00:02:33,759
>> Many of our colleagues who do
computations tend to think in terms of

67
00:02:33,759 --> 00:02:34,321
algorithms.

68
00:02:34,321 --> 00:02:37,177
They think in terms of what
are the series of steps I

69
00:02:37,177 --> 00:02:39,560
need to do in order to
solve some problem?

70
00:02:39,560 --> 00:02:40,361
Or they.

71
00:02:40,361 --> 00:02:42,680
>> [CROSSTALK].
>> Might think in terms of theorems.

72
00:02:42,680 --> 00:02:45,277
If I try to describe this
problem in a particular way,

73
00:02:45,277 --> 00:02:47,601
is it solvable quizzically
by some algorithm?

74
00:02:47,601 --> 00:02:48,470
>> Yeah.

75
00:02:48,470 --> 00:02:50,337
>> And, truthfully,
machine learning is a lot of that.

76
00:02:50,337 --> 00:02:53,771
But the difference between the person
who's trying to solve our problem as

77
00:02:53,771 --> 00:02:55,569
an AI person or
as a computing person and

78
00:02:55,569 --> 00:02:59,005
somebody who's trying to solve our
problem as a machine learning person is

79
00:02:59,005 --> 00:03:02,416
that the algorithm stops being central,
the data starts being central.

80
00:03:02,416 --> 00:03:05,347
And so what I hope you get out of this
class, or at least part of the stuff

81
00:03:05,347 --> 00:03:08,082
that you do, is understanding that
you have to believe the data,

82
00:03:08,082 --> 00:03:11,740
you have to do something with the data,
you have to be consistent with the data.

83
00:03:11,740 --> 00:03:15,057
The algorithms that fall out of
all that are algorithms, but

84
00:03:15,057 --> 00:03:19,099
they're algorithms that take the data
as primary or at least important.

85
00:03:19,099 --> 00:03:20,902
>> I'm going to go with co-equal.

86
00:03:20,902 --> 00:03:22,369
>> So the algorithms and
data are co-equal.

87
00:03:22,369 --> 00:03:23,170
>> Co-equal.

88
00:03:23,170 --> 00:03:25,639
>> Well if you believe in Lisp,
they're the same thing.

89
00:03:25,639 --> 00:03:26,280
>> Exactly!

90
00:03:26,280 --> 00:03:26,941
>> All right.
So there you go.

91
00:03:26,941 --> 00:03:28,709
>> They knew back in the 70s.

92
00:03:28,709 --> 00:03:30,110
>> So
it turns out we do agree on most things.

93
00:03:30,110 --> 00:03:31,378
>> [NOISE] That was close.

94
00:03:31,378 --> 00:03:31,879
>> Excellent!

95
00:03:31,879 --> 00:03:36,283
So, the rest of the semester
will go exactly like this.

96
00:03:36,283 --> 00:03:38,620
>> [LAUGH].
>> [LAUGH] Except you won't see us.

97
00:03:38,620 --> 00:03:40,588
You'll see our hands though.

98
00:03:40,588 --> 00:03:41,255
>> This side.

99
00:03:41,255 --> 00:03:41,989
This side.

100
00:03:41,989 --> 00:03:43,190
>> You'll see our hands, though.

101
00:03:43,190 --> 00:03:45,025
Thank you, Michael.

102
00:03:45,025 --> 00:03:46,594
>> It's all right.

103
00:03:46,594 --> 00:03:48,762
>> [LAUGH] What?

104
00:03:48,762 --> 00:03:49,530
[LAUGH].

105
00:03:49,530 --> 00:03:50,965
>> What?
[LAUGH].

106
00:03:50,965 --> 00:03:53,100
>> That was good,
that took me back to when I was four.

107
00:03:53,100 --> 00:03:54,304
Okay, so.

108
00:03:54,304 --> 00:03:54,868
>> Senor Wences.

109
00:03:54,868 --> 00:03:55,836
>> Hm?
>> It's called SeÃ±or Wences.

110
00:03:55,836 --> 00:03:56,403
>> Yes, I know.

111
00:03:56,403 --> 00:03:57,404
>> Yeah, okay.
>> I remember that.

112
00:03:57,404 --> 00:03:58,112
>> Mm-hm, yeah.
>> I'm not

113
00:03:58,112 --> 00:03:59,173
that much younger than you are.

114
00:03:59,173 --> 00:03:59,940
>> Little bit.

115
00:03:59,940 --> 00:04:01,175
>> Ten, 12 years only.

116
00:04:01,175 --> 00:04:02,243
>> No come on.

117
00:04:02,243 --> 00:04:03,277
>> You can count gray hairs.

118
00:04:03,277 --> 00:04:07,036
Anyway the point is the rest of
the semester will go like this.

119
00:04:07,036 --> 00:04:10,084
We will talk about supervised learning
and a whole series of algorithms.

120
00:04:10,084 --> 00:04:13,423
Step back a little bit and talk about
the theory behind them, and try to

121
00:04:13,423 --> 00:04:16,935
connect theory of machine learning
with theory of computing notions, or

122
00:04:16,935 --> 00:04:18,535
at least that kind of basic idea.

123
00:04:18,535 --> 00:04:20,961
What does it mean to be a hard
problem versus an easier problem?

124
00:04:20,961 --> 00:04:24,273
Will move into randomized optimization
and unsupervised learning where we

125
00:04:24,273 --> 00:04:27,530
will talk about all the issues that we
brought up here and try to connect them

126
00:04:27,530 --> 00:04:31,025
back to some of the things that we did
in the section on supervised learning.

127
00:04:31,025 --> 00:04:33,974
And then finally, we will spend our
time on reinforcement learning.

128
00:04:33,974 --> 00:04:37,160
And a generalization of these
traditional reinforcement learning,

129
00:04:37,160 --> 00:04:38,870
which involves multiple agents.

130
00:04:38,870 --> 00:04:39,480
So we'll talk about a little bit of.

131
00:04:39,480 --> 00:04:40,354
>> Mm-hm.
>> Game theory,

132
00:04:40,354 --> 00:04:42,210
which Michael loves to talk about.

133
00:04:42,210 --> 00:04:42,883
I love to talk about.

134
00:04:42,883 --> 00:04:46,074
And the applications of all the stuff
that we've been learning to

135
00:04:46,074 --> 00:04:48,520
solving problems of how to
actually act in the world?

136
00:04:48,520 --> 00:04:50,225
How to build that world
out to do something?

137
00:04:50,225 --> 00:04:51,878
Or build that agent to play a game or

138
00:04:51,878 --> 00:04:55,600
to teach you how to do whatever you,
you need to be taught how to do?

139
00:04:55,600 --> 00:04:58,601
But at the end of the day,
we're going to teach you how to

140
00:04:58,601 --> 00:05:01,672
think about data,
how to think about algorithms, and

141
00:05:01,672 --> 00:05:04,571
how to build artifacts that you know,
will learn?

142
00:05:04,571 --> 00:05:05,970
>> Let's do this thing.

143
00:05:05,970 --> 00:05:07,174
>> Excellent.
All right.

144
00:05:07,174 --> 00:05:08,008
Well thank you Michael.

145
00:05:08,008 --> 00:05:08,842
>> Sure.

146
00:05:08,842 --> 00:05:13,314
>> I will see you next time we're
in the same place at the same time.
