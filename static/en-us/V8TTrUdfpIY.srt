1
00:00:00,000 --> 00:00:02,905
As we talk about algorithms, we're going to talk about 2 costs.

2
00:00:02,905 --> 00:00:07,483
The first is step complexity, and the second is work complexity.

3
00:00:07,483 --> 00:00:14,531
So as an example here we have 8 elements that we'd like to combine using this tree style structure.

4
00:00:14,531 --> 00:00:17,365
And so we're going to try to characterize the number of steps

5
00:00:17,365 --> 00:00:21,799
that it's going to take us to do this computation as well as the total amount of work.

6
00:00:21,799 --> 00:00:25,536
So first we're going to look at the number of steps.

7
00:00:25,536 --> 00:00:28,947
We see that it's going to take us 3 steps to finish.

8
00:00:28,947 --> 00:00:31,874
This first step here we'll do 4 operations,

9
00:00:31,874 --> 00:00:34,743
the second step can be done in parallel with 2 operations,

10
00:00:34,743 --> 00:00:38,455
and then the third step is a final operation to get a final result.

11
00:00:38,455 --> 00:00:41,639
But we can also count the total amount of work that we've done here.

12
00:00:41,639 --> 00:00:47,873
We've done 1, 2, 3, 4, 5, 6, 7 operations.

13
00:00:47,873 --> 00:00:53,922
So we'd say the step complexity is 3 and the work complexity is 7.

14
00:00:53,922 --> 00:00:58,136
So we'll compare the step and work complexity of the parallel implementations that we develop

15
00:00:58,136 --> 00:01:01,104
against the step and work complexity for a serial implementation.

16
00:01:01,104 --> 00:01:03,444
And 1 more piece of terminology.

17
00:01:03,444 --> 00:01:06,667
We will say that a parallel algorithm is work-efficient.

18
00:01:06,667 --> 00:01:09,248
If it's work complexity, it's asymptotically the same,

19
00:01:09,248 --> 00:01:13,066
so within a constant factor as the work complexity of the sequential algorithm.

20
00:01:13,066 --> 00:01:16,754
Now if we can reduce the step complexity in our parallel implementation

21
00:01:16,754 --> 00:01:18,655
compared to the serial implementation

22
00:01:18,655 --> 00:01:22,089
while still having a reasonable work complexity that isn't too expensive,

23
00:01:22,089 --> 00:01:25,128
we expect that this will lead to faster runtime overall.

24
00:01:25,128 --> 00:01:28,954
So the real key here is to formulate the most efficient parallel algorithm,

25
00:01:28,954 --> 00:01:31,968
and that's the focus of this lecture and the next lecture.
