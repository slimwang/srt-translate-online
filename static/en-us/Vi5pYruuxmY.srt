1
00:00:00,320 --> 00:00:01,950
Okay. So, Team Awesome, thanks so

2
00:00:01,950 --> 00:00:04,420
much for participating in our hackathon last week.

3
00:00:04,420 --> 00:00:06,490
We really loved your [LAUGH] project and

4
00:00:06,490 --> 00:00:09,810
we'll be providing it to our students in the course.

5
00:00:09,810 --> 00:00:13,530
So, I just wanted to know your process and

6
00:00:13,530 --> 00:00:16,000
how you arrived at your final typology.

7
00:00:16,000 --> 00:00:18,960
And how did you break up the work between your group?

8
00:00:18,960 --> 00:00:21,050
You had a group of six or seven.

9
00:00:21,050 --> 00:00:23,790
>> Basically, the idea is we were just thinking about what we

10
00:00:23,790 --> 00:00:27,350
can do that's nice or useful.

11
00:00:27,350 --> 00:00:31,160
And then, after we came up with a few ideas,

12
00:00:31,160 --> 00:00:34,180
we thought of something that would fit well together.

13
00:00:34,180 --> 00:00:37,320
>> I guess we started kind of brainstorming on what

14
00:00:37,320 --> 00:00:39,170
kind of cool things we could visualize.

15
00:00:39,170 --> 00:00:43,250
We first went to the D3 repository and saw various things.

16
00:00:43,250 --> 00:00:45,520
And, we saw a map and thought, well, you know,

17
00:00:45,520 --> 00:00:49,010
Twitter, we can perhaps correlate location based information.

18
00:00:49,010 --> 00:00:52,360
And, we wanted to have something really pretty to look at at the end.

19
00:00:52,360 --> 00:00:54,990
so, I guess that's kind of how we started and kind of,

20
00:00:54,990 --> 00:01:00,620
looked at what the tweets kind of, contained and see any emoticons, hashtags.

21
00:01:00,620 --> 00:01:04,510
In short sentences, so thinking what one can do with that information.

22
00:01:04,510 --> 00:01:06,200
>> We kind of took the original spell and

23
00:01:06,200 --> 00:01:09,070
we did some, we added some functionality to it.

24
00:01:09,070 --> 00:01:12,390
One thing that we did is we did a sentiment analyzer.

25
00:01:12,390 --> 00:01:16,010
We put a sentiment analyzer in the spell to give a sentiment for

26
00:01:16,010 --> 00:01:17,710
the tweet, original tweet.

27
00:01:17,710 --> 00:01:19,890
We also put in a few filters in the spells.

28
00:01:19,890 --> 00:01:24,130
So, one thing we did is we are only, since the map is only for

29
00:01:24,130 --> 00:01:24,750
the United States,

30
00:01:24,750 --> 00:01:28,630
so we added a filter only located in the United States region.

31
00:01:28,630 --> 00:01:30,650
And, we also have another filter.

32
00:01:31,990 --> 00:01:35,810
Since we're very interested in, you know, putting this on a map, we only get,

33
00:01:35,810 --> 00:01:39,610
we're only getting tweets that has a latitude and longitude information.

34
00:01:39,610 --> 00:01:40,890
>> So, you checked whether or

35
00:01:40,890 --> 00:01:43,480
not it existed and then made sure that it was in the region.

36
00:01:43,480 --> 00:01:47,650
And then, ran sentiment on the entire Tweet coming out of the spout.

37
00:01:47,650 --> 00:01:48,190
>> Yeah.

38
00:01:48,190 --> 00:01:51,710
>> Did you think of putting the sentiment analyzer in to its own bolt?

39
00:01:51,710 --> 00:01:54,360
Or, was it just more efficient or,

40
00:01:54,360 --> 00:01:57,746
was that something that or Chris, recommended?

41
00:01:57,746 --> 00:02:00,260
>> So, we originally did try that.

42
00:02:00,260 --> 00:02:04,598
And then, I think that to initialize the sentiment analyzer it requires I

43
00:02:04,598 --> 00:02:07,870
think a couple hundreds of megabytes of memory.

44
00:02:07,870 --> 00:02:11,530
And, since we're using a virtual cluster and we have, you know,

45
00:02:11,530 --> 00:02:16,140
maybe 10 instance of the bolts we don't have enough memory to actually do that.

46
00:02:16,140 --> 00:02:17,620
So, we put in the spout instead.

47
00:02:17,620 --> 00:02:22,210
I know it's kind of like a bottleneck now because sentiment analyzer,

48
00:02:22,210 --> 00:02:25,450
it takes time to give, score each, tweet.

49
00:02:25,450 --> 00:02:30,120
But, you know, given, given the constraint that's, that's where we end up.

50
00:02:30,120 --> 00:02:35,220
The parse tweet, bolt, we're doing the filtering on the skip words, so we took

51
00:02:35,220 --> 00:02:40,000
out all the pronouns, and, you know, articles that we are not interested in.

52
00:02:40,000 --> 00:02:44,155
So, we filter them out, and then send them to the next next spout.

53
00:02:45,290 --> 00:02:49,890
And, the next one next bolt is called info bolt and

54
00:02:49,890 --> 00:02:54,100
this is the bolt that does the emoticon analysis.

55
00:02:54,100 --> 00:02:57,430
So, this one takes in the tweet from the previous bolt and

56
00:02:57,430 --> 00:03:02,660
then it then it maps each emoticon it sees to cinnamon score so

57
00:03:02,660 --> 00:03:04,970
a happy face would be like, a large number.

58
00:03:04,970 --> 00:03:08,170
And then, a sad face would be a pretty small number.

59
00:03:08,170 --> 00:03:10,420
But, that's kind of the scale that we went with.

60
00:03:10,420 --> 00:03:12,640
Now, the next bolt is called top-words.

61
00:03:12,640 --> 00:03:14,480
So, starting from this bolt,

62
00:03:14,480 --> 00:03:19,170
we are looking at information that are only grouped by the county ID, county_id.

63
00:03:19,170 --> 00:03:24,120
So, all the, just the tweets that go to a single bolt,

64
00:03:24,120 --> 00:03:27,550
they have a sort of pretty consistent set of counties and, that way,

65
00:03:27,550 --> 00:03:29,480
we can aggregate the stats for them.

66
00:03:29,480 --> 00:03:33,940
And, in the top-words bolt, you did aggregation on the stats for, you know,

67
00:03:33,940 --> 00:03:36,440
the most frequent tweets,

68
00:03:36,440 --> 00:03:40,610
say we're also doing some manipulation with the sentiment score,

69
00:03:40,610 --> 00:03:45,030
where we combine the emoticon sentiments and the tweet sentiments.

70
00:03:45,030 --> 00:03:48,128
And, the report-bolt, that's the last bolt that we have.

71
00:03:48,128 --> 00:03:52,390
For this bolt, I did more processing on the final sentiment, you know,

72
00:03:52,390 --> 00:03:53,510
the moving average for

73
00:03:53,510 --> 00:03:58,760
the sentiment score, and also send the sentiment score to the D3 map.
