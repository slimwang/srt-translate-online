1
00:00:00,340 --> 00:00:04,129
Before jumping into the code let's
quickly review the components

2
00:00:04,129 --> 00:00:05,887
of a Markov decision process,

3
00:00:05,887 --> 00:00:09,754
or MDP, and see how they are implemented
using the BURLAP library.

4
00:00:09,754 --> 00:00:14,860
The first component of an MDP is a set
of states S that the system can be in.

5
00:00:14,860 --> 00:00:19,650
Associated to each state S,
in S, is a set of actions A(s),

6
00:00:19,650 --> 00:00:22,470
that can be taken at the state,
little s.

7
00:00:22,470 --> 00:00:27,360
Additionally, there is
a transition function T(s,a,s'),

8
00:00:27,360 --> 00:00:31,440
that gives the probability
that if we are in state s, and

9
00:00:31,440 --> 00:00:35,650
take action a,
that we end up in state s prime.

10
00:00:35,650 --> 00:00:37,930
Finally, there is a reward function.

11
00:00:37,930 --> 00:00:44,090
R(s,a,s'), which gives
the reward we attain by taking

12
00:00:44,090 --> 00:00:50,450
action a at state s and
ending up in state s prime.

13
00:00:50,450 --> 00:00:54,790
Recall that it is sometimes more natural
to express the reward as a function of

14
00:00:54,790 --> 00:01:00,300
just s and a, or even as a function
of just the initial state, s.

15
00:01:01,420 --> 00:01:05,921
We will use the most general form,
R(s,a,s') in this

16
00:01:05,921 --> 00:01:11,220
tutorial since reward functions are
implemented in BURLAP in this manner.

17
00:01:11,220 --> 00:01:16,280
A terminal state is a state in which
no further agent action is possible.

18
00:01:16,280 --> 00:01:20,220
After entering the terminal state
an agent receives no more reward for

19
00:01:20,220 --> 00:01:21,880
the rest of time.

20
00:01:21,880 --> 00:01:26,750
In lecture, we did not define terminal
states as a component of an MDP,

21
00:01:26,750 --> 00:01:31,210
because they can be considered states
without any associated actions.

22
00:01:31,210 --> 00:01:32,392
However, in BURLAP,

23
00:01:32,392 --> 00:01:36,500
we will have the capability to
specially denote terminal states.

24
00:01:36,500 --> 00:01:39,790
So it is good to keep this concept
in mind as we build our MDP.
