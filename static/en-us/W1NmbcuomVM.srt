1
00:00:00,200 --> 00:00:02,950
In architecting the data store and the computational

2
00:00:02,950 --> 00:00:06,670
resources that back the data store at a server,

3
00:00:06,670 --> 00:00:09,300
the system administrator has a choice of either

4
00:00:09,300 --> 00:00:12,930
replicating or partitioning the data. If you replicating the

5
00:00:12,930 --> 00:00:15,710
data what that means is. That every data

6
00:00:15,710 --> 00:00:19,090
server has the full corpus of data that is

7
00:00:19,090 --> 00:00:22,030
needed to serve a particular request. Think of it

8
00:00:22,030 --> 00:00:25,740
as say, gmail. If it is gmail, then if

9
00:00:25,740 --> 00:00:28,010
a gmail request gets sent to anyone of

10
00:00:28,010 --> 00:00:30,920
these servers. They can handle the request that comes

11
00:00:30,920 --> 00:00:33,510
in because they have the full corpus of data

12
00:00:33,510 --> 00:00:36,640
to deal with a incoming request. We mentioned that

13
00:00:36,640 --> 00:00:39,940
failures are inevitable in giant scale services because

14
00:00:39,940 --> 00:00:44,550
of the number of computation elements that live within

15
00:00:44,550 --> 00:00:47,790
a data center. If failures occur, what happens when

16
00:00:47,790 --> 00:00:51,430
we have replicated data? What they means is that

17
00:00:51,430 --> 00:00:54,450
the harvest is going to be unchanged because if

18
00:00:54,450 --> 00:00:57,910
some data repository is failed. Because it is

19
00:00:57,910 --> 00:01:01,520
replicated, we can redirect a client's request to

20
00:01:01,520 --> 00:01:04,640
another live server that has full access to

21
00:01:04,640 --> 00:01:07,890
the later repository and therefore the harvest that

22
00:01:07,890 --> 00:01:10,450
you're going to get with replication in 100%, it

23
00:01:10,450 --> 00:01:13,770
is unaffected. On the other hand because the

24
00:01:13,770 --> 00:01:16,400
server capacity has come down due to these failures,

25
00:01:16,400 --> 00:01:18,440
the heal is going to come down. In other

26
00:01:18,440 --> 00:01:22,550
words, with replication. The service is unavailable for

27
00:01:22,550 --> 00:01:27,370
some users for some amount of time. But all the users that are able to get the

28
00:01:27,370 --> 00:01:30,420
service, get complete harvest in term of the

29
00:01:30,420 --> 00:01:34,810
fidelity for the query that is returned and answered

30
00:01:34,810 --> 00:01:37,570
by the server. The other alternative of course

31
00:01:37,570 --> 00:01:41,780
for architecting the internal data depository of the server

32
00:01:41,780 --> 00:01:43,770
is to partition the data. So if you

33
00:01:43,770 --> 00:01:46,370
partition the data, and lets say that There are

34
00:01:46,370 --> 00:01:49,110
end partitions of the full compass of data. And

35
00:01:49,110 --> 00:01:53,880
let's say that some of the service fail, then

36
00:01:53,880 --> 00:01:57,570
some portion of the corpus of data becomes unavailable.

37
00:01:57,570 --> 00:02:00,860
If this happens, what it means is that the

38
00:02:00,860 --> 00:02:03,400
harvest is going to be done because some portion of

39
00:02:03,400 --> 00:02:07,270
the data corpus. Is unavailable, and therefore the harvest

40
00:02:07,270 --> 00:02:12,050
is going to come down, but it is possible to keep Q unchanged, so long as the

41
00:02:12,050 --> 00:02:15,750
computation capacity is unchanged. Then we can serve

42
00:02:15,750 --> 00:02:19,560
the same number of user community. It's just that

43
00:02:19,560 --> 00:02:25,290
the fidelity of the result may not be as good as when All of the data corpuses

44
00:02:25,290 --> 00:02:28,520
available. For example, if this is a server

45
00:02:28,520 --> 00:02:32,660
that is serving search results and if some portion

46
00:02:32,660 --> 00:02:35,670
of the data repository is unavailable. In

47
00:02:35,670 --> 00:02:39,120
that case, each query that comes in will

48
00:02:39,120 --> 00:02:42,800
get service, but it is going to get. A

49
00:02:42,800 --> 00:02:45,280
subset of the query results for the search

50
00:02:45,280 --> 00:02:48,060
that they are doing. So the important message

51
00:02:48,060 --> 00:02:50,230
that I want to convey through these pictures

52
00:02:50,230 --> 00:02:54,680
is that dq is independent of whether we

53
00:02:54,680 --> 00:02:58,000
are replicating or we are partitioning the data.

54
00:02:58,000 --> 00:03:01,180
Given a certain server capacity, The D Qs

55
00:03:01,180 --> 00:03:03,840
are constant, because we are assuming that this

56
00:03:03,840 --> 00:03:06,682
is cheap. This space is cheap and therefore

57
00:03:06,682 --> 00:03:09,856
processing incoming requests are not disc bound, but

58
00:03:09,856 --> 00:03:13,770
it is network bound. The only exception is

59
00:03:13,770 --> 00:03:17,190
if the queries Result in significant in right

60
00:03:17,190 --> 00:03:20,100
traffic to the disk. Now this is rare

61
00:03:20,100 --> 00:03:22,940
in giant scale services. But if that happens,

62
00:03:22,940 --> 00:03:28,780
then replication may require more DQ than partitioning. But as a first order of

63
00:03:28,780 --> 00:03:32,110
approximation, so long as we assume that

64
00:03:32,110 --> 00:03:37,060
giant scale services are serving client requests which

65
00:03:37,060 --> 00:03:42,530
are network bound, The DQ is independent of the strategy that is used by the

66
00:03:42,530 --> 00:03:45,190
system administrator for managing the data whether

67
00:03:45,190 --> 00:03:48,210
it is replication or partitioning. Now what this

68
00:03:48,210 --> 00:03:51,000
also means is that this is giving

69
00:03:51,000 --> 00:03:54,470
an object lesson to the system administrator. In

70
00:03:54,470 --> 00:03:57,720
saying that beyond a certain point, you

71
00:03:57,720 --> 00:04:02,210
probably want to replicate and partition. Why? Because

72
00:04:02,210 --> 00:04:04,850
failures are bound to happen, and a

73
00:04:04,850 --> 00:04:07,970
failures are bound to happen if you partition

74
00:04:07,970 --> 00:04:10,540
the data, then a portion of the

75
00:04:10,540 --> 00:04:13,890
data corpus becomes unavailable. On the other hand,

76
00:04:13,890 --> 00:04:17,149
if beyond a certain point Even if

77
00:04:17,149 --> 00:04:19,470
you have partitioned data, if you replicate it,

78
00:04:19,470 --> 00:04:25,350
then you're making sure that, even if one replica is down, some of the replica,

79
00:04:25,350 --> 00:04:28,580
of the same partition is available for

80
00:04:28,580 --> 00:04:32,260
serving a particular client request. And replication, beyond

81
00:04:32,260 --> 00:04:35,620
a certain point is important because Users would

82
00:04:35,620 --> 00:04:39,570
normally prefer complete data or a complete harvest.

83
00:04:39,570 --> 00:04:42,880
Take for instance, you're accessing your email through

84
00:04:42,880 --> 00:04:46,250
the Internet. You would rather put up with

85
00:04:46,250 --> 00:04:48,780
a service being unavailable for some amount of

86
00:04:48,780 --> 00:04:53,180
time rather than seeing that you only have access

87
00:04:53,180 --> 00:04:55,700
to a portion of your main box. And

88
00:04:55,700 --> 00:04:58,420
that's the reason why replication beyond a certain

89
00:04:58,420 --> 00:05:01,580
point is better for dealing with giant scale

90
00:05:01,580 --> 00:05:04,650
services. On the other hand, for searches, it may

91
00:05:04,650 --> 00:05:07,190
be okay to have a harvest which

92
00:05:07,190 --> 00:05:11,350
is not complete. So in structuring different services

93
00:05:11,350 --> 00:05:17,650
as a giant scale service, one has to make a decision. Of whether partitioning is

94
00:05:17,650 --> 00:05:22,320
the right approach or at what point we may want to partition and then replicate

95
00:05:22,320 --> 00:05:25,800
as well. As a concrete example, Inktomi which

96
00:05:25,800 --> 00:05:29,680
is a CDN server uses partial replication It

97
00:05:29,680 --> 00:05:35,070
uses full replication for email because of what I just said, and that is

98
00:05:35,070 --> 00:05:40,230
a user would expect complete harvest for a service like email.

99
00:05:40,230 --> 00:05:42,960
But on the other hand, if it is a web cache that is

100
00:05:42,960 --> 00:05:48,740
being implemented as giant-scale service, it is okay if it is not replicated.
