1
00:00:00,000 --> 00:00:03,000
Here is one of my favorite examples of unsupervised learning--

2
00:00:03,000 --> 00:00:05,000
one that is yet unsolved.

3
00:00:05,000 --> 00:00:08,000
At Google, I had the opportunity to participate--

4
00:00:08,000 --> 00:00:10,000
in the building of Street View,

5
00:00:10,000 --> 00:00:13,000
which is a huge photographic database--

6
00:00:13,000 --> 00:00:16,000
of many, many streets in the world.

7
00:00:16,000 --> 00:00:18,000
As you dive into Street View--

8
00:00:18,000 --> 00:00:20,000
you can get ground imagery--

9
00:00:20,000 --> 00:00:23,000
of almost any location in the world--

10
00:00:23,000 --> 00:00:26,000
like this house here, that I chose at random.

11
00:00:26,000 --> 00:00:29,000
In these images, there is vast regularities.

12
00:00:29,000 --> 00:00:31,000
You can go somewhere else--

13
00:00:31,000 --> 00:00:33,000
and you'll find that the type of objects--

14
00:00:33,000 --> 00:00:35,000
visible in Street View--

15
00:00:35,000 --> 00:00:37,000
is not entirely random.

16
00:00:37,000 --> 00:00:39,000
For example, there is many images of homes--

17
00:00:39,000 --> 00:00:41,000
many images of cars--

18
00:00:41,000 --> 00:00:44,000
trees, pavement, lane markers--

19
00:00:44,000 --> 00:00:47,000
stop sign, just to name a few.

20
00:00:47,000 --> 00:00:52,000
So one of the fascinating, unsolved, unsupervised learning tasks is:

21
00:00:52,000 --> 00:00:55,000
Can you take hundreds of billions of images--

22
00:00:55,000 --> 00:00:58,000
as comprised in the Street View data set--

23
00:00:58,000 --> 00:01:01,000
and discover from it that there are concepts such as--

24
00:01:01,000 --> 00:01:05,000
trees, lane markers, stop signs, cars, and pedestrians?

25
00:01:05,000 --> 00:01:07,000
It seems to be tedious to hand label each image--

26
00:01:07,000 --> 00:01:09,000
for the occurrence of such objects.

27
00:01:09,000 --> 00:01:11,000
And attempts to do so--

28
00:01:11,000 --> 00:01:14,000
has resulted in very small image data sets.

29
00:01:14,000 --> 00:01:16,000
Humans can learn from data--

30
00:01:16,000 --> 00:01:18,000
even without explicit target labels.

31
00:01:18,000 --> 00:01:20,000
We often just observe.

32
00:01:20,000 --> 00:01:23,000
In observing, we apply unsupervised learning techniques.

33
00:01:23,000 --> 00:01:27,000
So one of the great, great open questions of artificial intelligence is:

34
00:01:27,000 --> 00:01:32,000
Can you observe many intersections and many streets and many roads--

35
00:01:32,000 --> 00:01:35,000
and learn from it what concepts are contained in the imagery?

36
00:01:35,000 --> 00:01:39,000
Of course, I can't teach you anything as complex in this class.

37
00:01:39,000 --> 00:01:41,000
I don't even know the answer myself.

38
00:01:41,000 --> 00:01:43,000
So let me start with something simple.

39
00:01:43,000 --> 00:01:47,000
Clustering. Clustering is the most basic form of unsupervised learning.

40
00:01:47,000 --> 00:01:50,000
And I will tell you about two algorithms that are very related.

41
00:01:50,000 --> 00:01:52,000
One is called k-means,

42
00:01:52,000 --> 00:01:55,000
one is called expectation maximization.

43
00:01:55,000 --> 00:01:59,000
K-means is a nice, intuitive algorithm to derive clusterings.

44
00:01:59,000 --> 00:02:02,000
Expectation maximization is a probabilistic--

45
00:02:02,000 --> 00:02:04,000
generalization of k-means.

46
00:02:04,000 --> 99:59:59,999
They were derived from first principles.
