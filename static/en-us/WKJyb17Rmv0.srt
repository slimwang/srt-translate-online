1
00:00:00,024 --> 00:00:02,292
So, let's take a closer look at the code, line by line,

2
00:00:02,292 --> 00:00:05,169
so we can all be sure we know what each call does.

3
00:00:05,169 --> 00:00:07,491
We're going to walk through the CPU code first.

4
00:00:07,491 --> 00:00:12,891
The first thing we're going to do is declare the size of the array and determine how many bytes it uses.

5
00:00:12,891 --> 00:00:16,761
We then fill it up in this loop with floating point numbers,

6
00:00:16,781 --> 00:00:19,662
where array element i is simply set to i.

7
00:00:19,662 --> 00:00:23,168
All of this is standard C, nothing GPU-specific so far.

8
00:00:23,168 --> 00:00:25,921
One thing to note, though, is a common Cuda convention.

9
00:00:25,921 --> 00:00:35,487
Data on the CPU, the host, starts with h underscore. Data on the GPU, the device, starts with d underscore.

10
00:00:35,487 --> 00:00:38,547
This is just a convention. You can name your variables anything you want.

11
00:00:38,547 --> 00:00:42,296
But naming variables in this way helps you avoid the single most common beginner

12
00:00:42,296 --> 00:00:48,334
error in Cuda, where you try to access a piece of data on the CPU from the GPU, or vice versa.

13
00:00:48,334 --> 00:00:51,131
If you're accessing data through a pointer on the CPU,

14
00:00:51,131 --> 00:00:55,352
your pointer better point to something in CPU memory, or you're going to have a bad time.

15
00:00:55,352 --> 00:01:00,702
Same thing for the GPU. You'll find lots of Cuda code that you see uses this convention.

16
00:01:00,702 --> 00:01:02,725
So, let's scroll up just a little bit.

17
00:01:04,831 --> 00:01:09,608
And the first interesting thing that you see is how to declare a pointer on the GPU.

18
00:01:09,608 --> 00:01:14,494
It looks just like a pointer declared on the CPU. It's just a float star.

19
00:01:14,494 --> 00:01:20,979
Now to tell Cuda that your data is actually on the GPU, not the CPU, look at the next 2 lines.

20
00:01:20,979 --> 00:01:26,418
We're using cudaMalloc with 2 arguments, the pointer and the number of bytes to allocate.

21
00:01:26,418 --> 00:01:30,252
CudaMalloc means allocate the data on the GPU,

22
00:01:30,252 --> 00:01:33,758
whereas a plain Malloc would mean allocate the data on the CPU.

23
00:01:33,758 --> 00:01:37,537
The next thing we do is actually copy the data from the CPU,

24
00:01:37,537 --> 00:01:43,005
the array h underscore in on to the GPU, the array d underscore in.

25
00:01:43,005 --> 00:01:47,744
This call is cudamMemcpy--it's just like a regular Memcpy, but it takes

26
00:01:47,744 --> 00:01:52,101
4 arguments instead of 3. The first 3 arguments are the same as

27
00:01:52,101 --> 00:01:57,381
regular C Memcpy, the destination, the source, and the number of bytes.

28
00:01:57,381 --> 00:02:00,256
The fourth argument says the direction of the transfer.

29
00:02:00,256 --> 00:02:05,746
The 3 choices are Cuda memory host to device, Cuda memory device to host,

30
00:02:05,746 --> 00:02:08,695
and Cuda memory device to device.
