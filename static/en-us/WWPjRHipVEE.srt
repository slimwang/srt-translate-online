1
00:00:00,080 --> 00:00:04,300
Now that we know what the purpose of the
cache is, and how big approximately it

2
00:00:04,300 --> 00:00:08,240
needs to be, let's look at how
it is organized internally.

3
00:00:08,240 --> 00:00:12,630
The question we need to ask ourselves is
how do we determine if we have a hit or

4
00:00:12,630 --> 00:00:16,560
miss, so we need to know what
data do we have in the cache and

5
00:00:16,560 --> 00:00:19,510
then when the processor gives us
an address, we need to determine whether

6
00:00:19,510 --> 00:00:23,580
that data is or is not in the cache and
we need to do that very quickly.

7
00:00:23,580 --> 00:00:26,910
And the other important question is,
how do we determine

8
00:00:26,910 --> 00:00:30,500
what to kick out from the cache,
once we are out of room in it, and

9
00:00:30,500 --> 00:00:34,390
we need to put more stuff in it,
because we are just having a cache miss.

10
00:00:34,390 --> 00:00:39,860
So, for the first question of, how do we
know whether we have a hit or a miss.

11
00:00:39,860 --> 00:00:41,889
We want something that is very fast.

12
00:00:42,970 --> 00:00:47,050
That means it needs to be a table of
some sort that we can quickly index

13
00:00:47,050 --> 00:00:51,900
with some bits of the address and it
tells us what we have in the cache and

14
00:00:51,900 --> 00:00:55,140
if we do have what we are looking for
then it gives us the data.

15
00:00:55,140 --> 00:00:58,500
So conceptually, the cache is a table

16
00:00:58,500 --> 00:01:02,610
which we index with some bits that we
take from the address of the data.

17
00:01:03,790 --> 00:01:07,770
So some stuff here needs to tell
us whether we have a hit and

18
00:01:07,770 --> 00:01:12,340
the rest of the stuff here is the data
we want if we do have the hit.

19
00:01:12,340 --> 00:01:17,380
How much data we have in each cache
entry is called the block size or

20
00:01:17,380 --> 00:01:21,940
the line size, because the entry in
the cache is also called a line and

21
00:01:21,940 --> 00:01:25,330
they tell us how many bytes
are in each of these entries.

22
00:01:25,330 --> 00:01:28,140
If we have only one byte per entry,

23
00:01:28,140 --> 00:01:31,340
then every address will map
to different to entries.

24
00:01:31,340 --> 00:01:32,970
If you have a block size of one,

25
00:01:32,970 --> 00:01:36,050
that means the entry in
the cache is only one byte.

26
00:01:36,050 --> 00:01:39,430
Every single byte address
will have a different entry.

27
00:01:39,430 --> 00:01:41,510
That creates several problems.

28
00:01:41,510 --> 00:01:47,150
One, usually the processor can issue
accesses not only to a single byte, but

29
00:01:47,150 --> 00:01:51,490
also for example, loadward and storeward
will access a four byte location.

30
00:01:51,490 --> 00:01:52,860
So for a single access,

31
00:01:52,860 --> 00:01:57,040
now we would need to look up four
different lines in the cache.

32
00:01:57,040 --> 00:01:59,730
That complicates and
slows down the cache a lot, so

33
00:01:59,730 --> 00:02:02,960
we definitely don't want
the block size to be this small.

34
00:02:02,960 --> 00:02:07,660
We want the block size to be at
least as large as the largest

35
00:02:07,660 --> 00:02:09,410
single access that we
can do in the cache.

36
00:02:10,758 --> 00:02:15,037
And hopefully slightly larger then that,
just so that when we do a loadward or

37
00:02:15,037 --> 00:02:18,560
storeward we find the data in the same
cache block most of the time.

38
00:02:18,560 --> 00:02:21,780
The next thing that we want to
consider when deciding the block size,

39
00:02:21,780 --> 00:02:24,080
is spatial locality.

40
00:02:24,080 --> 00:02:26,640
If we miss in the cache on one axis,

41
00:02:26,640 --> 00:02:32,080
we will bring in an entire block
worth of memory stuff into the cache.

42
00:02:32,080 --> 00:02:34,720
So if there is no spacial locality,

43
00:02:34,720 --> 00:02:38,690
we want to bring in just what
we are currently accessing.

44
00:02:38,690 --> 00:02:41,170
But if there is any spacial locality,

45
00:02:41,170 --> 00:02:44,930
we want to bring more than
what we are just accessing.

46
00:02:44,930 --> 00:02:50,470
So typically, block sizes of
32 to 128 bytes work well,

47
00:02:50,470 --> 00:02:54,430
both from the perspective of their
larger than a typical access.

48
00:02:54,430 --> 00:02:59,960
And also they capture much of the
spacial locality that exist in programs.

49
00:02:59,960 --> 00:03:05,050
Now let's look at block sizes of
something like 1KB, in that case

50
00:03:05,050 --> 00:03:10,150
what happens is we fetch a lot of data
from memory every time we have a miss,

51
00:03:10,150 --> 00:03:14,350
and if there is not enough locality
a lot of the data will not be used, so

52
00:03:14,350 --> 00:03:16,970
we are occupying space in our cache.

53
00:03:16,970 --> 00:03:21,120
Remember that the cache is only
16 to 64 of these kilobytes.

54
00:03:21,120 --> 00:03:23,990
So if we bring in a block like this,

55
00:03:23,990 --> 00:03:28,460
we are consuming a significant part
of the overall space in the cache.

56
00:03:28,460 --> 00:03:32,400
And we are doing it probably with
data that we won't use much.

57
00:03:32,400 --> 00:03:35,230
So it turns out that for
level one caches at least,

58
00:03:35,230 --> 00:03:38,140
we don't want the block
size to be too large.

59
00:03:38,140 --> 00:03:43,290
So block sizes of 32 to 128
kilobytes are a balance between

60
00:03:43,290 --> 00:03:47,010
getting use of spacial locality
when we bring stuff in,

61
00:03:47,010 --> 00:03:50,650
versus not being dependent
too much on there being

62
00:03:50,650 --> 00:03:54,130
a lot of spacial locality because some
programs don't have that much of it.
