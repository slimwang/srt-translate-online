1
00:00:00,012 --> 00:00:02,180
>> All right. So we should take a moment to define

2
00:00:02,180 --> 00:00:04,530
inductive learning. So inductive learning is

3
00:00:04,530 --> 00:00:05,920
learning from examples. It's the kind

4
00:00:05,920 --> 00:00:09,410
of learning problem that we've been looking at the whole time, But

5
00:00:09,410 --> 00:00:11,932
we haven't been very precise about all the various quantities that we

6
00:00:11,932 --> 00:00:14,940
want to be able to talk about. So the number of properties

7
00:00:14,940 --> 00:00:17,710
that we actually need to be thinking about when we go and

8
00:00:17,710 --> 00:00:21,910
define what an inductive learning problem is, and measure what an inductive

9
00:00:21,910 --> 00:00:25,020
learning algorithm does. So one of them is just a simple thing

10
00:00:25,020 --> 00:00:27,950
like, what's the probability that the training is actually is going

11
00:00:27,950 --> 00:00:29,938
work. You know, whatever it is that it's trying to produce,

12
00:00:29,938 --> 00:00:33,610
it may be that in some cases, because the data is

13
00:00:33,610 --> 00:00:35,740
really noisy or just you know, got a, got a bad set

14
00:00:35,740 --> 00:00:39,230
of data, it might not actually work. So, we generally talk

15
00:00:39,230 --> 00:00:44,550
about a quantity like 1 minus delta as the probability of success.

16
00:00:44,550 --> 00:00:46,600
Delta here obviously is a probability of failure and this is

17
00:00:46,600 --> 00:00:50,670
just 1 minus that. There's also issues like the number of examples

18
00:00:50,670 --> 00:00:54,292
to train on. How many, how much data does the does the algorithm

19
00:00:54,292 --> 00:00:56,760
get to see? . Is there a letter you like for that, Charles?

20
00:00:58,030 --> 00:00:58,290
>> no.

21
00:00:58,290 --> 00:00:58,880
>> Okay.

22
00:00:58,880 --> 00:01:00,180
>> Is there a letter you like?

23
00:01:00,180 --> 00:01:02,700
>> I don't know, sometimes I like M for number of samples. But I thought

24
00:01:02,700 --> 00:01:05,860
maybe you went, you would want N because, you know, things tend to grow with N.

25
00:01:05,860 --> 00:01:07,600
>> Yeah. I did want N, but then I thought well,

26
00:01:07,600 --> 00:01:09,488
we can't use N because we use N for everything else.

27
00:01:09,488 --> 00:01:13,290
>> [LAUGH] Fair enough. There's also something that we really

28
00:01:13,290 --> 00:01:16,220
haven't talked about yet, but you could imagine that the complexity

29
00:01:16,220 --> 00:01:18,140
of the hypothesis class might matter. Why, why

30
00:01:18,140 --> 00:01:20,430
do you think that could come into play, Charles?

31
00:01:20,430 --> 00:01:22,560
>> Well, if you don't have a very

32
00:01:22,560 --> 00:01:26,280
complex hypothesis class, then there's some things, well,

33
00:01:26,280 --> 00:01:27,490
do you mean the complexity of the class

34
00:01:27,490 --> 00:01:29,690
or the complexity of the hypotheses in the class?

35
00:01:29,690 --> 00:01:31,880
>> That's a good question. Do we mean the complexity of the

36
00:01:31,880 --> 00:01:34,880
class or the complexity of the hypotheses in the class? Well it

37
00:01:34,880 --> 00:01:38,120
depends on how we measure complexity. But the complexity of the class

38
00:01:38,120 --> 00:01:41,880
could be like the sum of the complexities of all the hypotheses

39
00:01:41,880 --> 00:01:43,270
in the class, so it could be both.

40
00:01:43,270 --> 00:01:47,550
>> Hm. Well if, if you mean, you know, a hypothesis class is complex if

41
00:01:47,550 --> 00:01:51,640
it has very complex hypotheses, then you can say, well, if you have a hypothesis

42
00:01:51,640 --> 00:01:54,470
class that can't represent much, then it

43
00:01:54,470 --> 00:01:56,870
will be hard for you to, well, represent

44
00:01:56,870 --> 00:01:57,500
much. It will be hard for you

45
00:01:57,500 --> 00:02:00,320
to learn anything complicated. So that could matter.

46
00:02:00,320 --> 00:02:03,360
>> Sure. That's right. Now, could you see a downside to having

47
00:02:03,360 --> 00:02:07,050
a complexity class, I'm sorry, a hypothesis class that is very, very

48
00:02:07,050 --> 00:02:07,530
complex?

49
00:02:07,530 --> 00:02:10,560
>> You mean like my daughter? sure. I think

50
00:02:10,560 --> 00:02:12,360
you could, it would be much easier to overfit.

51
00:02:12,360 --> 00:02:14,690
>> Right. So getting something that actually works well might

52
00:02:14,690 --> 00:02:16,750
be challenging. You might need a lot more data to

53
00:02:16,750 --> 00:02:18,600
kind of nail down what your're, what you're really talking

54
00:02:18,600 --> 00:02:20,162
about. So it's a bit of a double edged sword.

55
00:02:20,162 --> 00:02:22,680
All right. So then, there, another issue is, well, you

56
00:02:22,680 --> 00:02:24,430
know, it may be easy to learn if you don't

57
00:02:24,430 --> 00:02:28,270
have to learn very well. [LAUGH] So the, the accuracy

58
00:02:28,270 --> 00:02:32,650
to which the target concept is approximated, often written as epsilon,

59
00:02:32,650 --> 00:02:34,840
is another thing that's going to be important in understanding

60
00:02:34,840 --> 00:02:38,330
the complexity of a learning algorithm. And and so those, those

61
00:02:38,330 --> 00:02:41,600
are kind of the main complexity related quantities that I,

62
00:02:41,600 --> 00:02:45,140
that I wanted to talk about. But there's also some choices

63
00:02:45,140 --> 00:02:48,060
as to how the learning problem is actually framed. There's

64
00:02:48,060 --> 00:02:50,900
the manner in which training examples are presented. And there's the

65
00:02:50,900 --> 00:02:54,460
manner in which training examples are selected for presentation. And we're

66
00:02:54,460 --> 00:02:58,160
going to talk about both of these. Let me just first

67
00:02:58,160 --> 00:02:59,520
say that when I talk about the

68
00:02:59,520 --> 00:03:02,790
manner in which training examples are presented, there's,

69
00:03:02,790 --> 00:03:07,260
there's two that I think are really, really important to look at. One is batch

70
00:03:07,260 --> 00:03:08,400
and that's mostly what we've looked at

71
00:03:08,400 --> 00:03:11,190
so far, that there's a training set that's

72
00:03:11,190 --> 00:03:14,780
fixed and handed over to the algorithm in a big bolus, right. A big group.

73
00:03:14,780 --> 00:03:15,690
>> A big batch.

74
00:03:15,690 --> 00:03:19,848
>> A big batch, exactly. Or it could also be presented on line, so

75
00:03:19,848 --> 00:03:23,209
one at a time. So we say to the training algorithm, or the learning algorithm,

76
00:03:23,209 --> 00:03:25,459
here's an example. And then it has to predict what

77
00:03:25,459 --> 00:03:28,530
the label is. And then the algorithm can say, oh

78
00:03:28,530 --> 00:03:30,570
here's what the right label is. Let's try again. Here's

79
00:03:30,570 --> 00:03:32,660
another example. And it can go back and forth like that.

80
00:03:32,660 --> 00:03:33,225
>> Mm-hm.

81
00:03:33,225 --> 00:03:35,210
>> We haven't really talked about algorithms that work that way, but

82
00:03:35,210 --> 00:03:38,500
it is useful in the context of computational learning theory to have

83
00:03:38,500 --> 00:03:40,990
both kinds of algorithms. They have different sorts of behavior. All right.

84
00:03:40,990 --> 00:03:44,150
So let's talk about the manner in which training examples are selected.
