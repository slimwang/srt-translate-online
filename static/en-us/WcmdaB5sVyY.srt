1
00:00:00,200 --> 00:00:02,930
So let's take another look
at this n by n matrix.

2
00:00:02,930 --> 00:00:06,495
What we're going to do is to divide it
into what we're going to call tiles.

3
00:00:06,495 --> 00:00:08,210
They're square chunks of the matrix.

4
00:00:08,210 --> 00:00:11,190
What we'll do is calculate
each tile in parallel,

5
00:00:11,190 --> 00:00:15,910
which would then calculate all total
forces on the elements within that tile.

6
00:00:15,910 --> 00:00:18,800
Then we'll add the resulting
forces across horizontal

7
00:00:18,800 --> 00:00:22,192
tiles to get the total force for
each destination object.

8
00:00:22,192 --> 00:00:24,800
We're going to say a tile
is p by p elements.

9
00:00:24,800 --> 00:00:28,140
So we'll make n square over
p squared tiles overall.

10
00:00:28,140 --> 00:00:30,380
We're not going to talk
about how big a tile is yet.

11
00:00:30,380 --> 00:00:31,350
We'll cover that later.

12
00:00:31,350 --> 00:00:34,230
But for now just think when
we run this particular tile,

13
00:00:34,230 --> 00:00:36,260
we're going to run it
within a kudu thread block.

14
00:00:36,260 --> 00:00:39,250
And we can potentially share data
between threads in the block.

15
00:00:39,250 --> 00:00:41,380
Recall that the x axis
here is the source and

16
00:00:41,380 --> 00:00:43,120
the y axis is the destination.

17
00:00:43,120 --> 00:00:47,670
We'd really like to only fetch each
object once per tile and reuse it among

18
00:00:47,670 --> 00:00:52,070
all the threads in the tile, instead
of fetching each item p times per tile.

19
00:00:52,070 --> 00:00:57,560
Thus, instead of doing two p squared
memory fetches per tile, p times p,

20
00:00:57,560 --> 00:01:01,500
and two fetches for each item,
we will instead do how many fetches?
