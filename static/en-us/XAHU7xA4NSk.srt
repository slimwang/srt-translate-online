1
00:00:00,000 --> 00:00:01,924
We're just about ready to wrap up the course.

2
00:00:01,924 --> 00:00:05,186
We've covered Stratton's taxonomy of parallel optimization patterns,

3
00:00:05,186 --> 00:00:09,020
and we've tied those back to the lessons and assignments that you've had throughout the course.

4
00:00:09,020 --> 00:00:10,922
We've discussed the wide array of libraries

5
00:00:10,922 --> 00:00:14,256
that let you easily exploit the computational horsepower of the GPU.

6
00:00:14,256 --> 00:00:16,418
We've reviewed a few programming power tools

7
00:00:16,418 --> 00:00:19,791
to help you write high-performance applications with less work.

8
00:00:19,791 --> 00:00:23,847
And finally, we've talked about other platforms, including CUDA support for other languages

9
00:00:23,847 --> 00:00:26,597
like Python and MATLAB and Fortran

10
00:00:26,597 --> 00:00:31,251
as well as cross-platform solutions for CUDA-style massively parallel programming.

11
00:00:31,251 --> 00:00:33,378
So to close the lecture and the course,

12
00:00:33,378 --> 00:00:37,121
we're going to hear about one of the more exciting new features in the latest CUDA GPUs,

13
00:00:37,121 --> 00:00:39,035
dynamic parallelism.

14
00:00:39,035 --> 00:00:42,862
We've invited the real expert on this topic, Dr. Stephen Jones from NVIDIA,

15
00:00:42,862 --> 00:00:45,390
to give us a guest lecture on dynamic parallelism.

16
00:00:45,390 --> 00:00:48,090
We've also recorded an interview with Stephen for those of you interested

17
00:00:48,090 --> 00:00:49,967
in diving a bit deeper afterwards.

18
00:00:49,967 --> 00:00:52,462
So let's turn it over to Stephen, then we'll wrap up the course.
