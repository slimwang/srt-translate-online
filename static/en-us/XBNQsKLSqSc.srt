1
00:00:00,150 --> 00:00:05,580
We will now look at two other metrics, known as sensitivity and specificity.

2
00:00:05,580 --> 00:00:07,520
Let's consider this diagram.

3
00:00:07,520 --> 00:00:12,610
In this case, the circle represents actual positives,

4
00:00:12,610 --> 00:00:18,730
which is in fact a sum of the true positives and the false negatives.

5
00:00:18,730 --> 00:00:24,530
The sensitivity is defined as the true positives, divided by

6
00:00:24,530 --> 00:00:30,230
true positives plus the false negatives, which are all the actual positives.

7
00:00:30,230 --> 00:00:33,750
Similarly, let's look at all the actual negatives.

8
00:00:33,750 --> 00:00:39,720
In this case, it is a sum of true negatives and the false positives.

9
00:00:39,720 --> 00:00:43,020
The metric specificity is defined as the true

10
00:00:43,020 --> 00:00:49,140
negatives divided by the sum of the true negatives and the false positives.

11
00:00:49,140 --> 00:00:54,390
In our example, we were classifying person f and person b.

12
00:00:54,390 --> 00:00:59,950
In this case we would denote f as a positive case and

13
00:00:59,950 --> 00:01:01,930
b as a negative case for f.

14
00:01:03,030 --> 00:01:07,450
Let us denote the true positives, which is the number of

15
00:01:07,450 --> 00:01:13,870
actual positives that were classified or predictive to be positives, with TP.

16
00:01:13,870 --> 00:01:16,120
Let's denote the false negatives,

17
00:01:16,120 --> 00:01:20,550
which are actual positives classified as negative, with FN.

18
00:01:20,550 --> 00:01:23,590
Let's denote true negatives, which are the number of

19
00:01:23,590 --> 00:01:28,610
actual negatives that are classified to be negative, with TN.

20
00:01:28,610 --> 00:01:30,440
And false positives,

21
00:01:30,440 --> 00:01:36,200
which are actually negatives classified as positive, with FP.

22
00:01:36,200 --> 00:01:42,205
Also remember, in the language of hypothesis testing where events are classified

23
00:01:42,205 --> 00:01:47,949
as belonging to a null hypothesis or an alternate hypothesis, false positives

24
00:01:47,949 --> 00:01:54,070
are called type I errors, and false negatives are called type II errors.

25
00:01:54,070 --> 00:01:58,510
The accuracy is given as the sum of the true positive, and

26
00:01:58,510 --> 00:02:02,470
the true negative divided by all the cases.

27
00:02:02,470 --> 00:02:06,750
All the cases are sum of everything listed here.

28
00:02:06,750 --> 00:02:12,430
With this notation, we can write the sensitivity and specificity like this.

29
00:02:12,430 --> 00:02:16,860
Sometimes, you will see the specificity written as 1 minus the false

30
00:02:16,860 --> 00:02:21,970
positive over the sum of true negative, and the false positive.

31
00:02:21,970 --> 00:02:25,540
This essentially gives you the expression above.

32
00:02:25,540 --> 00:02:29,790
So now you're familiar with the accuracy metric,

33
00:02:29,790 --> 00:02:33,580
the sensitivity metric, and the specificity metric.

34
00:02:33,580 --> 00:02:40,610
For our poisoned wine classifier, we would want our sensitivity to be very high.

35
00:02:40,610 --> 00:02:44,720
That is, we want to catch almost all instances of poisoning.

36
00:02:44,720 --> 00:02:49,740
For the example that you showed in the quiz, this metric is less important.

37
00:02:49,740 --> 00:02:56,590
For our poisoned wine classifier, the specificity metric is less important,

38
00:02:56,590 --> 00:03:02,930
since if we falsely label a harmless wine as poisoned, it's not as dangerous.

39
00:03:02,930 --> 00:03:09,180
For the example that you gave, we want the specificity to be very high.

40
00:03:09,180 --> 00:03:13,700
We will return to the concept of sensitivity and specificity and

41
00:03:13,700 --> 00:03:18,760
show you how to choose between classifiers based on these metrics.
