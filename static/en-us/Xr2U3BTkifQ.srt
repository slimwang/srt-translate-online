1
00:00:00,245 --> 00:00:01,760
Alright, so what we're going to do to figure

2
00:00:01,760 --> 00:00:03,300
out how Q learning works, is we're going to think

3
00:00:03,300 --> 00:00:06,290
about what it means to estimate this Q function

4
00:00:06,290 --> 00:00:10,930
from transitions. So, let's just remember this is the

5
00:00:10,930 --> 00:00:12,660
form of the Q equation, that we've been

6
00:00:12,660 --> 00:00:16,040
talking about. And, we can't do this. We can't

7
00:00:16,040 --> 00:00:19,730
solve this, because we don't have access to R

8
00:00:19,730 --> 00:00:25,978
and T. All we have access to are transitions.

9
00:00:25,978 --> 00:00:27,322
>> So this a really, I guess, I'm going to

10
00:00:27,322 --> 00:00:29,128
guess you said this before, but when you, when you

11
00:00:29,128 --> 00:00:30,724
write out this equation it really jumps out at

12
00:00:30,724 --> 00:00:33,180
me. This is the difference between what I was talking

13
00:00:33,180 --> 00:00:36,970
about, solving MDPs and reinforcement learning. In solving MDPs

14
00:00:36,970 --> 00:00:38,970
we had R and we had T and now we

15
00:00:38,970 --> 00:00:40,210
do not have them, so we have to come up

16
00:00:40,210 --> 00:00:42,850
with some other way to solve these kinds of equations.

17
00:00:42,850 --> 00:00:43,210
>> That's right.

18
00:00:43,210 --> 00:00:46,620
>> Okay. So if we did have R and T, then we could solve this?

19
00:00:46,620 --> 00:00:48,560
>> Yeah, this is, I mean, the same

20
00:00:48,560 --> 00:00:51,190
things that you talked about, value iteration, policy iteration?

21
00:00:51,190 --> 00:00:54,390
It can be formulated in terms of Q. So it's, yeah, there's,

22
00:00:54,390 --> 00:00:57,540
this is easy to do, well, [LAUGH] it's polynomial to do if

23
00:00:57,540 --> 00:01:00,600
you have access to T and R. But but again, in the

24
00:01:00,600 --> 00:01:03,810
learning scenario we don't have the model. What we have are transitions.

25
00:01:03,810 --> 00:01:04,379
>> Okay, okay.

26
00:01:04,379 --> 00:01:06,600
>> So, here's how we're going to use transitions. This

27
00:01:06,600 --> 00:01:09,540
is what a transition is. We, we observe that we

28
00:01:09,540 --> 00:01:12,220
were in some state S of the MDP. And then

29
00:01:12,220 --> 00:01:16,400
action A was chosen somehow. And, then a transition happens.

30
00:01:16,400 --> 00:01:18,580
We land in a state. We get the reward for landing

31
00:01:18,580 --> 00:01:21,900
in that state. And we find out what state we're in. So

32
00:01:21,900 --> 00:01:25,050
that's, that's the transition. And what are we going to do with

33
00:01:25,050 --> 00:01:28,100
it? Well, what we're going to do. Is imagine that we've got an

34
00:01:28,100 --> 00:01:31,510
estimate of the Q function, Q hat, and we're going to update

35
00:01:31,510 --> 00:01:34,850
it as follows. Here's how we're going to use all these quantities from

36
00:01:34,850 --> 00:01:38,200
the transition. We're going to take the, the state and action that

37
00:01:38,200 --> 00:01:41,450
we just experienced. And we're going to change it; we going to update it;

38
00:01:41,450 --> 00:01:43,820
we're going to move a little bit. Alpha, this is alpha,

39
00:01:43,820 --> 00:01:45,930
this is called a learning rate. We're going to move a

40
00:01:45,930 --> 00:01:50,040
little bit in the direction of the immediate reward plus

41
00:01:50,040 --> 00:01:54,100
the discounted estimated value of the next state. So, we're going to

42
00:01:54,100 --> 00:01:58,310
take our estimate Q hat, we going to take the state

43
00:01:58,310 --> 00:02:00,910
that we end up in as prime. We're going to look at

44
00:02:00,910 --> 00:02:03,430
all the different actions we could take from there and

45
00:02:03,430 --> 00:02:06,540
take the maximum. So this together is kind of an estimate

46
00:02:06,540 --> 00:02:07,380
of the utility, right?

47
00:02:07,380 --> 00:02:08,491
>> Mm-hm.

48
00:02:08,491 --> 00:02:10,030
>> And this is the utility of the state that we're

49
00:02:10,030 --> 00:02:14,430
going to. This altogether is the utility of the state that,

50
00:02:14,430 --> 00:02:16,570
that we're in. To the state S. So this is kind

51
00:02:16,570 --> 00:02:18,310
of the utility of the state that we're landing in as

52
00:02:18,310 --> 00:02:22,080
prime. And this all together is, is related to the utility

53
00:02:22,080 --> 00:02:24,170
of the state, right? You can see that it's related. In

54
00:02:24,170 --> 00:02:27,220
that we've got the immediate reward, which kind of matches to

55
00:02:27,220 --> 00:02:32,750
this. We've got the discounting. We don't have the sum over transitions

56
00:02:32,750 --> 00:02:34,960
but we do have the max A and the lookup in the

57
00:02:34,960 --> 00:02:37,880
next, in the Q function. Alright so this, this is the Q

58
00:02:37,880 --> 00:02:40,530
learning equation. Alright, let me just say a little bit more about

59
00:02:40,530 --> 00:02:43,790
this, this alpha arrow notation, which I really like but is not

60
00:02:43,790 --> 00:02:46,760
all that standard. So if you, when I write you know something

61
00:02:46,760 --> 00:02:50,170
like V gets with an alpha X. What we mean is we're

62
00:02:50,170 --> 00:02:54,490
moving alpha of the way from the current value V towards X,

63
00:02:54,490 --> 00:02:57,960
which can be written this way. That V gets 1 minus alpha

64
00:02:57,960 --> 00:03:01,500
of V plus alpha of x. And so in particular, if

65
00:03:01,500 --> 00:03:05,120
you think about this as so if alpha is 0. That's

66
00:03:05,120 --> 00:03:06,860
sort of a learning rate of 0, which shouldn't learn at

67
00:03:06,860 --> 00:03:09,630
all, and in fact, if you set alpha to 0 here, it's

68
00:03:09,630 --> 00:03:12,760
going to zero out X, and it's going to only assign V to

69
00:03:12,760 --> 00:03:15,900
V, so nothing's going to change. So learning rate of 0

70
00:03:15,900 --> 00:03:20,030
corresponds to no learning. And if we set alpha to 1,

71
00:03:20,030 --> 00:03:22,980
that's like full learning, so we forget everything that we knew and

72
00:03:22,980 --> 00:03:24,770
we just jumped to the new value. And that's

73
00:03:24,770 --> 00:03:26,560
what happens here, that 1 minus alpha is 0,

74
00:03:26,560 --> 00:03:31,400
so the V goes away, and we just get X assigned to V. So does that make sense?

75
00:03:31,400 --> 00:03:33,570
>> That does make sense. And and if alpha

76
00:03:33,570 --> 00:03:35,430
were in between 0 and 1 like one half, you're

77
00:03:35,430 --> 00:03:38,810
basically making V the average of the old value

78
00:03:38,810 --> 00:03:41,350
of V, and the new value X that you see.

79
00:03:41,350 --> 00:03:42,250
>> Good.
