1
00:00:00,000 --> 00:00:03,000
From Robert S. in Perth in Western Australia,

2
00:00:03,000 --> 00:00:07,000
"What is Stanford's motivation for offering these courses for free?

3
00:00:07,000 --> 00:00:15,000
Are academics--like us--being coerced or incentivized or are we just curious to see what happens?"

4
00:00:15,000 --> 00:00:22,000
The answer is it's you. It's you people out there that we have a developed a great, deep relationship with.

5
00:00:22,000 --> 00:00:27,000
I've received many hundreds of emails from people whose lives I believe we changed.

6
00:00:27,000 --> 00:00:33,000
It's extremely gratifying to be able to bring our work and our teaching

7
00:00:33,000 --> 00:00:37,000
not just to a Stanford campus but to the entire world.

8
00:00:37,000 --> 00:00:40,000
That's the biggest thing I've ever done in my academic career so far.

9
00:00:40,000 --> 00:00:46,000
I actually attended a Katy Perry concert on Monday, I have to admit.

10
00:00:46,000 --> 00:00:51,000
I might not look like a typical Katy Perry fan, but I went.

11
00:00:51,000 --> 00:00:54,000
There were about 16,000 people in the stadium. It was packed.

12
00:00:54,000 --> 00:00:56,000
She was very proud of this,

13
00:00:56,000 --> 00:00:59,000
and I was thinking, "Wow. We have more students in our class right now

14
00:00:59,000 --> 00:01:04,000
that spend several hours a week studying material and being empowered by what we teach you."

15
00:01:04,000 --> 00:01:07,000
It's been just amazing.

16
00:01:07,000 --> 00:01:09,000
I would agree with that. It's been amazing.

17
00:01:09,000 --> 00:01:12,000
How many of your would rather have gone to the Katy Perry concert

18
00:01:12,000 --> 00:01:16,000
than of done your homework? Raise your hands.

19
00:01:16,000 --> 00:01:19,000
Luckily we don't see them right now. >>Yeah, not too many, I don't think.

20
00:01:19,000 --> 00:01:22,000
So we are doing it for you.

21
00:01:22,000 --> 00:01:25,000
I guess from my point of view I did the text book,

22
00:01:25,000 --> 00:01:28,000
and I thought it was great that I had some kind of connection with students

23
00:01:28,000 --> 00:01:31,000
both when I taught the class personally, and then also knowing that

24
00:01:31,000 --> 00:01:34,000
other professors were teaching the class.

25
00:01:34,000 --> 00:01:37,000
But it felt like it was incomplete, and I thought we could do more.

26
00:01:37,000 --> 00:01:42,000
We could reach more people and we could reach them in a richer way by putting the class online.

27
00:01:42,000 --> 00:01:45,000
Yeah. And I should say we were kind of the first to announce an experiment like this.

28
00:01:45,000 --> 00:01:50,000
There is, of course, more free classes on the way right now and about 10 more to come.

29
00:01:50,000 --> 00:01:53,000
And I can tell you Stanford didn't coerce us.

30
00:01:53,000 --> 00:01:57,000
In fact, Stanford was surprised we did this, and they embraced us.

31
00:01:57,000 --> 00:02:02,000
They understood the vision of this. This is certainly an experiment that is unprecedented.

32
00:02:02,000 --> 00:02:07,000
And I should say that there had been work going on at Stanford for years

33
00:02:07,000 --> 00:02:14,000
with Andrew Ng and Daphne Koller and others and work at other universities--MIT and elsewhere.

34
00:02:14,000 --> 00:02:19,000
We made a little tweak on it to push it out to you guys in way that's slightly different than what had been done before,

35
00:02:19,000 --> 00:02:22,000
but we're really following up on work that's been done by others.

36
00:02:22,000 --> 00:02:27,000
Professor Rodney Brooks from MIT--a good friend of mine, a person I admire--

37
00:02:27,000 --> 00:02:31,000
once said in a documentary that Mars exploration should be done by a

38
00:02:31,000 --> 00:02:34,000
swarm of smaller and independent robots.

39
00:02:34,000 --> 00:02:39,000
It would be fast, cheap, and as he put it, out of control.

40
00:02:39,000 --> 00:02:42,000
What do you think about this?

41
00:02:42,000 --> 00:02:47,000
I was at NASA under the era that was known as "faster, better, cheaper."

42
00:02:47,000 --> 00:02:52,000
But not out of control. >>But not out of control. They didn't mention that part.

43
00:02:52,000 --> 00:02:57,000
But Goldin, who was the NASA administrator there was following up on some

44
00:02:57,000 --> 00:03:02,000
lost missions that were very expensive ½ billion to 1 billion dollar missions,

45
00:03:02,000 --> 00:03:07,000
and when they fail that's a lot of money down the drain.

46
00:03:07,000 --> 00:03:11,000
So his mantra--similar to Brooks--was to say, "Let's see what we can do cheaper."

47
00:03:11,000 --> 00:03:18,000
I thought that was a great idea of NASA, and I think it's a great idea for lots of applications.

48
00:03:18,000 --> 00:03:23,000
Yeah, it's interesting. When he made that comment, I think we were just beginning to explore Mars.

49
00:03:23,000 --> 00:03:26,000
The first Rover was being sent up. The question was legitimate.

50
00:03:26,000 --> 00:03:31,000
Should we send one complex machine and just put all your eggs into that basket or send many of them?

51
00:03:31,000 --> 00:03:35,000
I think history proves him wrong in the follow sense:

52
00:03:35,000 --> 00:03:38,000
The reliability of the device has not been the issue.

53
00:03:38,000 --> 00:03:40,000
It's not been the case that we send one machine and it got lost,

54
00:03:40,000 --> 00:03:42,000
we send another machine and it got lost.

55
00:03:42,000 --> 00:03:45,000
By and large it actually outperformed the expectations.

56
00:03:45,000 --> 00:03:47,000
You can argue we're actually using swarms.

57
00:03:47,000 --> 00:03:52,000
We're sending them out right now, this very moment--just sequential swarms.

58
00:03:52,000 --> 00:03:54,000
To do certain measurements you need a certain complexity in instruments.

59
00:03:54,000 --> 00:03:58,000
If you use very, very small robots, they just couldn't carry those instruments.

60
00:03:58,000 --> 00:04:03,000
So in hindsight, it looked like we lost the most robots and it was a complete disaster,

61
00:04:03,000 --> 00:04:06,000
but if we sent 10,000 times as many, we would've at least retained some.

62
00:04:06,000 --> 00:04:11,000
I would give him right, but at this point I think he was actually wrong in this case.

63
00:04:11,000 --> 00:04:17,000
Capture Whiz in Denver asked, "It seems the AI techniques we've learned could be valuable for human use as well as robots.

64
00:04:17,000 --> 00:04:20,000
Have you used them in your personal life such as in decision making?"

65
00:04:20,000 --> 00:04:23,000
That's actually interesting. It's a very deep question.

66
00:04:23,000 --> 00:04:25,000
Herb Simon--I used to be very good friends with Herb Simon--

67
00:04:25,000 --> 00:04:28,000
who was one of the founders of Artificial Intelligence, who passed away many years ago,

68
00:04:28,000 --> 00:04:31,000
a Professor at Carnegie Mellon, a noble laureate,

69
00:04:31,000 --> 00:04:37,000
and he kept telling me about bounded rationality was optimal decision making.

70
00:04:37,000 --> 00:04:42,000
And in a single sentence, optimal decision making you really try to find the optimal decision.

71
00:04:42,000 --> 00:04:44,000
In bounded rationality you try to satisfy,

72
00:04:44,000 --> 00:04:49,000
so you have a threshold that says if the decision is good, I'm just going to implement the decision.

73
00:04:49,000 --> 00:04:56,000
I find myself vastly on the satisfying side of it.

74
00:04:56,000 --> 00:04:58,000
For example, take this class.

75
00:04:58,000 --> 00:05:00,000
We could have sat down for years trying to make the optimal movies,

76
00:05:00,000 --> 00:05:03,000
build the optimal server, or we could just do it.

77
00:05:03,000 --> 00:05:07,000
We decided to just do it. In doing so, we made lots of compromises.

78
00:05:07,000 --> 00:05:09,000
I think some of the early videos weren't very good.

79
00:05:09,000 --> 00:05:13,000
We had lots of server crashes, which I deeply regret, and I apologize for.

80
00:05:13,000 --> 00:05:16,000
But at the same time we were able to get something done.

81
00:05:16,000 --> 00:05:18,000
I find myself much less on the optimality camp.

82
00:05:18,000 --> 00:05:24,000
If people talk about optimal decision making, I always picture the people sit around forever and don't get their act together.

83
00:05:24,000 --> 00:05:27,000
For me, acting and doing something is really important.

84
00:05:27,000 --> 00:05:30,000
It's been the discourse with Herb Simon, who made me aware of that conflict

85
00:05:30,000 --> 00:05:35,000
and made me polarize myself and say, look, I'm going to be a fast actor no matter what.

86
00:05:35,000 --> 00:05:43,000
I think another thing that also came out of CMU is this idea of the reasonable person principle.

87
00:05:43,000 --> 00:05:48,000
CMU has that as kind of a motto-- >>But then they kicked me out.

88
00:05:48,000 --> 00:05:51,000
>>Yeah-- >>I quit. I don't know. >>Yeah.

89
00:05:51,000 --> 00:05:57,000
The idea of the principle is if somebody did something that you thought is crazy

90
00:05:57,000 --> 00:06:01,000
or you think is trying to attack your or undermine you,

91
00:06:01,000 --> 00:06:05,000
go under the assumption that maybe they're a reasonable person after all.

92
00:06:05,000 --> 00:06:09,000
They say, well, how could a reasonable person come to this crazy decision?

93
00:06:09,000 --> 00:06:13,000
If you look at decision theory you would say, well, it could be because

94
00:06:13,000 --> 00:06:16,000
he knows something that I don't know--his state of knowledge is different--

95
00:06:16,000 --> 00:06:18,000
or because his goals are different.

96
00:06:18,000 --> 00:06:22,000
If you think about things that way, it tend often to diffuse the situation, and you say,

97
00:06:22,000 --> 00:06:27,000
"Ah, now I understand why somebody is acting the way that they're acting."

98
00:06:27,000 --> 00:06:34,000
Okay, Peter--question for you by Max K. from New "Yoik", wherever that is. Sorry.

99
00:06:34,000 --> 00:06:40,000
A lot of people noticed your books and the bibliography are staggering.

100
00:06:40,000 --> 00:06:47,000
Any methods that you could recommend to us for dealing with learning a lot of complex material?

101
00:06:47,000 --> 00:06:50,000
I guess you just have to read a lot, right?

102
00:06:50,000 --> 00:06:55,000
Yes, there's a lot of entries in the bibliography, and we had some help there.

103
00:06:55,000 --> 00:07:01,000
In the first edition, Doug Edwards especially did a lot of research work.

104
00:07:01,000 --> 00:07:07,000
Since then we just got a lot of suggestions from people of things that we left out.

105
00:07:07,000 --> 00:07:12,000
Coincidentally, a lot of the suggestions of things we left out happened to be their work,

106
00:07:12,000 --> 00:07:15,000
but often they were right that that was something that we should add.

107
00:07:15,000 --> 00:07:18,000
We went, and we read a lot of papers.

108
00:07:18,000 --> 00:07:21,000
We just kept on trying to learn.

109
00:07:21,000 --> 00:07:28,000
I think just being excited about the field and wanting to learn more and keeping at it--

110
00:07:28,000 --> 00:07:32,000
it can be confusing and hard at first when you're first getting started,

111
00:07:32,000 --> 00:07:35,000
and then it all starts to come together.

112
00:07:35,000 --> 00:07:38,000
You say, "Oh yeah. I've seen this before. I've seen this author before.

113
00:07:38,000 --> 00:07:41,000
I've seen this idea before. This idea relates to another idea."

114
00:07:41,000 --> 00:07:45,000
You start getting to the point where it becomes easier rather than harder.

115
00:07:45,000 --> 00:07:47,000
Keep at it, and you'll get there.

116
00:07:47,000 --> 00:07:50,000
I can let you in on a little secret in my professional academic life.

117
00:07:50,000 --> 00:07:55,000
Students join Stanford and ask me "what should I read?"

118
00:07:55,000 --> 00:07:58,000
I tend to tell them don't read anything.

119
00:07:58,000 --> 00:08:04,000
It sounds a little bit bizarre, but I deeply believe the best way to learn is to solve problems.

120
00:08:04,000 --> 00:08:09,000
Pick a problem that's interesting and don't worry that it has been solved before or not.

121
00:08:09,000 --> 00:08:13,000
Just make sure that it is challenging enough for you that you can actually do something about it.

122
00:08:13,000 --> 00:08:16,000
It's not as challenging as something you can't do anything about.

123
00:08:16,000 --> 00:08:18,000
Then start solving it.

124
00:08:18,000 --> 00:08:24,000
As you solve it and as you solve the first version of it, then start reading papers.

125
00:08:24,000 --> 00:08:32,000
The reason is, first of all, if you just read papers, your thinking will be so engraved in the way people thought before you.

126
00:08:32,000 --> 00:08:34,000
It's really hard for you to find something new and something interesting.

127
00:08:34,000 --> 00:08:37,000
Obviously, the problem isn't solved, otherwise you wouldn't have to read any papers.

128
00:08:37,000 --> 00:08:40,000
Just buy the product, and the problem is solved.

129
00:08:40,000 --> 00:08:47,000
Secondly, your ability to understand papers I think goes up greatly with your ability to solve problems.

130
00:08:47,000 --> 00:08:53,000
If you really try to understand the subject really deeply, and maybe you fail or maybe have certain successes,

131
00:08:53,000 --> 00:08:56,000
then these other papers will make much more sense.

132
00:08:56,000 --> 00:09:00,000
I've always driven my own life by trying to solve problems that I have no clue how to solve,

133
00:09:00,000 --> 00:09:05,000
and I just get into it. It has always worked well and worked well for my students.

134
00:09:05,000 --> 00:09:09,000
The students that come to me with literature,

135
00:09:09,000 --> 00:09:12,000
maybe they're successful with some other professor, but with me,

136
00:09:12,000 --> 00:09:15,000
I tend to discourage them and say just do something interesting.

137
00:09:15,000 --> 00:09:17,000
Now there's an interesting that's hard.

138
00:09:17,000 --> 00:09:21,000
It's easy to come up with an idea that's so fundamental like building the human brain

139
00:09:21,000 --> 00:09:23,000
that would be great if we solved it but you can't.

140
00:09:23,000 --> 00:09:26,000
My favorite is inventing a gravity shield.

141
00:09:26,000 --> 00:09:30,000
It's impossible to even know what the first step is how you go about inventing a gravity shield.

142
00:09:30,000 --> 00:09:33,000
The trick is to find problems that are reasonably manageable.

143
00:09:33,000 --> 00:09:38,000
Where you think if I sit down, I can do this in relatively short enough time to solve the problem.

144
00:09:38,000 --> 00:09:42,000
As you do it, keep your eyes open to what's the next problem to solve.

145
00:09:42,000 --> 00:09:47,000
If you're smart, then as you solve your first problem maybe in the first couple of weeks,

146
00:09:47,000 --> 00:09:51,000
you'll probably find 10 other interesting problems that have really come up along the way

147
00:09:51,000 --> 00:09:53,000
that you didn't think of before.

148
00:09:53,000 --> 00:09:55,000
That for me has been always the best path of learning.

149
00:09:55,000 --> 00:10:00,000
Then go back, consult the literature, see what people have written, but don't read too much, in my opinion.

150
00:10:00,000 --> 00:10:02,000
You can quote me for that.

151
00:10:02,000 --> 00:10:08,000
I think that's great advice. You're all going to be so busy anyways. You won't have time to read that much.

152
00:10:08,000 --> 00:10:12,000
Congratulations to everyone. We got very good results on the midterm.

153
00:10:12,000 --> 00:10:16,000
You did a great job and keep it up. >>Amazingly well.

154
00:10:16,000 --> 00:10:20,000
Thank you. See you soon. >>So long.

