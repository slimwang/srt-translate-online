1
00:00:00,170 --> 00:00:02,200
So let's take our conversation about the validity of field

2
00:00:02,200 --> 00:00:05,676
values a little further and look at auditing a cross-field

3
00:00:05,676 --> 00:00:08,380
constraint. So, remember this is a constraint where we have

4
00:00:08,380 --> 00:00:11,640
multiple fields per item, that must be in agreement in some

5
00:00:11,640 --> 00:00:14,960
way. Once again, let's look at a Wikipedia page for

6
00:00:14,960 --> 00:00:18,290
city. In this case Bern in the country of Switzerland.

7
00:00:18,290 --> 00:00:20,330
So here we have a nice example of a city

8
00:00:20,330 --> 00:00:26,940
that has values for population, area and one for population density.

9
00:00:26,940 --> 00:00:29,450
Any time you have a situation like this, where

10
00:00:29,450 --> 00:00:32,790
you can essentially check at least one field against

11
00:00:32,790 --> 00:00:35,310
another, you have a nice way of validating field

12
00:00:35,310 --> 00:00:40,010
values throughout your entire dataset. So, the cross-field constraint here

13
00:00:40,010 --> 00:00:42,920
is that population divided by area gives us the

14
00:00:42,920 --> 00:00:46,570
population density. And we'll employ this as one check

15
00:00:46,570 --> 00:00:50,040
in auditing our data for the city's collection. So

16
00:00:50,040 --> 00:00:52,390
here I've written a little program to do exactly that.

17
00:00:52,390 --> 00:00:55,300
And it does something like calculate the population density based

18
00:00:55,300 --> 00:00:59,920
on the individual values for population and area. And compare that

19
00:00:59,920 --> 00:01:04,410
to the population density specified within the dataset itself. And we're

20
00:01:04,410 --> 00:01:06,080
just going to make sure the difference isn't more than ten to

21
00:01:06,080 --> 00:01:09,750
account for rounding errors and that sort of thing. Now,

22
00:01:09,750 --> 00:01:11,870
this is just a first pass of this and just an

23
00:01:11,870 --> 00:01:13,600
example to show you the type of thing that we might

24
00:01:13,600 --> 00:01:17,030
do in auditing a cross-field constraint. All right, let's run this.

25
00:01:18,170 --> 00:01:21,630
We should only see output here. Yep. And we've got a number

26
00:01:21,630 --> 00:01:24,180
of bad population densities or possibly

27
00:01:24,180 --> 00:01:26,810
bad population densities. So what I usually

28
00:01:26,810 --> 00:01:29,880
do in situations like this is, I pick one and I basically just

29
00:01:29,880 --> 00:01:32,080
go look at the data and see if I can figure out what's

30
00:01:32,080 --> 00:01:35,100
going on. Okay, this one stood out to me, so let's go take

31
00:01:35,100 --> 00:01:37,530
a look at that. Now, in the interest of time, I've already pulled

32
00:01:37,530 --> 00:01:40,770
this one up in our original dataset. And I've actually hidden some of

33
00:01:40,770 --> 00:01:43,490
the fields here, so it's easier to see the values that we actually

34
00:01:43,490 --> 00:01:46,360
care about in this case. So, here's the area

35
00:01:46,360 --> 00:01:50,990
field, populationDensity and the populationTotal. Now what we want is

36
00:01:50,990 --> 00:01:54,480
for this value divided by this value to be pretty

37
00:01:54,480 --> 00:01:57,310
close to this value. And if you look at this,

38
00:01:57,310 --> 00:01:59,560
you can see that there's no way that can possibly

39
00:01:59,560 --> 00:02:03,150
happen given the size of this. Okay and as I

40
00:02:03,150 --> 00:02:06,035
look at the rest of these values here. I also

41
00:02:06,035 --> 00:02:09,192
see some values that appear to me to be impossibly

42
00:02:09,192 --> 00:02:12,479
large as the area of land for a given city. Especially

43
00:02:12,479 --> 00:02:14,816
given that when I look at the Wikipedia page and as

44
00:02:14,816 --> 00:02:17,552
I look at Wikipedia pages for other cities, I notice that

45
00:02:17,552 --> 00:02:21,329
area is actually measured in square kilometers. So there's no way

46
00:02:21,329 --> 00:02:24,946
I have this many square kilometers. However if I look at

47
00:02:24,946 --> 00:02:27,826
Yoakum, Texas, I can see that it's value for area is

48
00:02:27,826 --> 00:02:31,650
12 square kilometers. My guess is that this is a rounded

49
00:02:31,650 --> 00:02:34,310
value. If I go back and look at this data and

50
00:02:34,310 --> 00:02:38,010
if I interpret this instead of kilometers as not

51
00:02:38,010 --> 00:02:42,450
even meters, but millimeters then this makes sense. Now from

52
00:02:42,450 --> 00:02:45,020
my perspective having a land area specified in millimeters is

53
00:02:45,020 --> 00:02:47,845
a little crazy. But I can see reasons why the

54
00:02:47,845 --> 00:02:50,730
dbpedia folks might have set things up that way. But

55
00:02:50,730 --> 00:02:52,530
if I think about shifting the decimal point for this

56
00:02:52,530 --> 00:02:56,710
value appropriately so, that it describes square kilometers, instead of

57
00:02:56,710 --> 00:02:59,468
square millimeters. Then I end up with a value that's

58
00:02:59,468 --> 00:03:04,060
11.7 square kilometers, which is pretty close to this value, right

59
00:03:04,060 --> 00:03:07,570
here. And these values were collected some time ago. So, I'm

60
00:03:07,570 --> 00:03:10,710
willing to bet that our problem here, that we're seeing in

61
00:03:10,710 --> 00:03:14,680
auditing this cross-field constraint. Is really one of having made a faulty

62
00:03:14,680 --> 00:03:17,550
assumption about the land area. And that in fact is what

63
00:03:17,550 --> 00:03:20,030
the problem is. And now of course, in order to verify

64
00:03:20,030 --> 00:03:21,870
this, we'd want to look through a number of other fields

65
00:03:21,870 --> 00:03:24,640
here. And actually maybe do a bit of Googling around to really

66
00:03:24,640 --> 00:03:28,200
be sure that is exactly what's going on here. And that it's

67
00:03:28,200 --> 00:03:30,555
just an issue of units as opposed to an actual problem with the

68
00:03:30,555 --> 00:03:34,600
cross-field constraint, that we know has to exist between these three fields.

69
00:03:34,600 --> 00:03:36,100
And that's an example of auditing

70
00:03:36,100 --> 00:03:38,624
a cross-field constraint in our Cities dataset.
