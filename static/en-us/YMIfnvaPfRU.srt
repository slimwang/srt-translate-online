1
00:00:00,230 --> 00:00:05,040
Suppose, I've got a depth scene here and

2
00:00:05,040 --> 00:00:08,610
I'd like to match it to some model or
some previously observed depth scene.

3
00:00:08,610 --> 00:00:10,250
How might I do that?

4
00:00:10,250 --> 00:00:13,990
Well, what I need to do,
is I need to find some patches,

5
00:00:13,990 --> 00:00:19,490
some locations on my object and match
them to some locations on my object.

6
00:00:19,490 --> 00:00:23,390
And you know it should be somewhat
invariant to how I look at it.

7
00:00:23,390 --> 00:00:25,100
All right, so I'm looking over here,
looking over there.

8
00:00:25,100 --> 00:00:27,980
I want to find the same thing,
the object might be rotated.

9
00:00:27,980 --> 00:00:31,400
Things might,
we've seen this movie before.

10
00:00:31,400 --> 00:00:36,518
Remember we we're matching pictures as
we had two pictures that were rotated,

11
00:00:36,518 --> 00:00:39,708
translated, scaled, and
we wanted to align them.

12
00:00:39,708 --> 00:00:41,435
Do you remember SIF?

13
00:00:41,435 --> 00:00:44,900
SIF was a way of saying,
in Harris points, remember they were

14
00:00:44,900 --> 00:00:47,290
Harris Stevens points, and
nobody ever remembered Stevens.

15
00:00:47,290 --> 00:00:51,250
We had ways of finding points, and
then generating a descriptor and

16
00:00:51,250 --> 00:00:57,140
that descriptor had to be,
sort of discriminative and yet, robust.

17
00:00:57,140 --> 00:00:59,640
That is, we wanted them to be
relatively unique but robust, so

18
00:00:59,640 --> 00:01:02,280
that when we found a description
here and we matched it with

19
00:01:02,280 --> 00:01:05,540
the description there,
it would most likely be the right one.

20
00:01:05,540 --> 00:01:06,410
And then we improve that,

21
00:01:06,410 --> 00:01:09,400
we use ransack in order to find
the right sets of matches.

22
00:01:09,400 --> 00:01:11,490
Well, we can do exactly
the same thing with depth.

23
00:01:11,490 --> 00:01:15,550
You know what's drawn here is that
I've got this interest point and

24
00:01:15,550 --> 00:01:19,310
I've got this sort of neighborhood
of these five points around it or

25
00:01:19,310 --> 00:01:21,790
I might look at a, at a volume of these.

26
00:01:21,790 --> 00:01:25,210
And what I'm going to do it, I might
find the relationship between these

27
00:01:25,210 --> 00:01:28,130
points and say the little local
normals associated with the point, or

28
00:01:28,130 --> 00:01:30,040
something to do with the geometry.

29
00:01:30,040 --> 00:01:33,250
The idea is whatever it is that
I'm measuring is not a function

30
00:01:33,250 --> 00:01:35,270
of how I looked at the points.

31
00:01:35,270 --> 00:01:40,040
So in fact, the way we often do these
is, we typically will build a, we'll,

32
00:01:40,040 --> 00:01:43,150
we'll take these points and
we'll build a, a description and

33
00:01:43,150 --> 00:01:44,690
we'll put them into a histogram.

34
00:01:44,690 --> 00:01:48,760
Okay, so maybe we just quantized these
different orientations into, you know,

35
00:01:48,760 --> 00:01:52,710
five different levels, so we have,
you know, five, level thing, and

36
00:01:52,710 --> 00:01:54,550
then we might have distances.

37
00:01:54,550 --> 00:01:58,430
So, in fact, one example,
they used a five by five by five

38
00:01:58,430 --> 00:02:01,970
histogram that gave you 125
different values, okay?

39
00:02:01,970 --> 00:02:04,900
Remember in SIF I think we
had 128 different values.

40
00:02:04,900 --> 00:02:07,430
So here we have 125 different values.

41
00:02:07,430 --> 00:02:09,669
And then for every patch,
we compute these and

42
00:02:09,669 --> 00:02:13,680
we can compare them against the patches
in our model, find the putative matches,

43
00:02:13,680 --> 00:02:17,220
and then do something like ransack to,
to do the matching.

44
00:02:17,220 --> 00:02:21,850
There's a version called
the fast point feature histogram

45
00:02:21,850 --> 00:02:24,430
which is a way of doing this in 3D,
and again,

46
00:02:24,430 --> 00:02:28,020
I think is probably influenced
directly in the Point Cloud Library.

47
00:02:29,040 --> 00:02:33,820
So there are a couple of places
where the Point Cloud Library, I,

48
00:02:33,820 --> 00:02:36,220
I already pointed you
at 'PointClouds.org'.

49
00:02:36,220 --> 00:02:39,720
For many of you in the robotics
universe there's something called ROS,

50
00:02:39,720 --> 00:02:43,040
the Robot Operating System originally
out of Willow Garage and then it's,

51
00:02:43,040 --> 00:02:46,080
it's robotic software open found,
it's got all those letters in it,

52
00:02:46,080 --> 00:02:49,650
it's an open source ongoing development
system for doing robotics and

53
00:02:49,650 --> 00:02:51,650
the Point Cloud Library and
by the way, Open CV,

54
00:02:51,650 --> 00:02:55,040
Computer Vision Library
are all part of that universe.

55
00:02:55,040 --> 00:02:58,680
And that's really helped make it easy
for people to do that development.

56
00:02:58,680 --> 00:03:01,670
And there are drivers, by the way,
in that for using the Kinect or

57
00:03:01,670 --> 00:03:05,400
PrimeSense sensors as well, so you can
go get your point clouds that way.

58
00:03:05,400 --> 00:03:10,130
So here's a picture that I showed
you before from pointclouds.org.

59
00:03:10,130 --> 00:03:14,040
And in fact, here it says,
ransack cylinder segmentation.

60
00:03:14,040 --> 00:03:17,830
So basically, they ransacked to
find the different planes and

61
00:03:17,830 --> 00:03:19,790
to also find these different cylinders.

62
00:03:19,790 --> 00:03:22,530
You know how to do that already,
so you could do this and

63
00:03:22,530 --> 00:03:25,650
it basically gives you a direct
interpretation of the geometry
