1
00:00:00,056 --> 00:00:03,256
Well we need the SyncThreads call for correctness.

2
00:00:03,256 --> 00:00:06,397
This is what ensures that all the data in the tile has been placed in the shared memory,

3
00:00:06,397 --> 00:00:09,740
before we attempt to copy it to its transposed location in global memory.

4
00:00:09,740 --> 00:00:12,796
So we can't really eliminate the SyncThreads call.

5
00:00:12,796 --> 00:00:17,032
Now the more threads in the block, the more time on average they spend waiting.

6
00:00:17,032 --> 00:00:20,196
So reducing the number of threads that are actually waiting in the barrier

7
00:00:20,196 --> 00:00:23,506
by reducing the number of threads in the block will work,

8
00:00:23,506 --> 00:00:27,488
whereas increasing the number of threads per block will make the problem worse.

9
00:00:27,488 --> 00:00:32,094
And this final one is a little more subtle. And this, again, verges on a ninja level optimization.

10
00:00:32,094 --> 00:00:38,789
Every thread block runs on a single SM but every SM can potentially hold more than one thread block.

11
00:00:38,789 --> 00:00:43,106
In this case, the threads in one thread block can still be making progress while

12
00:00:43,106 --> 00:00:46,749
those at the other thread block are gathering at a SyncThreads barrier.

13
00:00:46,749 --> 00:00:52,115
So this final strategy of increasing the number of blocks per SM can actually be a good one as well.
