1
00:00:00,330 --> 00:00:04,030
Let me start with a somewhat trivial
example just to contrast the notion of

2
00:00:04,030 --> 00:00:07,660
fast memory obliviousness
to fast memory awareness.

3
00:00:07,660 --> 00:00:10,340
Consider the problem of
sequential reduction.

4
00:00:10,340 --> 00:00:13,570
Let's start by reviewing
the fast memory aware version.

5
00:00:13,570 --> 00:00:18,340
It scans the list in units of size L
to match the memory transfer size.

6
00:00:18,340 --> 00:00:20,760
Notice that l is an explicit variable or

7
00:00:20,760 --> 00:00:24,910
parameter of the algorithm, but
at least the algorithm is I/O optimal.

8
00:00:24,910 --> 00:00:27,830
It performs just n/L transfers.

9
00:00:27,830 --> 00:00:31,730
By contrast, suppose that the hardware
in the operating system managed fast

10
00:00:31,730 --> 00:00:32,980
memory for you.

11
00:00:32,980 --> 00:00:37,940
For instance, maybe you already know
about caches from the OMSCSHPCA course.

12
00:00:37,940 --> 00:00:41,940
If so, you could regard this hardware
managed fast memory as a cache.

13
00:00:41,940 --> 00:00:43,720
Or, maybe you know about
virtual memory and

14
00:00:43,720 --> 00:00:48,260
translation look-aside buffers from
the OMSCS operating systems class.

15
00:00:48,260 --> 00:00:50,500
If so, you could imagine
the operating system and

16
00:00:50,500 --> 00:00:54,960
the hardware acting in concert to move
pages of data from disk to main memory.

17
00:00:54,960 --> 00:00:58,150
They would swap pages out of main
memory, which would be the fast memory

18
00:00:58,150 --> 00:01:02,090
in this case, back and forth to
disk whenever main memory is full.

19
00:01:02,090 --> 00:01:04,870
In either case, the purpose of
the automatic systems is to let you

20
00:01:04,870 --> 00:01:06,800
write the conventional algorithm.

21
00:01:06,800 --> 00:01:10,430
It's a lot simpler, because fast
memory is automatically managed,

22
00:01:10,430 --> 00:01:13,560
the algorithm doesn't need to
move data around explicitly.

23
00:01:13,560 --> 00:01:16,810
The automatic system takes each read or
write,

24
00:01:16,810 --> 00:01:20,840
checks that the data is already in fast
memory, if so, it returns the value and

25
00:01:20,840 --> 00:01:24,380
otherwise it goes to slow memory
in order to retrieve the value.

26
00:01:24,380 --> 00:01:25,940
And if it retrieves the value,
of course,

27
00:01:25,940 --> 00:01:28,940
it'll do transfers in blocks of size L.

28
00:01:28,940 --> 00:01:33,390
Notice that the conventional algorithm
makes no references to z or L.

29
00:01:33,390 --> 00:01:37,110
Thus, we say that the algorithm
is oblivious to fast memory.

30
00:01:37,110 --> 00:01:40,620
So if we had a good model of how
automatic data movement works,

31
00:01:40,620 --> 00:01:43,430
we'll be able to analyze
conventional algorithms, and

32
00:01:43,430 --> 00:01:46,680
say how many memory
transfers would they incur.

33
00:01:46,680 --> 00:01:50,100
Given such a model, we'll be able to
analyze conventional algorithms, and

34
00:01:50,100 --> 00:01:54,652
in this case show that the conventional
way to do a reduction also incurs just

35
00:01:54,652 --> 00:01:56,600
n/L transfers.

36
00:01:56,600 --> 00:01:58,490
This discussion points
out two questions,

37
00:01:58,490 --> 00:02:00,645
which is what this lesson is all about.

38
00:02:00,645 --> 00:02:05,095
First, what should we assume about
how the automatic system behaves?

39
00:02:05,095 --> 00:02:08,455
Secondly, can we create
algorithms without z or

40
00:02:08,455 --> 00:02:13,115
L parameters that nevertheless match the
performance of algorithms that do use z

41
00:02:13,115 --> 00:02:14,605
and L parameters?

42
00:02:14,605 --> 00:02:17,865
That's what we mean by oblivious,
though, of course,

43
00:02:17,865 --> 00:02:19,905
we mean it in a positive sense.

44
00:02:19,905 --> 00:02:22,000
One last note about terminology.

45
00:02:22,000 --> 00:02:25,340
We will by convention refer
to this fast memory as cache.

46
00:02:25,340 --> 00:02:26,370
Itâ€™s just a shortcut.

47
00:02:26,370 --> 00:02:28,205
Sometimes cache really means say,

48
00:02:28,205 --> 00:02:30,900
virtual memory backed main memory for
disk.

49
00:02:30,900 --> 00:02:34,320
It helps that it's a lot easier to say
cache oblivious than automatic fast

50
00:02:34,320 --> 00:02:35,170
memory oblivious.
