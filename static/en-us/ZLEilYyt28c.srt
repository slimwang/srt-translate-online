1
00:00:00,000 --> 00:00:06,000
As the final method in this unit, I'd like now to talk about k-nearest neighbors.

2
00:00:06,000 --> 00:00:09,000
And the distinguishing factor of k-nearest neighbors

3
00:00:09,000 --> 00:00:13,000
is that it is a nonparametric machine learning method.

4
00:00:13,000 --> 00:00:16,000
So far we've talked about parametric methods.

5
00:00:16,000 --> 00:00:21,000
Parametric methods have parameters, like probabilities or weights,

6
00:00:21,000 --> 00:00:25,000
and the number of parameters is constant.

7
00:00:25,000 --> 00:00:29,000
Or to put it differently, the number of parameters is independent of the training set size.

8
00:00:29,000 --> 00:00:34,000
So for example in the Naive Bayes, if we bring up more data,

9
00:00:34,000 --> 00:00:37,000
the number of condition probabilities will stay the same.

10
00:00:37,000 --> 00:00:41,000
Well, that wasn't technically always the case.

11
00:00:41,000 --> 00:00:46,000
Our vocabulary might increase and as such the number of parameters.

12
00:00:46,000 --> 00:00:53,000
But for any fixed dictionary, the number of parameters are truly independent of the training set size.

13
00:00:53,000 --> 00:00:56,000
The same was true, for example, in our regression cases

14
00:00:56,000 --> 00:01:02,000
where the number of regression weights is independent of the number of data points.

15
00:01:02,000 --> 00:01:06,000
Now this is very different from non-parametric

16
00:01:06,000 --> 00:01:10,000
where the number of parameters can grow.

17
00:01:10,000 --> 00:01:13,000
In fact, it can grow a lot over time.

18
00:01:13,000 --> 00:01:16,000
Those techniques are called non-parametric.

19
00:01:16,000 --> 00:01:20,000
Nearest neighbor is so straightforward.

20
00:01:20,000 --> 00:01:23,000
I'd really like to introduce you using a quiz.

21
00:01:23,000 --> 00:01:25,000
So here's my quiz.

22
00:01:25,000 --> 00:01:29,000
Suppose we have a number of data points.

23
00:01:29,000 --> 00:01:37,000
I want you for 1-nearest neighbor to check those squared areas

24
00:01:37,000 --> 00:01:41,000
that you believe will carry a positive label.

25
00:01:41,000 --> 00:01:45,000
And I will give you the label of the existing data points.

26
00:01:45,000 --> 00:01:50,000
So please check any of those boxes that you believe are now

27
00:01:50,000 --> 00:01:54,000
1-nearest neighbor that carry a positive label.

28
00:01:54,000 --> 99:59:59,999
And the algorithm, of course, searches for the nearest point in this Euclidean space and just copies its label.
