1
00:00:00,080 --> 00:00:03,360
Okay Michael so before we get started diving into

2
00:00:03,360 --> 00:00:06,150
a particular formalism or framework that I want to

3
00:00:06,150 --> 00:00:07,630
talk about, that we are going to use for

4
00:00:07,630 --> 00:00:09,880
this mini course or at least the first half or

5
00:00:09,880 --> 00:00:12,220
so of it. I want to remind everybody what

6
00:00:12,220 --> 00:00:14,170
the differences are between the three types of learning

7
00:00:14,170 --> 00:00:15,660
that we said we are going to look at

8
00:00:15,660 --> 00:00:18,390
over this entire course. Th, you recall what they are?

9
00:00:18,390 --> 00:00:22,250
>> Well reading off the slides supervised, unsupervised and reinforcement.

10
00:00:22,250 --> 00:00:25,180
>> That's right. And you know, again these things are all strongly

11
00:00:25,180 --> 00:00:28,610
related to one other but it's very useful to think about them as being very

12
00:00:28,610 --> 00:00:31,760
separate. So just as a reminder, supervised learning

13
00:00:31,760 --> 00:00:35,130
sort of takes the form of function approximation

14
00:00:35,130 --> 00:00:40,500
where you're given a bunch of x, y pairs And your goal is to find

15
00:00:40,500 --> 00:00:45,470
a function f that will map some new x to a proper y, you recall that?

16
00:00:45,470 --> 00:00:46,290
>> Yep.

17
00:00:46,290 --> 00:00:50,680
>> Unsupervised learning is very similar to supervised learning except that

18
00:00:50,680 --> 00:00:53,810
it turns out that you're given a bunch of x's

19
00:00:53,810 --> 00:00:56,870
and your goal is to find some f. That gives

20
00:00:56,870 --> 00:01:00,110
you a compact description of the set of x's that

21
00:01:00,110 --> 00:01:04,310
you've seen. So we call this clustering, or description as

22
00:01:04,310 --> 00:01:08,000
opposed to function approximation, and finally we're getting to reinforcement

23
00:01:08,000 --> 00:01:11,400
learning. Now reinforcement learning is actually a, a name that

24
00:01:11,400 --> 00:01:14,020
means many things in different fields, and here we tend

25
00:01:14,020 --> 00:01:16,380
to talk about it in a relatively specific way, and

26
00:01:16,380 --> 00:01:19,800
superficially it looks a lot like Supervised learning, in

27
00:01:19,800 --> 00:01:23,260
that we're going to be given a string of pairs

28
00:01:23,260 --> 00:01:26,190
of data, and we're going to try to learn some

29
00:01:26,190 --> 00:01:29,130
functions. But in the function approximation case, a supervized learning

30
00:01:29,130 --> 00:01:35,250
case, we were given a bunch of X and Y pairs. We were asked to learn F, but

31
00:01:35,250 --> 00:01:38,140
in reinforcement learning, we were given something totally different.

32
00:01:38,140 --> 00:01:42,300
Were instead going to be given x's and z's, and

33
00:01:42,300 --> 00:01:45,030
I'll tell you what the x's and the z's stand for in

34
00:01:45,030 --> 00:01:47,860
a minute, and then were going to have to learn some f that

35
00:01:47,860 --> 00:01:50,970
is going to generate y's, and so even though its going to look

36
00:01:50,970 --> 00:01:53,940
a lot like function approximation, its going to turn out that it's going to

37
00:01:53,940 --> 00:01:57,690
have a very different character. And that's really what the, the next

38
00:01:57,690 --> 00:02:00,000
few slides in a little bit of discussion is really about, is

39
00:02:00,000 --> 00:02:03,010
understanding what that character is. You'll also notice from the title here

40
00:02:03,010 --> 00:02:04,640
that I have decision making reinforcement

41
00:02:04,640 --> 00:02:07,580
learning, and that's because reinforcement learning is

42
00:02:07,580 --> 00:02:10,590
one mechanism for doing decision making. And again, I'll define

43
00:02:10,590 --> 00:02:13,050
that in just a second. Okay, so you with me, Michael?

44
00:02:13,050 --> 00:02:15,460
>> I think so. So should y be circled?

45
00:02:15,460 --> 00:02:17,400
because in some sense, you, you underlined the things we

46
00:02:17,400 --> 00:02:19,090
were given and you circled the things we needed to

47
00:02:19,090 --> 00:02:21,330
find, so y is something that we're going to find, right?

48
00:02:21,330 --> 00:02:22,330
>> Yeah, I suppose that I like that.

49
00:02:22,330 --> 00:02:23,650
>> All right. Interesting.

50
00:02:23,650 --> 00:02:25,625
>> Now it's a theta.

51
00:02:25,625 --> 00:02:30,810
>> [LAUGH] It's a Y trapped inside of a theta and it's yelling, Y?

52
00:02:30,810 --> 00:02:32,940
>> [LAUGH] I like that. I'm a Y

53
00:02:32,940 --> 00:02:36,720
trapped in a theta. Hm, I need to write a book

54
00:02:36,720 --> 00:02:40,290
about that. Okay, good. That's a good point Michael. So before

55
00:02:40,290 --> 00:02:42,840
we were learning, effectively trying to learn one thing and here

56
00:02:42,840 --> 00:02:46,060
we're still learning one thing. Because it's going to produce another thing

57
00:02:46,060 --> 00:02:49,590
for the deterministically, usually. But it's worth pointing out that we

58
00:02:49,590 --> 00:02:52,160
are going to be figuring how to produce both of these things

59
00:02:52,160 --> 00:02:54,680
as opposed to be given those things. Good job. OK. Are

60
00:02:54,680 --> 00:02:56,760
you ready to move forward,l Michael, with an example and a quiz?

61
00:02:56,760 --> 00:02:57,338
>> Awesome.

62
00:02:57,338 --> 00:02:58,020
>> Excellent.
