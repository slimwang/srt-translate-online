1
00:00:00,170 --> 00:00:03,150
So let's discuss the performance
of multi-threading and

2
00:00:03,150 --> 00:00:07,040
how can it be better than simply
running things one at a time.

3
00:00:07,040 --> 00:00:10,660
So if we have a processor with
no multi-threading support,

4
00:00:10,660 --> 00:00:13,320
then this is how to threads might run.

5
00:00:13,320 --> 00:00:16,620
These are cycles going
in this direction, so

6
00:00:16,620 --> 00:00:19,060
each notch here is a cycle.

7
00:00:19,060 --> 00:00:22,320
And we have four instructions
that can execute in this cycle.

8
00:00:22,320 --> 00:00:24,300
So this is what might happen.

9
00:00:24,300 --> 00:00:30,080
A green thread might be using this,
and this slot in this cycle.

10
00:00:30,080 --> 00:00:34,220
And the other two issue slots are not
used because the processor has no

11
00:00:34,220 --> 00:00:37,570
ready instructions to dispatch
to execution in this cycle.

12
00:00:37,570 --> 00:00:41,630
Let's say there is a data dependence so
next cycle one instruction can wake up.

13
00:00:42,795 --> 00:00:48,290
And then let's say that in the next
cycle we can have three instructions go,

14
00:00:48,290 --> 00:00:51,850
but then let's say that all of
the instructions are now waiting for

15
00:00:51,850 --> 00:00:52,720
something to happen.

16
00:00:52,720 --> 00:00:56,800
So let's say for a few cycles
we don't get much happening.

17
00:00:56,800 --> 00:01:00,550
Then, when it happens,
we get to execute, let's say, all four.

18
00:01:00,550 --> 00:01:03,590
And then maybe another cycle with two,
et cetera.

19
00:01:03,590 --> 00:01:06,170
So things can be like this, basically.

20
00:01:06,170 --> 00:01:09,940
Much of the time we
are running with a less than

21
00:01:09,940 --> 00:01:12,620
fully utilized processor pipeline.

22
00:01:12,620 --> 00:01:15,880
Let's say that at this point
we get an interrupt, and

23
00:01:15,880 --> 00:01:19,120
because there is another
thread that is read to run,

24
00:01:19,120 --> 00:01:22,790
we now get many cycles of
the operating system doing its thing.

25
00:01:22,790 --> 00:01:25,100
So it's also going to utilize
the pipeline in some way.

26
00:01:25,100 --> 00:01:30,350
But it spends many cycles basically
figuring out which thread to run next.

27
00:01:30,350 --> 00:01:34,240
Eventually decides that it's
going to be the blue thread and

28
00:01:34,240 --> 00:01:38,050
begins executing instructions from
that thread on the processor.

29
00:01:38,050 --> 00:01:40,810
So this is where we return
from the interrupt and

30
00:01:40,810 --> 00:01:42,580
start executing a new thread.

31
00:01:42,580 --> 00:01:45,720
Because let's say we have
these two threads ready to go.

32
00:01:45,720 --> 00:01:50,480
So the blue thread in a similar
way will be using the processor.

33
00:01:50,480 --> 00:01:53,660
Partially, let's say it
has a level one miss,

34
00:01:53,660 --> 00:01:56,170
takes a while to get
the thing from level two.

35
00:01:56,170 --> 00:01:59,810
Meanwhile, maybe it's able to
do something for a while, but

36
00:01:59,810 --> 00:02:01,880
eventually runs out of things to do.

37
00:02:01,880 --> 00:02:06,090
And then for example starts
doing something again, and

38
00:02:06,090 --> 00:02:08,070
let's say this whole cycle is used.

39
00:02:08,070 --> 00:02:11,215
So this is what might happen
in a processor with no

40
00:02:11,215 --> 00:02:12,870
multi-threading support.

41
00:02:12,870 --> 00:02:17,980
In that case really, the overhead that
you created by having to switch between

42
00:02:17,980 --> 00:02:22,170
threads, is probably larger than the
gains we are getting from running them.

43
00:02:22,170 --> 00:02:25,290
We we're better off just running
a single thread that does the work

44
00:02:25,290 --> 00:02:27,040
of both of these threads.

45
00:02:27,040 --> 00:02:32,870
So really, a single processor with no
multi-threading Is capable of doing this

46
00:02:32,870 --> 00:02:36,610
with a good operating system,
not because it's better for

47
00:02:36,610 --> 00:02:42,090
performance to break work into
multiple threads, but because we want

48
00:02:42,090 --> 00:02:45,920
to be able to simultaneously run several
applications and make progress in them.

49
00:02:45,920 --> 00:02:50,130
So that for example if you're playing
games and playing music at the same

50
00:02:50,130 --> 00:02:53,920
time, we alternate between the game and
the music player.

51
00:02:53,920 --> 00:02:57,840
Fast enough for you to not be able to
tell that they are really executing one

52
00:02:57,840 --> 00:02:59,240
at a time on your one core.

53
00:03:00,990 --> 00:03:04,700
If you have a chip multiprocessor,
we get to do something like this.

54
00:03:04,700 --> 00:03:09,440
Now we have two cores, each of
which pretty much gets to execute.

55
00:03:09,440 --> 00:03:13,460
One thread, so it's faster,
of course, than this, and

56
00:03:13,460 --> 00:03:19,130
we can benefit truly from being able
to write multi-threaded programs.

57
00:03:19,130 --> 00:03:24,630
But, you have to have two cores for
it, so the cost is about twice.

58
00:03:24,630 --> 00:03:26,044
The cost of a single core here.

59
00:03:26,044 --> 00:03:31,610
So with fine-grain multi-threading,
what we have is really one core,

60
00:03:31,610 --> 00:03:35,860
but with separate sets of registers for
these threads and some scheduling logic.

61
00:03:35,860 --> 00:03:39,690
With fine-grain multi-threading every
cycle we can switch between threads.

62
00:03:39,690 --> 00:03:41,810
So what happens is,

63
00:03:41,810 --> 00:03:45,610
the green thread gets exactly
same behavior in the first cycle.

64
00:03:45,610 --> 00:03:47,940
In the second cycle we
do the blue thread.

65
00:03:47,940 --> 00:03:51,580
So we get the behavior of
it's first cycle here.

66
00:03:51,580 --> 00:03:55,660
Then we do some of the work
from the green thread again.

67
00:03:55,660 --> 00:03:59,110
Then from the blue thread,
third cycle of the green thread,

68
00:03:59,110 --> 00:04:01,110
third cycle of the blue thread.

69
00:04:01,110 --> 00:04:04,350
And now, we would be running the green
thread except that there is nothing

70
00:04:04,350 --> 00:04:05,490
to run there.

71
00:04:05,490 --> 00:04:08,720
But what happens is the blue
thread has something to do.

72
00:04:08,720 --> 00:04:12,020
So we spend another cycle
on the blue thread and

73
00:04:12,020 --> 00:04:14,540
then the green thread is
still somewhere here.

74
00:04:14,540 --> 00:04:18,730
There is nothing ready to run but
these operations are going on.

75
00:04:18,730 --> 00:04:22,200
So the blue thread gets
one more cycle here.

76
00:04:22,200 --> 00:04:25,480
At this point,
the blue thread has nothing to do, but

77
00:04:25,480 --> 00:04:28,000
the green one now has something to do.

78
00:04:28,000 --> 00:04:32,960
So, we end up doing the work of the
green thread and then for another cycle.

79
00:04:32,960 --> 00:04:37,620
Then let's say neither of the threads
can do something, but then the blue

80
00:04:37,620 --> 00:04:41,110
thread is able to do this because
it's been three cycles since here.

81
00:04:43,130 --> 00:04:49,970
And then again, and as you can see,
we get done faster than here because we

82
00:04:49,970 --> 00:04:53,446
are able to eliminate some of the cycles
where we were not able to do anything.

83
00:04:53,446 --> 00:04:58,810
So, fine-grain multi-threading
benefits from the fact that when there

84
00:04:58,810 --> 00:05:03,130
is a long period of idleness in one
thread, for example, due a cache miss,

85
00:05:03,130 --> 00:05:07,030
you might be able to run still
instructions from the other thread.

86
00:05:07,030 --> 00:05:09,910
And finally,
let's see what happens in SMT.

87
00:05:09,910 --> 00:05:10,760
In SMT,

88
00:05:10,760 --> 00:05:14,630
we are able to mix instructions from
different threads in the same cycle.

89
00:05:14,630 --> 00:05:17,090
So what we will get is the.

90
00:05:17,090 --> 00:05:19,250
Green one get's this.

91
00:05:19,250 --> 00:05:22,480
The blue one also wants to use
the bottom slot, and let's say there

92
00:05:22,480 --> 00:05:26,250
is a unit there, for example,
the load unit that you have to use here.

93
00:05:26,250 --> 00:05:30,120
But we can still run
this in the same cycle.

94
00:05:30,120 --> 00:05:32,970
Next cycle the green thread does this.

95
00:05:32,970 --> 00:05:36,200
The blue one wants to now do this,
this, and this.

96
00:05:36,200 --> 00:05:38,280
And we can let's say do this too.

97
00:05:38,280 --> 00:05:42,280
But let's say there is a dependence from
this to this so we can only do this one.

98
00:05:42,280 --> 00:05:44,830
Next cycle,
the green thread can do this, and

99
00:05:44,830 --> 00:05:47,880
from the blue thread we can maybe
do this instruction, or maybe not.

100
00:05:47,880 --> 00:05:51,400
So let's say we can't because
maybe this one depends also

101
00:05:51,400 --> 00:05:54,140
on the one that we haven't done,
or the next one.

102
00:05:54,140 --> 00:05:57,020
Now, however, there is some period
of idleness in the green thread, and

103
00:05:57,020 --> 00:06:01,160
now the blue thread gets to make up for
missing out on some things, so

104
00:06:01,160 --> 00:06:05,860
it's able to maybe do this, and
this dependent instruction.

105
00:06:05,860 --> 00:06:08,610
And, at this point, the green thread
is ready to run something, so

106
00:06:08,610 --> 00:06:12,120
we can choose whether to run
the green or the blue one.

107
00:06:12,120 --> 00:06:14,460
Let's say that the green thread
has a higher priority, so

108
00:06:14,460 --> 00:06:17,610
we always try to do instructions
from the green thread.

109
00:06:17,610 --> 00:06:20,730
And only fill the gaps
with the blue ones.

110
00:06:20,730 --> 00:06:22,250
Now we've done this,

111
00:06:22,250 --> 00:06:26,010
next cycle we still do whatever
we can from the green thread.

112
00:06:26,010 --> 00:06:27,940
We now can do this.

113
00:06:27,940 --> 00:06:31,490
And now we only have
the blue thread left to do.

114
00:06:31,490 --> 00:06:34,050
If the green thread has more
stuff to do, we can do this.

115
00:06:34,050 --> 00:06:40,850
So as you can see, with SMT,
we get to populate unused slots

116
00:06:40,850 --> 00:06:45,280
in what would otherwise be a full
speed execution of the green threads.

117
00:06:45,280 --> 00:06:47,840
So that the blue thread
gets to make progress

118
00:06:47,840 --> 00:06:50,930
while the green thread really
is not suffering for it.

119
00:06:50,930 --> 00:06:53,070
And we can do that for
more than just two threads.

120
00:06:53,070 --> 00:06:55,580
So for
example if we had four threads we might

121
00:06:55,580 --> 00:06:58,430
be able to actually do another thread.

122
00:06:58,430 --> 00:07:02,282
At a slightly slower pace than blue
while we are also doing this, so

123
00:07:02,282 --> 00:07:06,520
with SMT what we are doing,
we are really using underutilized

124
00:07:06,520 --> 00:07:11,120
issue slots in our out of
order super scaling processor.

125
00:07:11,120 --> 00:07:14,378
The hardware cost to
do this is very small.

126
00:07:14,378 --> 00:07:18,050
Our fetch stage needs to be slightly
more complicated to allow us to

127
00:07:18,050 --> 00:07:19,840
fetch from one or the other PC.

128
00:07:21,040 --> 00:07:25,080
And a register file needs to be slightly
more complicated because really there

129
00:07:25,080 --> 00:07:27,830
are now two sets of
architectural registers.

130
00:07:27,830 --> 00:07:31,060
But other than that the whole
complicated out of order engine

131
00:07:31,060 --> 00:07:32,390
stays the same.

132
00:07:32,390 --> 00:07:35,703
So let's say this is going to
cost us something like 5% of

133
00:07:35,703 --> 00:07:38,850
the cost of a no
multi-threaded processor.

134
00:07:38,850 --> 00:07:43,550
This here, again after we do
registry naming and everything else,

135
00:07:43,550 --> 00:07:46,280
the process scheduler
stays just the same.

136
00:07:46,280 --> 00:07:49,730
We just need to put instructions
from multiple threads

137
00:07:49,730 --> 00:07:53,210
in the instruction window, so
that they could be scheduled from there.

138
00:07:53,210 --> 00:07:54,640
And now also when we commit,

139
00:07:54,640 --> 00:07:57,640
we have to figure out which instruction
belongs to which commit and so

140
00:07:57,640 --> 00:08:01,830
on, so the cost is slightly larger than
fine grain, but still not very large.

141
00:08:01,830 --> 00:08:06,850
Because again most of the complicated
preservation stations and

142
00:08:06,850 --> 00:08:11,350
execution units, and everything else,
stays pretty much unmodified.

143
00:08:11,350 --> 00:08:15,849
So this is going to have performance
that is maybe very, very close to a CMP.

144
00:08:17,000 --> 00:08:22,000
Two threads here, two threads here maybe
making almost as much progress, but

145
00:08:22,000 --> 00:08:24,800
at a very small fraction of this cost.
