1
00:00:01,933 --> 00:00:08,266
(Sebastian) Okay. Here's from Custer Kriptis in Greece.

2
00:00:08,267 --> 00:00:15,699
"Thanks a lot for this class. Are you providing a downloadable form of this course for people that completed it?

3
00:00:15,700 --> 00:00:27,532
"I would personally want to archive the lectures, given that I might want to refer to it in the future. Thank you, professors."

4
00:00:27,533 --> 00:00:34,766
(Peter) Yes, I think we covered that before. I think they'll always be there on YouTube. But we should package them up

5
00:00:34,767 --> 00:00:40,966
in a way to make it easy to gather them all together at once. So we'll look into trying to get that done.

6
00:00:40,967 --> 00:00:45,666
(Sebastian) Yeah. I also hope that the website will just stay up, and then people can just always go back.

7
00:00:45,667 --> 00:00:50,799
I find that the course the way we lay it out is not meant to be an encyclopedia or a reference book,

8
00:00:50,800 --> 00:00:54,766
so if you want to go back, it might be hard to find stuff, as you probably experienced.

9
00:00:54,767 --> 00:00:58,732
It's really meant to be for one-time consumption, you just go through it for the experience.

10
00:00:58,733 --> 00:01:05,465
So we might, in future months and years, add more information on how to find things and how to access things

11
00:01:05,467 --> 00:01:11,332
very quickly once you've learned it and just want to refresh it. That's clearly, I think, a deficiency of the current system.

12
00:01:11,333 --> 00:01:16,599
Evo from Houston, Texas says, "I agree with you to try things out instead of just reading books.

13
00:01:16,600 --> 00:01:22,932
"However, could you say a bit about types of materials you should/could study in order to get a broader foundation

14
00:01:22,933 --> 00:01:28,732
"in the field of A.I.? And thanks a bunch for this great initiative. Evo."

15
00:01:28,733 --> 00:01:36,099
Well, obviously there's one book that stands out among all others, one book that captures 95% of the marketplace,

16
00:01:36,100 --> 00:01:39,632
one book that has been translated into more languages than any other book,

17
00:01:39,633 --> 00:01:46,466
and clearly, chapter 26 is the best chapter, because I wrote it. (laughter) But this book so happens to be written

18
00:01:46,467 --> 00:01:50,932
by a person that sits on my left, you wouldn't believe it. And I highly recommend it.

19
00:01:50,933 --> 00:01:54,832
Peter, you said that you would take the proceeds of the sales this quarter and donate them?

20
00:01:54,833 --> 00:01:59,866
(Peter) That's right, and donate them to charity. My publisher did notice that the sales were going up

21
00:01:59,867 --> 00:02:04,466
because you all were buying books, so thank you. (Sebastian) That's really generous of you.

22
00:02:04,467 --> 00:02:10,265
(Peter) Yeah, well, it's generous of all you to buy the book, and I hope you got some good use out of it.

23
00:02:10,267 --> 00:02:15,932
(Sebastian) So you can tell I'm not doing this for Peter's personal profit, but that's actually a really good book,

24
00:02:15,933 --> 00:02:20,066
and I think Peter put a lot of work into the third edition. (Peter) Yeah. (Sebastian) I think more than the first two editions.

25
00:02:20,067 --> 00:02:24,066
(Peter) That's right. (Sebastian) It's amazing how the later editions consume more work.

26
00:02:24,067 --> 00:02:29,432
(Peter) The first edition was easiest, because Stuart Russell and I were doing it, and we just said,

27
00:02:29,433 --> 00:02:35,299
"We'll put what we put into our class when we teach it, and if you don't like it, too bad," and so it was easy--

28
00:02:35,300 --> 00:02:38,032
We just wrote it down. (Sebastian) And then all the professors (unintelligible).

29
00:02:38,033 --> 00:02:44,832
(Peter) Yeah. And then we felt like we were doing this for the world and not for ourselves, and that made it much harder.

30
00:02:44,833 --> 00:02:50,532
And we had to sort of double-check everything. (Sebastian) Yeah. But I've taught from this book many times,

31
00:02:50,533 --> 00:02:57,932
and I find it amazingly well-researched. It is a big book. It's not 500 pages, it's... can you tell how many pages it is?

32
00:02:57,933 --> 00:03:02,399
(Peter) 1,100, I think. (Sebastian) Oh my God, 1,100 pages. Well, it's going to keep you busy for a while.

33
00:03:02,400 --> 00:03:06,699
(Peter) Yeah. (Sebastian) The other thing that's nice about it is there's lots of references in there to other texts.

34
00:03:06,700 --> 00:03:12,932
I also wrote a book that isn't quite as popular as Peter's. It's more specific, on probabilistic robotics,

35
00:03:12,933 --> 00:03:16,532
so it looks into robotics from Bayes network perspective.

36
00:03:16,533 --> 00:03:24,432
And if, after this, you care about robotics and perception and real world systems, you can buy it.

37
00:03:24,433 --> 00:03:29,066
The sales didn't go up as a result of this class. We didn't use it as text at all.

38
00:03:29,067 --> 00:03:33,432
So if I teach a future robotics class, I might use that as a text.

39
00:03:33,433 --> 00:03:38,132
(Peter) And to answer Evo, I think you should also look into reading journal articles.

40
00:03:38,133 --> 00:03:44,166
Once you start getting into a field, then you should become competent to read the current research,

41
00:03:44,167 --> 00:03:50,699
and that's really where things are happening. And if you want to keep up with where the field is going,

42
00:03:50,700 --> 00:03:54,932
going to have to be able to learn to read those as well as read the textbooks.

43
00:03:54,933 --> 00:04:02,099
(Sebastian) Anul Lorena from Mexico City--hi, Mexico City--says, "Dear professors, you talked about

44
00:04:02,100 --> 00:04:06,766
"top-notch lists of students. Do you think it would be possible to know, after giving us the final score,

45
00:04:06,767 --> 00:04:13,899
"the overall place you got among the 40 or 80,000 students? That would be encouraging for future courses."

46
00:04:13,900 --> 00:04:21,232
And the answer is absolutely yes, we'll let you know your rank. We're kind of dabbling with the idea of

47
00:04:21,233 --> 00:04:27,932
contacting our top-notch students to solicit--for those of you who want to do it--to send us your c.v.

48
00:04:27,933 --> 00:04:32,399
We have good connections to a local search engine company and they're always looking for great people.

49
00:04:32,400 --> 00:04:38,166
It'd be a pleasure, actually, to assist some of you in finding you jobs, to be honest.

50
00:04:38,167 --> 00:04:45,432
I have to admit, I've been impressed by some of you, many of you, and the amazing high-quality answers

51
00:04:45,433 --> 00:04:50,866
you've given to a really challenging set of exam questions. At some point we looked at the number of--

52
00:04:50,867 --> 00:04:57,699
the ratio of top-notch students in this class outpaced the ratio of top-notch students at Stanford.

53
00:04:57,700 --> 00:05:03,732
So it would be a pleasure. So please stay tuned, and if you are doing really well, you might receive email by me.

54
00:05:03,733 --> 00:05:08,199
(Peter) And we'll be careful to respect your privacy and not spam you too much, and let you make the contact

55
00:05:08,200 --> 00:05:12,432
if you want to, but we may be able to help-- (Sebastian) Absolutely. (Peter) --make that connection.

56
00:05:12,433 --> 00:05:18,699
(Sebastian) This is really meant just as an assistance if you care about it; if not, just ignore us, please.

57
00:05:18,700 --> 00:05:22,832
Vicki in Brazil. "Hi, I just wanted to thank you, professors, for this excellent opportunity that I had.

58
00:05:22,833 --> 00:05:28,832
"I really appreciate the subject and the challenges it has brought. Please let us know of any incoming classes.

59
00:05:28,833 --> 00:05:33,299
"Professor Thrun and Professor Norvig, your passion is contagious."

60
00:05:33,300 --> 00:05:37,732
(Peter) Well, you're welcome again, Vicki. It's too easy. There aren't any hard questions this week.

61
00:05:37,733 --> 00:05:43,699
(Sebastian) Yeah, no one says, "This course sucks." Except once you said you didn't sleep much.

62
00:05:43,700 --> 00:05:48,932
(Peter) That's true. (laughter) (Sebastian) Well, I have to admit, these comments are moving me, honestly,

63
00:05:48,933 --> 00:05:54,399
they make me really emotional about this class, and make me feel really close to you guys.

64
00:05:54,400 --> 00:06:02,766
So here's one last question I'd like to ask, and I tried to find one that's a little bit less about the wonderful experience.

65
00:06:02,767 --> 00:06:12,666
Here's one by Neco from Moscow. "I want to ask about neural nets, evolution in programming, genetic algorithms,

66
00:06:12,667 --> 00:06:19,532
"fuzzy logic, fuzzy time series. The professors never mentioned these topics at all over the class. Why is this?

67
00:06:19,533 --> 00:06:24,766
"And will these topics be covered next classes?" And he actually hopes that they will.

68
00:06:24,767 --> 00:06:29,999
And the answer is that we only had ten weeks, and so we can't cover everything.

69
00:06:30,000 --> 00:06:37,866
Like Sebastian said, my book is 1,100 pages. That was too many, and all of A.I. is even larger than that.

70
00:06:37,867 --> 00:06:44,666
So we had to come up with a sampling. And in each area we chose a couple examples, and we left out other examples.

71
00:06:44,667 --> 00:06:50,999
So, like why didn't we do genetic algorithms? So genetic algorithms are certainly very popular, they're a big part of A.I.

72
00:06:51,000 --> 00:06:58,232
It's a commonly used tool. But the way we see it, genetic algorithms are another type of search algorithm.

73
00:06:58,233 --> 00:07:03,666
And we introduced a couple search algorithms, and since it wasn't a class just about those,

74
00:07:03,667 --> 00:07:10,899
we didn't want to exhaustively cover all of them. And so we covered what we could in the amount of time we had.

75
00:07:10,900 --> 00:07:16,999
(Sebastian) One of the most popular tools right now are probabilities. And of course, probabilities in machine learning,

76
00:07:17,000 --> 00:07:22,032
probabilities for inference, and probabilities and uncertainty. So for example, when it comes to fuzzy,

77
00:07:22,033 --> 00:07:27,866
I think these days probability has become somewhat more popular than fuzzy logic, which tries to achieve similar things--

78
00:07:27,867 --> 00:07:31,932
not exactly the same thing, but it's often used to represent uncertainty.

79
00:07:31,933 --> 00:07:36,132
And as Peter said, I think there's many topics we had to leave out. We did want to go in-depth in some topics

80
00:07:36,133 --> 00:07:40,432
and really teach you the skill of using it. We didn't just want to make an overview class.

81
00:07:40,433 --> 00:07:45,899
And you can take my word for it, we also left them out at Stanford. So Stanford students have no clue about these things, either.

82
00:07:45,900 --> 00:07:51,299
And these are important concepts and they're worth studying, and I think a lot of interesting stuff is happening in these fields.

83
00:07:51,300 --> 00:07:58,799
And so our apologies for not dragging this class on for another eight weeks or so.

84
00:07:58,800 --> 00:08:06,332
Well, I think that's our last office hour. (Peter) That's it. So, thank you all for watching and participating in the class.

85
00:08:06,333 --> 00:08:09,532
Good luck on the final exam. I know you'll all do great.

86
00:08:09,533 --> 00:08:12,966
You've done great so far, and it's been a pleasure working with you.

87
00:08:12,967 --> 00:08:20,432
(Sebastian) So it was great having you in class. We've been blown away by the wonderful feedback we received.

88
00:08:20,433 --> 00:08:26,166
I think it was one of the best ways to spend my time, and I'm so glad I could reach so many of you.

89
00:08:26,167 --> 00:08:35,765
When I was a student, I couldn't get access to good education at the scale that we aspire to provide to you for free.

90
00:08:35,767 --> 00:08:40,566
So thank you so much, and I hope you stay tuned for possible future classes.

91
00:08:40,567 --> 00:08:45,266
(Peter) And it's been a great experiment, I've learned a lot from doing it. I hope you've learned.

92
00:08:45,267 --> 00:08:53,366
And I hope the field of A.I. and the field of education and online education can take some lessons from this.

93
00:08:53,367 --> 00:08:57,432
There's still a lot we have to analyze to kind of understand what went on.

94
00:08:57,433 --> 00:09:03,032
We know we worked really hard and didn't sleep very much. We don't quite understand all the lessons

95
00:09:03,033 --> 00:09:08,499
from what worked and what doesn't work. We're going to go back and analyze that and try to figure it out,

96
00:09:08,500 --> 00:09:11,232
and then try to figure out what the next steps are in the next class.

97
00:09:11,233 --> 00:09:15,132
And I hear, Peter, you're going to do a TED Talk, right? (Peter) I am. (Sebastian) That's wonderful.

98
00:09:15,133 --> 00:09:20,332
So Ted is this big conference that takes place in February--technology, entertainment, design.

99
00:09:20,333 --> 00:09:26,999
It's a meeting where the brightest and the best in the world report on their experiences,

100
00:09:27,000 --> 00:09:30,966
and Peter's going to be the person doing it. (Peter) So by February I have to understand what just happened.

101
00:09:30,967 --> 00:09:36,267
(Sebastian) Yeah, I'm happy to help you. All right. Goodbye. (Peter) Goodbye and thank you.
