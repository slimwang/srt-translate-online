1
00:00:00,190 --> 00:00:02,145
So let's try to think about a method that might perform better

2
00:00:02,145 --> 00:00:06,417
for matrices with varying numbers of non-zero elements per row.

3
00:00:06,417 --> 00:00:08,814
If you'll recall, the approach that we pursued in Unit 4

4
00:00:08,814 --> 00:00:12,887
was to assign a thread to each element, do 1 multiplication per element,

5
00:00:12,887 --> 00:00:18,146
then use a backwards inclusive segmented sum scan to add up the partial products

6
00:00:18,146 --> 00:00:19,596
and generate a result per row.

7
00:00:19,596 --> 00:00:23,300
Let's look at this approach step by step so that we can understand it.

8
00:00:23,300 --> 00:00:26,138
So we're going to start with a CSR representation of the matrix.

9
00:00:26,138 --> 00:00:29,274
So step 1, we are going to use the row pointer data structure

10
00:00:29,274 --> 00:00:34,312
to generate an array with 1s for segment heads and 0s for non-segment heads.

11
00:00:34,312 --> 00:00:37,545
Then were going to launch a thread for each element in the matrix.

12
00:00:37,545 --> 00:00:40,019
We're going to multiply it by the corresponding vector element,

13
00:00:40,019 --> 00:00:42,755
which we fetch using the index data structure.

14
00:00:42,755 --> 00:00:47,925
For thread n, that code will look like value(n) times x(index(n)).

15
00:00:47,925 --> 00:00:51,083
Then were going to perform our backwards inclusive segmented sum scan,

16
00:00:51,083 --> 00:00:54,034
which will sum up all of the partial products in the matrix row.

17
00:00:54,034 --> 00:00:57,401
And then finally, the output of that sum scan will be a sparse vector,

18
00:00:57,401 --> 00:01:00,277
which we might want to pack back into a dense vector.

19
00:01:00,277 --> 00:01:04,590
And we can use the row pointer addresses to gather that sparse vector back into the dense vector.

20
00:01:04,590 --> 00:01:09,693
Now let's go answer the same question we asked about the thread per row approach.
