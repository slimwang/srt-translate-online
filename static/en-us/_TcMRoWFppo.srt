1
00:00:00,370 --> 00:00:02,530
So now you have a small neural network.

2
00:00:02,530 --> 00:00:05,370
It's not particularly deep,
just two layers.

3
00:00:05,370 --> 00:00:07,440
You can make it bigger, more complex,

4
00:00:07,440 --> 00:00:10,330
by increasing the size of that
hidden layer in the middle.

5
00:00:10,330 --> 00:00:13,370
But it turns out that increasing
this H is not particularly

6
00:00:13,370 --> 00:00:15,020
efficient in general.

7
00:00:15,020 --> 00:00:19,170
You need to make it very, very big,
and then it gets really hard to train.

8
00:00:19,170 --> 00:00:22,820
This is where the central idea of
deep learning comes into play.

9
00:00:22,820 --> 00:00:26,360
Instead, you can also add more
layers and make your model deeper.

10
00:00:26,360 --> 00:00:28,550
There are lots of good
reasons to do that.

11
00:00:28,550 --> 00:00:30,570
One is parameter efficiency.

12
00:00:30,570 --> 00:00:34,320
You can typically get much more
performance with fewer parameters

13
00:00:34,320 --> 00:00:36,430
by going deeper rather than wider.

14
00:00:37,510 --> 00:00:40,340
Another one is that a lot of
natural phenomena that you might be

15
00:00:40,340 --> 00:00:41,350
interested in,

16
00:00:41,350 --> 00:00:45,920
tend to have a hierarchical structure
which deep models naturally capture.

17
00:00:45,920 --> 00:00:48,120
If you poke at a model for
images, for example, and

18
00:00:48,120 --> 00:00:50,230
visualize what the model learns,

19
00:00:50,230 --> 00:00:55,350
you'll often find very simple things at
the lowest layers, like lines or edges.

20
00:00:55,350 --> 00:00:56,450
Once you move up,

21
00:00:56,450 --> 00:00:59,820
you tend to see more complicated
things like geometric shapes.

22
00:00:59,820 --> 00:01:03,660
Go further up and you start seeing
things like objects, faces.

23
00:01:03,660 --> 00:01:07,095
This is very powerful because the model
structure matches the kind of

24
00:01:07,095 --> 00:01:10,050
abstractions that you might
expect to see in your data.

25
00:01:10,050 --> 00:01:12,910
And as a result the model has
an easier time learning them.
