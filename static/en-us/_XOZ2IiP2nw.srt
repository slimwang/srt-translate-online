1
00:00:00,269 --> 00:00:02,937
More interesting from the GPU context is a merge sort.

2
00:00:02,937 --> 00:00:06,746
And it's really interesting to discuss how to map this efficiently to a GPU

3
00:00:06,746 --> 00:00:10,681
because it's a great instance of a divide-and-conquer approach to the problem.

4
00:00:10,681 --> 00:00:16,186
So here's a tree that represents our merge sort, and what's particularly interesting about mapping this to a GPU

5
00:00:16,186 --> 00:00:20,563
is that the problem starts off with tons of little tiny parallel problems,

6
00:00:20,563 --> 00:00:27,246
and then as the algorithm proceeds, we eventually end up with only 1 very large problem to solve,

7
00:00:27,246 --> 00:00:31,198
and that's the final merge. This is more challenging many of the algorithms we've discussed,

8
00:00:31,198 --> 00:00:35,305
where we have the luxury of being able to solve lots of little parallel problems

9
00:00:35,305 --> 00:00:37,841
independently throughout the whole computation.

10
00:00:37,841 --> 00:00:40,678
So what we do at each stage of this tree is the same.

11
00:00:40,678 --> 00:00:46,498
The only operation that we need is merging 2 sorted lists together into 1 sorted list.

12
00:00:46,498 --> 00:00:51,855
We begin with n items, which we treat as n sorted 1-element lists,

13
00:00:51,855 --> 00:00:57,791
then we run n over 2 merges to create n over 2, sorted 2-element lists.

14
00:00:57,791 --> 00:01:04,031
Then we run n over 4 merges to create n over 4, sorted 4-element lists, and so on.

15
00:01:04,031 --> 00:01:09,668
Overall this is log n stages, and in each stage we merge a total of n elements,

16
00:01:09,668 --> 00:01:14,975
so the overall number of operations that were complexity is order of n log n.

17
00:01:14,975 --> 00:01:20,083
This algorithmic exposes a lot of parallelism within each step, each individual merge:

18
00:01:20,083 --> 00:01:24,854
this merge, this merge, this merge, this merge, and so on can proceed in parallel.

19
00:01:24,854 --> 00:01:28,828
Now the hard part about mapping this to the GPU is that the number

20
00:01:28,828 --> 00:01:34,429
and size of merge as we do on each step differs greatly between the first step and the last.

21
00:01:34,429 --> 00:01:39,408
So I'm going to talk about a GPU implementation that has 3 stages.

22
00:01:39,408 --> 00:01:47,042
The first stage, this blue stage here, is merging a very large number of very short sequences.

23
00:01:48,944 --> 00:01:50,847
Because we have many, many tasks and each is very small,

24
00:01:50,847 --> 00:01:53,983
we might choose to assign 1 merge to 1 thread,

25
00:01:53,983 --> 00:01:58,422
which can perform each individual merge using a serial algorithm on that thread.

26
00:01:58,422 --> 00:02:03,279
We might get better memory coalescing performance if we use shared memories as staging area to read many

27
00:02:03,279 --> 00:02:06,393
input elements or store many output elements at the same time.

28
00:02:06,393 --> 00:02:09,452
I'd say it's more common, though, at the start of a large merge sort,

29
00:02:09,452 --> 00:02:14,424
to just sort a block of elements, say, 1024 within shared memory and then start the merge sort

30
00:02:14,424 --> 00:02:20,063
with sorted chunks of size 1024. In other words, if we're actually doing this in practice,

31
00:02:20,063 --> 00:02:23,735
we're probably going to use a different algorithm to do this blue stage here

32
00:02:23,735 --> 00:02:28,605
with lots of little tiny tasks and then use merge sort to do the last 2 stages here,

33
00:02:28,605 --> 00:02:33,878
and we're going to see a good algorithm for an in block sort after we finish the discussion on merge sort.

34
00:02:33,878 --> 00:02:35,512
Now we move on to stage 2.

35
00:02:35,512 --> 00:02:41,227
Now we have lots of small sorted blocks, and we need to merge these small sorted blocks together.

36
00:02:41,227 --> 00:02:46,618
On the GPU for these intermediate merges, we would usually assign 1 merge to 1 thread block.

37
00:02:46,618 --> 00:02:50,642
Now, the obvious way to merge 2 sorted sequences is a serial algorithm.

38
00:02:50,642 --> 00:02:54,262
So let's take a little bit of a closer look at the algorithm that we choose to use here,

39
00:02:54,262 --> 00:02:56,942
and we'll come back to this diagram a little bit later.

40
00:02:56,942 --> 00:03:00,705
The obvious way to merge 2 sorted sequences is a serial algorithm,

41
00:03:00,705 --> 00:03:02,807
and here's our little serial processor here.

42
00:03:02,807 --> 00:03:07,409
The input to this algorithm is 2 sorted sequences, and the output is 1 sorted sequence.

43
00:03:07,409 --> 00:03:13,650
And so the algorithm is that the serial processor looks at the head of each one of the sorted sequences,

44
00:03:13,650 --> 00:03:19,561
chooses whichever element is smaller, outputs it on to the tail of the output sequence,

45
00:03:19,561 --> 00:03:24,661
and then advances the input sequence from which he took the previous element.

46
00:03:24,661 --> 00:03:27,125
However, this would be a poor match for the GPU

47
00:03:27,125 --> 00:03:30,133
because this is a serial algorithm and it wouldn't keep all of our hardware busy.

48
00:03:30,133 --> 00:03:35,816
So it's instructive to look another way, a better way, a more parallel way to merge 2 sorted sequences.
