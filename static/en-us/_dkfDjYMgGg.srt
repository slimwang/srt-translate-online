1
00:00:00,180 --> 00:00:03,700
You're probably asking yourselves,
if the event-driven model has

2
00:00:03,700 --> 00:00:06,114
just one thread,
then how did it achieve concurrency?

3
00:00:06,114 --> 00:00:09,700
In the multi-process and
the multi-threaded models,

4
00:00:09,700 --> 00:00:13,290
we had each execution context,
whether it's a process or

5
00:00:13,290 --> 00:00:16,680
a thread,
handle only one request at a time.

6
00:00:16,680 --> 00:00:20,940
To achieve concurrency, we would simply
add multiple execution context, so

7
00:00:20,940 --> 00:00:23,730
multiple processes or multiple threads.

8
00:00:23,730 --> 00:00:27,583
And then, if necessar,y if we
have fewer CPUs than contexts,

9
00:00:27,583 --> 00:00:30,720
then we would have to
context-switch among them.

10
00:00:30,720 --> 00:00:34,240
The way the event-driven model achieves
concurrency is by interleaving

11
00:00:34,240 --> 00:00:38,930
the processing of multiple requests,
within a same execution context.

12
00:00:38,930 --> 00:00:42,080
Here in the event-driven model,
we have a single thread, and

13
00:00:42,080 --> 00:00:47,220
the single thread switches its execution
among the processing that's required for

14
00:00:47,220 --> 00:00:48,730
different requests.

15
00:00:48,730 --> 00:00:51,990
Let's say we have a client request
coming into the system, so

16
00:00:51,990 --> 00:00:54,620
it's a request for client C1.

17
00:00:54,620 --> 00:00:58,170
And we receive a request for
a connection that gets dispatched,

18
00:00:58,170 --> 00:01:01,030
the accept operation gets processed.

19
00:01:01,030 --> 00:01:03,290
Then, we receive the actual request.

20
00:01:03,290 --> 00:01:08,590
So it's an HTTP message that gets
processed, the message gets parsed,

21
00:01:08,590 --> 00:01:09,720
we extract the files.

22
00:01:09,720 --> 00:01:12,700
So now we actually need
to read the file and

23
00:01:12,700 --> 00:01:15,530
we initiate I/O from
the reading file handler.

24
00:01:16,530 --> 00:01:20,340
So at that point, the request for
client one has been processed through

25
00:01:20,340 --> 00:01:24,930
several of these steps and it's
waiting on the disk I/O to complete.

26
00:01:24,930 --> 00:01:27,430
Let's say, in the meantime,
two more requests have come in.

27
00:01:27,430 --> 00:01:32,830
So client two and client three have
sent a request for a connection.

28
00:01:32,830 --> 00:01:35,190
Let's say the client two
request was picked up first,

29
00:01:35,190 --> 00:01:39,720
the connection was accepted, and
now for the processing of client two,

30
00:01:39,720 --> 00:01:42,550
we need to wait for
the actual HTTP message to be received.

31
00:01:43,920 --> 00:01:47,330
So the processing of client
two is waiting on an event

32
00:01:47,330 --> 00:01:51,930
from the network that will have the HTTP
message that needs to be received.

33
00:01:51,930 --> 00:01:55,930
And let's say client three,
its request has been accepted and

34
00:01:55,930 --> 00:01:57,420
it's currently being handled,

35
00:01:57,420 --> 00:02:01,700
so the client three request is in
the accept connection handler.

36
00:02:01,700 --> 00:02:04,390
Some amount of time later,
the processing of

37
00:02:04,390 --> 00:02:08,500
all of these three requests has
moved a little bit further along.

38
00:02:08,500 --> 00:02:13,260
So the request for C3,
the accept connection was completed,

39
00:02:13,260 --> 00:02:18,920
and now that request is waiting on
an event with the HTTP message.

40
00:02:18,920 --> 00:02:23,600
The request for client two, that one,
perhaps, we're waiting on the disk I/O,

41
00:02:23,600 --> 00:02:26,710
in order to read the file
that needs to be sent out.

42
00:02:26,710 --> 00:02:31,690
And maybe the request for client C1,
already started sending the file in

43
00:02:31,690 --> 00:02:35,450
chunks at a time, so blocks of
some number of bytes at a time.

44
00:02:35,450 --> 00:02:38,900
So, it's waiting in one
of those iterations.

45
00:02:38,900 --> 00:02:43,440
So, although we have only one
execution context, only one thread,

46
00:02:43,440 --> 00:02:49,400
if we take a look, we have concurrent
execution of multiple client requests.

47
00:02:49,400 --> 00:02:54,070
It just happens to be interleaved, given
that there's one execution context.

48
00:02:54,070 --> 00:02:56,710
However, they're multiple,
at the same time,

49
00:02:56,710 --> 00:02:58,710
multiple client requests being handled.
