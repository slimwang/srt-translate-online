1
00:00:00,790 --> 00:00:04,160
Now that you're familiar with the Bag of Words representation,

2
00:00:04,160 --> 00:00:08,182
let's get your hands on the keyboard and have you using it in sklearn.

3
00:00:08,182 --> 00:00:12,400
In sklearn Bag of Words is called CountVectorizer, presumably because it's

4
00:00:12,400 --> 00:00:16,520
counting the number of times various words show up in a corpus.

5
00:00:16,520 --> 00:00:19,450
Now I'm going to walk you through some examples on the interpreter.

6
00:00:19,450 --> 00:00:20,350
And in the next few videos,

7
00:00:20,350 --> 00:00:23,930
you get some hands-on experience via programming quizzes.

8
00:00:23,930 --> 00:00:27,430
I head over to the interpreter and using the online documentation for

9
00:00:27,430 --> 00:00:30,325
reference, I import the CountVectorizer.

10
00:00:30,325 --> 00:00:36,430
CountVectorizer lives in the feature_extraction.text part of sklearn.

11
00:00:37,470 --> 00:00:38,860
She got wrong the first time.

12
00:00:38,860 --> 00:00:42,670
But I can import it just like any other object in sklearn.

13
00:00:42,670 --> 00:00:44,010
Then I create my vectorizer.

14
00:00:44,010 --> 00:00:48,880
And I need to feed it some documents that come in the form of strings.

15
00:00:48,880 --> 00:00:50,710
I liked Sebastian's example, but

16
00:00:50,710 --> 00:00:53,980
I think I want to do something that sounds a little bit more like the emails

17
00:00:53,980 --> 00:00:56,810
that I would actually expect to see in an inbox.

18
00:00:56,810 --> 00:00:58,570
So we'll make up some strings.

19
00:00:58,570 --> 00:01:01,940
These aren't really emails, but they kind of sound like them.

20
00:01:01,940 --> 00:01:04,900
The first thing I need to do to get these into CountVectorizer is I need to

21
00:01:04,900 --> 00:01:06,610
put them into a list.

22
00:01:06,610 --> 00:01:08,790
Now I'm going to create the bag-of-words,

23
00:01:08,790 --> 00:01:13,410
which is what I get when I put this email list into my CountVectorizer.

24
00:01:13,410 --> 00:01:15,230
And I actually did this a, a little bit wrong.

25
00:01:15,230 --> 00:01:17,510
There's two steps that I forgot here.

26
00:01:17,510 --> 00:01:20,920
The first is that I need to fit my data using my Vectorizer.

27
00:01:20,920 --> 00:01:23,310
The next thing is I need to transform it.

28
00:01:23,310 --> 00:01:24,480
So first, I'll do the fit.

29
00:01:24,480 --> 00:01:27,930
This is where it's actually figuring out what all the words in the corpus are,

30
00:01:27,930 --> 00:01:30,330
all the words in all the emails.

31
00:01:30,330 --> 00:01:33,820
And assigning say, numbers or list indices to each of them.

32
00:01:33,820 --> 00:01:36,730
And then the transform is where it actually takes all the words in

33
00:01:36,730 --> 00:01:41,420
the corpus and figures out how many counts of each word occur.

34
00:01:41,420 --> 00:01:43,631
My syntax isn't perfect here, but this should work.

35
00:01:46,314 --> 00:01:49,190
And now to start to understand this, let me print my bag-of-words.

36
00:01:49,190 --> 00:01:50,680
See what it looks like.

37
00:01:50,680 --> 00:01:54,740
What I get is a bunch of tuples and integers, and while this looks

38
00:01:54,740 --> 00:01:58,880
rather opaque, we can actually unpack it in a fairly straightforward way.

39
00:01:58,880 --> 00:02:01,110
Let's take this row as an example.

40
00:02:01,110 --> 00:02:04,770
The way to interpret this is that in document number one,

41
00:02:04,770 --> 00:02:06,780
word number seven occurs one time.

42
00:02:06,780 --> 00:02:08,490
Now, of course,

43
00:02:08,490 --> 00:02:12,090
we have to ask what word number seven is in order to interpret this as humans.

44
00:02:13,270 --> 00:02:14,800
But all of the information is there.

45
00:02:15,850 --> 00:02:21,270
Similarly, I can see in document number one, word number six occurs three times.

46
00:02:21,270 --> 00:02:24,060
So just out of curiosity, let's go back up to document number one and

47
00:02:24,060 --> 00:02:26,990
figure out what we think word number six is.

48
00:02:26,990 --> 00:02:31,290
So document number one is going to be string two.

49
00:02:31,290 --> 00:02:33,640
Because the indexing starts at zero.

50
00:02:33,640 --> 00:02:37,520
And I can see that there is a actually a word that's repeated three times, and

51
00:02:37,520 --> 00:02:39,450
it's the word great.

52
00:02:39,450 --> 00:02:41,720
So assuming that that's what word number seven is,

53
00:02:41,720 --> 00:02:42,820
things are starting to make sense.

54
00:02:43,940 --> 00:02:46,190
From looking at the sklearn documentation,

55
00:02:46,190 --> 00:02:49,750
I see that there's an attribute of the bag-of-words called the vocabulary.

56
00:02:49,750 --> 00:02:52,630
And this is a way that I can test my hypothesis.

57
00:02:52,630 --> 00:02:55,860
So I call the function get on my vocabulary.

58
00:02:55,860 --> 00:02:58,230
And I pass to it an argument which is the word.

59
00:02:58,230 --> 00:03:01,880
And my hypothesis is that what it should return, because this line gave

60
00:03:01,880 --> 00:03:06,140
us the clue, that word number six in document one occurred three times.

61
00:03:06,140 --> 00:03:06,970
And that's what happens.

62
00:03:06,970 --> 00:03:10,120
So this way, for any word in the corpus,

63
00:03:10,120 --> 00:03:14,720
I can figure out what feature number it is in my bag-of-words.

64
00:03:14,720 --> 00:03:17,270
You can also go the other direction too.

65
00:03:17,270 --> 00:03:20,150
If you want to ask, for example, what is the word associated with

66
00:03:20,150 --> 00:03:24,030
feature number six, there's a way you can extract this information too.

67
00:03:24,030 --> 00:03:27,120
We'll get to that in the next lesson on feature selection in a really

68
00:03:27,120 --> 00:03:28,650
cool example.

69
00:03:28,650 --> 00:03:31,180
But now, I want to get your hands on the keyboard with a quiz.
