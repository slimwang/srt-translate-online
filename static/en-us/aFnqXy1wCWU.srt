1
00:00:00,000 --> 00:00:03,000
In summary, then, we've learned how to do a lot with MDPs--

2
00:00:03,000 --> 00:00:06,000
especially using reinforcement learning.

3
00:00:06,000 --> 00:00:08,000
If we don't know what the MDP is,

4
00:00:08,000 --> 00:00:11,000
we know how to estimate it and then solve it.

5
00:00:11,000 --> 00:00:15,000
We can estimate the utility for some fixed policy, pi;

6
00:00:15,000 --> 00:00:18,000
or we could estimate the Q values for the

7
00:00:18,000 --> 00:00:22,000
optimal policy while executing an exploration policy.

8
00:00:22,000 --> 00:00:25,000
And we saw something about how we can make the right trade-offs

9
00:00:25,000 --> 00:00:28,000
between exploration and exploitation.

10
00:00:28,000 --> 00:00:31,000
So reinforcement learning remains one of the most exciting areas of AI.

11
00:00:31,000 --> 00:00:35,000
Some of the biggest surprises have come out of reinforcement learning--

12
00:00:35,000 --> 00:00:37,000
things like Tesauro's backgammon player

13
00:00:37,000 --> 00:00:39,000
or Andrew Ng's helicopter;

14
00:00:39,000 --> 00:00:43,000
and we think that there's a lot more that we can learn.

15
00:00:43,000 --> 99:59:59,999
It's an exciting field, and one where there's plenty of room for new innovation.
