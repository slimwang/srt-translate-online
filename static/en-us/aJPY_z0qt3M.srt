1
00:00:00,310 --> 00:00:02,380
Which ones did you think,
David, and why?

2
00:00:02,380 --> 00:00:05,550
>> So for learning a script, I said that
five of the things we've talked about so

3
00:00:05,550 --> 00:00:08,250
far would really help
an agent learn a script.

4
00:00:08,250 --> 00:00:10,430
So we've seen in the past
that semantic networks and

5
00:00:10,430 --> 00:00:12,530
frames are representationally
equivalent.

6
00:00:12,530 --> 00:00:16,149
We saw that when we put the raven's
progressive matrices problems

7
00:00:16,149 --> 00:00:20,010
in terms of first semantic networks and
then converted them to frames.

8
00:00:20,010 --> 00:00:23,140
Frames, as we've seen, are very useful
for storing the type of information

9
00:00:23,140 --> 00:00:26,050
necessary to construct
a thorough script.

10
00:00:26,050 --> 00:00:28,490
And if semantic networks
are representationally equivalent,

11
00:00:28,490 --> 00:00:32,479
then we can also imagine a script
composed of semantic networks instead.

12
00:00:32,479 --> 00:00:35,280
To skip the middle couple for a second,
I can imagine incremental concept

13
00:00:35,280 --> 00:00:37,790
learning to be very important
to learning scripts.

14
00:00:37,790 --> 00:00:40,140
We can an imagine an AI agent
acting in the world and

15
00:00:40,140 --> 00:00:43,830
encountering multiple events everyday,
and even to start to kind of develop

16
00:00:43,830 --> 00:00:48,090
a categorization scheme for
those different experiences.

17
00:00:48,090 --> 00:00:51,745
So for example, that agent might learn
that if I'm developing a script for

18
00:00:51,745 --> 00:00:55,695
fast food, whether or not I see a
McDonald's logo or a Wendy's logo when I

19
00:00:55,695 --> 00:00:59,185
walk in, is not necessarily
important to which script I run.

20
00:00:59,185 --> 00:01:01,915
But whether or not I see a counter
with cashiers behind it or

21
00:01:01,915 --> 00:01:04,275
a hostess waiting to see me,
is important.

22
00:01:04,275 --> 00:01:08,225
So that way, an agent can use
incremental concept learning to learn

23
00:01:08,225 --> 00:01:12,762
the difference, for example, a fast
food script and a fine dining script.

24
00:01:12,762 --> 00:01:16,300
So Ashok discussed before, planning
happens when an agent has an initial

25
00:01:16,300 --> 00:01:20,200
state and a goal state and figures
out how to navigate between the two.

26
00:01:20,200 --> 00:01:21,510
Once they figured out that plan for

27
00:01:21,510 --> 00:01:23,830
navigating between that initial
state and that goal state,

28
00:01:23,830 --> 00:01:27,590
that then becomes a script that could be
transferred to a new similar situation

29
00:01:27,590 --> 00:01:29,886
without having to completely
re-plan the route from scratch.

30
00:01:29,886 --> 00:01:34,220
And finally common sense reasoning helps
the agent out because it gives the agent

31
00:01:34,220 --> 00:01:37,380
a kind of a language within which to
learn the script in the first place.

32
00:01:37,380 --> 00:01:40,660
It can learn a script within this
language of primitive actions that

33
00:01:40,660 --> 00:01:44,860
it understands and then can use those to
make sense of new and novel situations.

34
00:01:44,860 --> 00:01:47,690
Production systems and learning by
recording cases don't really apply as

35
00:01:47,690 --> 00:01:50,720
much to scripts because they both
involve representations at a very

36
00:01:50,720 --> 00:01:54,850
different level of abstraction,
at a very low level of abstraction.

37
00:01:54,850 --> 00:01:57,250
With learning by recording cases,
we tend to stick with the cases,

38
00:01:57,250 --> 00:01:59,240
whereas scripts we have
an abstraction over them.

39
00:01:59,240 --> 00:02:02,560
And production systems are more like
atoms of knowledge representation

40
00:02:02,560 --> 00:02:05,750
instead of molecules or compounds
like we deal with with scripts.

41
00:02:05,750 --> 00:02:06,660
>> That's good, David.

42
00:02:06,660 --> 00:02:10,070
I may add, one of the things
regarding the semantic networks.

43
00:02:10,070 --> 00:02:12,640
Recall that when we
discussed semantic networks,

44
00:02:12,640 --> 00:02:16,470
we had considered how we could use
semantic networks to interpret stories.

45
00:02:16,470 --> 00:02:17,700
We'll use this same example.

46
00:02:17,700 --> 00:02:19,270
Ashok wanted to become rich.

47
00:02:19,270 --> 00:02:20,370
He got a gun.

48
00:02:20,370 --> 00:02:24,270
And we said that inside a semantic
network the notes that correspond to

49
00:02:24,270 --> 00:02:28,550
Ashok wanted rich and gun get activated.

50
00:02:28,550 --> 00:02:32,357
And the activation spread from there and
there's a path that formed a spare

51
00:02:32,357 --> 00:02:36,920
semantic network that path is the
interpretation of this particular story.

52
00:02:36,920 --> 00:02:39,640
In a sense a script is that part.

53
00:02:39,640 --> 00:02:42,270
>> Of course if you think you see a
connection between production systems or

54
00:02:42,270 --> 00:02:45,190
learning by recording cases and
scripts that I haven't seen.

55
00:02:45,190 --> 00:02:47,560
Or if you think the connection
between the other topics and

56
00:02:47,560 --> 00:02:49,830
scripts isn't quite as
close as I've described,

57
00:02:49,830 --> 00:02:51,980
feel free to head over to our forums and
we'll discuss it there.
