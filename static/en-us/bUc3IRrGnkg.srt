1
00:00:00,315 --> 00:00:05,120
Salza identifies eight design principles that goes hand

2
00:00:05,120 --> 00:00:09,820
in hand with the levels of protection that we just talked about. In designing a

3
00:00:09,820 --> 00:00:14,720
secure system, the first principle to adhere to is

4
00:00:14,720 --> 00:00:19,950
economy of mechanisms, and by that, what is meant is

5
00:00:19,950 --> 00:00:25,480
that the mechanism should be easy enough, so that

6
00:00:25,480 --> 00:00:29,190
it can be verified. The mechanism should be easy enough so that it can be

7
00:00:29,190 --> 00:00:34,830
verified whether it works or not, that's important, Economy of Mechanisms.

8
00:00:34,830 --> 00:00:40,610
The second principle is what he calls fail safe defaults, the

9
00:00:40,610 --> 00:00:46,050
idea is you want to explicitly allow access to the system

10
00:00:46,050 --> 00:00:50,940
or information. The default should not be no access. The reason

11
00:00:50,940 --> 00:00:55,090
for saying this is because if the default is no access then there is no way

12
00:00:55,090 --> 00:00:59,180
to guarantee that, that information is protected. This

13
00:00:59,180 --> 00:01:02,250
is a negative statement again. So instead of a

14
00:01:02,250 --> 00:01:05,129
negative statement like that, you want to explicitly

15
00:01:05,129 --> 00:01:07,820
allow access to information. That's what is a

16
00:01:07,820 --> 00:01:11,510
second design principle, is in designing the system,

17
00:01:11,510 --> 00:01:15,910
you make sure that the default is fail safe.

18
00:01:15,910 --> 00:01:21,170
The third design principle is what he calls complete mediation. And by

19
00:01:21,170 --> 00:01:26,910
that what is meant is that the security mechanism should not

20
00:01:26,910 --> 00:01:32,310
take any shortcuts. For example in authentication, you want to make

21
00:01:32,310 --> 00:01:36,830
sure that when somebody presents credentials

22
00:01:36,830 --> 00:01:39,580
for authenticating themselves with the system,

23
00:01:40,630 --> 00:01:45,950
that has to be checked completely. And what that means is that,

24
00:01:45,950 --> 00:01:51,220
there should be no shortcuts to authentication. An example of a shortcut,

25
00:01:51,220 --> 00:01:56,280
will be a password file that lives on storage, if it

26
00:01:56,280 --> 00:02:00,910
is cached, for performance reasons, that can

27
00:02:00,910 --> 00:02:05,830
be a source of secuirty violation. Because the actual password

28
00:02:05,830 --> 00:02:10,419
file on the storage system may have changed, but the cached copy in memory may

29
00:02:10,419 --> 00:02:12,820
not be reflecting it, and that would

30
00:02:12,820 --> 00:02:17,760
result in violation of security. If the authentication

31
00:02:17,760 --> 00:02:23,920
uses the cached copy instead of the persistent copy. So that's an example of why

32
00:02:23,920 --> 00:02:27,840
you need complete mediation in designing a secure

33
00:02:27,840 --> 00:02:30,950
system, so that's another principle that a secure

34
00:02:30,950 --> 00:02:34,680
system should adhere to. The next design principle

35
00:02:34,680 --> 00:02:38,030
is what is called open design, meaning that

36
00:02:38,030 --> 00:02:40,540
you want to make the design completely open,

37
00:02:40,540 --> 00:02:43,340
so in other words you publish the design exactly

38
00:02:43,340 --> 00:02:50,270
spec it out and publish it, but protect the keys that are used by the design.

39
00:02:50,270 --> 00:02:53,460
What that means is that cracking the design,

40
00:02:53,460 --> 00:02:56,280
even though it is published, in order to access

41
00:02:56,280 --> 00:03:01,600
the design or get any useful service out of the system, you have to present

42
00:03:01,600 --> 00:03:08,470
keys. And those authentication keys should be so hard to break.

43
00:03:08,470 --> 00:03:11,525
Computationally breaking the keys should become

44
00:03:11,525 --> 00:03:13,980
infeasible. So that's what is meant by

45
00:03:13,980 --> 00:03:23,120
open design. And what does open design principle also foster is the underlying

46
00:03:23,120 --> 00:03:28,540
tenet that detection is easier than prevention. We

47
00:03:28,540 --> 00:03:33,700
don't know what all attacks are possible from the bad guys. And

48
00:03:33,700 --> 00:03:38,990
so it is not possible to prevent all of them. And

49
00:03:38,990 --> 00:03:43,900
therefore, what we want to do is, you want to publish

50
00:03:43,900 --> 00:03:48,760
the design but make breaking the protection computationally

51
00:03:48,760 --> 00:03:52,060
infeasible and detect that a violation has

52
00:03:52,060 --> 00:03:54,870
happened, than try to prevent it, detect

53
00:03:54,870 --> 00:03:59,580
that a violation has happened, so that's the key idea behind this open design

54
00:03:59,580 --> 00:04:04,600
principle. The next principle talks about separation

55
00:04:04,600 --> 00:04:06,840
of privilege. You may have seen quite

56
00:04:06,840 --> 00:04:13,530
often in banks, two keys may be necessary to open the vault of the bank.

57
00:04:13,530 --> 00:04:18,730
And the two keys will be held by two different individuals, so that both of

58
00:04:18,730 --> 00:04:23,220
them have to come together in order to open the vault. So this is the idea

59
00:04:23,220 --> 00:04:28,440
behind separation of privilege. The next principle talks about,

60
00:04:28,440 --> 00:04:34,130
least privilege. That is, we want to use the absolute minimum

61
00:04:34,130 --> 00:04:39,130
capability that we need, in order to carry out a certain task.

62
00:04:39,130 --> 00:04:44,450
So the controls in the system should be based on need to know. An example would

63
00:04:44,450 --> 00:04:51,080
be, to do certain things on your computer. For instance, if you want to install

64
00:04:51,080 --> 00:04:57,500
certain new pieces of software, you may be able to do that as a normal

65
00:04:57,500 --> 00:05:00,910
user on your laptop, but for certain things

66
00:05:00,910 --> 00:05:05,010
you may need administrative privileges. So clearly identifying

67
00:05:05,010 --> 00:05:08,830
what functions you need administrative privilege

68
00:05:08,830 --> 00:05:13,230
or superuser privilege, versus, what functions

69
00:05:13,230 --> 00:05:18,680
you need normal privilege and ensuring that the right level of privilege is

70
00:05:18,680 --> 00:05:23,025
provided or afforded. By the system to the user, is an important design

71
00:05:23,025 --> 00:05:31,030
principle. And in fact, this is the origin for the idea of Firewalls,

72
00:05:31,030 --> 00:05:36,180
that are common these days in organizational setups. What firewalls do is

73
00:05:36,180 --> 00:05:39,260
to insure that individuals within an

74
00:05:39,260 --> 00:05:43,760
organization are able access external information from

75
00:05:43,760 --> 00:05:50,370
inside the corporate network only on a need basis, or information that is inside

76
00:05:50,370 --> 00:05:55,500
the corporate network is allowed to get out only under authorized conditions.

77
00:05:56,640 --> 00:06:01,160
So that's the, the need to know based controls, and that has become very

78
00:06:01,160 --> 00:06:03,210
common these days with the prevalence of

79
00:06:03,210 --> 00:06:08,700
firewalls in, in any administrative setup. Another principle

80
00:06:08,700 --> 00:06:13,900
is, least common mechanism. Or in other words, if there is a mechanism that

81
00:06:13,900 --> 00:06:17,830
the system wants to implement to assure

82
00:06:17,830 --> 00:06:22,240
information security. At what level should that mechansim

83
00:06:22,240 --> 00:06:24,980
be implemented? Should it be implemented in the

84
00:06:24,980 --> 00:06:28,030
kernel? Or should it be available as a

85
00:06:28,030 --> 00:06:30,900
library that is outside the kernel? Because there

86
00:06:30,900 --> 00:06:34,280
are implications when something is inside the kernel,

87
00:06:34,280 --> 00:06:39,380
it has access to information that is also inside the kernel. Wheres, if it is a

88
00:06:39,380 --> 00:06:42,480
library sitting on top of the kernel, then

89
00:06:42,480 --> 00:06:47,760
you can limit the amount of damage a malfunctioning

90
00:06:47,760 --> 00:06:52,290
mechanism can do to the system as a whole. So that's the idea

91
00:06:52,290 --> 00:06:57,130
behind these common mechanisms. And the last design principle that Salza

92
00:06:57,130 --> 00:07:02,620
identifies is psychological acceptability. And

93
00:07:02,620 --> 00:07:07,890
by that, what is meant is the mechanisms being easy

94
00:07:07,890 --> 00:07:13,260
to use for the end user, so that they completely understand what they are doing.

95
00:07:13,260 --> 00:07:18,220
When they are using a particular mechanism

96
00:07:18,220 --> 00:07:20,338
that is provided by the system, so good

97
00:07:20,338 --> 00:07:24,280
user interface is something that is extremely important

98
00:07:24,280 --> 00:07:26,530
as one of the design principles in building

99
00:07:26,530 --> 00:07:31,750
a secure system. Two things jump out when you look at this set of design

100
00:07:31,750 --> 00:07:35,196
principles. That is lead out by Salza in

101
00:07:35,196 --> 00:07:39,115
his seminal paper back in the early 70s.

102
00:07:39,115 --> 00:07:44,454
The first thing that jumps out is all of these are positive statements. They are

103
00:07:44,454 --> 00:07:49,180
not negative statements. I mentioned earlier saying that,

104
00:07:49,180 --> 00:07:52,470
my system prevents all violations, is a negative

105
00:07:52,470 --> 00:07:55,610
statement because, it is saying that my

106
00:07:55,610 --> 00:07:58,610
system is bullet proof. No system is bullet

107
00:07:58,610 --> 00:08:01,640
proof, and therefore all the things that are

108
00:08:01,640 --> 00:08:05,144
being laid out as design principles are positive

109
00:08:05,144 --> 00:08:11,470
statements and they give a way by which you can say that these

110
00:08:11,470 --> 00:08:18,080
are the things that it can do. And you build enough into your design, such that

111
00:08:18,080 --> 00:08:21,440
you can detect violations when they occur,

112
00:08:21,440 --> 00:08:24,800
rather than trying to prevent them. Prevention is

113
00:08:24,800 --> 00:08:30,380
much harder than detection. The other thing that jumps out is the fact that all

114
00:08:30,380 --> 00:08:32,919
of these principles, laid out in the

115
00:08:32,919 --> 00:08:37,900
early 70s, are applicable to today's systems and

116
00:08:37,900 --> 00:08:41,950
these principles were crafted when computers were

117
00:08:41,950 --> 00:08:44,690
not even connected to the extent that they

118
00:08:44,690 --> 00:08:47,530
are today. So the two key takeaways

119
00:08:47,530 --> 00:08:50,870
from these design principles are, first of all,

120
00:08:50,870 --> 00:08:56,320
you want to build the system in such a way that cracking the protection boundary

121
00:08:56,320 --> 00:09:00,850
is computationally infeasible. That's the first takeaway. The second

122
00:09:00,850 --> 00:09:04,720
takeaway is you build the system to detect violations

123
00:09:04,720 --> 00:09:08,780
rather than prevent violations. Because prevention is much harder.

124
00:09:08,780 --> 00:09:11,300
Detection on the other hand, is something that is doable.
