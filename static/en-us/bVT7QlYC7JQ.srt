1
00:00:00,000 --> 00:00:05,000
I'd like to illustrate the problem, using a very simple environment

2
00:00:05,000 --> 00:00:07,000
that looks, as follows:

3
00:00:07,000 --> 00:00:09,000
Suppose you live in world like this;

4
00:00:09,000 --> 00:00:11,000
and your agent starts over here,

5
00:00:11,000 --> 00:00:13,000
and there are 2 possible outcomes.

6
00:00:13,000 --> 00:00:16,000
You can exit the maze over here--

7
00:00:16,000 --> 00:00:18,000
where you get a plus 100--

8
00:00:18,000 --> 00:00:20,000
or you can exit the maze over here,

9
00:00:20,000 --> 00:00:22,000
where you receive a minus 100.

10
00:00:22,000 --> 00:00:25,000
Now, in a fully observable case,

11
00:00:25,000 --> 00:00:28,000
and in a deterministic case,

12
00:00:28,000 --> 00:00:32,000
the optimal plan might look something like this;

13
00:00:32,000 --> 00:00:35,000
and whether or not is goes straight over here or not, depends on the details.

14
00:00:35,000 --> 00:00:38,000
For example, whether the agent has momentum or not.

15
00:00:38,000 --> 00:00:44,000
But you'll find a single sequence of actions and states that might cut the corners,

16
00:00:44,000 --> 00:00:47,000
as close as possible, to reach the plus 100 as fast as possible.

17
00:00:47,000 --> 00:00:50,000
That's conventional planning.

18
00:00:50,000 --> 00:00:53,000
Let's contrast this with the case we just learned about,

19
00:00:53,000 --> 00:00:57,000
which is the fully observable case or the stochastic case.

20
00:00:57,000 --> 00:01:01,000
We just learned that the best thing to compute is a policy

21
00:01:01,000 --> 00:01:04,000
that assigns to every possible state, an optimal action;

22
00:01:04,000 --> 00:01:07,000
and simplified speaking, this might look as follows:

23
00:01:07,000 --> 00:01:09,000
Where each of these arrows corresponds

24
00:01:09,000 --> 00:01:12,000
to a sample control policy.

25
00:01:12,000 --> 00:01:16,000
And those are defined in part of the state space that are even far away.

26
00:01:16,000 --> 00:01:18,000
So this wouuld be an example of a control policy

27
00:01:18,000 --> 00:01:22,000
where all the arrows gradually point you over here.

28
00:01:22,000 --> 00:01:25,000
We just learned about this, using MDPs and value iteration.

29
00:01:25,000 --> 00:01:29,000
The case I really want to get at is the case of partial observability--

30
00:01:29,000 --> 00:01:32,000
which we will eventually solve, using a technique called POMDP.

31
00:01:32,000 --> 00:01:37,000
And in this case, I'm going to keep the location of the agent in the maze observable.

32
00:01:37,000 --> 00:01:43,000
The part I'm going to make unobservable is where, exactly, I receive plus 100

33
00:01:43,000 --> 00:01:45,000
and where I receive minus 100.

34
00:01:45,000 --> 00:01:48,000
Instead, I'm going to put a sign over here

35
00:01:48,000 --> 00:01:51,000
that tells the agent where to expect plus 100,

36
00:01:51,000 --> 00:01:53,000
and where to expect minus 100.

37
00:01:53,000 --> 00:01:57,000
So the optimum policy would be to first move to the sign,

38
00:01:57,000 --> 00:01:59,000
read the sign;

39
00:01:59,000 --> 00:02:03,000
and then return and go to the corresponding exit,

40
00:02:03,000 --> 00:02:07,000
for which the agent now knows where to receive plus 100.

41
00:02:07,000 --> 00:02:10,000
So, for example, if this exit over here gives us plus 100,

42
00:02:10,000 --> 00:02:12,000
the sign will say Left.

43
00:02:12,000 --> 00:02:15,000
If this exit over here gives us plus 100, the sign will say Right.

44
00:02:15,000 --> 00:02:17,000
What makes this environment interesting is

45
00:02:17,000 --> 00:02:21,000
that if the agent knew which exit would have plus 100,

46
00:02:21,000 --> 00:02:23,000
it will go north, from a starting position.

47
00:02:23,000 --> 00:02:26,000
It goes south exclusively to gather information.

48
00:02:26,000 --> 00:02:30,000
So the question becomes: Can we devise a method for planning

49
00:02:30,000 --> 00:02:36,000
that understands that, even though we'd wish to receive the plus 100 as the best exit,

50
00:02:36,000 --> 00:02:40,000
there's a detour necessary to gather information.

51
00:02:40,000 --> 00:02:42,000
So here's a solution that doesn't work:

52
00:02:42,000 --> 00:02:46,000
Obviously, the agent might be in 2 different worlds--and it doesn't know.

53
00:02:46,000 --> 00:02:49,000
It might be in the world where there's plus 100 on the Left side

54
00:02:49,000 --> 00:02:51,000
or it might be in the world with plus 100 on the Right side,

55
00:02:51,000 --> 00:02:53,000
with minus 100 in the corresponding other exit.

56
00:02:53,000 --> 00:02:59,000
What doesn't work is you can't solve the problem for both of these cases

57
00:02:59,000 --> 00:03:00,000
and then put these solutions together--

58
00:03:00,000 --> 00:03:02,000
for example, by averaging.

59
00:03:02,000 --> 00:03:04,000
The reason why this doesn't work is

60
00:03:04,000 --> 00:03:08,000
this agent, after averaging, would go north.

61
00:03:08,000 --> 00:03:11,000
It would never have the idea that it is worthwhile to go south,

62
00:03:11,000 --> 00:03:15,000
read the sign, and then return to the optimal exit.

63
00:03:15,000 --> 00:03:18,000
When it arrives, finally, at the intersection over here,

64
00:03:18,000 --> 00:03:20,000
it doesn't really know what to do.

65
00:03:20,000 --> 00:03:22,000
So here is the situation that does work--

66
00:03:22,000 --> 00:03:25,000
and it's related to information space or belief space.

67
00:03:25,000 --> 00:03:29,000
In the information space or belief space representation you do planning,

68
00:03:29,000 --> 00:03:31,000
not in the set of physical world states,

69
00:03:31,000 --> 00:03:34,000
but in what you might know about those states.

70
00:03:34,000 --> 00:03:39,000
And if you're really honest, you find out that there's a multitude of belief states.

71
00:03:39,000 --> 00:03:44,000
Here's the initial one, where you just don't know where to receive 100.

72
00:03:44,000 --> 00:03:48,000
Now, if you move around and either reach one of these exits or the sign,

73
00:03:48,000 --> 00:03:51,000
you will suddenly know where to receive 100.

74
00:03:51,000 --> 00:03:55,000
And that makes your belief state change--

75
00:03:55,000 --> 00:03:58,000
and that makes your belief state change.

76
00:03:58,000 --> 00:04:01,000
So, for example, if you find out that 100 is Left,

77
00:04:01,000 --> 00:04:03,000
then your belief state will look like this--

78
00:04:03,000 --> 00:04:05,000
where the ambiguity is now resolved.

79
00:04:05,000 --> 00:04:09,000
Now, how would you jump from this state space or this state space?

80
00:04:09,000 --> 00:04:12,000
The answer is: when you read the sign,

81
00:04:12,000 --> 00:04:16,000
there's a 50 percent chance that the location over here

82
00:04:16,000 --> 00:04:19,000
will result in a transition to the location over here--

83
00:04:19,000 --> 00:04:23,000
50 percent because there's a 50 percent chance that the plus 100 is on the Left.

84
00:04:23,000 --> 00:04:28,000
There's also a 50 percent chance that the plus 100 is on the Right,

85
00:04:28,000 --> 00:04:31,000
so the transition over here is stochastic;

86
00:04:31,000 --> 00:04:35,000
and with 50 percent chance, it will result in a transition over here.

87
00:04:35,000 --> 00:04:39,000
If we now do the MDP trick in this new belief space,

88
00:04:39,000 --> 00:04:44,000
and you pour water in here, it kind of flows through here

89
00:04:44,000 --> 00:04:48,000
and creates all these gradients--as we had before.

90
00:04:48,000 --> 00:04:51,000
We do the same over here and all these gradients are being created

91
00:04:51,000 --> 00:04:53,000
point to this exit on the Left side.

92
00:04:53,000 --> 00:04:58,000
Then, eventually, this water will flow through here and create gradients like this;

93
00:04:58,000 --> 00:05:02,000
and then flow back through here, where it creates gradients like this.

94
00:05:02,000 --> 00:05:06,000
So the value function is plus 100 over here, plus 100 over here

95
00:05:06,000 --> 00:05:08,000
that gradually decrease down here, down here;

96
00:05:08,000 --> 00:05:11,000
and then gradually further decrease over here--

97
00:05:11,000 --> 00:05:15,000
and even further decrease over there, so we've got arrows like these.

98
00:05:15,000 --> 00:05:20,000
And that shows you that in this new belief space, you can find a solution.

99
00:05:20,000 --> 00:05:24,000
In fact, you can use value iteration--MDP's value iteration--

100
00:05:24,000 --> 00:05:28,000
in this new space to find a solution to this really complicated

101
00:05:28,000 --> 00:05:30,000
partially observable planning process.

102
00:05:30,000 --> 00:05:33,000
And the solution--just to reiterate--

103
00:05:33,000 --> 00:05:35,000
we'll suggest: Go south first,

104
00:05:35,000 --> 00:05:37,000
read the sign,

105
00:05:37,000 --> 00:05:41,000
expose yourself to the random position to the Left or Right world

106
00:05:41,000 --> 99:59:59,999
in which you are now able to reach the plus 100 with absolute confidence.
