1
00:00:00,430 --> 00:00:07,160
The product DQ, that is the data server query, and the rate of query

2
00:00:07,160 --> 00:00:13,320
that is coming into the server. This DQ represents some sort of system limit for

3
00:00:13,320 --> 00:00:16,170
a given server capacity the product DQ

4
00:00:16,170 --> 00:00:19,630
is a constant. Said differently for a different

5
00:00:19,630 --> 00:00:25,676
system capacity, we can increase the number of clients that we are serving if we

6
00:00:25,676 --> 00:00:29,050
reduce the amount of data that we're

7
00:00:29,050 --> 00:00:32,540
using to process the incoming queries. That is,

8
00:00:32,540 --> 00:00:39,000
we're increasing Q by decreasing the harvest or D. Or can do the opposite and

9
00:00:39,000 --> 00:00:44,750
that is, we can entertain a smaller set of queries. That is the yield will come

10
00:00:44,750 --> 00:00:50,760
down but we will be able to give the complete data that is needed

11
00:00:50,760 --> 00:00:53,160
for serving that query. An example of would

12
00:00:53,160 --> 00:00:56,610
be, if I am a client that is accessing

13
00:00:56,610 --> 00:01:02,140
a server for my mail, I would want to get all my mail, not part of the mail.

14
00:01:02,140 --> 00:01:08,050
So in that case, I will be happy if the server gives me a harvest of one, even

15
00:01:08,050 --> 00:01:12,000
it means that not all the incoming clients maybe

16
00:01:12,000 --> 00:01:16,240
served by the server due to the capacity limitation

17
00:01:16,240 --> 00:01:20,880
of the server at any point of time. So as a system administrator, we have some

18
00:01:20,880 --> 00:01:24,310
choices to play with. The important thing is

19
00:01:24,310 --> 00:01:28,730
that in giant's scale services. The performance is limited

20
00:01:28,730 --> 00:01:34,220
by network and not by the I/O capacity. We can have as much I/O capacity as we

21
00:01:34,220 --> 00:01:37,670
want by having more hardware resources here, but

22
00:01:37,670 --> 00:01:41,180
what we are bound by is the network capacity.

23
00:01:41,180 --> 00:01:45,920
So if we increase the capacity of a server, we have a choice as a system

24
00:01:45,920 --> 00:01:50,690
administrator. We can either increase the harvest, keeping

25
00:01:50,690 --> 00:01:54,302
the yield the same. Or, we can increase the

26
00:01:54,302 --> 00:01:57,030
number of clients we are serving. That is,

27
00:01:57,030 --> 00:01:59,800
we can increase the yield, keeping D a

28
00:01:59,800 --> 00:02:03,050
constant. That's the knob that a system administrator

29
00:02:03,050 --> 00:02:07,060
can play with in terms of dealing with capacity

30
00:02:07,060 --> 00:02:09,520
increases at the server. Similarly, if I am

31
00:02:09,520 --> 00:02:12,880
a system administrator, and some nodes in the server

32
00:02:12,880 --> 00:02:16,480
fail, then again we have a choice of

33
00:02:16,480 --> 00:02:20,990
either decreasing the harvest or decreasing the yield, in

34
00:02:20,990 --> 00:02:24,090
order to deal with reduced DQ value. Of

35
00:02:24,090 --> 00:02:26,980
course, it all depends on how the server itself

36
00:02:26,980 --> 00:02:29,510
is architected, if the failures can be hidden

37
00:02:29,510 --> 00:02:32,530
through replication and so on. But the important message

38
00:02:32,530 --> 00:02:38,860
I want to convey to you is that this DQ represents a system constant, so far

39
00:02:38,860 --> 00:02:41,170
as the server is concerned, in terms of

40
00:02:41,170 --> 00:02:43,970
the capacity. Given a particular capacity of the

41
00:02:43,970 --> 00:02:46,860
server, DQ is fixed. So as a system

42
00:02:46,860 --> 00:02:50,990
administrator you have a choice of either sacrificing

43
00:02:50,990 --> 00:02:54,180
yield for harvest or harvest for yield. You

44
00:02:54,180 --> 00:02:57,720
cannot increase both the harvest and yield without

45
00:02:57,720 --> 00:03:02,100
increasing the server capacity. At traditional measure that has been used in

46
00:03:02,100 --> 00:03:10,160
servers, is the notion of IOOPS, or I/O operations per second, and these are

47
00:03:10,160 --> 00:03:13,310
meaningful in database kinds of applications.

48
00:03:13,310 --> 00:03:16,670
Where the applications are disbound, but the

49
00:03:16,670 --> 00:03:20,070
giant scale applications are network bound,

50
00:03:20,070 --> 00:03:23,180
and for network bound applications this manager

51
00:03:23,180 --> 00:03:30,400
DQ is much more intuitive as to what is going on in terms of managing the

52
00:03:30,400 --> 00:03:33,950
incoming load to the server - And managing

53
00:03:33,950 --> 00:03:36,170
the corpus of data that the server has

54
00:03:36,170 --> 00:03:39,210
to look at in order to satisfy incoming

55
00:03:39,210 --> 00:03:43,210
queries. Another metric that system administrators have often

56
00:03:43,210 --> 00:03:45,330
used is what is called up time. You

57
00:03:45,330 --> 00:03:48,570
may have heard of terminologies like mean time

58
00:03:48,570 --> 00:03:52,010
between failure and mean time to repair.

59
00:03:52,010 --> 00:03:55,570
Meantime between failure is, what is the expected

60
00:03:55,570 --> 00:03:58,700
time between two successive failures inside a

61
00:03:58,700 --> 00:04:02,750
data center? And similarly meantime to repair is

62
00:04:02,750 --> 00:04:07,870
if a failure is detected, how much time does it take to bring up a failed

63
00:04:07,870 --> 00:04:13,880
server, that need time to repair. And the up-time is defined as the ratio of

64
00:04:13,880 --> 00:04:19,110
the difference between, mean time between failure and MTTR, that is mean time to

65
00:04:19,110 --> 00:04:27,190
repair, and MTBF, that is uptime is equal to MTBF minus MTTR

66
00:04:27,190 --> 00:04:32,930
divided my MTBF. That is uptime. And you want the the uptime to be

67
00:04:32,930 --> 00:04:38,750
close to one. And usually uptime is measured in nines. Meaning point nine,

68
00:04:38,750 --> 00:04:44,120
nine, nine, nine. Five nines or six nines and so on. So you want the up time to

69
00:04:44,120 --> 00:04:50,230
be as close to one as possible for giant scale services. But again, this up time

70
00:04:50,230 --> 00:04:54,590
as a metric is not very satisfying because

71
00:04:54,590 --> 00:04:57,800
if there are no queries giving the time that

72
00:04:57,800 --> 00:05:01,030
is needed for repairing, that is, during the MTT

73
00:05:01,030 --> 00:05:04,250
par, the mean time to repair, if no queries

74
00:05:04,250 --> 00:05:07,010
come into the server, then you haven't

75
00:05:07,010 --> 00:05:10,530
made anybody unhappy. In that sense, the uptime

76
00:05:10,530 --> 00:05:16,460
is not a very intuitive measure of how well a server is performing. It is better

77
00:05:16,460 --> 00:05:22,550
to look at yield as the output metric. And the harvest, again, is the output

78
00:05:22,550 --> 00:05:29,680
metric for say how well a server is able to deal with the dynamism and scale of

79
00:05:29,680 --> 00:05:33,380
requesting handled by a particular giant-scale service. We'll

80
00:05:33,380 --> 00:05:36,320
see that this DQ principle is very powerful

81
00:05:36,320 --> 00:05:40,200
in advising the system administrator on how to

82
00:05:40,200 --> 00:05:43,400
architect the system. How much to replicate? How

83
00:05:43,400 --> 00:05:48,430
much to partition in terms of the data set that the server is handling? How to

84
00:05:48,430 --> 00:05:51,210
deal with failures? How to gracefully degrade the

85
00:05:51,210 --> 00:05:55,240
servers when the volume of incoming traffic increases

86
00:05:55,240 --> 00:05:59,880
beyond a server capacity? All of these are questions that

87
00:05:59,880 --> 00:06:04,140
can be handled very elegantly using the DQ principle. And

88
00:06:04,140 --> 00:06:08,840
the key underlying assumption in the DQ principle, is that

89
00:06:08,840 --> 00:06:13,530
the giant scaled services are network bound, and not I/O bound.
