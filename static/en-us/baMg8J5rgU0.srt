1
00:00:00,970 --> 00:00:01,589
All right.

2
00:00:01,589 --> 00:00:06,000
So that ends our conversation about
discriminative classification methods.

3
00:00:06,000 --> 00:00:10,530
We've seen sort of the general
approach to finding a window and

4
00:00:10,530 --> 00:00:15,810
somehow deciding that that window
is class A or class not A.

5
00:00:15,810 --> 00:00:19,890
And we've talked about generative
methods which are not used nearly

6
00:00:19,890 --> 00:00:24,808
as much for recognition,
and discriminative methods.

7
00:00:24,808 --> 00:00:26,974
The ones we talked about
are boosting SVMs and

8
00:00:26,974 --> 00:00:29,940
they have a deep history
in computer vision.

9
00:00:29,940 --> 00:00:31,670
Recently other methods, and

10
00:00:31,670 --> 00:00:33,915
we mentioned some of them have
become big computer vision.

11
00:00:33,915 --> 00:00:36,770
But one that I think is really

12
00:00:36,770 --> 00:00:39,610
being pushed on most these days
is what's called random forests.

13
00:00:41,470 --> 00:00:45,550
And one of the reasons is they've become
they've been shown to be incredibly

14
00:00:45,550 --> 00:00:48,190
effective for some problems that
people might not have thought.

15
00:00:48,190 --> 00:00:53,260
Like labeling depth images as to
whether a point comes from an arm, or

16
00:00:53,260 --> 00:00:55,673
a, a upper-arm or lower-arm.

17
00:00:55,673 --> 00:00:57,330
A leg, a torso, etcetera.

18
00:00:57,330 --> 00:00:58,990
And I'll tell you that's
actually how the Kinect

19
00:00:58,990 --> 00:01:00,710
does its whole skeleton thing.

20
00:01:00,710 --> 00:01:02,950
Maybe we'll talk about
that in a future lecture.

21
00:01:04,129 --> 00:01:08,330
But random forces also, you actually
can write your own random forest code.

22
00:01:08,330 --> 00:01:11,060
You might now want to because
the packages will work better.

23
00:01:11,060 --> 00:01:14,070
But they're pretty easy to
understand what's going on.

24
00:01:14,070 --> 00:01:17,290
So that's another method that has
become big in discrimination,

25
00:01:17,290 --> 00:01:18,950
in discriminative learning.

26
00:01:18,950 --> 00:01:24,500
I'll also end by saying, 15 years
ago when I was teaching computer

27
00:01:24,500 --> 00:01:28,930
vision most of the students who took
computer vision had also taken graphics.

28
00:01:28,930 --> 00:01:30,530
There was an interesting images and
things.

29
00:01:30,530 --> 00:01:34,240
And so they were familiar with
things like Lambertian shading and

30
00:01:34,240 --> 00:01:36,440
other sorts of models like that and
geometry.

31
00:01:37,950 --> 00:01:42,400
Much less familiar with
things like feature vectors.

32
00:01:42,400 --> 00:01:45,810
Now there's been a tremendous
shift because of the dominance

33
00:01:45,810 --> 00:01:49,990
of machine learning in computer vision,
a lot of the students will take

34
00:01:49,990 --> 00:01:52,740
a lot of machine learning along
with the computer vision.

35
00:01:52,740 --> 00:01:55,700
That's one of the reasons why
I'm not going to go more into

36
00:01:55,700 --> 00:01:57,850
things like how SVMs work boosting, etc.

37
00:01:57,850 --> 00:02:01,454
Because if you really want to understand
that, there's such a wealth of stuff you

38
00:02:01,454 --> 00:02:04,000
have to do that's actually
a whole other course.

39
00:02:04,000 --> 00:02:06,850
In fact, machine learning
has grown that I think the,

40
00:02:06,850 --> 00:02:09,720
the Udacity machine learning
course that I know about currently

41
00:02:09,720 --> 00:02:12,568
is one flavor of machine learning,
and then there's others.

42
00:02:12,568 --> 00:02:14,080
And in Computer Vision,

43
00:02:14,080 --> 00:02:16,670
you're looking at the one's that
work on large feature vectors.

44
00:02:16,670 --> 00:02:20,080
So, we're going to stop here with
recognition, and like I said,

45
00:02:20,080 --> 00:02:20,930
if you want to do more,

46
00:02:20,930 --> 00:02:23,920
you really want to do that in
the context of machine learning classes.
