1
00:00:00,340 --> 00:00:03,760
But even though the unsupervised learning problem isn't really that crisply

2
00:00:03,760 --> 00:00:07,270
defined, we can define a basic clustering problem and, and be somewhat

3
00:00:07,270 --> 00:00:09,190
crisp about it. So, that's what I want to do next.

4
00:00:09,190 --> 00:00:12,500
I want to say that one of the classic unsupervised problems is

5
00:00:12,500 --> 00:00:16,320
clustering, taking a set of objects and putting them into groups.

6
00:00:16,320 --> 00:00:18,140
And so, here's what we're going to assume. We're going to assume that we're

7
00:00:18,140 --> 00:00:21,940
given some set of objects X and we're given information about

8
00:00:21,940 --> 00:00:25,940
how they relate to each other in the form of inter-object distances.

9
00:00:25,940 --> 00:00:28,530
So we're going to assume that for objects x and y in the set of

10
00:00:28,530 --> 00:00:34,480
objects we have D(x,y) which is the same as D(y,x). Which says how far apart

11
00:00:34,480 --> 00:00:37,000
they are in, in some space. Now they don't actually have to be in

12
00:00:37,000 --> 00:00:43,220
some metric space. They just need to have this, this distance matrix D to find.

13
00:00:43,220 --> 00:00:44,770
>> So that makes sense, now let me ask you,

14
00:00:44,770 --> 00:00:45,950
so you said they don't have to be in a metric

15
00:00:45,950 --> 00:00:47,740
space. So you mean it literally does not have to be

16
00:00:47,740 --> 00:00:49,910
a real distance? It doesn't have to be a, a metric.

17
00:00:49,910 --> 00:00:51,017
>> Yeah, I don't, I don't think

18
00:00:51,017 --> 00:00:53,082
we're going to depend on that. I think we just need

19
00:00:53,082 --> 00:00:55,830
some kind of way of measuring how far apart things are. And

20
00:00:55,830 --> 00:00:58,650
it doesn't mean that they're embedded in some two dimensional space or

21
00:00:58,650 --> 00:01:02,010
three dimensional space. There's just numbers that relate them to one another.

22
00:01:02,010 --> 00:01:04,580
>> So they don't have to obey the triangle inequality, for example.

23
00:01:04,580 --> 00:01:08,690
>> I don't think so. I don't think we're going to depend on that in any way.

24
00:01:08,690 --> 00:01:12,382
>> Okay. So this is just like KNN because everything is

25
00:01:12,382 --> 00:01:16,152
like KNN. Where you have this notion of similarity and distance and

26
00:01:16,152 --> 00:01:19,020
that's where your domain knowledge is. So you've got a bunch of

27
00:01:19,020 --> 00:01:21,020
objects and your domain knowledge is

28
00:01:21,020 --> 00:01:23,570
these distances, these similarities between objects.

29
00:01:23,570 --> 00:01:26,334
>> Exactly, right. And in fact it's, it's surprisingly

30
00:01:26,334 --> 00:01:29,585
similar to KNN in that they surprisingly depend on similarness.

31
00:01:29,585 --> 00:01:32,670
>> Hm. So that's good. So KNN is similar to everything, so

32
00:01:32,670 --> 00:01:36,847
its distance is small to all things. [LAUGH] Wow, that is very meta.

33
00:01:36,847 --> 00:01:38,480
>> Alright. So that's, that's the input and

34
00:01:38,480 --> 00:01:41,320
the output that a clustering algorithm needs to,

35
00:01:41,320 --> 00:01:44,642
to create is a partition. Which is to say

36
00:01:44,642 --> 00:01:46,550
we're going to, I'll write it this way. That P

37
00:01:46,550 --> 00:01:49,430
of, P sub D. The partition function defined for

38
00:01:49,430 --> 00:01:54,510
some particular distance set D, for, for some object

39
00:01:54,510 --> 00:01:58,660
x, is just going to be some label, but it's such that if x and y are going to be

40
00:01:58,660 --> 00:02:01,430
assigned to the same cluster, the same partition, then

41
00:02:01,430 --> 00:02:03,920
they're going to have the same output of this PD function.

42
00:02:03,920 --> 00:02:04,600
>> Okay.

43
00:02:04,600 --> 00:02:05,390
>> That make some sense?

44
00:02:05,390 --> 00:02:06,360
>> That does make sense.

45
00:02:06,360 --> 00:02:07,930
>> What would be a trivial clustering

46
00:02:07,930 --> 00:02:09,680
algorithm based on this definition? Right, it's

47
00:02:09,680 --> 00:02:11,230
taking its input the objects and then

48
00:02:11,230 --> 00:02:13,596
the distances. And then it spits out partitions.

49
00:02:13,596 --> 00:02:15,602
>> A trivial one would be, well, a trivial

50
00:02:15,602 --> 00:02:18,170
one would be put everything in the same partition.

51
00:02:18,170 --> 00:02:20,412
>> Yeah. So that would be one. So that would

52
00:02:20,412 --> 00:02:22,924
be, that would look like this. P, for all x in

53
00:02:22,924 --> 00:02:27,106
the set of objects, PD of x equals, let's say,

54
00:02:27,106 --> 00:02:30,220
1. So that means that all objects are in partition 1.

55
00:02:30,220 --> 00:02:31,870
>> We're all humans.

56
00:02:31,870 --> 00:02:32,850
>> That's right.

57
00:02:32,850 --> 00:02:35,488
>> Okay. Here's another trivial one. Every

58
00:02:35,488 --> 00:02:38,040
single object is in its own partition.

59
00:02:38,040 --> 00:02:39,400
>> Yes, good, that's the other one I was

60
00:02:39,400 --> 00:02:41,920
thinking of. Which maybe we could write like this. We'll

61
00:02:41,920 --> 00:02:44,000
just use the object name itself as the name

62
00:02:44,000 --> 00:02:46,610
of of the cluster. And now every object is in

63
00:02:46,610 --> 00:02:49,770
its own cluster. Now, we didn't define, as part

64
00:02:49,770 --> 00:02:53,010
of this, this problem definition, whether we should like the

65
00:02:53,010 --> 00:02:54,620
one where everybody's in the same cluster or the

66
00:02:54,620 --> 00:02:57,000
one that everyone's in different clusters or something in between,

67
00:02:57,000 --> 00:03:01,140
it's not really in the, in this definition at this level of detail.

68
00:03:01,140 --> 00:03:04,220
>> Hm. Well, that's fine. I mean, we can all be humans

69
00:03:04,220 --> 00:03:09,268
and we can all be unique snowflakes at the same time. [LAUGH]
