1
00:00:00,000 --> 00:00:02,000
So we learned quite a bit.

2
00:00:02,000 --> 00:00:04,000
We learned about Naive Bayes

3
00:00:04,000 --> 00:00:06,000
as our first supervised learning methods.

4
00:00:06,000 --> 00:00:08,000
The setup was that we had

5
00:00:08,000 --> 00:00:14,000
features of documents or trading examples and labels.

6
00:00:14,000 --> 00:00:17,000
In this case, SPAM or not SPAM.

7
00:00:17,000 --> 00:00:19,000
And from those pieces,

8
00:00:19,000 --> 00:00:23,000
we made a generative model for the SPAM class

9
00:00:23,000 --> 00:00:25,000
and the non-SPAM class

10
00:00:25,000 --> 00:00:28,000
that described the condition of probability

11
00:00:28,000 --> 00:00:30,000
of each individual feature.

12
00:00:30,000 --> 00:00:33,000
We then used first maximum likelihood

13
00:00:33,000 --> 00:00:36,000
and then a Laplacian smoother

14
00:00:36,000 --> 00:00:38,000
to fit those primers over here.

15
00:00:38,000 --> 00:00:41,000
And then using Bayes rule,

16
00:00:41,000 --> 00:00:44,000
we could take any training examples over here

17
00:00:44,000 --> 00:00:48,000
and figure out what the class probability was over here.

18
00:00:48,000 --> 00:00:51,000
This is called a generative model

19
00:00:51,000 --> 00:00:55,000
in that the condition of probabilities all aim to maximize

20
00:00:55,000 --> 00:01:00,000
the probability of individual features as if those

21
00:01:00,000 --> 00:01:02,000
describe the physical world.

22
00:01:02,000 --> 00:01:06,000
We also used what is called a bag of words model,

23
00:01:06,000 --> 00:01:09,000
in which our representation of each email

24
00:01:09,000 --> 00:01:12,000
was such that we just counted the occurrences of words,

25
00:01:12,000 --> 00:01:15,000
irrespective of their order.

26
00:01:15,000 --> 00:01:19,000
Now this is a very powerful method for fighting SPAM.

27
00:01:19,000 --> 00:01:21,000
Unfortunately, it is not powerful enough.

28
00:01:21,000 --> 00:01:24,000
It turns out spammers know about Naive Bayes,

29
00:01:24,000 --> 00:01:27,000
and they've long learned to come up with messages

30
00:01:27,000 --> 00:01:31,000
that are fooling your SPAM filter if it uses Naive Bayes.

31
00:01:31,000 --> 00:01:33,000
So companies like Google and others

32
00:01:33,000 --> 00:01:35,000
have become much more involved

33
00:01:35,000 --> 00:01:38,000
in methods for SPAM filtering.

34
00:01:38,000 --> 00:01:42,000
Now I can give you some more examples how to filter SPAM,

35
00:01:42,000 --> 99:59:59,999
but all of those quite easily fit with the same Naive Bayes model.
