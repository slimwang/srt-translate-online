1
00:00:00,280 --> 00:00:03,240
Couple of other things to think about when you compare, yeah, film,

2
00:00:03,240 --> 00:00:06,720
digital cameras and the concept of photography.

3
00:00:06,720 --> 00:00:09,280
So in essence, if you really look at these two cameras,

4
00:00:09,280 --> 00:00:13,900
this is a traditional film camera and this is a digital SLR.

5
00:00:13,900 --> 00:00:16,930
Basically, they have the same functionalities, right?

6
00:00:16,930 --> 00:00:18,360
They have the same set of features.

7
00:00:18,360 --> 00:00:21,390
You can zoom and focus, you can control the aperture and

8
00:00:21,390 --> 00:00:25,490
exposure shutter release and advance a kind of built-in into motors.

9
00:00:25,490 --> 00:00:30,340
And but again mostly, what you can take is one picture but clicking ones and

10
00:00:30,340 --> 00:00:31,380
that's what you get.

11
00:00:31,380 --> 00:00:35,000
So in essence if you were to kind of compare the growth of

12
00:00:35,000 --> 00:00:38,870
digital photography from film photography not much is different.

13
00:00:38,870 --> 00:00:41,020
You still get the same kinds of images, and

14
00:00:41,020 --> 00:00:44,630
some may argue that film was giving you better resolution and better detail.

15
00:00:44,630 --> 00:00:48,170
But, what does computational photography do to it?

16
00:00:48,170 --> 00:00:53,090
Film or digital photography, we can use the devices, but

17
00:00:53,090 --> 00:00:58,330
in computational photography we can changes some of these functionalities, live.

18
00:00:58,330 --> 00:01:01,380
So for example, as we've discussed, we can control and

19
00:01:01,380 --> 00:01:05,664
change the optics, illumination, sensor, and movement of the camera.

20
00:01:05,664 --> 00:01:08,880
This could be for example how we build panoramas or

21
00:01:08,880 --> 00:01:13,410
how we controlled the lighting illumination, and of course how the optics is

22
00:01:13,410 --> 00:01:16,900
controlled or the sensor was controlled for dual photography.

23
00:01:16,900 --> 00:01:21,250
We can also actually exploit more characteristics of the wavelength,

24
00:01:21,250 --> 00:01:26,430
the speed of the scene, depth, and polarization and all additional information

25
00:01:26,430 --> 00:01:30,490
that might be available to our camera live, based on what we want to do.

26
00:01:30,490 --> 00:01:33,990
Again, there has been a whole long history of using depth.

27
00:01:33,990 --> 00:01:36,980
For doing focusing in traditional cameras we can actually use

28
00:01:36,980 --> 00:01:42,110
this much more in a live manner with computational photography cameras.

29
00:01:42,110 --> 00:01:43,590
Further, you know,

30
00:01:43,590 --> 00:01:47,410
in the old days of photography it took a probe to measure the light.

31
00:01:47,410 --> 00:01:48,580
We could take a picture with that,

32
00:01:48,580 --> 00:01:53,490
but now a probes could also be much more dynamic changing things as we use them.

33
00:01:53,490 --> 00:01:56,630
We can apply actuators, and we played around with this a little bit when moving

34
00:01:56,630 --> 00:02:01,610
the cameras, but also moving the optics and the apertures and stuff like that.

35
00:02:01,610 --> 00:02:05,090
We can also start using information by a network of cameras that

36
00:02:05,090 --> 00:02:09,139
has put a bunch of different cameras in the environment to all be connected, and

37
00:02:09,139 --> 00:02:12,050
now of course we would get a multi-view synchronized images.
