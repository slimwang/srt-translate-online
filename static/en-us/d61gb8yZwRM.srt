1
00:00:00,340 --> 00:00:06,320
We saw the system's issues at a macro level from the point of view of

2
00:00:06,320 --> 00:00:13,120
administering the engine that powers internet scale computing. How do

3
00:00:13,120 --> 00:00:18,664
we program services such as websearch and airline reservation on top of the

4
00:00:18,664 --> 00:00:22,430
data center cluster resources? How do

5
00:00:22,430 --> 00:00:25,830
they exploit the hardware parallelism that's available

6
00:00:25,830 --> 00:00:29,310
in these clusters? We will learn about

7
00:00:29,310 --> 00:00:32,700
the map produced programming paradigm that answers

8
00:00:32,700 --> 00:00:35,920
these questions. The term Big Data, has

9
00:00:35,920 --> 00:00:39,320
become a buzz word. Computations in giant

10
00:00:39,320 --> 00:00:46,310
scale services are usually simple, but they work over large data sets and hence,

11
00:00:46,310 --> 00:00:48,800
the name Big Data. And naturally, because

12
00:00:48,800 --> 00:00:51,260
they are working with a large data set,

13
00:00:51,260 --> 00:00:54,180
these computations take a long time to compute.

14
00:00:54,180 --> 00:00:56,540
For example let's say that I want to

15
00:00:56,540 --> 00:01:00,770
search for John F Kennedy's photographs in all

16
00:01:00,770 --> 00:01:03,580
the documents that are available on the web.

17
00:01:03,580 --> 00:01:05,360
It's going to take a long time. And that

18
00:01:05,360 --> 00:01:08,110
is an example of a Big Data computation.

19
00:01:08,110 --> 00:01:12,540
Similar examples include online reservations, shopping, et cetera.

20
00:01:12,540 --> 00:01:16,430
And applications that work on Big Data would

21
00:01:16,430 --> 00:01:18,710
like to exploit the pluralism that's available

22
00:01:18,710 --> 00:01:21,150
in the cluster at the data centers. I

23
00:01:21,150 --> 00:01:24,860
mentioned in the last lesson that data

24
00:01:24,860 --> 00:01:28,740
centers these days comprise of computation elements on

25
00:01:28,740 --> 00:01:31,100
the order of thousands and even 10,000

26
00:01:31,100 --> 00:01:35,040
nodes that are ready to do computations. And

27
00:01:35,040 --> 00:01:38,230
we would like to exploit the computational resources

28
00:01:38,230 --> 00:01:42,370
available in such Big Data centers to do

29
00:01:42,370 --> 00:01:48,020
computation on Big Data. For example, if it is John F Kennedy's photographs, I'm

30
00:01:48,020 --> 00:01:50,490
looking in all the different documents. We

31
00:01:50,490 --> 00:01:55,200
can parallelize that's search for Kennedy's photo

32
00:01:55,200 --> 00:02:00,410
in all the documents in parallel on all the available nodes in the data

33
00:02:00,410 --> 00:02:03,350
center. And since computations are also called

34
00:02:03,350 --> 00:02:07,240
embarrassingly parallel computations. What does this mean?

35
00:02:07,240 --> 00:02:09,970
Well, there is not much synchronization or

36
00:02:09,970 --> 00:02:14,000
coordination that is needed among the parallel threads

37
00:02:14,000 --> 00:02:17,600
that comprise the applications and that run

38
00:02:17,600 --> 00:02:21,240
on different nodes of the computational cluster. Looking

39
00:02:21,240 --> 00:02:25,820
for John F Kennedy's photographs in all the documents on the web, is a good

40
00:02:25,820 --> 00:02:29,660
example of such an embarrassingly parallel application. What

41
00:02:29,660 --> 00:02:32,390
are all the issues in programming in the

42
00:02:32,390 --> 00:02:39,050
large, on large data sets, so the data sets are also large and the computational

43
00:02:39,050 --> 00:02:44,650
resources on which we want to run this big data application is also vast.

44
00:02:44,650 --> 00:02:47,080
So some of the interesting issues in

45
00:02:47,080 --> 00:02:50,250
programming in the large include, how to parallelize

46
00:02:50,250 --> 00:02:54,490
an application across let's say, 10,000 machines.

47
00:02:54,490 --> 00:02:57,830
How to handle the data distribution and plumbing

48
00:02:57,830 --> 00:03:01,320
between the producers of data and consumers of

49
00:03:01,320 --> 00:03:05,470
data. Remember these are embarrassingly parallel applications, but different

50
00:03:05,470 --> 00:03:08,970
phases of the application will require data from one

51
00:03:08,970 --> 00:03:10,980
phase of the application to be passed on to

52
00:03:10,980 --> 00:03:13,130
the next phase of the application. That's what

53
00:03:13,130 --> 00:03:16,750
we mean by plumbing between the producers of data,

54
00:03:16,750 --> 00:03:20,360
intermediate data to be more specific, and consumers of

55
00:03:20,360 --> 00:03:22,880
that intermediate data. And of course, one of the

56
00:03:22,880 --> 00:03:26,820
biggest challenges in Big Data applications on

57
00:03:26,820 --> 00:03:30,750
large computational clusters is failure handling. Recall what

58
00:03:30,750 --> 00:03:32,990
we said about the nature of these

59
00:03:32,990 --> 00:03:36,344
data centers. They employ thousands and thousands of

60
00:03:36,344 --> 00:03:42,600
processes. When you have so many parts, in any setting, failure is not a

61
00:03:42,600 --> 00:03:47,880
question of if it will happen. It is a question of, when it is going to happen?

62
00:03:47,880 --> 00:03:52,850
So that's a fact of life, and therefore, programming models for Big Data, have

63
00:03:52,850 --> 00:03:58,980
to worry about the fact that failures are to be expected in this environment.
