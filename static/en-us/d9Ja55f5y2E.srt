1
00:00:00,430 --> 00:00:03,690
Clustered object offers several advantages. First of

2
00:00:03,690 --> 00:00:06,320
all, the object reference is the same on

3
00:00:06,320 --> 00:00:09,330
all the nodes, so that's very very important.

4
00:00:09,330 --> 00:00:12,800
Regardless of which node a particular server is

5
00:00:12,800 --> 00:00:16,400
executing, they all have the same object reference.

6
00:00:16,400 --> 00:00:19,020
But under the covers, you can now have

7
00:00:19,020 --> 00:00:23,270
incremental optimization of the implementation of the object.

8
00:00:23,270 --> 00:00:25,940
According on the usage pattern, you can have

9
00:00:25,940 --> 00:00:28,240
different levels of replication of the same

10
00:00:28,240 --> 00:00:31,920
object, so it allows for incremental optimization. And

11
00:00:31,920 --> 00:00:35,150
you can also have different implementations of

12
00:00:35,150 --> 00:00:38,880
the same object, depending on the usage pattern.

13
00:00:38,880 --> 00:00:40,870
And it also allows for the potential

14
00:00:40,870 --> 00:00:45,500
for dynamic adaptations of the representations. The advantage

15
00:00:45,500 --> 00:00:47,570
of course of the replication is that, the

16
00:00:47,570 --> 00:00:52,990
object references can access the respective replicas independently.

17
00:00:52,990 --> 00:00:55,438
And this means that you have less locking of

18
00:00:55,438 --> 00:00:59,220
shared data structures. Let's think about the process object

19
00:00:59,220 --> 00:01:01,698
as a concrete example. So if you think about

20
00:01:01,698 --> 00:01:04,194
the process object, it's one per CPU and with

21
00:01:04,194 --> 00:01:07,732
mostly read only. And, and therefore page fault handling

22
00:01:07,732 --> 00:01:11,008
can start on all of these different processors, independent

23
00:01:11,008 --> 00:01:14,060
of one another. And if they touch different regions

24
00:01:14,060 --> 00:01:18,260
of the address space, then the path taken by the

25
00:01:18,260 --> 00:01:22,070
page fault handling for all these different threads can be

26
00:01:22,070 --> 00:01:25,080
different. So what that means is that, page fault handling

27
00:01:25,080 --> 00:01:28,280
for instance, will scale in this case using this as

28
00:01:28,280 --> 00:01:31,870
a concrete service with the number of processes. It'll scale to

29
00:01:31,870 --> 00:01:34,656
the number of processes. And this is important because, page

30
00:01:34,656 --> 00:01:37,500
fault handling is something that is going to happen often, and so

31
00:01:37,500 --> 00:01:39,880
you want to make sure it scales with the number of

32
00:01:39,880 --> 00:01:43,380
processes. On the other hand, if we want to get rid

33
00:01:43,380 --> 00:01:46,120
of a region, then the destruction of region

34
00:01:46,120 --> 00:01:49,220
may take more time because the region may

35
00:01:49,220 --> 00:01:52,610
have multiple representations, and all of the representations

36
00:01:52,610 --> 00:01:56,180
of that particular region has to be gotten

37
00:01:56,180 --> 00:01:58,210
rid of. And so destruction of a region

38
00:01:58,210 --> 00:02:00,980
may take more time but that's okay because

39
00:02:00,980 --> 00:02:03,640
you don't expect region destructions to happen as

40
00:02:03,640 --> 00:02:08,430
often as handling page faults to service the ongoing

41
00:02:08,430 --> 00:02:11,838
needs of the thread. So, the principle again is to make sure

42
00:02:11,838 --> 00:02:15,030
that the common case is optimized, the common case is page fault

43
00:02:15,030 --> 00:02:20,250
handling. Region creation, region destruction. All of those things happen

44
00:02:20,250 --> 00:02:25,530
more rarely and it is okay if those functionalities take a little bit more time.
