1
00:00:00,136 --> 00:00:01,709
The typical program looks like this.

2
00:00:01,709 --> 00:00:05,736
First, the CPU allocates storage on the GPU.

3
00:00:05,736 --> 00:00:10,040
Then, the CPU copies some input data from the CPU to the GPU.

4
00:00:10,040 --> 00:00:15,752
Next, the CPU calls some kernels watching these kernels on the GPU that process this data.

5
00:00:15,752 --> 00:00:20,699
And finally, the CPU copies the results back to the CPU from the GPU.

6
00:00:20,699 --> 00:00:25,827
Now, two of these steps require moving data back and forth between the CPU and the GPU.

7
00:00:25,827 --> 00:00:27,129
Is this expensive?

8
00:00:27,129 --> 00:00:32,603
Well, in general, you'd like to minimize data transfer between the CPU and the GPU as much as you can.

9
00:00:32,603 --> 00:00:36,738
If you're going to move a lot of data and do only a little bit of computation on that data,

10
00:00:36,738 --> 00:00:40,405
Cuda or GPU computing probably isn't a great fit for your problem.

11
00:00:40,405 --> 00:00:45,880
Generally, we've found that the most successful GPU computing applications do a lot of computation

12
00:00:45,880 --> 00:00:48,957
and have a high ratio of computation to communication.

13
00:00:48,957 --> 00:00:50,600
They send their data to the GPU.

14
00:00:50,600 --> 00:00:53,721
They do a lot of work, and only then, they bring it back.
