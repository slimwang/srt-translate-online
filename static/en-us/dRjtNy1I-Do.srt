1
00:01:11,540 --> 00:01:14,810
>> That's good David. Note though, that this sentence is a little bit like,

2
00:01:14,810 --> 00:01:18,720
a shark enjoyed eating the frog. This is one representation for

3
00:01:18,720 --> 00:01:22,320
this sentence, and under the representation we may have two action frames.

4
00:01:22,320 --> 00:01:26,070
One corresponding to the word loved, another corresponded to word watching, and

5
00:01:26,070 --> 00:01:31,260
then connect them, to the slot result. I hope you can see how agents might

6
00:01:31,260 --> 00:01:35,778
be able to understand simple stories. In fact, this is quite similar to

7
00:01:35,778 --> 00:01:40,166
the way Watson and Siri go about to understand the stories that we talk to them.

8
00:01:40,166 --> 00:01:43,420
Almost surely the human interactions with the machines of tomorrow,

9
00:01:43,420 --> 00:01:46,730
will not be based on the keyboards and mouses that we have today.

10
00:01:46,730 --> 00:01:49,820
We'll talk to the machines, the machines will talk back to us, and

11
00:01:49,820 --> 00:01:52,550
when we talk to the machines we'll be telling the machines stories.

12
00:01:52,550 --> 00:01:55,427
Stories like Anika decided to have a glass of water, or

13
00:01:55,427 --> 00:01:59,100
a shark enjoyed eating the frog. And when we tell the stories,

14
00:01:59,100 --> 00:02:02,960
the stories will have context. They will have ambiguities. And

15
00:02:02,960 --> 00:02:06,840
we will expect the machines to do common sense reasoning. The power of this

16
00:02:06,840 --> 00:02:12,380
particular lesson lies in the [UNKNOWN] of a representation, that enables

17
00:02:12,380 --> 00:02:16,730
a particular kind of common sense reasoning. We'll continue this discussion,

18
00:02:16,730 --> 00:02:20,360
about common sense reasoning of more complex stories, in the next lesson.
