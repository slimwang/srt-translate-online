1
00:00:00,320 --> 00:00:03,469
There are two finer points that I
wanted to mention about Q-learning.

2
00:00:03,469 --> 00:00:09,380
First is that the success of
Q-learning depends to some extent,

3
00:00:09,380 --> 00:00:12,190
well, to a large extent on exploration.

4
00:00:12,190 --> 00:00:18,760
So we need to explore as much of
the state and action space as possible.

5
00:00:18,760 --> 00:00:21,350
One way to accomplish
this is with randomnes.

6
00:00:21,350 --> 00:00:26,070
And the way we can interject that fairly
easily in the step of Q-learning,

7
00:00:26,070 --> 00:00:30,360
where we are selecting an action,
we flip a coin and

8
00:00:30,360 --> 00:00:35,080
randomly decide if we're going to
randomly choose an action.

9
00:00:35,080 --> 00:00:38,360
So that means really
two flips of the coin.

10
00:00:38,360 --> 00:00:41,490
The first is are we going to
choose a random action or

11
00:00:41,490 --> 00:00:44,910
are we just going to pick the action
with the highest Q value?

12
00:00:44,910 --> 00:00:49,300
Then if we decide okay, we're going to
choose an action randomly, now we need

13
00:00:49,300 --> 00:00:52,770
to flip the coin again to choose which
of those actions we're going to select.

14
00:00:54,010 --> 00:00:59,138
Typical way to implement this is
to set this probability at about

15
00:00:59,138 --> 00:01:03,490
0.3 or
something at the beginning of learning.

16
00:01:04,840 --> 00:01:08,820
And then over each iteration to slowly
make it smaller and smaller and

17
00:01:08,820 --> 00:01:13,660
smaller until eventually we essentially
don't choose random actions at all.

18
00:01:13,660 --> 00:01:18,740
What we gain here is when we're choosing
these random actions fairly frequently

19
00:01:18,740 --> 00:01:21,730
is we're forcing
the system to explore and

20
00:01:21,730 --> 00:01:24,590
try different actions
in different states.

21
00:01:24,590 --> 00:01:28,070
And it also causes us to arrive at
different states that we might not

22
00:01:28,070 --> 00:01:31,340
otherwise arrive at if we didn't
try those random actions.
