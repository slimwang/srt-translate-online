1
00:00:00,242 --> 00:00:02,305
So let's look at those results.

2
00:00:02,305 --> 00:00:09,455
On my laptop we had a maximum number of threads running of 2048 out of a maximum possible of 2048.

3
00:00:09,455 --> 00:00:13,621
This means that as long as we have enough thread blocks to fill the machine,

4
00:00:13,621 --> 00:00:17,922
enough thread blocks to run on all the SMs, then we should get 100% occupancy.

5
00:00:17,922 --> 00:00:23,660
On the other hand, the Fermi GPUs that Amazon uses and that Udacity runs on were limited to

6
00:00:23,660 --> 00:00:29,400
a maximum number of threads running at 1024 out of a maximum possible of 1536,

7
00:00:29,400 --> 00:00:34,004
and this means that we're going to achieve at best 66% occupancy, okay,

8
00:00:34,004 --> 00:00:38,442
so occupancy refers to the percentage of threads that are actually running versus the

9
00:00:38,442 --> 00:00:41,544
number of threads that actually could be running.

10
00:00:41,544 --> 00:00:47,717
There's a useful tool that's a spreadsheet in the CUDA tool kit installation called the CUDA Occupancy Calendar

11
00:00:47,717 --> 00:00:52,890
that lets you just plug in your numbers and see how your kernels are going to perform in terms of occupancy

12
00:00:52,890 --> 00:00:55,991
on all the various GPU's that have existed over time.
