1
00:00:00,280 --> 00:00:02,500
>> Okay, so, let me give you just a few more

2
00:00:02,500 --> 00:00:06,710
examples, Michael, of a, how PCA and ICA differ. And I'm going to

3
00:00:06,710 --> 00:00:09,760
do this mainly by talking about certain things that ICA does. And

4
00:00:09,760 --> 00:00:11,660
this is really just for your edification, but I think it really

5
00:00:11,660 --> 00:00:15,190
helps, to think about, those sort of underlying models and how

6
00:00:15,190 --> 00:00:18,320
they differ, by thinking about how they react differently to different kinds

7
00:00:18,320 --> 00:00:20,900
of data. So, just, here's a couple of examples. The one we

8
00:00:20,900 --> 00:00:25,430
covered right away, was the blind source separation problem. And of course,

9
00:00:25,430 --> 00:00:27,950
what, what we recall is that ICA was, in

10
00:00:27,950 --> 00:00:30,660
some sense, designed to solve the blind source separation

11
00:00:30,660 --> 00:00:34,280
problem and in fact ICA does an excellent job

12
00:00:34,280 --> 00:00:37,180
at solving the blind source separation problem. Meanwhile, PCA

13
00:00:37,180 --> 00:00:41,310
does a terrible job at solving the blind source

14
00:00:41,310 --> 00:00:44,780
separation problem and that's just because it's assuming this

15
00:00:44,780 --> 00:00:47,600
kind of Gaussian distribution, it just does not recover

16
00:00:47,600 --> 00:00:50,730
what's going on. But here's something that ICA does

17
00:00:50,730 --> 00:00:56,250
differently from PCA. Is because it's got this kind of blind source root in it,

18
00:00:56,250 --> 00:00:59,100
it's actually directional. And what I mean by

19
00:00:59,100 --> 00:01:02,320
that is, you recall I drew this sort

20
00:01:02,320 --> 00:01:05,770
of matrix before, where we had features this

21
00:01:05,770 --> 00:01:09,500
way. And we had samples of those features

22
00:01:09,500 --> 00:01:13,640
like sound, time samples of sound this way.

23
00:01:13,640 --> 00:01:15,730
It turns out that for PCA, it doesn't

24
00:01:15,730 --> 00:01:18,850
matter whether I give you this matrix or I give you

25
00:01:18,850 --> 00:01:23,440
the transpose of this matrix. It ends up finding the same answer.

26
00:01:23,440 --> 00:01:23,500
>> Hm.

27
00:01:23,500 --> 00:01:24,890
>> And that should make sense, right?

28
00:01:24,890 --> 00:01:27,030
Because it's just basically finding a new rotation

29
00:01:27,030 --> 00:01:28,790
of the data, and these are effectively

30
00:01:28,790 --> 00:01:32,070
just rotations of each other. For the purposes

31
00:01:32,070 --> 00:01:35,790
of, of, if you just kind of think about it geometrically in space. ICA on the

32
00:01:35,790 --> 00:01:38,430
other hand, gives you completely different answers, if

33
00:01:38,430 --> 00:01:41,150
you give it this versus giving it this.

34
00:01:41,150 --> 00:01:44,765
So ICA is highly directional. And PCA much less

35
00:01:44,765 --> 00:01:48,440
so. But ICA, because it's making this kind of

36
00:01:48,440 --> 00:01:51,730
fundamental assumption, does end up generating some really cool

37
00:01:51,730 --> 00:01:53,940
results. I'm going to give you another example of

38
00:01:53,940 --> 00:01:56,830
one. That's like a blind source separation. In fact,

39
00:01:56,830 --> 00:01:59,410
I'm going to give you two. Okay? So, imagine

40
00:01:59,410 --> 00:02:02,480
you had a bunch of inputs of faces. Okay?

41
00:02:02,480 --> 00:02:06,274
So, here's my input faces. I give you bunches and

42
00:02:06,274 --> 00:02:08,930
bunches and bunches of faces. What do you

43
00:02:08,930 --> 00:02:11,340
think PCA would do? What do you think the

44
00:02:11,340 --> 00:02:13,953
first principle component of PCA would be over

45
00:02:13,953 --> 00:02:17,520
pictures of thousands and thousands and thousands of faces.

46
00:02:17,520 --> 00:02:20,130
>> Over all darkness of the image.

47
00:02:20,130 --> 00:02:22,520
>> Actually that is exactly right. The first thing that

48
00:02:22,520 --> 00:02:25,150
PCA tends to do with images, we are actual, we

49
00:02:25,150 --> 00:02:28,210
are talking pictures, not just sketches here, is it finds

50
00:02:28,210 --> 00:02:31,010
the direction of maximum variance and that tends to be

51
00:02:31,010 --> 00:02:33,140
brightness or luminous. Which kind of makes sense because

52
00:02:33,140 --> 00:02:35,190
that's typically the kind of thing that kids vary the

53
00:02:35,190 --> 00:02:37,170
most. So in fact, the first thing people often

54
00:02:37,170 --> 00:02:39,930
do when they're trying to use PC on faces

55
00:02:39,930 --> 00:02:41,940
is they normalize all of that away. Because the

56
00:02:41,940 --> 00:02:44,710
first principal component isn't terribly helpful. It's just kind of

57
00:02:44,710 --> 00:02:46,450
giving you the average light. What do you think

58
00:02:46,450 --> 00:02:47,760
the second thing it would find it would be?

59
00:02:47,760 --> 00:02:49,460
>> Hair versus not hair?

60
00:02:49,460 --> 00:02:52,830
>> No. Interestingly enough. What it ends up finding is sort of the

61
00:02:52,830 --> 00:02:56,110
average face. Which is kind of like the question you asked me earlier

62
00:02:56,110 --> 00:02:57,980
about what happens if you go through the origin.

63
00:02:57,980 --> 00:02:58,850
>> Mm.

64
00:02:58,850 --> 00:03:01,050
>> So, there's actually names for this. It's called the

65
00:03:01,050 --> 00:03:03,260
Eigen Faces because, you know, as I noted before, it's

66
00:03:03,260 --> 00:03:05,540
an Eigen problem. And it basically finds kind of the

67
00:03:05,540 --> 00:03:10,950
average face. And that's kind of weird. But it works for reconstruction.

68
00:03:10,950 --> 00:03:12,360
I don't know what the average face here would look

69
00:03:12,360 --> 00:03:15,560
like. Probably something like this. Yeah, so you can see

70
00:03:15,560 --> 00:03:18,090
how useful that would be. Not even clear that's a

71
00:03:18,090 --> 00:03:21,590
face. But it works for reconstruction. Do you know what ICA

72
00:03:21,590 --> 00:03:22,980
ends up finding?

73
00:03:22,980 --> 00:03:23,370
>> Noses?

74
00:03:23,370 --> 00:03:27,230
>> Yes, it finds noses. It finds eye

75
00:03:27,230 --> 00:03:32,359
selectors. It finds mouth selectors. It finds hair selectors.

76
00:03:34,550 --> 00:03:37,280
And, I think, intuitively the way I would think about

77
00:03:37,280 --> 00:03:41,160
this is because PCA is doing this global orthogonality thing, it's

78
00:03:41,160 --> 00:03:44,510
going to be forced to find global features. ICA I didn't

79
00:03:44,510 --> 00:03:46,890
say was global, and that's because it's basically local, it doesn't

80
00:03:46,890 --> 00:03:50,780
care about orthogonality. So it tends to find parts of.

81
00:03:50,780 --> 00:03:52,640
If you feed it the metrics the right way, it tends

82
00:03:52,640 --> 00:03:55,330
to find parts of. And so it ends up finding these

83
00:03:55,330 --> 00:03:59,680
little selectors. So this has a really nice outcome in cases

84
00:03:59,680 --> 00:04:03,760
like natural images or natural scenes. So what do you think

85
00:04:03,760 --> 00:04:07,590
happens Michael, if I take natural scenes, you know, pictures of the

86
00:04:07,590 --> 00:04:11,020
forest and grass and walking around. Just things that I would see

87
00:04:11,020 --> 00:04:13,330
if I were just walking out in the world and taking bunches

88
00:04:13,330 --> 00:04:16,250
of pictures. And I feed it into ICA. Well the answer

89
00:04:16,250 --> 00:04:18,290
for PCA, by the way, is the same as before, is you

90
00:04:18,290 --> 00:04:21,290
get brightness, you get sort of the average image, things that really

91
00:04:21,290 --> 00:04:24,720
make sense if your goal is to do reconstruction. But ICA actually

92
00:04:24,720 --> 00:04:27,450
gives you something different. What do you think the independent

93
00:04:27,450 --> 00:04:33,330
components, the underlying causes, so to speak, of natural scenes are?

94
00:04:33,330 --> 00:04:37,440
>> I'm still thinking about the face parts. But, by analogy, it seems like it

95
00:04:37,440 --> 00:04:43,970
would be the, you know, things in the world like, trees, and rocks, and ground.

96
00:04:43,970 --> 00:04:46,520
>> Not quite, and that's I think in part because, there are too many of

97
00:04:46,520 --> 00:04:47,895
those things that kind of overlap in

98
00:04:47,895 --> 00:04:50,070
too many different ways. It actually finds something

99
00:04:50,070 --> 00:04:51,700
more fundamental.

100
00:04:51,700 --> 00:04:52,680
>> Edges.

101
00:04:52,680 --> 00:04:55,760
>> That's exactly right. ICA finds edges. Now

102
00:04:55,760 --> 00:04:58,600
for me, that is incredibly satisfying. It says that

103
00:04:58,600 --> 00:05:03,520
the independent components of the world are edges. Now

104
00:05:03,520 --> 00:05:04,650
there are two things that come out of this.

105
00:05:04,650 --> 00:05:07,120
One is just the satisfying feeling you get by

106
00:05:07,120 --> 00:05:09,910
realizing that in it there's a algorithm that, on

107
00:05:09,910 --> 00:05:12,780
it's own, recovers something fundamental like edges. That's very

108
00:05:12,780 --> 00:05:15,500
nice. But the second thing that's nice about it

109
00:05:15,500 --> 00:05:18,840
is, once I use ICA to do my

110
00:05:18,840 --> 00:05:22,420
feature transformation and discover that what it's learning are

111
00:05:22,420 --> 00:05:25,280
edge detectors, well then I can just write edge

112
00:05:25,280 --> 00:05:28,370
detectors. I can just write algorithms that are very

113
00:05:28,370 --> 00:05:31,660
fast, very efficient, that can go through images of

114
00:05:31,660 --> 00:05:34,430
natural scenes and pull out the edges. It's unclear

115
00:05:34,430 --> 00:05:37,160
how to do that with, you know, different principled

116
00:05:37,160 --> 00:05:40,600
projections, but if edges are the fundamental building blocks

117
00:05:40,600 --> 00:05:42,980
of natural scenes then there are people who know how to

118
00:05:42,980 --> 00:05:45,370
write edge projectors very quickly. By the way, you get a

119
00:05:45,370 --> 00:05:47,110
similar result, I won't talk about it, but you get a

120
00:05:47,110 --> 00:05:50,020
similar result in our information retrieval

121
00:05:50,020 --> 00:05:52,910
problem where you have documents. And

122
00:05:52,910 --> 00:05:55,445
you can read this in the material we gave you. But

123
00:05:55,445 --> 00:05:58,500
what ICA ends up giving you for documents are topics. And

124
00:05:58,500 --> 00:06:02,230
they're very easily interpreted that way. Collections of words that select

125
00:06:02,230 --> 00:06:06,000
for specific topics that are themselves made up of collections of words

126
00:06:06,000 --> 00:06:09,820
that select for topics and collections of uncorrelated words

127
00:06:09,820 --> 00:06:13,560
that get rid of distracter documents. So the independent

128
00:06:13,560 --> 00:06:16,060
components of scenes are edges and the independent components

129
00:06:16,060 --> 00:06:20,230
of documents are topics. And that feels very nice, but

130
00:06:20,230 --> 00:06:22,030
in both of these cases, both with edges and

131
00:06:22,030 --> 00:06:24,680
with topics, it turns out that the form of these

132
00:06:24,680 --> 00:06:27,080
topics are something that you can compute very, very

133
00:06:27,080 --> 00:06:32,010
quickly. And sort of independently of the underlying ICA algorithm.

134
00:06:32,010 --> 00:06:34,520
So why does that matter, Michael? Well, remember what I

135
00:06:34,520 --> 00:06:37,110
said originally about unsupervised learning and what it was good

136
00:06:37,110 --> 00:06:41,860
for, was understanding your data. Doing kind of data analysis

137
00:06:41,860 --> 00:06:44,340
from a human being's point of view. So what something

138
00:06:44,340 --> 00:06:47,320
like ICA, and other algorithms we might imagine, do, is

139
00:06:47,320 --> 00:06:49,960
they allow you to do analysis over your data, to

140
00:06:49,960 --> 00:06:54,190
discover fundamental features of them, like edges, or topics or

141
00:06:54,190 --> 00:06:57,130
noses and eyes. And then once you understand that's what's making

142
00:06:57,130 --> 00:07:01,240
up your data, you can simply write code that will select for it, or figure

143
00:07:01,240 --> 00:07:02,570
out what the important parts of your

144
00:07:02,570 --> 00:07:05,670
data are correspondingly. And so here, we haven't

145
00:07:05,670 --> 00:07:08,180
just done this feature transformation problem for

146
00:07:08,180 --> 00:07:11,080
the sake of doing classification, feature transformation actually

147
00:07:11,080 --> 00:07:14,000
helps us to understand the fundamental underlying

148
00:07:14,000 --> 00:07:15,960
causes, or at least structure of our data.
