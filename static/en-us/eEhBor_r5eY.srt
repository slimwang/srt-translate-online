1
00:00:00,000 --> 00:00:06,000
I'd like to say a few words about how to improve the results of stereo vision.

2
00:00:06,000 --> 00:00:11,000
Here is a vision assembly that James David built up of two cameras.

3
00:00:11,000 --> 00:00:14,000
In addition to having these two cameras, he also put a projector into the scene

4
00:00:14,000 --> 00:00:17,000
that emitted a random light pattern.

5
00:00:17,000 --> 00:00:23,000
In fact, it emitted a striped pattern, shown over here on this frog,

6
00:00:23,000 --> 00:00:29,000
and by adding texture to the scene, you can making correspondence easier.

7
00:00:29,000 --> 00:00:33,000
This is a striped pattern of unequal distances.

8
00:00:33,000 --> 00:00:38,000
There's a coding over here, which makes certain stripes larger than others.

9
00:00:38,000 --> 00:00:41,000
If you run the same algorithm I just told you,

10
00:00:41,000 --> 00:00:44,000
you'll find that stereo vision becomes better,

11
00:00:44,000 --> 00:00:48,000
because we can now better disambiguate the correspondence of points.

12
00:00:48,000 --> 00:00:53,000
Here is the assembly used for imaging myself. This is me with a sweater on.

13
00:00:53,000 --> 00:00:55,000
That's my face.

14
00:00:55,000 --> 00:01:00,000
And you can see by emitting structured light, as it is called,

15
00:01:00,000 --> 00:01:03,000
you can enhance the performance of stereo

16
00:01:03,000 --> 00:01:06,000
and objects that otherwise have very poor texture.

17
00:01:06,000 --> 00:01:11,000
Another solution is called the Microsoft Kinect. You're probably familiar with it.

18
00:01:11,000 --> 00:01:15,000
It's a new gaming platform that's been sold at record pace.

19
00:01:15,000 --> 00:01:18,000
It uses a camera system, together with a laser.

20
00:01:18,000 --> 00:01:21,000
The laser adds texture to the scene,

21
00:01:21,000 --> 00:01:24,000
and by triangulation using the same method I showed you,

22
00:01:24,000 --> 00:01:26,000
it can recover depth.

23
00:01:26,000 --> 00:01:31,000
Here's my postdoc Christian using a Kinect-like sensor

24
00:01:31,000 --> 00:01:36,000
to do certain poses in front of a depth sensor.

25
00:01:36,000 --> 00:01:41,000
You can see in the screen how his pose is being perceived,

26
00:01:41,000 --> 00:01:51,000
and you can see Christian trying to do handstands and other acrobatic maneuvers.

27
00:01:51,000 --> 00:01:54,000
He's actually pretty good.

28
00:01:54,000 --> 00:02:07,000
That's all using effectively stereo vision.

29
00:02:07,000 --> 00:02:10,000
There is actually a whole bunch of different types of techniques

30
00:02:10,000 --> 00:02:13,000
for sensing range in computer vision.

31
00:02:13,000 --> 00:02:15,000
I'm just going to briefly talk about them.

32
00:02:15,000 --> 00:02:17,000
They're called laser range finders.

33
00:02:17,000 --> 00:02:19,000
They send off beams of light,

34
00:02:19,000 --> 00:02:22,000
and they measure the time until the light comes back into the sensor.

35
00:02:22,000 --> 00:02:25,000
They're being manufactured by many different companies.

36
00:02:25,000 --> 00:02:30,000
In our experiments using robots to drive through the desert and through traffic.

37
00:02:30,000 --> 00:02:35,000
We quite extensively used laser range finders as an alternative to stereo vision,

38
00:02:35,000 --> 00:02:38,000
because they give us very, very good range estimates.

39
00:02:38,000 --> 00:02:45,000
Here is a 3D model constructed by laser range finders of our neighborhood in Palo Alto,

40
00:02:45,000 --> 00:02:52,000
and it's easy to see how 3D points can making amazing 3D models,

41
00:02:52,000 --> 99:59:59,999
using techniques like stereo vision or like the laser range finders I just briefly talked about.
