1
00:00:00,570 --> 00:00:01,910
So now that we've got our basic search

2
00:00:01,910 --> 00:00:03,890
engine working, for the rest of the unit, we're

3
00:00:03,890 --> 00:00:05,730
going to learn more about how we actually get

4
00:00:05,730 --> 00:00:08,500
web pages on the internet. So far we've been

5
00:00:08,500 --> 00:00:12,560
using the magic get_page function. And we provided

6
00:00:12,560 --> 00:00:16,000
this function that takes as its input a URL,

7
00:00:16,000 --> 00:00:19,990
which is a resource locator on the web, and

8
00:00:19,990 --> 00:00:22,360
it produces as output the contents of that page.

9
00:00:24,660 --> 00:00:26,595
I can show you the Python code that we use for

10
00:00:26,595 --> 00:00:29,860
get_page. It won't really help very much in terms of understanding what's

11
00:00:29,860 --> 00:00:32,130
going on, on the internet. But I don't want you to

12
00:00:32,130 --> 00:00:35,320
think there's anything hidden here. So the main thing that we're doing

13
00:00:35,320 --> 00:00:39,860
in get_page is we're returning the result of calling URL open,

14
00:00:39,860 --> 00:00:43,090
passing in the URL. So that opens the web page that was

15
00:00:43,090 --> 00:00:46,030
requested. And then reading that page. And that returns the output

16
00:00:46,030 --> 00:00:49,790
of that page as a string. This is provided by the Python

17
00:00:49,790 --> 00:00:53,270
library urllib, so we needed to import that library. And so

18
00:00:53,270 --> 00:00:56,900
that's what's going on. The rest of this is an exception

19
00:00:56,900 --> 00:01:00,280
handler. So we call this a try block. That we are

20
00:01:00,280 --> 00:01:03,190
going to try these things. They might not always work. And this is

21
00:01:03,190 --> 00:01:07,160
where we use try. There might an error. Maybe the URL

22
00:01:07,160 --> 00:01:09,820
is bad. Maybe we don't actually get a page back. Maybe the

23
00:01:09,820 --> 00:01:12,844
internet request times out, doesn't always work even if its in

24
00:01:12,844 --> 00:01:15,810
the URL. So that's why you put this inside a try block.

25
00:01:15,810 --> 00:01:19,860
And if something fails, execution will jump to the except

26
00:01:19,860 --> 00:01:23,700
block. This is called the exception handler, and in this case

27
00:01:23,700 --> 00:01:27,720
we just return an empty string. So that means if

28
00:01:27,720 --> 00:01:31,070
we request a URL that can't be loaded instead of getting

29
00:01:31,070 --> 00:01:33,650
an error it will just return an empty string, and

30
00:01:33,650 --> 00:01:35,720
for the use in our web crawler this is a good

31
00:01:35,720 --> 00:01:38,700
thing. If we didn't do this then the WebCrawler would

32
00:01:38,700 --> 00:01:41,350
have to deal with a case where the page doesn't exist.

33
00:01:41,350 --> 00:01:45,840
In our case we just get an empty string, so there's no content on that page. So

34
00:01:45,840 --> 00:01:47,980
looking at the actual code for get_page doesn't really

35
00:01:47,980 --> 00:01:50,190
help us understand much about what's going on when

36
00:01:50,190 --> 00:01:52,840
we request a webpage. All the actual work

37
00:01:52,840 --> 00:01:55,360
is hidden in this Python library function. So in

38
00:01:55,360 --> 00:01:57,120
order to understand more about what's going on, we

39
00:01:57,120 --> 00:01:59,550
need to understand more about how the internet works.
