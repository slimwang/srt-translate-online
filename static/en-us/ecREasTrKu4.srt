1
00:00:00,340 --> 00:00:03,419
So you can think of
Logistic Regression as a ninja,

2
00:00:03,419 --> 00:00:08,150
who will look at your data and
cut it in half, based on the labels.

3
00:00:08,150 --> 00:00:12,839
And we can think of a Support Vector
Machine, as a slightly pickier ninja

4
00:00:12,839 --> 00:00:16,230
who will carefully look at
the points on the boundary and

5
00:00:16,230 --> 00:00:18,719
make the cut based on those.

6
00:00:18,719 --> 00:00:22,660
And in the same fashion, we can think of
a Neural Network as a team of ninjas,

7
00:00:22,661 --> 00:00:27,440
who will look at your data and
cut it into regions based on the labels.

8
00:00:27,440 --> 00:00:30,500
And we can think of
the Kernel Trick as another ninja,

9
00:00:30,500 --> 00:00:34,409
who's slightly confused trying to
split some apples and oranges.

10
00:00:34,409 --> 00:00:36,139
Suddenly, she comes
up with a great idea,

11
00:00:36,140 --> 00:00:40,060
the idea consists of
moving the apples up and

12
00:00:40,060 --> 00:00:44,400
the oranges down and then successfully
cutting a line through between them.

13
00:00:45,579 --> 00:00:47,409
Now here's an exercise for you.

14
00:00:47,409 --> 00:00:50,319
How would you solve the XOR problem?

15
00:00:50,320 --> 00:00:53,219
That is,
which of the algorithms we learned

16
00:00:53,219 --> 00:00:56,399
would you use to separate
these four points?

17
00:00:56,399 --> 00:00:57,869
There's more than one solution.

18
00:00:57,869 --> 00:00:58,369
Give it a try.


