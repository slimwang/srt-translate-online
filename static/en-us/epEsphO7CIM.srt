1
00:00:00,670 --> 00:00:05,270
Our second main principle for CS7637 was that learning in KBAI agents is

2
00:00:05,270 --> 00:00:08,710
often incremental. This means that information or data or

3
00:00:08,710 --> 00:00:12,970
experiences arrive one at a time. This is one of the key differences between

4
00:00:12,970 --> 00:00:16,970
knowledge based AI, and other forms of AI, like machine learning. In those

5
00:00:16,970 --> 00:00:20,920
forms a large amount of information is often given right at the beginning. Here,

6
00:00:20,920 --> 00:00:25,000
our agents learn step by step, incrementally. We first encountered this with

7
00:00:25,000 --> 00:00:30,390
learning by recording cases. Our agents learned each individual case one by one.

8
00:00:30,390 --> 00:00:34,350
The experiences themselves were the increments in this learning strategy.

9
00:00:34,350 --> 00:00:37,040
Case based reasoning also operated on individual cases, but

10
00:00:37,040 --> 00:00:39,550
it organized them into much more complex knowledge structures.

11
00:00:39,550 --> 00:00:43,390
Like tagging them in an array. Or organizing the my discrimination tree. But

12
00:00:43,390 --> 00:00:46,810
the fundamental object of knowledge were still individual cases that arrived one

13
00:00:46,810 --> 00:00:51,250
by one. We did a complex exercise where one by one we added these new cases into

14
00:00:51,250 --> 00:00:55,670
our discrimination tree. Incremental concept learning was, as the title suggest,

15
00:00:55,670 --> 00:00:59,450
incremental. Here were received positive and negative examples one at a time.

16
00:00:59,450 --> 00:01:03,870
Based on the difference between our current concept, and our new example, and

17
00:01:03,870 --> 00:01:06,760
whether or not the new example was a positive or negative example.

18
00:01:06,760 --> 00:01:10,700
We would change our concept. This is always done example by example,

19
00:01:10,700 --> 00:01:15,020
incrementally. Version spaces involved a very similar kind of knowledge.

20
00:01:15,020 --> 00:01:19,440
Here experiences came one at a time, and we generalized a specific model and

21
00:01:19,440 --> 00:01:22,810
specialized the general model to converge down to an understanding of

22
00:01:22,810 --> 00:01:26,120
the concept. Finally, learning by correcting mistakes is also

23
00:01:26,120 --> 00:01:30,470
deeply incremental. Here, the individual mistakes arrived incrementally, and

24
00:01:30,470 --> 00:01:33,600
based on the individual mistakes, our agent modified it's

25
00:01:33,600 --> 00:01:36,798
knowledge base to repair the cause of the previous mistake.

26
00:01:36,798 --> 00:01:41,130
To take away here is that many of our methods in learning, reasoning and memory.

27
00:01:41,130 --> 00:01:44,510
All involve dealing with information that comes incrementally, bit by bit,

28
00:01:44,510 --> 00:01:47,880
instead of processing a large amount of data all at the same time.

29
00:01:47,880 --> 00:01:51,190
One can also see this connects more closely to human experience,

30
00:01:51,190 --> 00:01:53,830
where we're constantly experiencing the world experience by

31
00:01:53,830 --> 00:01:57,450
experience instead of being given a lifetime of experiences all at once.
