1
00:00:00,180 --> 00:00:03,900
By rejecting the null, we know that at least two of the foods differ in terms

2
00:00:03,900 --> 00:00:09,710
of mean amount consumed. But we don't know which ones differ. We can see that

3
00:00:09,710 --> 00:00:13,634
all three of the means differ from each other. But we don't know if these

4
00:00:13,634 --> 00:00:18,130
differences are due to sampling error. Therefore, we need to do additional

5
00:00:18,130 --> 00:00:22,328
testing to see which means are different. This additional testing is called

6
00:00:22,328 --> 00:00:26,793
Multiple Comparison Tests. So we're able to compare all of the means with each

7
00:00:26,793 --> 00:00:32,900
other. We wouldn't do a multiple comparison test until after we've done ANOVA.

8
00:00:32,900 --> 00:00:37,188
One of the most common multiple comparison test is called Tukey's HSD, which

9
00:00:37,188 --> 00:00:43,144
stands for Honestly Significant Difference. It's named after John Tukey, a very

10
00:00:43,144 --> 00:00:48,469
influential statistician. Tukey's HSD evaluates the significance of the

11
00:00:48,469 --> 00:00:54,170
difference between any two group means. In statistics, we say that this test

12
00:00:54,170 --> 00:00:58,734
will allow us to make pairwise comparisons. The way that we calculate Tukey's

13
00:00:58,734 --> 00:01:03,494
HSD is just like the margin of error that you've learned before. Remember that

14
00:01:03,494 --> 00:01:08,742
with the Z-test, it was the Z critical value denoted Z star times the standard

15
00:01:08,742 --> 00:01:14,315
error. And remember with the t-test, it was the t critical value times the

16
00:01:14,315 --> 00:01:18,930
standard error. Recall that this is approximately equal to half the width of

17
00:01:18,930 --> 00:01:24,200
the confidence interval. But now when we're comparing three or more samples, we

18
00:01:24,200 --> 00:01:29,593
have a new statistic called q. And we multiply this by the square root of the

19
00:01:29,593 --> 00:01:35,192
mean square for within subject variability divided by n. You might ask how is

20
00:01:35,192 --> 00:01:39,872
this similar to these, well the mean square for within subject variability is

21
00:01:39,872 --> 00:01:46,102
the pooled variance. It's just the average square deviation of each value from

22
00:01:46,102 --> 00:01:51,492
its respective group mean. Therefore, the square root is the pooled standard

23
00:01:51,492 --> 00:01:58,180
deviation. q is the studentized range statistic. And we find this in yet

24
00:01:58,180 --> 00:02:03,470
another table. Its purpose is to adjust the whole HSD, so that it's less likely

25
00:02:03,470 --> 00:02:09,475
we commit a type 1 error. Remember, a type 1 error is when we reject the null

26
00:02:09,475 --> 00:02:14,400
hypothesis when it's actually true. Since q increases, when there are more

27
00:02:14,400 --> 00:02:19,560
groups that we're comparing, it makes it less likely to commit a type 1 error.

28
00:02:19,560 --> 00:02:23,976
Remember that if a sample mean was further away from the population mean than

29
00:02:23,976 --> 00:02:30,592
the margin of error, it was considered unlikely? Well, if two sample means are

30
00:02:30,592 --> 00:02:35,986
further apart than the Tukey's HSD, then that's considered honestly

31
00:02:35,986 --> 00:02:39,706
significantly different.
