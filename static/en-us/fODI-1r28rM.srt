1
00:00:00,530 --> 00:00:02,849
Welcome to Computer Vision.

2
00:00:02,850 --> 00:00:06,650
Robotics can essentially be broken
down into a three step cycle.

3
00:00:06,650 --> 00:00:10,320
The first step is to sense or
perceive the world.

4
00:00:10,320 --> 00:00:14,929
The second step is to decide what
to do based on that perception.

5
00:00:14,929 --> 00:00:18,920
And the third step is to perform
an action to carry out that decision.

6
00:00:20,059 --> 00:00:25,059
Computer vision is a major part of
the perception step in that cycle.

7
00:00:25,059 --> 00:00:28,689
If you ask Sebastian, he'll tell
you that 80% of the challenge of

8
00:00:28,690 --> 00:00:31,440
building a self-driving
car is perception.

9
00:00:31,440 --> 00:00:34,050
>> And
this module is all about perception.

10
00:00:34,049 --> 00:00:36,839
Computer vision is the art and
science of perceiving and

11
00:00:36,840 --> 00:00:39,630
understanding the world
around you through images.

12
00:00:39,630 --> 00:00:41,179
In the case of self-driving cars,

13
00:00:41,179 --> 00:00:44,039
computer vision helps us detect
lane markings, vehicles,

14
00:00:44,039 --> 00:00:48,369
pedestrians, and other elements in the
environment in order to navigate safely.

15
00:00:48,369 --> 00:00:50,929
Later in this nano degree program,
you'll be using laser and

16
00:00:50,929 --> 00:00:52,854
radar data for the task of perception.

17
00:00:52,854 --> 00:00:55,509
So you might ask,
why bother doing this at all with camera

18
00:00:55,509 --> 00:00:59,079
images when we have more sophisticated
instruments at our disposal?

19
00:00:59,079 --> 00:01:01,199
So why are we doing this, David?

20
00:01:01,200 --> 00:01:02,570
>> Good question.

21
00:01:02,570 --> 00:01:06,147
Self-driven cars employ a suite
of sophisticated sensors, but

22
00:01:06,147 --> 00:01:10,530
humans do the job of driving with
just two eyes and one good brain.

23
00:01:10,530 --> 00:01:12,890
In fact,
we can even do it with one eye closed.

24
00:01:14,750 --> 00:01:15,890
>> Indeed we can.

25
00:01:15,890 --> 00:01:19,320
So let's take a closer look at
why using cameras instead of

26
00:01:19,319 --> 00:01:22,869
other sensors might be an advantage
in developing self-driving cars.

27
00:01:22,870 --> 00:01:26,260
Radar and lidar see the world in 3D,
which can be a big advantage for

28
00:01:26,260 --> 00:01:28,800
knowing where you are relative
to your environment.

29
00:01:28,799 --> 00:01:32,609
A camera sees in 2D but at much higher
spatial resolution than radar and

30
00:01:32,609 --> 00:01:36,290
lidar, such that it's actually
possible to infer depth information

31
00:01:36,290 --> 00:01:37,830
from camera images.

32
00:01:37,829 --> 00:01:38,539
The big difference,

33
00:01:38,540 --> 00:01:43,060
however, comes down to cost where
cameras are significantly cheaper.

34
00:01:43,060 --> 00:01:44,040
>> That's right.

35
00:01:44,040 --> 00:01:46,720
It is altogether possible
that self-driving cars will

36
00:01:46,719 --> 00:01:49,780
eventually be outfitted with
just a handful of cameras, and

37
00:01:49,780 --> 00:01:52,409
a really smart algorithm
to do the driving.

38
00:01:52,409 --> 00:01:55,310
That's why we're really excited
to dive into computer vision with

39
00:01:55,310 --> 00:01:56,070
you in this module.

