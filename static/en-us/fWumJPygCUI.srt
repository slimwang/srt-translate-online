1
00:00:00,000 --> 00:00:05,879
Let's see problem five now is back
looking a little bit more deeply at the

2
00:00:05,879 --> 00:00:06,479
data.

3
00:00:06,480 --> 00:00:10,679
So this data set of that has been, you know,
it's a real data set.

4
00:00:10,679 --> 00:00:15,150
It's got a lot of noise and random
things in it. In particular, we

5
00:00:15,150 --> 00:00:20,670
haven't taken really good care about
removing duplicates from the data sets.

6
00:00:20,670 --> 00:00:25,500
And it's possible that some of the data
that's in the test set also exists in

7
00:00:25,500 --> 00:00:30,448
the training sets. It would be a problem
if you really read about overfitting, but

8
00:00:30,449 --> 00:00:35,100
it also might be just the reality of
things. It's very often that you train on

9
00:00:35,100 --> 00:00:37,170
some data and at this time,

10
00:00:37,170 --> 00:00:40,620
you know, when you're actually using your
classifier the same data shows up.

11
00:00:40,620 --> 00:00:45,000
It can happen. So depending on the use
case, you might want to sanitize your

12
00:00:45,000 --> 00:00:46,260
data or not.

13
00:00:46,260 --> 00:00:49,680
In this case, we're not going to sanitize
it, but we want to know how much overlap

14
00:00:49,680 --> 00:00:53,820
there is because it might actually if
you know the entire test that is

15
00:00:53,820 --> 00:00:59,280
contained in the training set then we we
are in trouble and we are really at risk

16
00:00:59,280 --> 00:01:03,390
of misleading ourselves in thinking that
we've created the perfect classifier.

