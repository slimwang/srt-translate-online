1
00:00:00,140 --> 00:00:04,560
Another technique that uses a similar
idea to what we did when we increased

2
00:00:04,560 --> 00:00:08,293
the block size to reduce the number
of misses, is called pre-fetching.

3
00:00:08,293 --> 00:00:14,070
The way prefetching works is that we
guess which blocks will be accessed soon

4
00:00:14,070 --> 00:00:18,080
in the future, before they're actually
accessed, and then we bring those

5
00:00:18,080 --> 00:00:22,300
blocks into the cache ahead of time,
before they actually will be accessed.

6
00:00:22,300 --> 00:00:23,250
So with no prefetching,

7
00:00:23,250 --> 00:00:27,380
if time goes to time goes to the right,
we might have an access here.

8
00:00:27,380 --> 00:00:32,430
Let's say load word A, and then we check
quickly whether it's in our cache,

9
00:00:32,430 --> 00:00:36,480
and if it is not, we will go to memory
and spend a lot of time waiting for

10
00:00:36,480 --> 00:00:41,510
it until it comes back, so here we
can supply the data to the processor.

11
00:00:41,510 --> 00:00:43,690
So this is what happens
with no prefetching.

12
00:00:43,690 --> 00:00:49,280
With prefetching, assuming that the load
would happen here, sometime before

13
00:00:49,280 --> 00:00:54,890
the load, we have to guess that A will
be accessed and request it from memory.

14
00:00:54,890 --> 00:01:00,160
Now, what was memory latency here,
will be here, and at this point,

15
00:01:00,160 --> 00:01:05,300
the block is in the cache, so
when we try to load it, we have a hit.

16
00:01:05,300 --> 00:01:09,570
As you can see, with prefetching, we
are guessing what will be accessed and

17
00:01:09,570 --> 00:01:12,400
start fetching it from
memory into the cache.

18
00:01:12,400 --> 00:01:16,620
If we guess correctly,
instead of a miss, we get a hit.

19
00:01:16,620 --> 00:01:20,960
If we guessed incorrectly,
we brought something into the cache

20
00:01:20,960 --> 00:01:23,700
that replaced something that
might have been useful.

21
00:01:23,700 --> 00:01:28,360
So with prefetching we have, the good
guesses will eliminate misses, but

22
00:01:28,360 --> 00:01:31,800
bad guesses lead to what is called

23
00:01:31,800 --> 00:01:36,930
cache pollution because we are bringing
stuff that is useless into the cache.

24
00:01:36,930 --> 00:01:40,060
If it doesn't get access, that means
that maybe it would never have been

25
00:01:40,060 --> 00:01:42,380
brought to the cache in the first place.

26
00:01:42,380 --> 00:01:43,750
And because of cache pollution,

27
00:01:43,750 --> 00:01:47,235
because we kick out something that might
have been useful with useless data,

28
00:01:47,235 --> 00:01:52,380
not only that we didn't
eliminate the miss here,

29
00:01:52,380 --> 00:01:55,455
because we guessed wrongly,
we also might have created another

30
00:01:55,455 --> 00:01:58,990
miss because we kicked out something
that later might be accessed.

31
00:01:58,990 --> 00:02:00,940
And that we don't like.

32
00:02:00,940 --> 00:02:06,210
So overall prefetching is about
trying to make good guesses so

33
00:02:06,210 --> 00:02:11,380
that we eliminate misses while
trying to eliminate bad guesses

34
00:02:11,380 --> 00:02:13,560
because we don't want to
create additional misses.
