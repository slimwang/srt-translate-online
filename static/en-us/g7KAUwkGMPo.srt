1
00:00:00,320 --> 00:00:03,810
We have covered a fairly large
number of topics in this course.

2
00:00:03,810 --> 00:00:06,890
You might recall this particular
chart from the first lesson.

3
00:00:06,890 --> 00:00:09,920
Let us go through each one of
these circles one-by-one and

4
00:00:09,920 --> 00:00:12,150
see the connections between them.

5
00:00:12,150 --> 00:00:13,190
So, in the fundamentals,

6
00:00:13,190 --> 00:00:16,680
we covered knowledge representations
like semantic networks.

7
00:00:16,680 --> 00:00:20,770
In fact, we used semantic networks to
address two-by-one matrix problems.

8
00:00:20,770 --> 00:00:23,480
Then we covered a series
of problem solving methods.

9
00:00:23,480 --> 00:00:26,170
There's already domain independent
journal purpose methods.

10
00:00:26,170 --> 00:00:30,030
They do not use a lot of knowledge, but
they're very powerful, generate and

11
00:00:30,030 --> 00:00:33,420
test, means-ends analysis,
and problem reduction.

12
00:00:33,420 --> 00:00:34,755
Then we turn to production systems.

13
00:00:34,755 --> 00:00:37,870
They are a specific kind
of cognitive architecture.

14
00:00:37,870 --> 00:00:42,540
Production systems combine reasoning,
learning, and memory.

15
00:00:42,540 --> 00:00:44,520
Production systems to
bolster technology for

16
00:00:44,520 --> 00:00:49,250
developing agents, and
a theory of human computation.

17
00:00:49,250 --> 00:00:50,840
>> Later we talked about planning.

18
00:00:50,840 --> 00:00:54,120
And in order to talk about planning we
first proposed a formal language for

19
00:00:54,120 --> 00:00:54,950
discussing the plan.

20
00:00:54,950 --> 00:00:56,250
It's called formal logic.

21
00:00:56,250 --> 00:00:58,830
We learned about the different rules and
syntax used for

22
00:00:58,830 --> 00:01:00,630
writing formula logical statements.

23
00:01:00,630 --> 00:01:03,480
And learned why this is very important,
that it allows agents to

24
00:01:03,480 --> 00:01:07,380
prove the accuracy of their
conclusions based on a set of axioms.

25
00:01:07,380 --> 00:01:10,360
That gave us a language that we could
then use to talk about planning, and

26
00:01:10,360 --> 00:01:14,560
as we found out actually, the origins of
planning where an agent's making proofs

27
00:01:14,560 --> 00:01:17,370
of why a certain set of actions
would lead to a certain goal.

28
00:01:17,370 --> 00:01:20,480
Here we talked about both partial order
planning and hierarchical planning,

29
00:01:20,480 --> 00:01:23,430
which are two planning methods that
allow agents to make advanced plans for

30
00:01:23,430 --> 00:01:24,840
complex tasks.

31
00:01:24,840 --> 00:01:28,400
And also allows us to reflect on the way
we ourselves plan our actions to complex

32
00:01:28,400 --> 00:01:28,910
environments.

33
00:01:29,970 --> 00:01:33,150
>> Under common sense reasoning we
covered several important lessons.

34
00:01:33,150 --> 00:01:36,153
Frames, understanding,
common sense reasoning and scripts.

35
00:01:36,153 --> 00:01:42,480
Frames is a structured knowledge to
that allows us to do understanding.

36
00:01:42,480 --> 00:01:45,270
Understanding is such
a common every day activity.

37
00:01:45,270 --> 00:01:48,630
We are trying to make sense of
the world, but the world is ambiguous.

38
00:01:48,630 --> 00:01:52,140
The word, take, for example can have so
many different meanings.

39
00:01:52,140 --> 00:01:55,240
We saw how frames allow us to
disambiguate different meanings of

40
00:01:55,240 --> 00:01:56,560
the word take.

41
00:01:56,560 --> 00:01:59,490
Under common sense reasoning
we made every day intuitive

42
00:01:59,490 --> 00:02:02,080
inferences about the world around us.

43
00:02:02,080 --> 00:02:03,700
With understanding and
common sense reasoning,

44
00:02:03,700 --> 00:02:05,950
we're concerned with
sentence-level understanding.

45
00:02:05,950 --> 00:02:09,241
Scripts is more concerned about
discourse-level understanding.

46
00:02:09,241 --> 00:02:10,770
Scripts is an even larger,

47
00:02:10,770 --> 00:02:13,780
just structure knowledge
presentation than frames.

48
00:02:13,780 --> 00:02:16,530
It, too allows us to make
sense of the world around us,

49
00:02:16,530 --> 00:02:19,280
both the physical world and
the social world.

50
00:02:19,280 --> 00:02:21,610
Frames also came up in some
of the other lessons, and

51
00:02:21,610 --> 00:02:24,380
particularly came up in
the lesson on production systems,

52
00:02:24,380 --> 00:02:27,310
when we were trying to
represent episodic knowledge.

53
00:02:27,310 --> 00:02:30,010
It also came up in the lesson on
configuration, when we were trying to

54
00:02:30,010 --> 00:02:34,380
represent plans, and the variables of
various plans that can take values.

55
00:02:34,380 --> 00:02:37,300
>> We talked about learning in many
lessons throughout this course.

56
00:02:37,300 --> 00:02:40,450
But certain lessons were explicitly and
solely concerned with learning.

57
00:02:40,450 --> 00:02:43,460
We started off by talking about learning
by recording cases, where an agent could

58
00:02:43,460 --> 00:02:47,650
build up a case library of its own prior
experiences to use for future reasoning.

59
00:02:47,650 --> 00:02:49,700
That formed a foundation of
analogical reasoning as well,

60
00:02:49,700 --> 00:02:51,280
that we'll talk about in a second.

61
00:02:51,280 --> 00:02:53,100
We also talked about incremental
concept learning and

62
00:02:53,100 --> 00:02:55,310
version spaces,
two different learning methods for

63
00:02:55,310 --> 00:02:58,830
learning about information that's
coming in incrementally, or bit by bit.

64
00:02:58,830 --> 00:03:01,640
That was one of our foundational
principles of this class that we

65
00:03:01,640 --> 00:03:04,650
discussed at the beginning and
that we'll revisit in a few minutes.

66
00:03:04,650 --> 00:03:06,880
We also talked about
classification under learning,

67
00:03:06,880 --> 00:03:09,660
which is one of the most
ubiquitous problems in AI.

68
00:03:09,660 --> 00:03:12,680
We talked about how classification
involves grouping large combinations of

69
00:03:12,680 --> 00:03:16,640
percepts into equivalence classes,
to allow for easier action selection.

70
00:03:16,640 --> 00:03:18,890
Learning also can open several other
lessons that we did throughout this

71
00:03:18,890 --> 00:03:23,320
class, including production systems,
key spaced reasoning, explanation based

72
00:03:23,320 --> 00:03:26,890
learning, analogical reasoning, and
learning about correcting mistakes.

73
00:03:26,890 --> 00:03:29,440
Metareasoning was also deeply connected
to learning, where we could learn from

74
00:03:29,440 --> 00:03:33,250
our own experiences by analyzing
our own prior thought processes.

75
00:03:33,250 --> 00:03:34,120
>> As David just said,

76
00:03:34,120 --> 00:03:38,090
analogical reasoning is another
major topic connected with learning.

77
00:03:38,090 --> 00:03:40,140
We talked about learning
by recording cases.

78
00:03:40,140 --> 00:03:43,100
We are simply assimilating cases
by recording them in a growing

79
00:03:43,100 --> 00:03:44,530
case library.

80
00:03:44,530 --> 00:03:47,870
As a new problem comes, we use methods
like nearest neighbor to retrieve

81
00:03:47,870 --> 00:03:51,590
the closest case, and
it invoked that case with a new problem.

82
00:03:51,590 --> 00:03:55,210
We talked about case-based reasoning,
in which we not only retrieved the case,

83
00:03:55,210 --> 00:03:56,470
but we also tweak it, or

84
00:03:56,470 --> 00:04:00,110
modify it in small ways in
order to achieve a new goal.

85
00:04:00,110 --> 00:04:01,360
In explanation-based learning,

86
00:04:01,360 --> 00:04:05,507
we saw how we could connect
instances to kinds of definitions.

87
00:04:05,507 --> 00:04:10,355
We constructed explanations that
told us how instance is an example

88
00:04:10,355 --> 00:04:11,277
of a given concept.

89
00:04:11,277 --> 00:04:15,275
This involved both abstraction and
transfer.

90
00:04:15,275 --> 00:04:18,269
We also connected explanation-based
learning to creativity.

91
00:04:18,269 --> 00:04:20,492
Analogical reasoning made
[INAUDIBLE] abstraction and

92
00:04:20,492 --> 00:04:22,170
transfer even more explicit.

93
00:04:22,170 --> 00:04:24,760
We talked about cross
analogical transfer for

94
00:04:24,760 --> 00:04:27,850
example from the solar system
to the atomic structure.

95
00:04:27,850 --> 00:04:28,905
We saw that when needed,

96
00:04:28,905 --> 00:04:32,890
rich mental models in order to be
able to do an analogical transfer.

97
00:04:34,030 --> 00:04:37,170
We concluded the lesson on
analogical reasoning by connecting

98
00:04:37,170 --> 00:04:40,192
it with analogical design or
design by analogy.

99
00:04:40,192 --> 00:04:44,310
And analogical reasoning too is
closely connected to creativity.

100
00:04:44,310 --> 00:04:47,040
>> Our discussion of visuospatial
reasoning started with our unit on

101
00:04:47,040 --> 00:04:48,700
constraint propagation.

102
00:04:48,700 --> 00:04:50,710
Constraint propagation
was a very abstract and

103
00:04:50,710 --> 00:04:54,420
general way of propagating constraints
to make sense of a new situation, and

104
00:04:54,420 --> 00:04:56,570
it comes up uniquely
in visual reasoning.

105
00:04:56,570 --> 00:05:00,130
Or we use line labeling to make
sense of 3D scenes even if they're

106
00:05:00,130 --> 00:05:01,510
presented in 2D.

107
00:05:01,510 --> 00:05:04,470
Where we use line labeling to make sense
of three dimensional scenes even if

108
00:05:04,470 --> 00:05:06,840
they're presented in
only two dimensions.

109
00:05:06,840 --> 00:05:08,800
We also how constraint
propagation can be used for

110
00:05:08,800 --> 00:05:10,500
natural language understanding.

111
00:05:10,500 --> 00:05:13,070
And we referenced how we might
also use it to understand music or

112
00:05:13,070 --> 00:05:14,590
tactile information.

113
00:05:14,590 --> 00:05:17,310
Then in visuospatial reasoning
we expanded on these notions to

114
00:05:17,310 --> 00:05:19,990
discuss whether it would be
possible to reason about the world

115
00:05:19,990 --> 00:05:22,080
without extracting propositions.

116
00:05:22,080 --> 00:05:24,650
This involved looking at scenes in
the world where there was no explicit

117
00:05:24,650 --> 00:05:26,990
causality, like a glass that's
been spilled on the table.

118
00:05:26,990 --> 00:05:28,250
We can infer what happened,

119
00:05:28,250 --> 00:05:31,880
but there's nothing in the visual scene
that tells us exactly how it arose.

120
00:05:31,880 --> 00:05:34,510
Similarly, we also discuss how this
could apply to other modalities,

121
00:05:34,510 --> 00:05:37,400
like tactile information or
musical information.

122
00:05:37,400 --> 00:05:41,400
>> In the unit on design and creativity,
we considered lessons in configuration,

123
00:05:41,400 --> 00:05:44,440
diagnosis, design and creativity.

124
00:05:44,440 --> 00:05:48,730
You may recall that in configuration,
we were worried about very routine,

125
00:05:48,730 --> 00:05:52,140
everyday kind of designs, and
we did that kind of design

126
00:05:52,140 --> 00:05:56,200
by having a library of clients at
different levels of abstraction.

127
00:05:56,200 --> 00:06:00,260
We selected a plan at a high level of
abstraction, assign values to some of

128
00:06:00,260 --> 00:06:04,360
the variables, and then refine the plan
at the next door level abstraction.

129
00:06:04,360 --> 00:06:05,810
All the components were known,

130
00:06:05,810 --> 00:06:09,380
we had to decide on the arrangement
of the components of configuration.

131
00:06:09,380 --> 00:06:13,050
In diagnosis, we were given data
about a malfunctioning system and

132
00:06:13,050 --> 00:06:16,980
we had to identify the fault
responsible for that malfunctioning.

133
00:06:16,980 --> 00:06:20,950
We took two views of diagnosis,
classification and abduction.

134
00:06:20,950 --> 00:06:24,110
In the classification view,
this data was mapped into

135
00:06:24,110 --> 00:06:28,160
equal classes that acted like
hypotheses for this data.

136
00:06:28,160 --> 00:06:32,150
In abduction, we composed this
elementary hypothesis into a composite

137
00:06:32,150 --> 00:06:36,010
hypothesis that could best
explain the entire data.

138
00:06:36,010 --> 00:06:39,731
Design thinking refers to thinking
about problems that are ill-defined and

139
00:06:39,731 --> 00:06:42,110
open-ended, and under-constrained.

140
00:06:42,110 --> 00:06:45,130
In design thinking, the problem and
solution often co-evolve.

141
00:06:45,130 --> 00:06:46,480
The problem doesn't remain fixed.

142
00:06:46,480 --> 00:06:47,980
The solution evolves, but

143
00:06:47,980 --> 00:06:51,280
that in turns it leads to improving
the understanding of the problem,

144
00:06:51,280 --> 00:06:55,090
both our understanding of the problem
and solution evolve together.

145
00:06:55,090 --> 00:06:58,930
We cut across creativity in
terms of novelty, value, and

146
00:06:58,930 --> 00:07:02,120
the non-obviousness of the results.

147
00:07:02,120 --> 00:07:05,810
We discuss the criteria under which we
would consider an agent to be creative.

148
00:07:05,810 --> 00:07:09,626
And we saw how many of the techniques
that you have learned in this particular

149
00:07:09,626 --> 00:07:13,150
class can compose the fundamental
processes of creativity.

150
00:07:13,150 --> 00:07:17,250
Like analogical reasoning, like visual
special reasoning, like meta-reasoning.

151
00:07:17,250 --> 00:07:20,081
>> Then we close the class by
talking about meta-cognition.

152
00:07:20,081 --> 00:07:23,440
Meta-cognition enable the agents to
reason about their own reasoning, or

153
00:07:23,440 --> 00:07:26,870
think about their own thinking, or have
knowledge of their own knowledge base.

154
00:07:26,870 --> 00:07:29,350
We started out by talking about
learning by correcting mistakes.

155
00:07:29,350 --> 00:07:31,800
Or an agent can look at a mistake
that's been made in the past,

156
00:07:31,800 --> 00:07:34,290
isolate the mistake,
explain the mistake and

157
00:07:34,290 --> 00:07:36,710
then fix the mistake so
that it didn't happen again.

158
00:07:36,710 --> 00:07:40,305
This was one narrow instance of
the broader idea of meta-reasoning.

159
00:07:40,305 --> 00:07:43,735
In meta-reasoning, we talked about
metacognition could bring together many

160
00:07:43,735 --> 00:07:46,040
of the different methods that we
talked about throughout this class.

161
00:07:46,040 --> 00:07:49,305
Meta-reasoning enabled an agent to
look at a new problem and select

162
00:07:49,305 --> 00:07:53,001
which of its many strategies would
be best for addressing that problem.

163
00:07:53,001 --> 00:07:55,735
It also would allow an agent to
integrate multiple different methods of

164
00:07:55,735 --> 00:07:57,830
reasoning at different
levels of distraction.

165
00:07:57,830 --> 00:08:00,950
We also talked about what how
meta-reasoning operates is also the way

166
00:08:00,950 --> 00:08:02,534
in which meta-reasoning operates.

167
00:08:02,534 --> 00:08:05,470
Meta-reasoning can reason
about case based reasoning, or

168
00:08:05,470 --> 00:08:07,580
it can reason using
case based reasoning.

169
00:08:07,580 --> 00:08:11,640
It could, for example, use production
rules to conduct case based reasoning.

170
00:08:11,640 --> 00:08:14,160
In this way it could integrate
many different methods

171
00:08:14,160 --> 00:08:16,370
at many different levels of instruction.

172
00:08:16,370 --> 00:08:19,750
Finally, this set up a notion of
ethics in artificial intelligence.

173
00:08:19,750 --> 00:08:21,820
As we're building AI agents
that are starting to have real,

174
00:08:21,820 --> 00:08:24,650
human level intelligence,
what are the ethical issues?

175
00:08:24,650 --> 00:08:27,910
What should we think about replacing
certain human jobs with robots,

176
00:08:27,910 --> 00:08:30,420
or what should we think about developing
robots that can interact with us on

177
00:08:30,420 --> 00:08:32,400
an everyday basis in the natural world?

178
00:08:32,400 --> 00:08:36,830
Under what conditions would we consider
these agents to actually be human-like?

179
00:08:36,830 --> 00:08:39,549
>> This summarizes 30 topics
that we covered in this class,

180
00:08:39,549 --> 00:08:40,140
which is quite a lot.

181
00:08:41,230 --> 00:08:44,420
Of course, there is a lot more to
talk about each of these 30 topics

182
00:08:44,420 --> 00:08:46,445
than we have covered so far.

183
00:08:46,445 --> 00:08:49,925
Therefore we have provided readings for
each of the topics.

184
00:08:49,925 --> 00:08:51,655
And you are welcome to
pursue the readings for

185
00:08:51,655 --> 00:08:54,495
whatever topic that
interests you the most.

186
00:08:54,495 --> 00:08:57,155
We would also love to hear about
your views about this on the forum.
