1
00:00:00,760 --> 00:00:05,600
So in our last video, we started talking about how uncaptured features,

2
00:00:05,600 --> 00:00:09,220
might be having an impact on the variance of inter-tweet time.

3
00:00:09,220 --> 00:00:13,290
Now in order to understand how this might be, let's look at a simple example.

4
00:00:14,320 --> 00:00:17,160
Let's suppose, we know that the model that is

5
00:00:17,160 --> 00:00:21,090
producing data is a known linear model, 2x plus 3.

6
00:00:21,090 --> 00:00:26,130
In addition to this we are going to add some background noise.

7
00:00:26,130 --> 00:00:30,360
Specifically, we're going to sample randomly from a normal distribution,

8
00:00:30,360 --> 00:00:33,560
with a mean of 0 and standard deviation of 50.

9
00:00:33,560 --> 00:00:37,580
We're going to sample many points of the input and

10
00:00:37,580 --> 00:00:41,160
output, and create a graph of the 95% confidence interval.

11
00:00:41,160 --> 00:00:46,500
So, here, we're just sampling points from x, our linear model and

12
00:00:46,500 --> 00:00:48,390
then some random noise.

13
00:00:48,390 --> 00:00:51,923
We've added our collected data points onto data points_1.

14
00:00:51,923 --> 00:00:55,870
Now for each value x, we have a spread of values.

15
00:00:55,870 --> 00:00:56,610
For that spread,

16
00:00:56,610 --> 00:01:01,340
we're going to calculate the 95th quintile, and the fifth quintile.

17
00:01:01,340 --> 00:01:03,000
And now we'll just plot.

18
00:01:03,000 --> 00:01:07,800
So in this graph, the red line is a real line, the true model.

19
00:01:07,800 --> 00:01:08,610
And the blue and

20
00:01:08,610 --> 00:01:13,740
green lines, represent the top and bottom end of the confidence interval.

21
00:01:13,740 --> 00:01:16,920
As you can see, as a result of introducing some of the noise,

22
00:01:16,920 --> 00:01:18,630
there's a little bit of a spread here.

23
00:01:18,630 --> 00:01:23,580
Now, let's suppose that instead of using the single variable model,

24
00:01:23,580 --> 00:01:28,610
with some normal noise we're going to adda new feature.

25
00:01:28,610 --> 00:01:32,120
So our model now depends on two features, x and y.

26
00:01:32,120 --> 00:01:37,620
But we're still only going to collect x values and the response values.

27
00:01:37,620 --> 00:01:40,010
We're not going to collect the y values.

28
00:01:40,010 --> 00:01:43,520
That is lets pretend we don't know about y and

29
00:01:43,520 --> 00:01:46,900
just let it influence the observed values of f.

30
00:01:46,900 --> 00:01:51,010
As you can see, not capturing the additional feature y,

31
00:01:51,010 --> 00:01:54,490
has resulted in dramatically increased uncertainty and

32
00:01:54,490 --> 00:01:57,530
consequently variance in the response value.

33
00:01:57,530 --> 00:02:02,770
In this way, we can see not capturing enough features is potentially a source of

34
00:02:02,770 --> 00:02:06,060
inaccuracy and uncertainty in our estimator.

35
00:02:06,060 --> 00:02:10,030
Thus let's try searching for features which we have not yet captured.

36
00:02:11,170 --> 00:02:15,030
If we successfully find features which have an influencing force over

37
00:02:15,030 --> 00:02:19,090
tweeting behavior, we just may be able to reduce the variance of our data.

38
00:02:20,860 --> 00:02:24,420
In the next few videos, we'll talk about a tool from the field of

39
00:02:24,420 --> 00:02:26,860
information theory for systematically doing so.
