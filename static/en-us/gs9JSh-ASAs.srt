1
00:00:00,200 --> 00:00:02,984
So far, we've seen three different memory consistency

2
00:00:02,984 --> 00:00:06,395
models. One is the sequential consistent memory model, the

3
00:00:06,395 --> 00:00:09,790
release consistent memory model. And, strictly speaking, I would

4
00:00:09,790 --> 00:00:12,840
say, the eager version and the lazy version are

5
00:00:12,840 --> 00:00:15,522
just variants of the same memory model, namely

6
00:00:15,522 --> 00:00:18,810
the release consistent memory model. And now we're going to

7
00:00:18,810 --> 00:00:22,060
transition and talk about software distributed shared memory, and

8
00:00:22,060 --> 00:00:25,340
how these memory models come into play in building

9
00:00:25,340 --> 00:00:27,837
software distributed shared memory. So we're dealing

10
00:00:27,837 --> 00:00:30,760
with a computational cluster, that is, in

11
00:00:30,760 --> 00:00:36,053
the cluster, each node of the cluster has its own private physical memory, but

12
00:00:36,053 --> 00:00:38,989
there is no physically shared memory. And

13
00:00:38,989 --> 00:00:43,165
therefore, the system, meaning the system software,

14
00:00:43,165 --> 00:00:46,210
has to implement the consistency model to

15
00:00:46,210 --> 00:00:50,543
the programmer. In a tightly coupled multiprocessor,

16
00:00:50,543 --> 00:00:55,438
coherence is maintained at individual memory access level by the

17
00:00:55,438 --> 00:01:00,880
hardware. Unfortunately, that fine grain of

18
00:01:00,880 --> 00:01:06,100
maintaining coherence at individual memory access level will lead to too

19
00:01:06,100 --> 00:01:11,230
much overhead in a cluster. Why? Because on every load or store instruction that

20
00:01:11,230 --> 00:01:15,710
is happening on any one of these processors, the system software has to butt

21
00:01:15,710 --> 00:01:18,140
in, and implement the coherence action

22
00:01:18,140 --> 00:01:21,450
in software through the entire cluster. And

23
00:01:21,450 --> 00:01:23,940
this is simply infeasible. So what do

24
00:01:23,940 --> 00:01:27,290
we do to implement software distributed shared

25
00:01:27,290 --> 00:01:34,600
memory? So, first part is to implement this sharing and coherence maintenance at

26
00:01:34,600 --> 00:01:40,880
the level of pages. So the granularity of coherence maintenance is at the level

27
00:01:40,880 --> 00:01:47,665
of a page. Now, even in a simple processor or in a true multiprocessor, the

28
00:01:47,665 --> 00:01:54,001
unit of coherence maintenance is not simply a single word that a processor is

29
00:01:54,001 --> 00:02:00,179
doing a load or a store on. Because in order to exploit spatial locality, the

30
00:02:00,179 --> 00:02:06,094
block size used in caches in processors tend to be bigger than the granularity

31
00:02:06,094 --> 00:02:12,613
of memory access that is possible from individual instructions in the processor.

32
00:02:12,613 --> 00:02:17,893
So we're taking this up a level and saying, if you're going to do it all in

33
00:02:17,893 --> 00:02:21,853
software, let's keep the granularity of coherence

34
00:02:21,853 --> 00:02:24,589
maintenance to be an entire page. And

35
00:02:24,589 --> 00:02:26,940
you're going to maintain the coherence of the

36
00:02:26,940 --> 00:02:31,510
distributed shared memory in software by cooperating

37
00:02:31,510 --> 00:02:33,590
with the operating system that is running

38
00:02:33,590 --> 00:02:35,940
on every node of the processor. So what

39
00:02:35,940 --> 00:02:38,290
we're going to do is, we're providing a

40
00:02:38,290 --> 00:02:43,340
global virtual memory abstraction to the application program

41
00:02:43,340 --> 00:02:45,800
running on the cluster. So the application

42
00:02:45,800 --> 00:02:49,780
programmer views the entire cluster as a globally

43
00:02:49,780 --> 00:02:52,850
shared virtual memory. Under the cover, what the

44
00:02:52,850 --> 00:02:57,265
DSM software is doing is, it is partitioning

45
00:02:57,265 --> 00:03:00,720
this global address space into chunks that are

46
00:03:00,720 --> 00:03:04,015
managed individually on the nodes of the different

47
00:03:04,015 --> 00:03:07,165
processors of the cluster. From the application point

48
00:03:07,165 --> 00:03:10,155
of view, what this global virtual memory abstraction

49
00:03:10,155 --> 00:03:13,077
is giving is address equivalence. And that is,

50
00:03:13,077 --> 00:03:15,399
if I access a memory location x in

51
00:03:15,399 --> 00:03:18,925
my program, that means exactly the same thing,

52
00:03:18,925 --> 00:03:22,795
whether I access the memory location x from processor

53
00:03:22,795 --> 00:03:27,803
1, processor 2, and so on and so forth. That's the idea in providing

54
00:03:27,803 --> 00:03:30,660
a global virtual memory abstraction. And the

55
00:03:30,660 --> 00:03:34,450
way the DSM software is going to handle maintenance

56
00:03:34,450 --> 00:03:38,180
of coherence is by having distributed ownership

57
00:03:38,180 --> 00:03:42,790
for the different virtual pages that constitute this

58
00:03:42,790 --> 00:03:45,020
global virtual address space. So you can

59
00:03:45,020 --> 00:03:48,160
think of this global virtual address space as

60
00:03:48,160 --> 00:03:50,750
constituted by several pages, and we're going to

61
00:03:50,750 --> 00:03:53,750
say some number of these pages are owned

62
00:03:53,750 --> 00:03:58,310
by processor 1. Some number of these pages are owned by processor 2. Some number

63
00:03:58,310 --> 00:04:03,930
by processor 3, and so on. So we split the ownership responsibility into

64
00:04:03,930 --> 00:04:09,040
individual processors. Now what that means, is that the owner

65
00:04:09,040 --> 00:04:13,450
particular page is also responsible for keeping complete

66
00:04:13,450 --> 00:04:15,970
coherence information for that particular page

67
00:04:15,970 --> 00:04:19,248
and taking the coherence actions commensurate with

68
00:04:19,248 --> 00:04:24,120
that page. And the local physical memories are available in each one of this

69
00:04:24,120 --> 00:04:32,540
processors is being used for hosting portions of the global virtual memory space

70
00:04:32,540 --> 00:04:35,430
in the individual processors commensurate with the

71
00:04:35,430 --> 00:04:38,700
access pattern that is being displayed by

72
00:04:38,700 --> 00:04:41,420
the application on the different processors. So for

73
00:04:41,420 --> 00:04:45,590
instance, if processor 1 accesses this portion of the

74
00:04:45,590 --> 00:04:49,470
global virtual memory space, then this portion of the

75
00:04:49,470 --> 00:04:53,100
address space is mapped into the local physical memory

76
00:04:53,100 --> 00:04:55,000
of this processor. So that a thread that

77
00:04:55,000 --> 00:04:57,640
is running on this processor can access this portion

78
00:04:57,640 --> 00:05:00,273
of the global address space. And it might be

79
00:05:00,273 --> 00:05:03,845
that same page is being shared with some other

80
00:05:03,845 --> 00:05:09,409
processor n over here. In that case, a copy of this page is existing in both

81
00:05:09,409 --> 00:05:14,995
this processor, as well as this processor. Now it is up to the processor that is

82
00:05:14,995 --> 00:05:18,675
responsible for the ownership of this particular page

83
00:05:18,675 --> 00:05:21,715
to worry about the consistency of this page,

84
00:05:21,715 --> 00:05:25,270
that is now resident in multiple locations. For

85
00:05:25,270 --> 00:05:29,240
instance, if this node, let's say, is the owner

86
00:05:29,240 --> 00:05:35,338
for this page. Then this node will have metadata that indicates that this

87
00:05:35,338 --> 00:05:42,220
particular page is currently shared by both p 1 and p n. So that

88
00:05:42,220 --> 00:05:48,470
is the directory that is associated with the portion of the global virtual

89
00:05:48,470 --> 00:05:50,850
memory space that is being owned and

90
00:05:50,850 --> 00:05:54,180
managed by this particular processor. So statically,

91
00:05:54,180 --> 00:05:56,900
we are making an association between a portion of

92
00:05:56,900 --> 00:06:00,900
the address space and the owner for that portion

93
00:06:00,900 --> 00:06:04,160
of the address space in terms of coherence maintenance

94
00:06:04,160 --> 00:06:07,530
for that portion of the global virtual memory space.
