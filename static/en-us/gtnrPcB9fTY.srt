1
00:00:00,310 --> 00:00:04,242
So the Stratton Taxonomy's 6th optimization technique is called compaction.

2
00:00:04,242 --> 00:00:07,614
And John has described compaction a couple of times.

3
00:00:07,614 --> 00:00:10,822
He described it in unit 4 and revisited it in unit 6,

4
00:00:10,822 --> 00:00:14,324
where it comes up in sparse matrix vector multiply and in-graph traversal.

5
00:00:14,324 --> 00:00:18,541
So I'm not going to go into great length describing what compaction is.

6
00:00:18,541 --> 00:00:20,130
Just as a quick review,

7
00:00:20,130 --> 00:00:22,698
compaction is useful when you have a computation to perform

8
00:00:22,698 --> 00:00:27,865
on a set of elements but the exact elements that require computation are not known in advance.

9
00:00:27,865 --> 00:00:30,537
If most of the elements require computation,

10
00:00:30,537 --> 00:00:33,874
then its simplest just to assign threads to every element

11
00:00:33,874 --> 00:00:37,938
and just have every thread check to see whether they should process or not.

12
00:00:37,938 --> 00:00:40,848
The threads that are active will do whatever they are suppose to do.

13
00:00:40,848 --> 00:00:43,932
The threads that will not will simply return.

14
00:00:43,932 --> 00:00:46,349
In that case you will end up storing something valid--

15
00:00:46,349 --> 00:00:48,756
some valid output in most cells

16
00:00:48,756 --> 00:00:51,290
and the cells in the output are the--

17
00:00:51,290 --> 00:00:53,958
the elements in the output where the thread wasn't active,

18
00:00:53,958 --> 00:00:57,361
because it didn't need to be processed you will end up with leaving blank.

19
00:00:57,361 --> 00:01:00,573
Now if relatively few of the elements require computation,

20
00:01:00,573 --> 00:01:04,268
then you're wasting a lot of storage on the output,

21
00:01:04,268 --> 00:01:06,271
and you're doing less efficient computation,

22
00:01:06,271 --> 00:01:11,314
because a lot of your threads are sitting idol, instead of doing some sort of useful work.

23
00:01:11,314 --> 00:01:16,083
Compacting the elements means creating a dense array containing only active elements.

24
00:01:16,083 --> 00:01:20,150
So that then you can do your processing on the stents array,

25
00:01:20,150 --> 00:01:22,887
producing a dense output array directly.

26
00:01:22,887 --> 00:01:27,427
You're not wasting storage on all these invalid, null output elements,

27
00:01:27,427 --> 00:01:30,431
and you're not wasting computation

28
00:01:30,431 --> 00:01:33,494
on all these threads that are just sitting around not doing anything

29
00:01:33,494 --> 00:01:35,969
while the other threads in their thread block are--

30
00:01:35,969 --> 00:01:39,211
the relatively few threads in this thread block

31
00:01:39,211 --> 00:01:41,404
that have active elements have have anything useful to do.

32
00:01:41,404 --> 00:01:45,164
So as a quiz, suppose that only every 8th element will be processed.

33
00:01:45,164 --> 00:01:47,916
So here I've drawn the elements that will be processed

34
00:01:47,916 --> 00:01:49,643
and all the ones I've left blank will not be processed.

35
00:01:49,643 --> 00:01:53,792
And the idea is that every 8th element--it requires processing.

36
00:01:53,792 --> 00:01:55,953
And assume that we're compute limited;

37
00:01:55,953 --> 00:01:59,858
in other words, that whatever operation is we're going to do on these every 8 elements

38
00:01:59,858 --> 00:02:01,795
is expensive,

39
00:02:01,795 --> 00:02:06,563
and that's the limiting factor rather than the memory bandwidth to fetch elements.

40
00:02:06,563 --> 00:02:09,699
So assume that we are limited by computation and not memory bandwidth.

41
00:02:09,699 --> 00:02:12,803
So the question is about how much less time

42
00:02:12,803 --> 00:02:14,690
will the computation take

43
00:02:14,690 --> 00:02:17,941
if a thread is launched to run on every element of the compacted array

44
00:02:17,941 --> 00:02:22,049
rather than if the thread is launched to run for every element of the original array?

45
00:02:22,049 --> 00:02:25,695
In other words, how much faster is it going to be to run on a compacted array?

46
00:02:25,695 --> 00:02:31,531
Will it be 8x faster, will it be 4x faster, will it be the same speed, 1x faster?

47
00:02:31,531 --> 00:02:33,443
And then I want to ask,

48
00:02:33,443 --> 00:02:36,531
what if only every 32nd element will be processed,

49
00:02:36,531 --> 00:02:40,131
and what if only 128th element must be processed?

50
00:02:40,131 --> 00:02:45,689
So for the answer I'm looking for an integer like 4 or 8 or 16 or 32 or 1,

51
00:02:45,689 --> 00:02:53,523
and you're telling me whether its 4 times faster, 8 times faster, 1 times faster and so on.
