1
00:00:00,037 --> 00:00:03,349
Okay, now we've talked about parallel communications patterns.

2
00:00:03,349 --> 00:00:04,487
Check that off.

3
00:00:04,487 --> 00:00:06,872
Now, that we've discussed the general forms of communication

4
00:00:06,872 --> 00:00:09,410
that we'll see among the code of threads in our parallel programs,

5
00:00:09,410 --> 00:00:13,581
let's talk about how those threads can most efficiently access memory in concert.

6
00:00:13,581 --> 00:00:17,156
An important subtopic of this is going to be how to exploit the data reuse

7
00:00:17,156 --> 00:00:20,435
that we saw during all those gathers and stencils codes.

8
00:00:20,435 --> 00:00:24,173
There were a lot of threads often accessing the same data at the same time

9
00:00:24,173 --> 00:00:28,246
and how can we exploit that to reduce the total amount of time spent on memory?

10
00:00:28,246 --> 00:00:33,382
The next big topic is how can threads communicate partial results by sharing memory?

11
00:00:33,382 --> 00:00:37,353
A real problem then becomes once threads are sharing memory

12
00:00:37,353 --> 00:00:38,787
and reading and writing from the same memory

13
00:00:38,787 --> 00:00:41,591
how do you keep them from stomping on each others' memory accesses?

14
00:00:41,591 --> 00:00:42,619
How can you do this safely?

15
00:00:42,619 --> 00:00:45,191
In order to better understand all of these topics,

16
00:00:45,191 --> 00:00:49,097
we need to dive a bit deeper and learn more about the underlying GPU hardware.
