1
00:00:00,111 --> 00:00:03,705
So the second and most important thing to understand about the programming model

2
00:00:03,705 --> 00:00:08,352
is that each CUDA block is considered to be its own independent program.

3
00:00:08,352 --> 00:00:12,079
That means CUDA objects are private to a block,

4
00:00:12,079 --> 00:00:17,786
so streams and events that you create inside a block can be used by any thread in that block,

5
00:00:17,786 --> 00:00:24,194
but they can't be used by or exchanged with any other block, including your children.

6
00:00:24,194 --> 00:00:28,644
So that means you can synchronize on common launch within your block,

7
00:00:28,644 --> 00:00:32,402
but you cannot synchronize on work launched by another block.

8
00:00:32,402 --> 00:00:38,541
You can't pass streams or events to your children and have them synchronize on it or you risk a deadlock.

9
00:00:38,541 --> 00:00:41,075
This is all part of composability that we looked at a minute ago.

10
00:00:41,075 --> 00:00:45,415
And finally, data that's private to a block, like shared memory for example,

11
00:00:45,415 --> 00:00:51,519
is private to that block. That means you cannot pass shared memory to your child kernels.

12
00:00:51,519 --> 00:00:55,625
So if I have a person data that might block as accumulated in shared memory,

13
00:00:55,625 --> 00:00:57,319
which is a pretty common thing to do in CUDA,

14
00:00:57,319 --> 00:01:02,630
I would have to write this out to global memory in order for my child kernel to see it.

15
00:01:02,630 --> 00:01:06,036
Remember your child kernel is another grid, it's not sets of blocks,

16
00:01:06,036 --> 00:01:11,106
and the first, most important, rule is all the blocks are considered independent programs,

17
00:01:11,106 --> 00:01:13,440
so no passing around of private data.
