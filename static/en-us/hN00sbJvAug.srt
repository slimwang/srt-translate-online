1
00:00:00,250 --> 00:00:06,182
In Unit 4, we looked at Sparse Matrix Vector Multiply, SpMv,

2
00:00:06,182 --> 00:00:11,043
noting that this is one of the most important operations in all of computing.

3
00:00:11,043 --> 00:00:14,317
What we're going to look at today is how to implement this efficiently.

4
00:00:14,317 --> 00:00:17,369
So first a quick recap on what SpMv is.

5
00:00:17,369 --> 00:00:20,751
We wish to multiply a matrix by a vector.

6
00:00:20,751 --> 00:00:26,675
If this matrix is dense where every entry in the entire matrix is represented in the matrix data structure,

7
00:00:26,675 --> 00:00:29,129
GPUs can get excellent performance,

8
00:00:29,129 --> 00:00:32,671
but many interesting matrices are what we call sparse.

9
00:00:32,671 --> 00:00:36,917
Many, if not most, of the entries in these matrices are 0.

10
00:00:36,917 --> 00:00:42,415
So we prefer to represent only the non-zeros in this matrix, which gives us 2 advantages.

11
00:00:42,415 --> 00:00:45,919
One, less storage since we don't have to represent a bunch of zeros,

12
00:00:45,919 --> 00:00:51,837
and two, less computation, since we're not doing a bunch of multiplications and additions of zeros.

13
00:00:51,837 --> 00:00:55,890
If you need a refresher on how to multiply a sparse matrix by a dense factor,

14
00:00:55,890 --> 00:00:58,195
please take a short trip back to Unit 4,

15
00:00:58,195 --> 00:01:03,697
because what we're going to talk about today is a strategy to build a more efficient SpMv.

16
00:01:03,697 --> 00:01:08,545
The broad question that we want to answer in thinking about how to make this problem efficiently is

17
00:01:08,545 --> 00:01:11,271
what is the role of a thread?

18
00:01:11,271 --> 00:01:14,001
Let's look at this sparse matrix to answer this question.

19
00:01:14,001 --> 00:01:18,551
Here we're using X's to represent non-zeros and blanks to represent zeros.

20
00:01:18,551 --> 00:01:21,048
We will consider 2 alternatives.

21
00:01:21,048 --> 00:01:25,819
The first is that we will assign 1 thread per row of the sparse matrix.

22
00:01:25,819 --> 00:01:31,059
Here a thread is responsible for computing 1 entry in the output vector,

23
00:01:31,059 --> 00:01:37,238
and we do this by taking the dot product of this row with this column.

24
00:01:37,238 --> 00:01:42,894
Second, we will assign 1 thread per element in the sparse matrix; for instance, this element here.

25
00:01:42,894 --> 00:01:45,875
Here a thread is responsible for doing 1 multiplication;

26
00:01:45,875 --> 00:01:50,151
in this case, times its corresponding element in the input vector--

27
00:01:50,151 --> 00:01:54,254
what we call a partial product, and then cooperating with other other threads--

28
00:01:54,254 --> 00:01:57,784
this thread, for instance, in summing up the partial products.

29
00:01:57,784 --> 00:01:59,887
So which is better?

30
00:01:59,887 --> 00:02:02,976
The answer is, it depends, and we'll look at how to do both of them.
