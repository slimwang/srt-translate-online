1
00:00:00,000 --> 00:00:03,693
So let's now visualize this
light-field from this perspective.

2
00:00:03,693 --> 00:00:07,058
I have my uv plane and my st plane.

3
00:00:07,058 --> 00:00:12,061
Any point on the uv plane is now
looking at this whole st plane.

4
00:00:12,061 --> 00:00:16,727
So any ray of light arriving at
one point on the uv plane is

5
00:00:16,727 --> 00:00:20,219
arriving from all
points on the st plane.

6
00:00:20,219 --> 00:00:21,723
What is the st plane?

7
00:00:21,723 --> 00:00:24,423
Well, here is a simple
way of looking at it.

8
00:00:24,423 --> 00:00:28,519
The uv plane has variety
of arrays of images.

9
00:00:28,519 --> 00:00:31,879
Now you can imagine that at this point,
I've basically taken a bunch of

10
00:00:31,879 --> 00:00:34,121
different images at
different orientations.

11
00:00:34,121 --> 00:00:36,841
So, again, if I could basically
create a pinhole here,

12
00:00:36,841 --> 00:00:38,723
this would see the scene differently.

13
00:00:38,723 --> 00:00:40,178
So what I would have this and

14
00:00:40,178 --> 00:00:44,371
the st would basically just be one
single image, from different viewpoints.

15
00:00:44,371 --> 00:00:47,208
Now by just reversing
this versus that again,

16
00:00:47,208 --> 00:00:51,001
imagine this to be in the st plane and
this to be in the uv plane.

17
00:00:51,001 --> 00:00:53,595
I actually now have
an array of images and

18
00:00:53,595 --> 00:00:56,736
I can traverse them one by
one by looking at them.

19
00:00:56,736 --> 00:01:00,490
Of course, the interesting parts of
this is I can now of course, be looking

20
00:01:00,490 --> 00:01:04,196
another one and interpolation can be
used to generate in between images.

21
00:01:04,196 --> 00:01:05,668
What happens in the other case?

22
00:01:05,668 --> 00:01:10,373
Where now, I'm looking at the st
plane and extracting information,

23
00:01:10,373 --> 00:01:11,658
so on the uv plane.

24
00:01:11,658 --> 00:01:16,641
So rays arriving at one point in
the st plane, that were bound for

25
00:01:16,641 --> 00:01:18,773
all points on the uv plane.

26
00:01:18,773 --> 00:01:22,171
Again, the same light structure here,
but except this time around,

27
00:01:22,171 --> 00:01:23,670
we're not seeing the object,

28
00:01:23,670 --> 00:01:26,963
but we're actually seeing more
local details of the same objects.

29
00:01:26,963 --> 00:01:29,283
And of course,
this would actually give me a uv plane.

30
00:01:29,283 --> 00:01:33,889
So this shows me local details in the uv
plane, while sd plane was actually

31
00:01:33,889 --> 00:01:38,139
showing me in the previous case
a lot more detail of the object.

32
00:01:38,139 --> 00:01:41,883
So the best way to think about it is
imagine, we can create an array of

33
00:01:41,883 --> 00:01:45,824
cameras and I would put a bunch of
different cameras in a grid pattern and

34
00:01:45,824 --> 00:01:47,883
use that to take a bunch of pictures.

35
00:01:47,883 --> 00:01:51,843
And now, I would have a huge
amounts of pictures there.

36
00:01:51,843 --> 00:01:55,408
And what I can basically do is using
this kind of stuff, move from one view

37
00:01:55,408 --> 00:01:58,447
to the other, interpolate between
one of them and actually,

38
00:01:58,447 --> 00:02:02,200
that would actually create a light-field
rather than pixels themselves.
