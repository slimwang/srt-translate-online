1
00:00:00,260 --> 00:00:03,840
That ends the introduction
to discriminative methods.

2
00:00:03,840 --> 00:00:07,145
So we talked about that basically
the idea is that we're going to

3
00:00:07,145 --> 00:00:10,568
build a representation and then
somehow we have to train a classifier

4
00:00:10,568 --> 00:00:13,810
that's going to look at
the division of the boundary.

5
00:00:13,810 --> 00:00:17,120
The simplest method we showed
was nearest neighbor or KNN.

6
00:00:17,120 --> 00:00:23,315
Oh, I didn't say, would k of set of,
of say, mm, six be a good idea?

7
00:00:23,315 --> 00:00:23,924
>> No.

8
00:00:23,924 --> 00:00:24,777
>> No why not?

9
00:00:24,777 --> 00:00:27,255
because how does it work?

10
00:00:27,255 --> 00:00:30,700
You'd find nearest k and
you pick whichever one has the most.

11
00:00:31,990 --> 00:00:35,200
Why are there nine
Supreme Court justices?

12
00:00:35,200 --> 00:00:39,250
Because you don't want a decision to
come out four-four, if there were eight.

13
00:00:39,250 --> 00:00:40,750
So k typically is odd, so

14
00:00:40,750 --> 00:00:44,150
that you get, you always
a majority one way or the other.

15
00:00:44,150 --> 00:00:45,040
All right.

16
00:00:45,040 --> 00:00:49,430
In the next two lessons we'll talk about
some much more sophisticated methods,

17
00:00:49,430 --> 00:00:52,270
and in particular,
their application to Computer Vision.
