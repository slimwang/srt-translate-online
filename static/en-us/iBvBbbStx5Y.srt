1
00:00:00,350 --> 00:00:02,040
>> So, we've got a whole bunch of trees we have

2
00:00:02,040 --> 00:00:04,100
to look at, Michael. And were going to have to come up with

3
00:00:04,100 --> 00:00:07,590
some clever way to look through them. And this get's us

4
00:00:07,590 --> 00:00:10,110
back, something that we've talked about before, which is the notion of

5
00:00:10,110 --> 00:00:16,370
bias. And in particular, the notion of inductive bias. Now, just

6
00:00:16,370 --> 00:00:18,875
as a quick refresher, I'm want to remind you that there is

7
00:00:18,875 --> 00:00:21,560
two kind of biases we worrying about when we think about algorithms

8
00:00:21,560 --> 00:00:25,660
that are searching through space. One is what's called a restriction bias.

9
00:00:27,040 --> 00:00:28,420
The other is called preference bias.

10
00:00:31,600 --> 00:00:34,430
So a restriction bias is nothing more than

11
00:00:34,430 --> 00:00:37,610
the hypothesis set that you actually care about. So

12
00:00:37,610 --> 00:00:39,190
in this case, with the decision trees, the

13
00:00:39,190 --> 00:00:43,146
hypothesis set is all possible decision trees. Okay? That

14
00:00:43,146 --> 00:00:46,701
means we're not considering, y equals 2x plus

15
00:00:46,701 --> 00:00:50,715
3. We're not considering quadratic equations. We're not considering

16
00:00:50,715 --> 00:00:54,050
non-boolean functions of a certain type. We're only considering

17
00:00:54,050 --> 00:00:56,420
decision trees, and all that they can represent. And

18
00:00:56,420 --> 00:00:59,130
nothing else. Okay? So that's already a restriction bias

19
00:00:59,130 --> 00:01:02,000
and it's important. Because, instead of looking at the infinite

20
00:01:02,000 --> 00:01:05,860
number uncountably infinite number of functions that are out there,

21
00:01:05,860 --> 00:01:08,120
that we might consider. We're only going to consider those

22
00:01:08,120 --> 00:01:10,920
that can be represented by a decision tree over

23
00:01:10,920 --> 00:01:13,440
in, you know, all the cases we've given so far

24
00:01:13,440 --> 00:01:17,080
discreet variable. But a preference bias is something that's just

25
00:01:17,080 --> 00:01:21,580
as important. And it tells us what source of hypotheses

26
00:01:21,580 --> 00:01:27,590
from this hypothesis set we prefer,

27
00:01:27,590 --> 00:01:32,924
and that is really at the heart of inductive bias. So Michael,

28
00:01:32,924 --> 00:01:38,044
given that, what would you say is the inductive

29
00:01:38,044 --> 00:01:42,960
bias of the ID3 algorithm? That is, given a whole

30
00:01:42,960 --> 00:01:48,590
bunch of decision trees, which decision trees would ID3 prefer,

31
00:01:48,590 --> 00:01:49,080
over others?

32
00:01:49,080 --> 00:01:54,500
>> So, it definitely tries, since it's, since it's making

33
00:01:54,500 --> 00:01:59,780
it's decisions top down. It's going to be more likely to produce a tree that has

34
00:01:59,780 --> 00:02:03,530
basically good splits near the top than a tree that has bad splits

35
00:02:03,530 --> 00:02:06,820
at the top. Even if the two trees can represent the same function.

36
00:02:06,820 --> 00:02:08,000
>> Good point.

37
00:02:10,199 --> 00:02:12,420
So good splits near the top.

38
00:02:15,580 --> 00:02:16,850
Alright. And you said something very important

39
00:02:16,850 --> 00:02:19,420
there Michael. Given two decision trees that

40
00:02:19,420 --> 00:02:23,620
are both correct. They both represent the,

41
00:02:23,620 --> 00:02:25,500
the function that we might care about.

42
00:02:25,500 --> 00:02:30,330
It would prefer the one that had the better split near the top. Okay,

43
00:02:30,330 --> 00:02:34,740
so any other preferences? Any other inductive bias on the, on the ID3 algorithm.

44
00:02:34,740 --> 00:02:38,090
>> It prefers ones that model the data

45
00:02:38,090 --> 00:02:40,680
better to ones that model the data worse.

46
00:02:40,680 --> 00:02:44,120
>> Right. So this is one that people often forget: it prefers

47
00:02:44,120 --> 00:02:49,420
correct ones to incorrect ones. So, given a tree that has very

48
00:02:49,420 --> 00:02:52,710
good splits at the top but produces the wrong answer. It will

49
00:02:52,710 --> 00:02:55,330
not take that one over one that doesn't have as good splits at

50
00:02:55,330 --> 00:02:57,820
the top, but does give you the correct answer. So that's really,

51
00:02:57,820 --> 00:03:00,100
those are really the two main things that are the inductive bias

52
00:03:00,100 --> 00:03:03,630
for ID3. Although, when you put those two together, in particular when

53
00:03:03,630 --> 00:03:05,730
you look at the first one, there's sort of a third one that

54
00:03:05,730 --> 00:03:09,460
comes out as well, which is ID3 algorithm tends to

55
00:03:09,460 --> 00:03:14,280
prefer shorter trees to longer trees. Now, that preference for shorter

56
00:03:14,280 --> 00:03:18,460
trees actually comes naturally from the fact that you're doing

57
00:03:18,460 --> 00:03:21,390
good splits at the top. Because you're going to take trees

58
00:03:21,390 --> 00:03:24,220
that actually separate the data well by labels, you're going to

59
00:03:24,220 --> 00:03:26,820
tend to come to the answer faster than you would if

60
00:03:26,820 --> 00:03:28,380
you didn't do that. So, if you go back to

61
00:03:28,380 --> 00:03:31,060
the example where we went before, where one of the attributes

62
00:03:31,060 --> 00:03:34,660
doesn't split the data at all, that is not something that ID3 would

63
00:03:34,660 --> 00:03:39,100
go for, and it would in fact create a longer and unnecessarily longer tree.

64
00:03:39,100 --> 00:03:42,440
So it tends to prefer shorter trees over longer trees. So long as

65
00:03:42,440 --> 00:03:45,350
they're correct and they give you good splits near the top of the tree.
