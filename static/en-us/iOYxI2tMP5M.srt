1
00:00:00,850 --> 00:00:02,798
All right, let's add a step now.

2
00:00:02,798 --> 00:00:05,900
I provided some fixed server log data.

3
00:00:05,900 --> 00:00:09,430
What we are doing here is counting the
number of hits to the main web page for

4
00:00:09,430 --> 00:00:11,450
each day in the logs.

5
00:00:11,450 --> 00:00:14,610
You can use the mapper or reducer
files I provided or write your own.

6
00:00:15,650 --> 00:00:21,420
Upload the extracted data, the mapper,
and reducer files to your S3 bucket.

7
00:00:21,420 --> 00:00:24,710
The mapper and reducer are written
in Python for Hadoop streaming.

8
00:00:24,710 --> 00:00:27,998
So, for the step 2 streaming program.

9
00:00:27,998 --> 00:00:30,940
So here is where you link to your
mapper and reducer programs.

10
00:00:30,940 --> 00:00:34,657
Click the folder icons to select
the files on your S3 bucket.

11
00:00:36,060 --> 00:00:40,573
And same thing for the input,
and find the output.

12
00:00:40,573 --> 00:00:43,470
And give this a name,
something like Hits.

13
00:00:43,470 --> 00:00:44,980
And run it, just hit Add.

14
00:00:46,730 --> 00:00:48,200
Down here you can see the step running.

15
00:00:49,520 --> 00:00:53,140
You can also view the logs to see
what's happening on the cluster and

16
00:00:53,140 --> 00:00:55,870
you can also see the jobs running
to make sure they're not failing.

17
00:00:55,870 --> 00:01:00,719
If they do fail you can look at the job
logs to help to bug your MapReduce code.

18
00:01:00,719 --> 00:01:02,607
All right, now that is done running,

19
00:01:02,607 --> 00:01:05,090
you should see the output
data on your S3 bucket.

20
00:01:06,260 --> 00:01:08,970
The process is similar for
high events spark jobs.

21
00:01:08,970 --> 00:01:11,700
You put your analysis code
input data on this three,

22
00:01:11,700 --> 00:01:13,190
then link to them when adding the step.

23
00:01:13,190 --> 00:01:15,330
And don't forget to
terminate the cluster.

24
00:01:15,330 --> 00:01:17,520
If you leave it running,
it can cost you quite a bit.
