1
00:00:00,210 --> 00:00:03,260
So if we look at the parallel operating system

2
00:00:03,260 --> 00:00:06,270
and page fault service the easy scenario for the

3
00:00:06,270 --> 00:00:08,480
parallel operating system is what I call as a

4
00:00:08,480 --> 00:00:12,550
multiprocess workload. And here what we're seeing is, yes you

5
00:00:12,550 --> 00:00:15,510
have threads executing on all the nodes of the

6
00:00:15,510 --> 00:00:19,280
multiprocessor, but these threads are completely independent of one

7
00:00:19,280 --> 00:00:21,790
another. Think of this as a separate process, this

8
00:00:21,790 --> 00:00:25,350
as an independent process. Maybe you have a web browser

9
00:00:25,350 --> 00:00:27,960
here, a word processor here, and so on. So they

10
00:00:27,960 --> 00:00:31,550
are completely independent processes. And if that is the case,

11
00:00:31,550 --> 00:00:34,150
if there's a page fault that has incurred on, on

12
00:00:34,150 --> 00:00:37,710
this node, simultaneously a page fault on another node, they can

13
00:00:37,710 --> 00:00:41,850
be handled completely independently. Why? Because the threads are independent.

14
00:00:41,850 --> 00:00:45,310
The page tables are distinct. And therefore, you don't have

15
00:00:45,310 --> 00:00:48,300
to serialize the page fault service, as I told you,

16
00:00:48,300 --> 00:00:50,890
the parallel operating system is going to have a page fault handler

17
00:00:50,890 --> 00:00:53,940
that's available in each one of these nodes. So the

18
00:00:53,940 --> 00:00:56,400
work can be done in parallel, so long as there is

19
00:00:56,400 --> 00:00:59,880
no data structures that are shared among these different units of

20
00:00:59,880 --> 00:01:02,470
work that the operating system has to do. And so long

21
00:01:02,470 --> 00:01:04,920
as page tables are distinct, which is the case in

22
00:01:04,920 --> 00:01:08,490
a multi-process workload, there is no stabilization. And life will be

23
00:01:08,490 --> 00:01:11,775
good. The hard scenario for a parallel operating system is a

24
00:01:11,775 --> 00:01:16,320
multi-threaded workload. Now what I mean by a multi-threaded workload is

25
00:01:16,320 --> 00:01:19,050
that you have a process that as multiple threads,

26
00:01:19,050 --> 00:01:24,085
so there is opportunity for exploiting the concurrency that's available

27
00:01:24,085 --> 00:01:27,400
in the multiprocessor by scheduling these threads on the

28
00:01:27,400 --> 00:01:30,660
different nodes of the multiprocessor. And to make it concrete,

29
00:01:30,660 --> 00:01:32,250
what I'm going to show you is two notes,

30
00:01:32,250 --> 00:01:34,940
N1 and N2, and let's assume that there are two

31
00:01:34,940 --> 00:01:38,340
cores available in each one of these nodes. In that

32
00:01:38,340 --> 00:01:41,380
case, what I can do is, the operating system may

33
00:01:41,380 --> 00:01:47,508
have chosen to put T1 and T3 on node N1, and T2 and T4 on node

34
00:01:47,508 --> 00:01:50,490
N2. So you have a multithreaded workload now

35
00:01:50,490 --> 00:01:55,680
executing on different nodes of the multiprocessor. And there

36
00:01:55,680 --> 00:01:57,810
is hardware concurrency, because there are multiple cores

37
00:01:57,810 --> 00:02:01,380
available. So in principle, all of these threads

38
00:02:01,380 --> 00:02:06,400
can work in parallel, and if they incur a page fault it is in incumbent on the

39
00:02:06,400 --> 00:02:09,520
operating system to see how it can ensure

40
00:02:09,520 --> 00:02:11,830
that there is no serialization of the work that

41
00:02:11,830 --> 00:02:15,010
needs to be done to service the page faults.

42
00:02:15,010 --> 00:02:17,650
So if we want to naiively think about what the

43
00:02:17,650 --> 00:02:21,770
parallel operating system would be doing in this scenario,

44
00:02:21,770 --> 00:02:24,080
the address space is shared and therefore, the page

45
00:02:24,080 --> 00:02:27,810
table is shared. And since the threads are executing

46
00:02:27,810 --> 00:02:31,820
on different processors, The TLBs will have shared entries,

47
00:02:31,820 --> 00:02:34,030
in the process of TLBs, because they are accessing

48
00:02:34,030 --> 00:02:38,350
the same address space. So that'll be the scenario. Now

49
00:02:38,350 --> 00:02:41,050
if you think about it, what we would want

50
00:02:41,050 --> 00:02:43,480
is to limit the amount of sharing in the operating

51
00:02:43,480 --> 00:02:46,620
system data structures when they are executing on different

52
00:02:46,620 --> 00:02:50,590
processors. In particular, for this particular mapping that I've shown

53
00:02:50,590 --> 00:02:54,100
you, that T1 and T3 are executing on N1 and

54
00:02:54,100 --> 00:02:56,860
T2 and T4 are executing on, on N2, what we

55
00:02:56,860 --> 00:03:01,260
would want is the operating system data structures, that they have to

56
00:03:01,260 --> 00:03:04,500
mess with, T1 and T3 have to mess with, should be distinct

57
00:03:04,500 --> 00:03:09,020
from the operating system data structures that T2 and T4 may have

58
00:03:09,020 --> 00:03:12,481
to mess with. And that will ensure that you can have scalability.
