1
00:00:00,330 --> 00:00:03,490
Imagine you're going on the Internet and reaching

2
00:00:03,490 --> 00:00:06,350
a Web portal, such as gmail, let's say,

3
00:00:06,350 --> 00:00:09,670
for accessing your email. In fact, while you're

4
00:00:09,670 --> 00:00:12,470
doing this, a million other clients are doing

5
00:00:12,470 --> 00:00:14,720
exactly the same thing, trying to reach the

6
00:00:14,720 --> 00:00:18,360
web portal through the IP network. The service

7
00:00:18,360 --> 00:00:22,160
that you're trying to reach may be architected

8
00:00:22,160 --> 00:00:26,576
to direct your particular request to a specific site.

9
00:00:26,576 --> 00:00:31,908
And the architecture within that site may look like this, a whole bunch of

10
00:00:31,908 --> 00:00:34,918
servers, maybe on the order of thousands

11
00:00:34,918 --> 00:00:38,444
or even 10,000, within a cold dark room,

12
00:00:38,444 --> 00:00:41,970
interconnected to one another through perhaps a

13
00:00:41,970 --> 00:00:46,109
high bandwidth communication backplane. And also all of

14
00:00:46,109 --> 00:00:48,625
the servers are connected to data stores

15
00:00:48,625 --> 00:00:51,605
for processing requests that may be coming in.

16
00:00:51,605 --> 00:00:56,341
And the servers may optionally use a backplane that allows them to talk to one

17
00:00:56,341 --> 00:01:02,970
another for servicing any particular request. Any of the servers may be able to

18
00:01:02,970 --> 00:01:06,750
handle an incoming client request. Now in

19
00:01:06,750 --> 00:01:09,830
the generic picture that I'm showing you here,

20
00:01:09,830 --> 00:01:12,500
the load manager that is sitting in

21
00:01:12,500 --> 00:01:16,920
between these servers, and the IP network redirects

22
00:01:16,920 --> 00:01:19,080
an incoming client's request to one the

23
00:01:19,080 --> 00:01:23,010
servers. The chosen server may than process the

24
00:01:23,010 --> 00:01:25,980
query and answer the client. The role of

25
00:01:25,980 --> 00:01:29,670
the load manager is to balance the client

26
00:01:29,670 --> 00:01:33,550
traffic among all the servers. Basically, the load

27
00:01:33,550 --> 00:01:35,570
manager has to make sure that no particular

28
00:01:35,570 --> 00:01:38,480
server is overloaded. One of the characteristics of

29
00:01:38,480 --> 00:01:42,540
most of the giant scale services is that

30
00:01:42,540 --> 00:01:45,010
the these client requests that are coming in are

31
00:01:45,010 --> 00:01:48,250
all independent of one another. Sometimes, this also called

32
00:01:48,250 --> 00:01:52,010
embarrassingly parallel, meaning that all of these client requests

33
00:01:52,010 --> 00:01:54,800
can be handled in parallel. So long as it is

34
00:01:54,800 --> 00:01:58,070
enough server capacity to meet all the incoming requests.

35
00:01:58,070 --> 00:02:00,570
So the rule of the load manager is to

36
00:02:00,570 --> 00:02:03,760
balance the client traffic and redirect them to the

37
00:02:03,760 --> 00:02:07,820
server so that no particular server is overloaded and all

38
00:02:07,820 --> 00:02:10,520
of the servers get equally utilized in

39
00:02:10,520 --> 00:02:14,620
servicing incoming requests. The other responsibility of

40
00:02:14,620 --> 00:02:17,200
the load manager is to hide partial

41
00:02:17,200 --> 00:02:20,210
failures. Because when we're talking about the

42
00:02:20,210 --> 00:02:23,530
scale of giant scale services, and the

43
00:02:23,530 --> 00:02:26,830
kind of computational power that resides in

44
00:02:26,830 --> 00:02:29,190
the data center for servicing these giant

45
00:02:29,190 --> 00:02:32,750
scale services, they're humongous, they're 10,000 nodes.

46
00:02:32,750 --> 00:02:39,050
And when you have so many nodes, compute nodes and data nodes and so on, it's

47
00:02:39,050 --> 00:02:41,820
not a question of if something will fail,

48
00:02:41,820 --> 00:02:43,910
but is a question of when something is going

49
00:02:43,910 --> 00:02:49,730
to fail. So the load manager has to make sure that it is observing the state

50
00:02:49,730 --> 00:02:54,160
of the servers and insuring that the incoming

51
00:02:54,160 --> 00:02:57,780
client requests are shielded from any such failures that

52
00:02:57,780 --> 00:03:01,220
may happen internally, within a particular site.
