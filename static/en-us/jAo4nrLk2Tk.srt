1
00:00:00,000 --> 00:00:01,660
This drives home an important point.

2
00:00:01,660 --> 00:00:03,889
You need to be aware of branch divergence.

3
00:00:03,889 --> 00:00:07,455
It's one of the fundamental things about GPU architectures

4
00:00:07,455 --> 00:00:11,263
or any massively parallel architecture that uses a SIMD approach.

5
00:00:11,263 --> 00:00:14,931
But don't freak out just because your code has an if statement or for loop.

6
00:00:14,931 --> 00:00:19,726
Reason it out, profile the code, figure out whether this is a real problem worth optimizing.

7
00:00:19,726 --> 00:00:22,813
There's no real recipe for reducing branch divergence.

8
00:00:22,813 --> 00:00:26,981
What to do depends on the algorithm, and sometimes the right answer is an entirely new algorithm.

9
00:00:26,981 --> 00:00:29,840
There are a couple of general principles, though.

10
00:00:29,840 --> 00:00:31,410
Try to avoid branchy code.

11
00:00:31,410 --> 00:00:33,645
If you have a lot of if or switch statements in your code,

12
00:00:33,645 --> 00:00:37,191
consider whether or not adjacent threads are likely to take different branches

13
00:00:37,191 --> 00:00:40,028
and if so, try to restructure.

14
00:00:40,028 --> 00:00:43,862
The second general principle is to beware large imbalance in thread workloads.

15
00:00:43,862 --> 00:00:48,392
Sometimes 1 thread can take much, much longer than the average thread to complete a task,

16
00:00:48,392 --> 00:00:51,432
and when this happens, the long-running thread can hold up the rest of the warp

17
00:00:51,432 --> 00:00:53,241
or even the rest of the thread block.

18
00:00:53,241 --> 00:00:55,699
We saw this in the example earlier where some threads performed a loop

19
00:00:55,699 --> 00:00:58,171
much more often than other threads in the same warp.

20
00:00:58,171 --> 00:01:01,048
So look carefully at loops and recursive calls

21
00:01:01,048 --> 00:01:04,473
to decide if this kind of work imbalance might be hurting you.

22
00:01:04,473 --> 00:01:07,376
In the next unit you'll see another example, breadth-first search in a graph,

23
00:01:07,376 --> 00:01:10,552
where each thread is assigned a work item of random size.

24
00:01:10,552 --> 00:01:12,677
And if 1 thread gets unlucky and picks up a work item

25
00:01:12,677 --> 00:01:15,183
that takes a thousand times longer than the rest of the threads,

26
00:01:15,183 --> 00:01:18,921
you're wasting a lot of computational horsepower as all the rest of those threads sit idle

27
00:01:18,921 --> 00:01:21,127
waiting for that one long-running thread to finish.

28
00:01:21,127 --> 00:01:23,994
So there's a lot of simple strategies that could mitigate this imbalance.

29
00:01:23,994 --> 00:01:25,956
You can restructure your code entirely.

30
00:01:25,956 --> 00:01:29,331
Or you might, for example, coarsely sort the work items before size.

31
00:01:29,331 --> 00:01:32,912
And John will dive deeper into parallel strategies for breadth-first search

32
00:01:32,912 --> 00:01:35,361
and a lot of other interesting problems in the next unit.
