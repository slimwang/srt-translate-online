1
00:00:00,190 --> 00:00:02,570
So, in summary about generative models,

2
00:00:02,570 --> 00:00:04,939
there are some good things about it,
right?

3
00:00:04,939 --> 00:00:08,650
It's pure probability, right, very,
very clean probabilistic thing.

4
00:00:08,650 --> 00:00:12,180
In fact, it's been known for a very
long time, which should give you a hint

5
00:00:12,180 --> 00:00:15,160
that it's not going to be
the most powerful method used,

6
00:00:15,160 --> 00:00:20,480
because it comes from a time when
computers were nonexistent or scarce.

7
00:00:20,480 --> 00:00:24,010
And we had to use a lot of
mathematical reasoning,

8
00:00:24,010 --> 00:00:25,940
pure mathematics in
order to do the work.

9
00:00:25,940 --> 00:00:29,610
But it is, it says here,
firm probabilistic grounding.

10
00:00:29,610 --> 00:00:32,259
It allows you to use your priors, so

11
00:00:32,259 --> 00:00:35,770
if you have priors,
maybe your context gives you a prior.

12
00:00:35,770 --> 00:00:37,230
I know I'm in a bedroom, so

13
00:00:37,230 --> 00:00:41,830
the probability of seeing a lamp is
a lot higher than if I'm in a garage,

14
00:00:41,830 --> 00:00:45,380
okay, that kind of thing, so
I can have a prior built into it.

15
00:00:45,380 --> 00:00:48,080
One that's in yellow here, actually,
there's two of them that are yellow

16
00:00:48,080 --> 00:00:50,050
because I think they
actually are important.

17
00:00:50,050 --> 00:00:52,940
One is that because you're doing this
parametric modeling of continuous

18
00:00:52,940 --> 00:00:56,420
functions, you can actually get away
with using a pretty small amount of data

19
00:00:56,420 --> 00:00:59,740
compared to other methods we're going to
look at later, the discriminate methods.

20
00:00:59,740 --> 00:01:02,200
So that's one, and
the second good thing about it is

21
00:01:03,300 --> 00:01:07,780
your models are about each category,
and just about the category.

22
00:01:07,780 --> 00:01:10,570
So when you tell me
about some new category,

23
00:01:10,570 --> 00:01:13,180
I just have to learn a model for
that category.

24
00:01:13,180 --> 00:01:16,150
I don't have to play with this model.

25
00:01:16,150 --> 00:01:20,010
Whereas if I'm trying to learn how to
distinguish between an a and a b and

26
00:01:20,010 --> 00:01:22,790
an a and a c, now you tell me about d's?

27
00:01:22,790 --> 00:01:25,610
I have to worry about
a's versus d's as well.

28
00:01:25,610 --> 00:01:28,230
So when you add in new categories,
and you're trying to discriminate,

29
00:01:28,230 --> 00:01:31,090
you often have to worry about
a lot of different categories.

30
00:01:31,090 --> 00:01:35,320
In the generative model, I just
build a model for that new category.

31
00:01:35,320 --> 00:01:38,210
There are some other advantages of
generative models that we haven't

32
00:01:38,210 --> 00:01:38,790
talked about.

33
00:01:38,790 --> 00:01:41,620
You can use unlabeled
data in interesting ways.

34
00:01:41,620 --> 00:01:43,880
You can also use it to generate data,
right?

35
00:01:43,880 --> 00:01:46,768
So if I say something is
distributed over a Gaussian,

36
00:01:46,768 --> 00:01:50,956
I can actually make more examples, and
there are times when that's useful.

37
00:01:50,956 --> 00:01:52,740
So that would be all the good news.

38
00:01:52,740 --> 00:01:55,920
What always follows the good
news is the not so good news.

39
00:01:55,920 --> 00:01:58,650
So, where did you get those priors?

40
00:01:58,650 --> 00:02:02,610
Okay, so again, do you go to Greece,
do you go to the Sears Prior Store?

41
00:02:02,610 --> 00:02:04,930
The sensitivity to priors
really matters, and

42
00:02:04,930 --> 00:02:07,370
the priors can be affected
by things like context.

43
00:02:07,370 --> 00:02:09,800
There's this other thing
that's also kind of annoying.

44
00:02:09,800 --> 00:02:13,370
I'm modeling skin and I've got not-skin.

45
00:02:13,370 --> 00:02:15,528
Well, skin you might say
is a plausible model.

46
00:02:15,528 --> 00:02:16,660
Not-skin?

47
00:02:16,660 --> 00:02:20,790
Modeling not-skin is kind of
a weird thing, all right?

48
00:02:20,790 --> 00:02:25,470
What I really want to do is model
sort of the, the boundary between all

49
00:02:25,470 --> 00:02:28,410
the stuff that's skin and
everything else that's out there.

50
00:02:28,410 --> 00:02:31,240
And by the way, a lot of the stuff
that's out there doesn't look anything

51
00:02:31,240 --> 00:02:34,240
like skin at all, so that stuff is easy.

52
00:02:34,240 --> 00:02:37,680
What I really need to worry about are
the things that are kind of like skin,

53
00:02:37,680 --> 00:02:38,580
but aren't.

54
00:02:38,580 --> 00:02:40,080
In fact, that's the next example.

55
00:02:40,080 --> 00:02:45,490
It says, the example hard cases aren't
special, and they should be, right?

56
00:02:45,490 --> 00:02:50,100
So I'm trying to recognize you know,
rattlesnakes in the brush.

57
00:02:50,100 --> 00:02:53,180
I don't have to worry about
what Maseratis look like.

58
00:02:53,180 --> 00:02:57,000
I do have to worry about the difference
between what rattlesnakes look like, and

59
00:02:57,000 --> 00:03:02,040
maybe different kinds of grass, because
there's a tight similarity between them.

60
00:03:02,040 --> 00:03:06,000
So this idea that modeling the hard
cases is really what's important.

61
00:03:06,000 --> 00:03:09,590
And in fact, I think that's what's most
important about discriminative learning.

62
00:03:09,590 --> 00:03:12,220
And then the last thing is, if you have
lots, and lots, and lots, and lots, and

63
00:03:12,220 --> 00:03:14,170
lots of data, it doesn't really help.

64
00:03:14,170 --> 00:03:15,600
If I'm modeling my world as a,

65
00:03:15,600 --> 00:03:20,030
sort of a single distribution,
once I have enough data, doesn't really,

66
00:03:20,030 --> 00:03:22,950
you know, I can fit some nice
mixture of Gaussians, I'm done.

67
00:03:22,950 --> 00:03:25,420
It's not helping me comparing
against other elements.

68
00:03:25,420 --> 00:03:29,230
So, it's not really
leveraging having large data.

69
00:03:29,230 --> 00:03:31,380
So those are the downsides
of generative models.
