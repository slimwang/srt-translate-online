1
00:00:00,260 --> 00:00:04,059
The other important parameter for an SVM is the C parameter.

2
00:00:04,059 --> 00:00:05,490
So what does C do?

3
00:00:05,490 --> 00:00:09,070
It controls the tradeoff between a smooth decision boundary and

4
00:00:09,070 --> 00:00:11,930
one that classifies all the training points correctly.

5
00:00:11,930 --> 00:00:14,410
So let's suppose our data looks like this.

6
00:00:14,410 --> 00:00:17,100
And just like we saw with gamma, there's a number of different,

7
00:00:17,100 --> 00:00:20,730
completely valid decision boundaries that you can draw in here.

8
00:00:20,730 --> 00:00:22,930
You could draw something that might be very straight, but

9
00:00:22,930 --> 00:00:26,210
it comes at the cost of a few points being misclassified.

10
00:00:26,210 --> 00:00:29,940
You could also draw in something that's considerably more wiggly, but

11
00:00:29,940 --> 00:00:33,980
where you get potentially all of the training points correct.

12
00:00:33,980 --> 00:00:36,580
Of course, the tradeoff of having something that's very intricate,

13
00:00:36,580 --> 00:00:37,660
very complicated like this.

14
00:00:37,660 --> 00:00:40,920
is that chances are it's not going to generalize quite as

15
00:00:40,920 --> 00:00:42,200
well to your test set.

16
00:00:42,200 --> 00:00:43,610
So something that's a little straighter,

17
00:00:43,610 --> 00:00:47,470
a little bit more straightforward may be actually the better choice once you

18
00:00:47,470 --> 00:00:50,140
start looking at the accuracy on your test set.

19
00:00:50,140 --> 00:00:51,670
So here's a quiz for you.

20
00:00:51,670 --> 00:00:55,360
It's a little bit tricky because you'll have to go to the sklearn documentation

21
00:00:55,360 --> 00:00:58,020
or potentially to play around with some code on your own to come up

22
00:00:58,020 --> 00:00:59,110
with the answer.

23
00:00:59,110 --> 00:01:01,590
And the question is let's say you have a large value of C.

24
00:01:01,590 --> 00:01:05,390
Does that mean you're going to get a smooth boundary or

25
00:01:05,390 --> 00:01:07,980
that you'll get more training points correct?

26
00:01:07,980 --> 00:01:09,410
There's going to be a tradeoff.

27
00:01:09,410 --> 00:01:12,820
Again to answer this quiz you're going to want to go to Google or

28
00:01:12,820 --> 00:01:15,480
potentially to the sklearn documentation.

29
00:01:15,480 --> 00:01:17,150
For those of you who are more adventurous or

30
00:01:17,150 --> 00:01:19,910
who like to go directly to the code to figure these things out,

31
00:01:19,910 --> 00:01:23,860
you can certainly play around with some code that will help you visualize this.

32
00:01:23,860 --> 00:01:26,610
One way you can do that is you can go back to the previous lesson,

33
00:01:26,610 --> 00:01:30,390
the naive Bayes lesson where you were drawing some decision boundaries that you

34
00:01:30,390 --> 00:01:34,140
could actually visualize in the Udacity interpreter.

35
00:01:34,140 --> 00:01:35,880
And instead of running those with naive Bayes,

36
00:01:35,880 --> 00:01:37,770
of course you can just run them with an SVM and

37
00:01:37,770 --> 00:01:41,470
play around with different values of C and use that to answer the question.

38
00:01:41,470 --> 00:01:44,630
If you do that, just a pro tip, use the rbf kernel, because this is

39
00:01:44,630 --> 00:01:48,600
where you'll actually see a big difference based on the value of C that you use.
