1
00:00:00,330 --> 00:00:03,460
At the end of the previous video we ended at the following iteration

2
00:00:03,460 --> 00:00:05,260
with the following paths forward.

3
00:00:05,260 --> 00:00:06,870
We started with a vague question.

4
00:00:06,870 --> 00:00:09,780
How popular were the different brands of candy?

5
00:00:09,780 --> 00:00:13,160
And we considered the two possible metrics, interselection time and

6
00:00:13,160 --> 00:00:16,190
total number of selections for quantifying this question.

7
00:00:16,190 --> 00:00:20,040
We ended up choosing as an initial guess interselection time.

8
00:00:20,040 --> 00:00:22,730
Now that we have a metric interselection time that we

9
00:00:22,730 --> 00:00:25,940
feel captures what we're interested in, we must use it

10
00:00:25,940 --> 00:00:30,060
to cast the above question as a problem of a statistical inference.

11
00:00:30,060 --> 00:00:31,970
So there are many options for doing so.

12
00:00:31,970 --> 00:00:36,310
One is point estimation, in which we explicitly try to create a estimator for

13
00:00:36,310 --> 00:00:38,570
our quantity interselection time.

14
00:00:38,570 --> 00:00:41,890
Another is confidence sets, in which we try to create an interval,

15
00:00:41,890 --> 00:00:46,620
which traps the true value of inter selection time with some confidence level.

16
00:00:46,620 --> 00:00:51,750
Classification, in which we choose various descriptive classes which may

17
00:00:51,750 --> 00:00:53,020
not be ordered.

18
00:00:53,020 --> 00:00:56,900
And try to classify interselection time into one of those classes.

19
00:00:56,900 --> 00:01:01,510
So for example in contrast with point estimation in which we explicitly try to

20
00:01:01,510 --> 00:01:05,710
come up with an estimator for the actual value of interselection time.

21
00:01:05,710 --> 00:01:10,000
In classification we may choose just broad categories like short or

22
00:01:10,000 --> 00:01:14,810
long and try to match the actual quantity to one of those classes.

23
00:01:14,810 --> 00:01:19,400
Hypothesis testing in which we for example, might try to determine if

24
00:01:19,400 --> 00:01:23,790
two different collections of inter selection time values came from two different

25
00:01:23,790 --> 00:01:28,750
probability distributions and how much confidence we have in that being true.

26
00:01:28,750 --> 00:01:32,840
Or lastly, parameter estimation in which we try to do things like.

27
00:01:32,840 --> 00:01:35,240
Find the parameter of a Poisson distribution,

28
00:01:35,240 --> 00:01:39,530
or find the bandwidth value on a kernel density estimation.

29
00:01:39,530 --> 00:01:42,640
Which we'll talk a lot more about, in a later lesson.

30
00:01:42,640 --> 00:01:46,600
Depending on the outcome of later phases, we may return to the question phase,

31
00:01:46,600 --> 00:01:50,860
to recast the same problem as a different statistical inference problem.

32
00:01:50,860 --> 00:01:53,640
For example, we may find the regression estimator we create has

33
00:01:53,640 --> 00:01:56,320
a very high variance, thus poor performance but

34
00:01:56,320 --> 00:02:00,140
can be recast as a classifier with a very high accuracy.

35
00:02:00,140 --> 00:02:02,140
Let's state this problem more formally.

36
00:02:02,140 --> 00:02:05,750
Our goal is to build a regression estimator, r.

37
00:02:05,750 --> 00:02:08,940
R will tell us its estimate for an interselection time for

38
00:02:08,940 --> 00:02:11,140
a candy, c, at any given turn.

39
00:02:11,140 --> 00:02:13,750
Our data points are just the candy selections and

40
00:02:13,750 --> 00:02:15,278
the order in which they were selected.

41
00:02:15,278 --> 00:02:18,290
With the inter-selection time written beside them.

42
00:02:18,290 --> 00:02:22,330
In other words, given the list of candy selections, and

43
00:02:22,330 --> 00:02:26,190
the number of turns since each candy had last been chosen.

44
00:02:26,190 --> 00:02:30,930
We are going to build an estimator, R, that will tell us at a given turn for

45
00:02:30,930 --> 00:02:34,960
a given candy how long it has been since it was last selected.

46
00:02:34,960 --> 00:02:38,020
Let's consider our next possible paths for analysis.

47
00:02:38,020 --> 00:02:41,270
At this stage really our only options are to proceed with

48
00:02:41,270 --> 00:02:42,370
the regression estimator.

49
00:02:43,400 --> 00:02:47,260
Which means identifying features or revisiting an earlier stop.

50
00:02:47,260 --> 00:02:50,010
In the next video we'll proceed with feature selection.
