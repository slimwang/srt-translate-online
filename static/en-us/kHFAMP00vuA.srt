1
00:00:00,380 --> 00:00:01,480
Alright, talk me through it.

2
00:00:01,480 --> 00:00:06,280
>> Okay, so I'm going to say that I think I know the answers for this

3
00:00:06,280 --> 00:00:08,109
one. And let's start with the first one.

4
00:00:08,109 --> 00:00:10,810
So R1 equals minus R2, which you'll notice

5
00:00:10,810 --> 00:00:14,350
they're equal and opposite. And in fact if you add them up, that is you sum

6
00:00:14,350 --> 00:00:16,129
them you end up with zero. So I'm

7
00:00:16,129 --> 00:00:18,050
going to say that's a zero sum stochastic game.

8
00:00:18,050 --> 00:00:20,130
>> Nice.

9
00:00:20,130 --> 00:00:22,690
>> For two, basically you're saying that for all intends

10
00:00:22,690 --> 00:00:25,450
and purposes, there's only one agent. Which just makes it

11
00:00:25,450 --> 00:00:27,050
a regular Markov decision process.

12
00:00:27,050 --> 00:00:29,100
>> Yeah. So isn't that interesting? That

13
00:00:30,190 --> 00:00:33,480
just by the other player irrelevant, then

14
00:00:33,480 --> 00:00:36,820
that's what an MDP is. It's like a game where the other players are irrelevant.

15
00:00:36,820 --> 00:00:40,020
>> Yeah, which, both of my children are like that.

16
00:00:40,020 --> 00:00:42,650
But okay, I think that's pretty cool. And in fact, I'd

17
00:00:42,650 --> 00:00:45,111
be right in saying that R2 doesn't have to equal

18
00:00:45,111 --> 00:00:47,450
to zero. As long as it just equals to some constant.

19
00:00:47,450 --> 00:00:50,500
>> Yeah, that's, I mean, constant. Actually, depending on

20
00:00:50,500 --> 00:00:52,570
how you think about it, it could be, we could just ignore

21
00:00:52,570 --> 00:00:56,240
the whole R2 thing and just say that. As far as the

22
00:00:56,240 --> 00:00:59,750
first player is concerned, since the second player really has no impact

23
00:00:59,750 --> 00:01:02,970
on anything. It doesn't matter. But the reason I put that in

24
00:01:02,970 --> 00:01:05,750
is I got kind of scared that like. I feel like if I

25
00:01:05,750 --> 00:01:09,410
lived my life and knew that my actions effected the state and

26
00:01:09,410 --> 00:01:13,050
my rewards, but they were also effecting the rewards of somebody who

27
00:01:13,050 --> 00:01:15,930
didn't matter. Like I feel like that would actually still have an influence

28
00:01:15,930 --> 00:01:18,910
on me. Sure, but then the way you get around that is

29
00:01:18,910 --> 00:01:22,167
you would say, well, your R1 is actually equal to your R2.

30
00:01:22,167 --> 00:01:22,475
>> Oh.

31
00:01:22,475 --> 00:01:23,194
>> [CROSSTALK] It would somehow [UNKNOWN].

32
00:01:23,194 --> 00:01:28,010
>> So, so if I had gone like that, wouldn't

33
00:01:28,010 --> 00:01:29,940
that be the case then that we're saying? Oh yeah,

34
00:01:29,940 --> 00:01:33,050
I see. That the second player is irrelevant, but the

35
00:01:33,050 --> 00:01:35,020
reward, but the first player may be relevant to both.

36
00:01:35,020 --> 00:01:35,740
>> Right.

37
00:01:35,740 --> 00:01:37,980
>> Yeah, okay, yeah I like that a little bit better. Yeah,

38
00:01:37,980 --> 00:01:41,140
I mean, once again, it all boils down to changing the rewards. Okay,

39
00:01:41,140 --> 00:01:43,430
and so given A and B, I know the answer to

40
00:01:43,430 --> 00:01:46,780
three must be C, unless you're tricking me, and it could be

41
00:01:46,780 --> 00:01:48,230
A or B again. And which I suppose you could have

42
00:01:48,230 --> 00:01:50,900
done, you didn't say they were mutually exclusive. So let me actually

43
00:01:50,900 --> 00:01:52,980
argue why it would be C? Well there is only one

44
00:01:52,980 --> 00:01:56,070
state and since you're in a stochastic game and you're going to

45
00:01:56,070 --> 00:02:00,500
be continually doing this. It means that you're basically doing the same

46
00:02:00,500 --> 00:02:02,870
game over and over and over again, so it's a repeated game.

47
00:02:02,870 --> 00:02:06,130
>> Yeah, yeah, yeah so in particular the actions impact the rewards,

48
00:02:06,130 --> 00:02:07,580
but they're not going to impact the transitions

49
00:02:07,580 --> 00:02:09,030
because you're always just going to back to

50
00:02:09,030 --> 00:02:11,250
where you were. The discount factor plays the

51
00:02:11,250 --> 00:02:12,978
role of, of decided when the game's going

52
00:02:12,978 --> 00:02:15,335
to end, stochastically. And, so yeah, it's exactly

53
00:02:15,335 --> 00:02:16,679
a repeated game, this is the one I

54
00:02:16,679 --> 00:02:18,839
feel most comfortable about because this really does

55
00:02:18,839 --> 00:02:20,989
recover that same model we've been talking about.

56
00:02:20,989 --> 00:02:21,880
>> I like it.

57
00:02:21,880 --> 00:02:24,510
>> Cool! Now, given that we actually are now

58
00:02:24,510 --> 00:02:26,450
in a model that generalizes MDPs, it would be

59
00:02:26,450 --> 00:02:28,970
nice if we can generalize some of the things

60
00:02:28,970 --> 00:02:31,250
that we did with MDPs, like Q learning and

61
00:02:31,250 --> 00:02:33,760
value iteration to this, this more general setting.

62
00:02:33,760 --> 00:02:35,050
So, that's what we're going to try next.

63
00:02:35,050 --> 00:02:35,640
>> Cool.
