1
00:00:00,130 --> 00:00:04,040
The final type of optimization for
reducing the miss rate that we will look

2
00:00:04,040 --> 00:00:10,360
at is a so called loop interchange which
is one of the compiler optimizations

3
00:00:10,360 --> 00:00:14,570
that can be done to transform the code
into code that has better locality.

4
00:00:14,570 --> 00:00:20,630
So suppose that we are initializing a
matrix like this by having an outer loop

5
00:00:20,630 --> 00:00:26,350
and an inner loop and then we initialize
the element and then loop like this.

6
00:00:26,350 --> 00:00:29,590
The layout of this matrix in memory

7
00:00:29,590 --> 00:00:33,500
if it's a C array is such
that it begins with a[0][0].

8
00:00:33,500 --> 00:00:37,880
The next element in memory
will be a[0][1], and so on.

9
00:00:39,150 --> 00:00:43,800
Eventually we have the last
element of this row.

10
00:00:43,800 --> 00:00:48,910
And only now we will have a[1][0] and
so on.

11
00:00:48,910 --> 00:00:53,820
So now let's look at how this
loop accesses these elements.

12
00:00:53,820 --> 00:00:56,170
i and j are both 0 at first.

13
00:00:56,170 --> 00:00:58,120
So we will access this element.

14
00:00:58,120 --> 00:01:00,740
Next, j will be incremented, so

15
00:01:00,740 --> 00:01:05,489
we will access this element, and
then this element, and so on.

16
00:01:05,489 --> 00:01:10,090
We will access all of the rows of
the matrix before we come back, and

17
00:01:10,090 --> 00:01:13,290
start accessing the second
element in each row.

18
00:01:13,290 --> 00:01:17,310
So the problem is, when this is
accessed, we fetch an entire cache

19
00:01:17,310 --> 00:01:21,650
block worth of stuff into the cache
just to use this one element.

20
00:01:21,650 --> 00:01:25,240
Then we're going to fetch a block
here to use this one element.

21
00:01:25,240 --> 00:01:28,080
And by the time we reach
the end of the matrix and

22
00:01:28,080 --> 00:01:32,200
look back here, we might have
run out of space in the cache.

23
00:01:32,200 --> 00:01:36,490
And the block that we would now use
has been kicked out of the cache.

24
00:01:36,490 --> 00:01:39,710
So we fetch it again,
use this one element, and so on.

25
00:01:39,710 --> 00:01:42,140
So we have one miss per access here.

26
00:01:42,140 --> 00:01:46,960
So a good compiler will detect
that the order of these loops

27
00:01:46,960 --> 00:01:51,250
doesn't match the layout in memory and
it's going to perform what is called

28
00:01:51,250 --> 00:01:56,080
a loop interchange which amounts
to simply sloping the two loops.

29
00:01:56,080 --> 00:02:02,430
So now the inner loop is the one that
moves to the next element in memory.

30
00:02:02,430 --> 00:02:06,320
So once we fetch a block from memory
we end up using the whole block.

31
00:02:06,320 --> 00:02:08,687
Only then we move to the next block and
so on.

32
00:02:08,687 --> 00:02:10,979
Once we are done with the row,
we move on to the next next row,

33
00:02:10,979 --> 00:02:14,830
so now we are nicely sequentially
accessing this matrix.

34
00:02:14,830 --> 00:02:18,894
Not only does it improve locality
because now we end up accessing

35
00:02:18,894 --> 00:02:23,334
the entire cache block at the time,
but also it makes the access nicely

36
00:02:23,334 --> 00:02:27,115
sequential so one of the prefetchers
can do a good job on it.

37
00:02:27,115 --> 00:02:30,919
So this works really well, it
dramatically improves the hit rate that

38
00:02:30,919 --> 00:02:33,582
we're getting, but
it is not always possible.

39
00:02:33,582 --> 00:02:37,690
You cannot just take any two nested
loops and transform form them this way.

40
00:02:37,690 --> 00:02:41,100
The compiler has to
prove that this code and

41
00:02:41,100 --> 00:02:44,830
this code are equivalent, which it
does by proving that there are no

42
00:02:44,830 --> 00:02:47,680
dependencies between
iterations of these loops.
