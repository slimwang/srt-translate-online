1
00:00:00,025 --> 00:00:07,070
[UNKNOWN] Also has effect on the latency that uses [UNKNOWN] as well as the loss

2
00:00:07,070 --> 00:00:10,904
rate. Here we've shown how [UNKNOWN] latency

3
00:00:10,904 --> 00:00:14,520
effect for two different users. The latency is

4
00:00:14,520 --> 00:00:20,110
shown in terms of round trip time in milliseconds and the loss rate are shown

5
00:00:20,110 --> 00:00:26,290
on the right side of the Y axis. Latencies are also shown on a log scale.

6
00:00:26,290 --> 00:00:29,740
In this particular experiment, we start sending traffic here

7
00:00:29,740 --> 00:00:33,560
and we stop sending traffic here, in both cases.

8
00:00:33,560 --> 00:00:36,810
We can see that, even though power boost allows

9
00:00:36,810 --> 00:00:40,000
you to just send at a higher traffic rate,

10
00:00:40,000 --> 00:00:44,030
actually users may experience high latency and loss. Over

11
00:00:44,030 --> 00:00:47,120
the duration that they're sending at a higher rate.

12
00:00:47,120 --> 00:00:49,460
The reason for this is that the access link

13
00:00:49,460 --> 00:00:52,460
may not be able to support the higher rate.

14
00:00:52,460 --> 00:00:57,080
So if a sender can only send at r sustained for an extended period of time but

15
00:00:57,080 --> 00:00:59,740
is allowed to burst at a rate r

16
00:00:59,740 --> 00:01:03,400
for some shorter period of time, Then buffers may

17
00:01:03,400 --> 00:01:06,480
fill up and the resulting buffers may introduce

18
00:01:06,480 --> 00:01:10,350
additional delays in the network since packets are being

19
00:01:10,350 --> 00:01:14,290
buffered up rather than dropped. TCP senders can continue

20
00:01:14,290 --> 00:01:17,450
to send at higher rates, such as little r,

21
00:01:17,450 --> 00:01:21,880
without seeing any packet loss even though the access link may not be able to

22
00:01:21,880 --> 00:01:24,940
send at that higher rate. As a result,

23
00:01:24,940 --> 00:01:28,200
packets buffer up and users see higher latency

24
00:01:28,200 --> 00:01:30,035
over the course of the power boost

25
00:01:30,035 --> 00:01:34,070
[UNKNOWN]. To solve this problem, you might imagine

26
00:01:34,070 --> 00:01:38,030
instead that a sender might shape it's rate

27
00:01:38,030 --> 00:01:42,370
never to exceed the sustained rate, Big R.

28
00:01:42,370 --> 00:01:47,780
If it did this, then it could avoid seeing these latency effects.

29
00:01:47,780 --> 00:01:52,760
So, search and senders, who are more interested in keeping latency under

30
00:01:52,760 --> 00:01:57,810
control, then they are in-sending at births devoims, may wish

31
00:01:57,810 --> 00:02:02,610
to run a traffic shaper in front of a power

32
00:02:02,610 --> 00:02:07,550
boost enabled link. So shaping traffic to a rate of

33
00:02:07,550 --> 00:02:13,040
less than this sustained rate r can prevent this buffering. More details

34
00:02:13,040 --> 00:02:16,940
about power boost and the experiments that we've run to keep latency under

35
00:02:16,940 --> 00:02:23,320
control in its presence are available in a paper we wrote called Broadband

36
00:02:23,320 --> 00:02:29,279
Internet Performance, A view from the Gateway. Which appeared in Sigcomm 2011.
