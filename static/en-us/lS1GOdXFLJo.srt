1
00:00:00,230 --> 00:00:05,500
Recall our illustration that shows how the operating system swaps between P1 and

2
00:00:05,500 --> 00:00:09,000
P2 for them to share the CPU.

3
00:00:09,000 --> 00:00:14,160
In this illustration, the process control blocks for P1 and P2 reside in memory.

4
00:00:14,160 --> 00:00:18,510
And the values of the CPU will change depending on which process is

5
00:00:18,510 --> 00:00:20,370
currently executing.

6
00:00:20,370 --> 00:00:25,570
Now we can more formally state that a context switch is the mechanism used by

7
00:00:25,570 --> 00:00:30,550
the operating system to switch the execution from the context of

8
00:00:30,550 --> 00:00:34,320
one process to the context of another process.

9
00:00:34,320 --> 00:00:39,270
In our diagram, this is happening both when the operating system switches from

10
00:00:39,270 --> 00:00:42,850
the execution of P1 to the execution of P2.

11
00:00:42,850 --> 00:00:46,980
And then again a second time when the OS switches from the execution of P2

12
00:00:46,980 --> 00:00:49,110
back to the execution of P1.

13
00:00:49,110 --> 00:00:53,260
This operation can be expensive, and that's for two reasons.

14
00:00:53,260 --> 00:00:56,970
First, there are direct costs, and this is basically the number of

15
00:00:56,970 --> 00:01:00,880
cycles that have to be executed to simply load and

16
00:01:00,880 --> 00:01:05,830
store all the values of the process control blocks to and from memory.

17
00:01:05,830 --> 00:01:08,188
There are also indirect costs.

18
00:01:08,188 --> 00:01:11,330
When process 1 is running on the CPU,

19
00:01:11,330 --> 00:01:16,050
a lot of its data is going to be stored into the processor cache.

20
00:01:16,050 --> 00:01:20,750
As long as P1 is executing, a lot of its data is likely going to

21
00:01:20,750 --> 00:01:25,240
be present somewhere in the processor cache hierarchy.

22
00:01:25,240 --> 00:01:30,630
In the picture, we show a single processor cache, but in practice, modern CPUs

23
00:01:30,630 --> 00:01:37,000
have a hierarchy of caches from L1 to L2, down to the last level cache.

24
00:01:37,000 --> 00:01:42,330
And each one is larger, but potentially slower than the previous one.

25
00:01:42,330 --> 00:01:46,930
More importantly, however, accessing this cache is much,

26
00:01:46,930 --> 00:01:50,050
much faster than accessing the memory.

27
00:01:50,050 --> 00:01:54,207
For instance, the accesses along the processor cache hierarchy will be on

28
00:01:54,207 --> 00:01:58,850
the order of cycles, whereas the accesses to memory will be on

29
00:01:58,850 --> 00:02:01,370
the order of hundreds of cycles, for instance.

30
00:02:01,370 --> 00:02:05,130
When the data we need is present in the cache, in this case,

31
00:02:05,130 --> 00:02:09,770
that's P1's data, we call this that the cache is hot.

32
00:02:09,770 --> 00:02:15,530
But when we context switch to P2, some, or even all, of the data belonging

33
00:02:15,530 --> 00:02:22,210
to P1 in the cache will be replaced to make room for the data needed by P2.

34
00:02:22,210 --> 00:02:28,960
So, the next time P1 is scheduled to execute, its data will not be in the cache.

35
00:02:28,960 --> 00:02:32,550
It will have to spend much more time to read data from memory,

36
00:02:32,550 --> 00:02:35,380
so it will incur cache misses.

37
00:02:35,380 --> 00:02:38,260
We call this the cold cache.

38
00:02:38,260 --> 00:02:42,080
Running with a cold cache is clearly bad because every single

39
00:02:42,080 --> 00:02:46,280
data access requires much longer latency to memory and

40
00:02:46,280 --> 00:02:48,900
it slows down the execution of the process.

41
00:02:48,900 --> 00:02:52,720
As a result, we clearly want to limit the frequency with

42
00:02:52,720 --> 00:02:54,410
which content switching is done.
