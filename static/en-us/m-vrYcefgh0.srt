1
00:00:00,370 --> 00:00:04,910
So we said that the SMT processor
is not that much more expensive

2
00:00:04,910 --> 00:00:09,940
than a single threaded processor that
has the same issue within everything.

3
00:00:09,940 --> 00:00:13,040
Let's see what the hardware changes for
SMT look like so

4
00:00:13,040 --> 00:00:17,160
that we can convince ourselves that it's
indeed not that much more expensive.

5
00:00:17,160 --> 00:00:22,560
In a normal processor, we would have
a program counter that we use to access

6
00:00:22,560 --> 00:00:25,430
the instruction cache to
fetch our instructions.

7
00:00:25,430 --> 00:00:27,430
Because this is a super
scalar processor,

8
00:00:27,430 --> 00:00:32,720
we are fetching more than just one
instruction with this program counter.

9
00:00:32,720 --> 00:00:36,370
Then we get into a decoder that
is capable of decoding multiple

10
00:00:36,370 --> 00:00:38,150
instructions per cycle.

11
00:00:38,150 --> 00:00:43,810
Then a renamer that gets to read and
update the RAT for this thread.

12
00:00:43,810 --> 00:00:48,790
And once the instructions is renamed it
gets to the reservation stations, and

13
00:00:48,790 --> 00:00:55,220
then from here we send the instructions
for execution, and in our ROB,

14
00:00:55,220 --> 00:00:59,770
we need to track what's the next
committed instruction from this thread.

15
00:00:59,770 --> 00:01:04,700
So if we want to add the ability
to simultaneously multi-thread

16
00:01:04,700 --> 00:01:06,810
another thread here.

17
00:01:06,810 --> 00:01:10,600
We definitely need a separate PC here.

18
00:01:10,600 --> 00:01:15,010
And we need a logic that will
fetch from these two PCs.

19
00:01:15,010 --> 00:01:19,670
We could do this every cycle we fetch,
from both of the PCs,

20
00:01:19,670 --> 00:01:21,960
half of the instructions.

21
00:01:21,960 --> 00:01:25,831
Or we can actually do one cycle fetch
everything you can from this PC,

22
00:01:25,831 --> 00:01:28,720
one cycle fetch everything
you can from this PC.

23
00:01:28,720 --> 00:01:33,920
So SMT usually refers to
what's happening here,

24
00:01:33,920 --> 00:01:38,170
but here we could actually be doing fine
grain multithreading as far as fetching

25
00:01:38,170 --> 00:01:39,470
is concerned.

26
00:01:39,470 --> 00:01:42,735
Most processors that do SMT
actually do it that way.

27
00:01:42,735 --> 00:01:47,950
Decoding is completely oblivious to
where the instructions came from.

28
00:01:47,950 --> 00:01:51,850
So we don't really need to change
anything about our decoding logic.

29
00:01:51,850 --> 00:01:56,610
The renamer, does the same thing
regardless of where the instruction came

30
00:01:56,610 --> 00:02:01,010
from, except that the RATs
accesses needs to be different.

31
00:02:01,010 --> 00:02:05,480
So now we have two RATs,
one for each thread.

32
00:02:05,480 --> 00:02:08,919
That we need to access depending
on what we're renaming.

33
00:02:08,919 --> 00:02:12,820
After renaming, instructions got
separate physical registers for

34
00:02:12,820 --> 00:02:13,870
each thread.

35
00:02:13,870 --> 00:02:18,590
So the reservation stations
are simply shared by the two threads.

36
00:02:18,590 --> 00:02:23,170
The execution units get to execute
the operations with the values

37
00:02:23,170 --> 00:02:27,330
they are given so they have no clue
where the instruction really came from.

38
00:02:27,330 --> 00:02:30,000
And then when we get to the ROB,

39
00:02:30,000 --> 00:02:34,230
we need to either have a separate ROB
with its own commit point in which case

40
00:02:34,230 --> 00:02:38,120
each of the threads gets to
commit each instruction in order.

41
00:02:38,120 --> 00:02:43,070
Or we actually put all the instructions
in interleaved order in the ROB,

42
00:02:43,070 --> 00:02:46,150
in which case we will not be
able to commit an instruction

43
00:02:46,150 --> 00:02:49,660
from one thread until all
the instructions from it and

44
00:02:49,660 --> 00:02:52,740
the other thread that
preceded have been committed.

45
00:02:52,740 --> 00:02:57,390
Because the ROB is a large In complex
piece of hardware, typically we don't do

46
00:02:57,390 --> 00:03:02,940
this and we actually suffer, here,
by just committing the threads together.

47
00:03:02,940 --> 00:03:08,240
But if we have sent the instructions, in
order, to the reservation stations and

48
00:03:08,240 --> 00:03:12,040
their ROB, then the order in
the ROB is still the correct order.

49
00:03:12,040 --> 00:03:16,430
It's just at sometimes we could have
committed a instruction from one thread,

50
00:03:16,430 --> 00:03:19,330
but we have to wait for the other
thread to also commit some instructions

51
00:03:19,330 --> 00:03:23,730
before that, so it's slightly less
optimal, but still works fine.

52
00:03:23,730 --> 00:03:26,170
The thing that happens at commit though,

53
00:03:26,170 --> 00:03:31,570
is that we deposit the results into
the architectural register file.

54
00:03:31,570 --> 00:03:36,100
And also when we send instructions for
execution, we send it along with

55
00:03:36,100 --> 00:03:41,610
the data, that comes from the ARF,
our threads do have different registers.

56
00:03:41,610 --> 00:03:45,110
Our zero here is not
the same as our zero here.

57
00:03:45,110 --> 00:03:50,390
So we need a separate ARF and a separate
path to each of the ARFs here and

58
00:03:50,390 --> 00:03:53,030
also the separate read ports here.

59
00:03:53,030 --> 00:03:55,890
So as you can see,
the complexity largely

60
00:03:55,890 --> 00:04:00,740
lies in having multiple pieces and being
able to fetch from either of them and

61
00:04:00,740 --> 00:04:04,030
in the logic that immediately
precedes the reservation stations.

62
00:04:04,030 --> 00:04:07,720
But the really complicated part of
the processor which is the reservation

63
00:04:07,720 --> 00:04:11,850
stations, the broadcast of results and
so on, stays the same.

64
00:04:11,850 --> 00:04:15,780
So this is why the cost is not
twice the cost of the processor.

65
00:04:15,780 --> 00:04:20,600
Most of the cost of the processor
is in the cache right here,

66
00:04:20,600 --> 00:04:25,670
the complex hardware here, the large
ROB where you can insert things and

67
00:04:25,670 --> 00:04:30,120
wait for them to finish and so on and
commit, and also the data cache.

68
00:04:30,120 --> 00:04:36,013
And what you're really adding is another
PC here, same size cache as before,

69
00:04:36,013 --> 00:04:40,680
another RAT, another ARF, but
keep the complex part alone.

70
00:04:40,680 --> 00:04:43,000
So that's why the cost is not very,
very high.
