1
00:00:00,160 --> 00:00:03,610
So now let's see what happens when we try to do multiple predictions

2
00:00:03,610 --> 00:00:08,760
simultaneously. Suppose we have the classical five stage pipeline with a fetch,

3
00:00:08,760 --> 00:00:13,240
decode, ALU, memory, and write register stages, and

4
00:00:13,240 --> 00:00:17,750
suppose that this is where our branches are resolved in the third stage.

5
00:00:17,750 --> 00:00:22,700
Suppose also that we have the following program. A branch that jumps to

6
00:00:22,700 --> 00:00:27,540
label A if registers R1 and R2 are not equal.

7
00:00:27,540 --> 00:00:32,820
Another branch in the program right after it that compares R1 and R3 and

8
00:00:32,820 --> 00:00:39,560
jumps to label B if they are not equal. Then we have some instruction A, B,

9
00:00:39,560 --> 00:00:45,780
C that are not branches. And then we have label A where we have instructions

10
00:00:45,780 --> 00:00:51,860
X and Y and we have then label B where we have instruction Z.

11
00:00:51,860 --> 00:00:57,680
Suppose that we are using a not taken predictor and that this branch.

12
00:00:57,680 --> 00:01:03,700
And also this branch, are taken, assuming that we start execution

13
00:01:03,700 --> 00:01:08,920
right here. The question for you is, how many cycles are wasted on

14
00:01:08,920 --> 00:01:13,140
mispredictions until we finally get to execute instruction Y,

15
00:01:13,140 --> 00:01:17,860
because what should be happening is that we jump after this branch here and

16
00:01:17,860 --> 00:01:23,380
execute x and y. What really happens is that, because of our not taken

17
00:01:23,380 --> 00:01:28,550
prediction, we go on and actually fetch this branch instead. So again, how

18
00:01:28,550 --> 00:01:33,590
many cycles are overall waited on mispredictions until we correctly get to Y?
