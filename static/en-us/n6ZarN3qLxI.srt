1
00:00:00,000 --> 00:00:02,385
We are ready to try to build various models.

2
00:00:02,385 --> 00:00:04,735
But before we get into the next steps,

3
00:00:04,735 --> 00:00:07,825
let's learn what it means to evaluate the model.

4
00:00:07,825 --> 00:00:11,502
As you must have noticed, we are constantly iterating to and

5
00:00:11,502 --> 00:00:16,540
fro from the validation phase and the questioning phase and the modeling phase.

6
00:00:16,540 --> 00:00:20,690
So what it is that we use to validate these models?

7
00:00:20,690 --> 00:00:25,170
We'll take a short digression from our example that we have been following

8
00:00:25,170 --> 00:00:29,910
to introduce some key concepts involved with the model validation techniques.

9
00:00:29,910 --> 00:00:34,809
We won't end up using all these techniques in our specific example, but

10
00:00:34,809 --> 00:00:39,869
this material is very important to clearly understand the concepts behind

11
00:00:39,869 --> 00:00:41,247
model validation.

12
00:00:41,247 --> 00:00:44,795
When we build models and train them,

13
00:00:44,795 --> 00:00:51,555
we need some way to measure how far out model is from the actual values.

14
00:00:51,555 --> 00:00:56,780
The loss function is just such a concept.

15
00:00:56,780 --> 00:01:03,790
It measures how far an estimated value of a quantity is from the true value.

16
00:01:03,790 --> 00:01:08,540
Let's take an example to see what the loss function is.

17
00:01:08,540 --> 00:01:10,990
Let's take the special case of parametric model.

18
00:01:10,990 --> 00:01:17,130
Let's say, the parameter is theta, which is the true value of a quantity.

19
00:01:17,130 --> 00:01:22,040
And then theta hat is an estimated value for the same quantity.

20
00:01:22,040 --> 00:01:27,660
Remember, theta hat is a function of the data that we collected.

21
00:01:27,660 --> 00:01:33,350
The idea is that we are fitting a parametric model to the data.

22
00:01:33,350 --> 00:01:37,500
And we always need a measure of how well we perform.

23
00:01:37,500 --> 00:01:41,360
We accomplish this by defining a loss function.

24
00:01:41,360 --> 00:01:46,310
It is up to you to choose how you define the loss function.

25
00:01:46,310 --> 00:01:50,860
The choice depends on the specific problem you're trying to solve.

26
00:01:50,860 --> 00:01:54,750
Here are some examples of loss functions you may encounter.

27
00:01:54,750 --> 00:01:59,300
I'm using the notation of theta and theta hat for a parametric model.

28
00:01:59,300 --> 00:02:02,110
One example is the squared error loss.

29
00:02:02,110 --> 00:02:04,490
In this case, you take the difference between theta and

30
00:02:04,490 --> 00:02:06,830
theta hat and square them.

31
00:02:06,830 --> 00:02:09,053
Another is the absolute error loss.

32
00:02:09,053 --> 00:02:13,500
In this case, you take the difference between theta and theta hat and

33
00:02:13,500 --> 00:02:16,116
the absolute value of that difference.

34
00:02:16,116 --> 00:02:22,770
An Lp Loss is essentially the Absolute Error Loss raised to the power p.

35
00:02:22,770 --> 00:02:26,670
Another very interesting quantity is the Kullback-Leibler Loss.

36
00:02:26,670 --> 00:02:28,970
It's a complicated formula and

37
00:02:28,970 --> 00:02:35,000
it's an information theoretic loss calculated for two different distributions.

38
00:02:35,000 --> 00:02:39,970
You will often encounter squared error loss in statistical learning.

39
00:02:39,970 --> 00:02:43,408
The square error loss is sensitive to outliers.

40
00:02:43,408 --> 00:02:47,896
For values of theta hat that are far from the values of theta,

41
00:02:47,896 --> 00:02:51,130
it contributes a large quantity to L.

42
00:02:51,130 --> 00:02:54,840
Also, notice this is always a positive quantity given it's

43
00:02:54,840 --> 00:02:56,900
a square of difference.

44
00:02:56,900 --> 00:03:00,910
The Absolute Error Loss is not so sensitive to outliers.

45
00:03:00,910 --> 00:03:06,370
However, it is not smooth at the value where theta hat is exactly

46
00:03:06,370 --> 00:03:10,770
equal to theta and thus, it's difficult to differentiate it at that point.

47
00:03:12,120 --> 00:03:15,770
We mentioned that the loss function depends on the selected data.

48
00:03:16,790 --> 00:03:21,080
Remember, theta-hat is a function of the data.

49
00:03:21,080 --> 00:03:27,290
We want a measurement that is averaged over many possible datasets.

50
00:03:27,290 --> 00:03:28,831
The risk is such a function.

51
00:03:28,831 --> 00:03:33,520
It is an average measure of the loss.

52
00:03:33,520 --> 00:03:39,580
And we calculate this by taking the expected value of the loss function.

53
00:03:39,580 --> 00:03:43,530
So as you see here, the risk is denoted by R which is

54
00:03:43,530 --> 00:03:48,600
the expected value of the loss function and it's calculated under the integral.
