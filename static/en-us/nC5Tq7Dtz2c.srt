1
00:00:00,360 --> 00:00:03,200
Continuous integration makes sure
that the software builds and

2
00:00:03,200 --> 00:00:06,000
runs successfully and
then you do the testing.

3
00:00:06,000 --> 00:00:09,290
There are still steps between this
point and the software release.

4
00:00:09,290 --> 00:00:12,040
Automating the release pipeline
down to the software release is

5
00:00:12,040 --> 00:00:13,850
called continuous delivery.

6
00:00:13,850 --> 00:00:16,010
But since some of QA
is a manual process,

7
00:00:16,010 --> 00:00:18,830
you cannot run the next step
completely automatically.

8
00:00:18,830 --> 00:00:22,630
You need a manual trigger in the
pipeline to deploy to the next stage,

9
00:00:22,630 --> 00:00:24,770
which is usually a staging server.

10
00:00:24,770 --> 00:00:27,800
For example,
testing against a real database.

11
00:00:27,800 --> 00:00:31,100
You can run more automated and
manual tests on staging.

12
00:00:31,100 --> 00:00:34,270
Once successful you can manually
trigger the deployment.

13
00:00:34,270 --> 00:00:37,790
It's important to note that a manual
trigger does not equal a manual build

14
00:00:37,790 --> 00:00:38,990
or deployment.

15
00:00:38,990 --> 00:00:40,710
Build and deployment is automatic,

16
00:00:40,710 --> 00:00:43,680
it's just the trigger that
starts the process is manual.

17
00:00:43,680 --> 00:00:46,680
There are integrations with
communication software that allows these

18
00:00:46,680 --> 00:00:49,780
manual triggers to be launched
in a more publicly visible and

19
00:00:49,780 --> 00:00:53,440
convenient way than logging into
a particular software program.

20
00:00:53,440 --> 00:00:55,120
For example, there are chatbots for

21
00:00:55,120 --> 00:00:58,960
popular team communication
platforms like Slack and HipChat

22
00:00:58,960 --> 00:01:03,410
that can be integrated with Jenkins,
CircleCI, and other CI solutions.

23
00:01:03,410 --> 00:01:07,260
These chat-bots can send build test
information to a public chat room.

24
00:01:07,260 --> 00:01:09,640
And react to commands
written into the chat.

25
00:01:09,640 --> 00:01:12,620
That makes it easy and
fast to coordinate within the team.

26
00:01:12,620 --> 00:01:17,120
If the CI build and test passes,
using chat, you can poll all involved

27
00:01:17,120 --> 00:01:19,900
developers with something like,
my change is good to go.

28
00:01:19,900 --> 00:01:23,030
And then issue that
command into the chat-bot.

29
00:01:23,030 --> 00:01:26,490
This makes for a fast and
transparent release process.

30
00:01:26,490 --> 00:01:30,120
We will not be setting up these chat
services, but see instructor notes for

31
00:01:30,120 --> 00:01:31,980
more information.

32
00:01:31,980 --> 00:01:35,090
>> If you have a service that handles
thousands of user transactions

33
00:01:35,090 --> 00:01:39,910
every second, over dozens or hundreds
of servers, you're not going to sit

34
00:01:39,910 --> 00:01:43,410
there and watch the log files
to see if it's working right.

35
00:01:43,410 --> 00:01:48,370
You, as a human being, literally cannot
read thousands of messages per second

36
00:01:48,370 --> 00:01:50,470
in hundreds of log files.

37
00:01:50,470 --> 00:01:53,020
You can't react the difference
between an acceptable and

38
00:01:53,020 --> 00:01:55,450
an unacceptable level of errors.

39
00:01:55,450 --> 00:01:59,460
Without monitoring systems to be your
eyes and ears you literally do not have

40
00:01:59,460 --> 00:02:03,890
the ability to notice or care about
something happening that fast.

41
00:02:03,890 --> 00:02:07,700
There are a few different ways that we
can gather data about our services.

42
00:02:07,700 --> 00:02:10,430
Not all of them apply to all services,
though.

43
00:02:10,430 --> 00:02:13,170
One is external probing,
or sending test queries.

44
00:02:13,170 --> 00:02:15,810
Some outside system will send
queries in to our system and

45
00:02:15,810 --> 00:02:18,408
see if it performs as expected and
record the results.

46
00:02:18,408 --> 00:02:22,380
Another is application-level metrics
that are exported by monitoring

47
00:02:22,380 --> 00:02:24,260
interfaces of our serving processes.

48
00:02:24,260 --> 00:02:27,030
This might include things like the
number of queries they're handling per

49
00:02:27,030 --> 00:02:29,330
second or what the latency is.

50
00:02:29,330 --> 00:02:32,010
Those can be pushed into
a monitoring system or

51
00:02:32,010 --> 00:02:34,230
pulled into it from the server.

52
00:02:34,230 --> 00:02:37,680
Another thing to monitor are stats that
are exported by our runtime environment,

53
00:02:37,680 --> 00:02:40,110
for instance,
the memory profile in a Java JVM.

54
00:02:40,110 --> 00:02:43,570
And then there's also information about
the computers that we're actually

55
00:02:43,570 --> 00:02:47,320
running on such as the load average or
the number of disc errors.

56
00:02:47,320 --> 00:02:50,590
You can actually very typically
discover that a disc is about to fail

57
00:02:50,590 --> 00:02:53,440
by monitoring the number
of errors it's having.

58
00:02:53,440 --> 00:02:57,750
Other sources of monitoring data can
include logs analysis, query profiling

59
00:02:57,750 --> 00:03:02,370
such as Google App engines app stats,
and external analytic services.

60
00:03:02,370 --> 00:03:06,800
There are also a number of data products
that a monitoring system can provide.

61
00:03:06,800 --> 00:03:08,880
The one everyone knows
about is alerting.

62
00:03:08,880 --> 00:03:11,560
Getting a page saying
the system is too slow.

63
00:03:11,560 --> 00:03:14,480
But your monitoring system can
also provide charts and graphs for

64
00:03:14,480 --> 00:03:16,220
performance analysis.

65
00:03:16,220 --> 00:03:20,200
Say things like this release is 10
percent faster than the last one.

66
00:03:20,200 --> 00:03:22,030
And also for capacity prediction.

67
00:03:22,030 --> 00:03:22,850
For instance,

68
00:03:22,850 --> 00:03:26,770
if it takes ten instances to support
1,000 transactions per second.

69
00:03:26,770 --> 00:03:29,970
Then if we scale to 2,000
transactions per second,

70
00:03:29,970 --> 00:03:32,710
we should expect to need
ten more instances.

71
00:03:32,710 --> 00:03:34,460
Also for growth measurement.

72
00:03:34,460 --> 00:03:36,350
You can plot a graph out of
your monitoring system and

73
00:03:36,350 --> 00:03:39,570
see that your service is doubling
traffic every three months.

74
00:03:39,570 --> 00:03:42,820
You can combine that with a capacity
prediction to get capacity needs

75
00:03:42,820 --> 00:03:43,420
forecasting.

76
00:03:43,420 --> 00:03:46,510
Tell you how many computers you're
going to need next quarter.

77
00:03:46,510 --> 00:03:47,650
And last but not least,

78
00:03:47,650 --> 00:03:51,490
your monitoring system can also provide
great metrics for debugging problems.

79
00:03:51,490 --> 00:03:55,480
For instance, suppose you're trying to
diagnose why your servers are crashing.

80
00:03:55,480 --> 00:03:59,090
If you notice from your monitoring
that each instance is using more and

81
00:03:59,090 --> 00:04:01,610
more memory proportional to
the number of user queries,

82
00:04:01,610 --> 00:04:03,710
that might indicate to look for
a memory leak.
