1
00:00:00,280 --> 00:00:02,750
Alright. So we talked through how it works when you've got

2
00:00:04,840 --> 00:00:07,689
you're trying to fit your data to a constant function,

3
00:00:07,689 --> 00:00:10,380
to a zero order polynomial. But let's, let's at least talk

4
00:00:10,380 --> 00:00:12,300
through how you do this in the more general case. This

5
00:00:12,300 --> 00:00:14,590
is, this is what I've been doing to, to fit various

6
00:00:14,590 --> 00:00:18,650
curves to the data at least implicitly. So, what we're

7
00:00:18,650 --> 00:00:20,720
really trying to do is we've got a set of data,

8
00:00:20,720 --> 00:00:25,320
x and y. Set n, n examples of x's and their

9
00:00:25,320 --> 00:00:30,110
corresponding y's. And what we're trying to find is these coefficients,

10
00:00:30,110 --> 00:00:35,870
C0, C1, C2, C3. Let's say if we're trying to do cubic regression

11
00:00:35,870 --> 00:00:40,720
where C0 gets added to C1 times x, which gets added to C2 times

12
00:00:40,720 --> 00:00:45,310
x squared. Which gets added to C3 times X cubed and we're trying to get

13
00:00:45,310 --> 00:00:48,420
that to look a lot like y. Now we're not

14
00:00:48,420 --> 00:00:50,730
going to get to exactly equal y but let's pretend for a

15
00:00:50,730 --> 00:00:53,210
moment that we could. We have a bunch of these

16
00:00:53,210 --> 00:00:55,630
examples and we want it to work for all of them.

17
00:00:55,630 --> 00:00:58,930
So we can arrange all of the, all these

18
00:00:58,930 --> 00:01:02,340
constraints, all these equations into matrix form. If you're familiar

19
00:01:02,340 --> 00:01:04,709
with linear algebra. So the way that we can

20
00:01:04,709 --> 00:01:08,410
write this is here are the, here are the coefficients

21
00:01:08,410 --> 00:01:11,220
that we're looking for, the C's, and here are

22
00:01:11,220 --> 00:01:13,210
what we're going to multiply them by. We're going to take

23
00:01:13,210 --> 00:01:17,360
the X one and look at the zeroth power, the first power,

24
00:01:17,360 --> 00:01:21,640
the second power, the third power. And that equation I'll

25
00:01:21,640 --> 00:01:24,370
use my hands cause that's I always, I always

26
00:01:24,370 --> 00:01:26,380
need to use my hands when I do matrix

27
00:01:26,380 --> 00:01:29,990
multiplication. So you're going to across here and down there

28
00:01:29,990 --> 00:01:33,220
to multiply these and add. And that needs to correspond

29
00:01:33,220 --> 00:01:37,730
to y1. And same thing this now the second

30
00:01:37,730 --> 00:01:41,790
row. Multiplied by these coefficients. Need to give us our

31
00:01:41,790 --> 00:01:44,530
y2 and so forth. Alright. So if we arrange

32
00:01:44,530 --> 00:01:46,730
all these x values into a matrix, and we'll call

33
00:01:46,730 --> 00:01:54,350
it, you know, x. And then we have these other guys. And we'll call this w, like

34
00:01:54,350 --> 00:01:58,450
the coefficents. Obviously w stands for coefficent. And we

35
00:01:58,450 --> 00:02:01,520
want that to sort of equal This vector of

36
00:02:01,520 --> 00:02:04,020
y's. And we basically just need to solve

37
00:02:04,020 --> 00:02:07,190
this equation for the w's. Now, we can't exactly

38
00:02:07,190 --> 00:02:09,570
solve it because it's not going to exactly equal, but

39
00:02:09,570 --> 00:02:11,820
we can solve it in a least squares sense.

40
00:02:11,820 --> 00:02:14,410
So let me just step through the steps for doing that.

41
00:02:14,410 --> 00:02:17,470
Alright, so let's, so here's how we're going to solve for w.

42
00:02:17,470 --> 00:02:20,500
So what we're going to do is premultiply by the transpose of

43
00:02:20,500 --> 00:02:24,500
x. Both sides. I mean really what we wanted to do at

44
00:02:24,500 --> 00:02:26,270
first is if we are solving for Y, we need to

45
00:02:26,270 --> 00:02:28,370
multiply by the inverse of X, but this isn't really going

46
00:02:28,370 --> 00:02:31,470
to be necessarily well behaved. But if we pre mulitplied by

47
00:02:31,470 --> 00:02:36,170
the X transpose then this thing is going to have a nice inverse.

48
00:02:37,290 --> 00:02:39,970
So now we can pre multiply by that inverse.

49
00:02:39,970 --> 00:02:42,300
All right. Now, conveniently because this has a nice

50
00:02:42,300 --> 00:02:46,470
inverse, the inverses cancel each other. [NOISE] We get

51
00:02:46,470 --> 00:02:49,080
that the weights we're looking for can be derived by

52
00:02:49,080 --> 00:02:53,670
taking the x matrix times its own transpose, inverting

53
00:02:53,670 --> 00:02:56,580
that, multiplying by x transpose and then multiplying it

54
00:02:56,580 --> 00:02:58,400
by the y. And that gives us exactly the

55
00:02:58,400 --> 00:03:03,480
coefficients that we need To have done our polynomial regression.

56
00:03:03,480 --> 00:03:07,170
And it just, it just so happens that we have some nice properties in terms

57
00:03:07,170 --> 00:03:11,330
of these x transpose x. Not only is it invertible, but it does the right

58
00:03:11,330 --> 00:03:15,660
thing in terms of minimizing the least squares. It does it as a projection. Now,

59
00:03:15,660 --> 00:03:17,770
we're not going to go through the process by

60
00:03:17,770 --> 00:03:19,320
by which we argue that this is true.

61
00:03:19,320 --> 00:03:21,540
>> Does it have something to do with calculus?

62
00:03:21,540 --> 00:03:25,630
>> It most likely has something to do with calculus. And we'll get

63
00:03:25,630 --> 00:03:28,490
back to calculus later. But in this particular case we can, we're just

64
00:03:28,490 --> 00:03:32,670
using projections and linear algebra. And most importantly the, the whole

65
00:03:32,670 --> 00:03:36,670
process is just we take the, the data we arrange it into

66
00:03:36,670 --> 00:03:39,190
this matrix with whatever sort of powers that we care about.

67
00:03:39,190 --> 00:03:42,550
And then we just compute this quantity and we're good to go.

68
00:03:42,550 --> 00:03:43,000
>> Okay.
