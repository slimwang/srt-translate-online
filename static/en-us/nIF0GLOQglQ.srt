1
00:00:00,000 --> 00:00:03,060
In this course, we tackled six different

2
00:00:03,060 --> 00:00:05,609
projects. We started by curing dataset

3
00:00:05,609 --> 00:00:07,350
and developing a predictive theory

4
00:00:07,350 --> 00:00:09,179
so that the neural networks would be

5
00:00:09,179 --> 00:00:11,099
able to identify correlation between the

6
00:00:11,099 --> 00:00:13,410
input and output data. We've been

7
00:00:13,410 --> 00:00:15,179
validated this theory us  ing some simple

8
00:00:15,179 --> 00:00:17,250
count based heuristics and found we were

9
00:00:17,250 --> 00:00:18,750
able to identify words with both

10
00:00:18,750 --> 00:00:20,789
positive and negative correlation to

11
00:00:20,789 --> 00:00:23,220
output data. However, when we train our

12
00:00:23,220 --> 00:00:25,470
first network on this data, it was only

13
00:00:25,470 --> 00:00:27,090
barely able to find correlation,

14
00:00:27,090 --> 00:00:30,539
struggling to cut through the noise. So

15
00:00:30,539 --> 00:00:32,488
what we did next we increase the amount

16
00:00:32,488 --> 00:00:33,930
of signal and decrease the amount of

17
00:00:33,930 --> 00:00:35,460
noise and found that each time we did

18
00:00:35,460 --> 00:00:37,110
this, our network was able to converge

19
00:00:37,110 --> 00:00:39,360
much much faster. Whereas our first

20
00:00:39,360 --> 00:00:41,430
network struggle to convert all, barely

21
00:00:41,430 --> 00:00:43,350
reaching accuracy of sixty percent, and

22
00:00:43,350 --> 00:00:44,730
only running it around a rate of a

23
00:00:44,730 --> 00:00:46,440
hundred reviews per second.

24
00:00:46,440 --> 00:00:49,350
Our final network was able to classify a

25
00:00:49,350 --> 00:00:51,090
tell accuracy level eighty-six percent,

26
00:00:51,090 --> 00:00:54,239
and went to knit properly was able to

27
00:00:54,239 --> 00:00:57,690
classify 7,000 views per second. Helping

28
00:00:57,690 --> 00:00:59,309
you find a piece these tools and

29
00:00:59,309 --> 00:01:00,629
techniques for framing a problem are

30
00:01:00,629 --> 00:01:02,309
incredibly general. Whenever you

31
00:01:02,309 --> 00:01:03,660
encounter a new dataset, you're going to

32
00:01:03,660 --> 00:01:04,830
need to come up with a new predictive

33
00:01:04,830 --> 00:01:07,110
theory, and then tune and tweet your

34
00:01:07,110 --> 00:01:09,119
model in your data set to make the

35
00:01:09,119 --> 00:01:11,010
correlation your data most obvious to

36
00:01:11,010 --> 00:01:12,360
the neural network, so they can protect

37
00:01:12,360 --> 00:01:15,090
both quickly and accurately. Hope you've

38
00:01:15,090 --> 00:01:16,080
enjoyed this tutorial, and

39
00:01:16,080 --> 00:01:17,729
hope you can continute to enjoy your Udacity

40
00:01:17,729 --> 00:01:24,200
course. Now let's go back to the classroom.

