1
00:00:00,000 --> 00:00:02,000
So you may have noticed a bit of redundancy

2
00:00:02,000 --> 00:00:05,000
in our handling of "quoted strings".

3
00:00:05,000 --> 00:00:09,000
We return the entire matched text,

4
00:00:09,000 --> 00:00:11,000
which includes these double quotes at the end.

5
00:00:11,000 --> 00:00:14,000
But, in some sense, they're not as much part of the meaning,

6
00:00:14,000 --> 00:00:18,000
as they are beginning and ending markers to tell us when the string starts.

7
00:00:18,000 --> 00:00:20,000
This is our default token value,

8
00:00:20,000 --> 00:00:24,000
but we might want to take a small pair of scissors to this string,

9
00:00:24,000 --> 00:00:28,000
and snip off the quotes at the beginning--and at the end.

10
00:00:28,000 --> 00:00:31,000
Here we have an example of a token definition

11
00:00:31,000 --> 00:00:34,000
that does just that.

12
00:00:34,000 --> 00:00:37,000
After matching the right kind of string,

13
00:00:37,000 --> 00:00:39,000
we take the token value--

14
00:00:39,000 --> 00:00:41,000
the entire thing--

15
00:00:41,000 --> 00:00:44,000
and we're going to use substring selection,

16
00:00:44,000 --> 00:00:46,000
starting at character 1--

17
00:00:46,000 --> 00:00:48,000
this is going to be character 1--

18
00:00:48,000 --> 00:00:50,000
and going up to, but not including,

19
00:00:50,000 --> 00:00:52,000
character negative 1.

20
00:00:52,000 --> 00:00:55,000
Now if you haven't seen this trick before in Python this might surprise you a bit,

21
00:00:55,000 --> 00:00:58,000
but you can count back from the end of the string,

22
00:00:58,000 --> 00:01:00,000
using negative numbers.

23
00:01:00,000 --> 00:01:04,000
So this is actually the negative first character.

24
00:01:04,000 --> 00:01:06,000
And remember that substring inclusion

25
00:01:06,000 --> 00:01:12,000
starts at 1 and goes up to, but not including, the negative 1.

26
00:01:12,000 --> 00:01:15,000
So this is going to get everything from the "q"

27
00:01:15,000 --> 00:01:17,000
over to the "s" in strings--

28
00:01:17,000 --> 00:01:20,000
or in other words, have exactly the effect that we wanted.

29
00:01:20,000 --> 00:01:22,000
Cute little trick, huh?

30
00:01:22,000 --> 00:01:25,000
So now I'm going to show you how to make

31
00:01:25,000 --> 00:01:27,000
a lexical analyzer--which, recall--

32
00:01:27,000 --> 00:01:31,000
is just a bunch of token definitions put together.

33
00:01:31,000 --> 00:01:33,000
I'm going to write it out in Python

34
00:01:33,000 --> 00:01:35,000
and we'll follow along.

35
00:01:35,000 --> 00:01:38,000
This top line--the import statement--is a lot like Import RE.

36
00:01:38,000 --> 00:01:43,000
It's telling Python where to find our lexical analyzer software

37
00:01:43,000 --> 00:01:46,000
or libraries that we're going to build upon.

38
00:01:46,000 --> 00:01:50,000
Just like regular expressions were called RE to save space,

39
00:01:50,000 --> 00:01:55,000
a lexical analyzer is just called "lex"--to save space.

40
00:01:55,000 --> 00:01:59,000
And now I'm going to give a list of all of the tokens that I care about.

41
00:01:59,000 --> 00:02:03,000
Here, I'm just going to be concerned with the 6 that we've previously spoken about:

42
00:02:03,000 --> 00:02:08,000
the Left Angle bracket; the Left Angle bracket, followed by a slash; the Right Angle bracket--

43
00:02:08,000 --> 00:02:11,000
these 3 make tags--

44
00:02:11,000 --> 00:02:15,000
an Equal sign, Strings that are surrounded by quotes,

45
00:02:15,000 --> 00:02:17,000
and every other word.

46
00:02:17,000 --> 00:02:19,000
I'm also going to use a little shortcut.

47
00:02:19,000 --> 00:02:22,000
Before, we used a Whitespace token,

48
00:02:22,000 --> 00:02:27,000
but if you like, you can write the word t_ignore instead

49
00:02:27,000 --> 00:02:32,000
and, implicitly, we'll ignore everything matching this regular expression.

50
00:02:32,000 --> 00:02:34,000
Here's my first token definition rule.

51
00:02:34,000 --> 00:02:36,000
It's for LANGLESLASH.

52
00:02:36,000 --> 00:02:39,000
Here's the regular expression that it matches.

53
00:02:39,000 --> 00:02:41,000
We return the text, unchanged.

54
00:02:41,000 --> 00:02:43,000
Here's another rule for the Left Angle bracket,

55
00:02:43,000 --> 00:02:47,000
the regular expression that it matches--and we return the text, unchanged.

56
00:02:47,000 --> 00:02:50,000
And you'll note that I have the LANGELSLASH rule ahead--

57
00:02:50,000 --> 00:02:52,000
before it--in the file.

58
00:02:52,000 --> 00:02:55,000
And that's because I want this one to win, on ties.

59
00:02:55,000 --> 00:02:58,000
If I see a Left Angle, followed by a slash,

60
00:02:58,000 --> 00:03:00,000
I want it to be the LANGLESLASH (token)--

61
00:03:00,000 --> 00:03:04,000
and not the Left Angle, followed by--say--a WORD(token).

62
00:03:04,000 --> 00:03:06,000
More on that in just a bit; I'll test that out and show it to you.

63
00:03:06,000 --> 00:03:09,000
Here's our rule for the Right Angle bracket.

64
00:03:09,000 --> 00:03:12,000
Here's our rule for the Equal sign token.

65
00:03:12,000 --> 00:03:14,000
Note that while these are long--

66
00:03:14,000 --> 00:03:17,000
they take up a bit of space--they're not actually particularly complicated.

67
00:03:17,000 --> 00:03:20,000
This has mostly been listing 5 regular expressions.

68
00:03:20,000 --> 00:03:22,000
Here's one now.

69
00:03:22,000 --> 00:03:25,000
This one is a little bit more complicated--here's are rule for STRING(token)s.

70
00:03:25,000 --> 00:03:28,000
Here's our regular expression that matches it.

71
00:03:28,000 --> 00:03:31,000
And there I am, dropping off--shaving off--

72
00:03:31,000 --> 00:03:33,000
the surrounding double quotes,

73
00:03:33,000 --> 00:03:35,000
just as you've seen before.

74
00:03:35,000 --> 00:03:39,000
Finally, there's our definition for the WORD(token).

75
00:03:39,000 --> 00:03:41,000
And now what we want to do is use

76
00:03:41,000 --> 00:03:44,000
these regular expressions, together--these token definitions--

77
00:03:44,000 --> 00:03:46,000
to break up a Web page.

78
00:03:46,000 --> 00:03:51,000
So here, I'll make a variable that holds the text of a hypothetical Web page.

79
00:03:51,000 --> 00:03:53,000
"This is my webpage!"

80
00:03:53,000 --> 00:03:57,000
Let's make it more exciting; Ho, ho--this is at least 10 percent more exciting!

81
00:03:57,000 --> 00:04:01,000
This function call tells our lexical analysis library

82
00:04:01,000 --> 00:04:05,000
that we want to use all of the token definitions above

83
00:04:05,000 --> 00:04:09,000
to make a lexical analyzer, and break up strings.

84
00:04:09,000 --> 00:04:12,000
This function call tells it which string to break up.

85
00:04:12,000 --> 00:04:14,000
I want to break up this Web page:

86
00:04:14,000 --> 00:04:16,000
"This is my webpage!"

87
00:04:16,000 --> 00:04:19,000
Now, recall that the output of a lexical analyzer

88
00:04:19,000 --> 00:04:21,000
is a list of tokens.

89
00:04:21,000 --> 00:04:24,000
I want to print out every element of that list.

90
00:04:24,000 --> 00:04:28,000
This call, .token, returns the next token that's available.

91
00:04:28,000 --> 00:04:31,000
If there are not more tokens,

92
00:04:31,000 --> 00:04:33,000
then we're going to break out of this loop.

93
00:04:33,000 --> 00:04:35,000
Otherwise, we print out the token.

94
00:04:35,000 --> 00:04:38,000
Well, let's go see what sort of output we get.

95
00:04:38,000 --> 00:04:41,000
The odds of me having written this, making no mistakes

96
00:04:41,000 --> 00:04:45,000
the first time, from scratch, are about zero.

97
00:04:45,000 --> 00:04:47,000
Let's go see what happens.

98
00:04:47,000 --> 00:04:51,000
Oh! I actually don't really believe it!

99
00:04:51,000 --> 00:04:54,000
We can see the output here at the bottom:

100
00:04:54,000 --> 00:04:57,000
LexToken (WORD, ' T ',' h ', ' i ', ' s '

101
00:04:57,000 --> 00:05:00,000
but it's not quite the output I was expecting.

102
00:05:00,000 --> 00:05:03,000
Oh, here's the mistake that I made--

103
00:05:03,000 --> 00:05:08,000
right now, I only have one character in t_WORD

104
00:05:08,000 --> 00:05:10,000
and if you look down here, instead of seeing

105
00:05:10,000 --> 00:05:12,000
the word, "This"--for "This is my webpage!"--

106
00:05:12,000 --> 00:05:15,000
I have each letter spelled out separately.

107
00:05:15,000 --> 00:05:17,000
Let me fix that.

108
00:05:17,000 --> 00:05:21,000
And now we get more of the output that we were expecting.

109
00:05:21,000 --> 00:05:24,000
Our first token is ' This ';

110
00:05:24,000 --> 00:05:26,000
our next token is a word, ' is '.

111
00:05:26,000 --> 00:05:28,000
Then we saw the Left Angle bracket,

112
00:05:28,000 --> 00:05:31,000
a word, ' b '--for bold,

113
00:05:31,000 --> 00:05:33,000
the Right Angle bracket; a word, ' my ';

114
00:05:33,000 --> 00:05:35,000
the LANGLESLASH,

115
00:05:35,000 --> 00:05:37,000
and then the word, ' webpage '.
