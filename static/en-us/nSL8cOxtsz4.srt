1
00:00:00,080 --> 00:00:03,320
A problem with adding more and more lights to a scene is the expense. Every

2
00:00:03,320 --> 00:00:06,660
light you add means yet another light that must be evaluated for the surface.

3
00:00:06,660 --> 00:00:10,160
One way around this is deferred rendering. Look at this demo. There are 50

4
00:00:10,160 --> 00:00:14,360
lights in the scene, and it runs just fine. Normally, you render a surface, and

5
00:00:14,360 --> 00:00:17,000
the fragment color for each pixel is stored, if it's the closest visible

6
00:00:17,000 --> 00:00:20,780
object. This is often called forward rendering. In a deferred rendering

7
00:00:20,780 --> 00:00:24,420
algorithm, you instead store data of some sort in each pixel. There are many

8
00:00:24,420 --> 00:00:28,052
variations, with names such as deferred shading versus deferred lighting. And

9
00:00:28,052 --> 00:00:31,479
here's just one. You could store the position, normal, and material color and

10
00:00:31,479 --> 00:00:35,590
shininess of the closest surface at each pixel. You also draw into the Z-buffer

11
00:00:35,590 --> 00:00:38,815
as usual. I'm not going to get into the details of how you store these various

12
00:00:38,815 --> 00:00:43,034
pieces of data, the point is that you can do so. It's just image data in

13
00:00:43,034 --> 00:00:46,424
another format. With deferred rendering every point light in the scene has an

14
00:00:46,424 --> 00:00:50,637
upper limit as to how far its light goes. This distance forms a sphere. So a

15
00:00:50,637 --> 00:00:54,688
sphere is drawn in a special way for each light. Another way of saying this is

16
00:00:54,688 --> 00:00:58,332
that each light can affect a volume in space. Whatever surfaces we find inside

17
00:00:58,332 --> 00:01:02,152
the sphere are affected by the light. Each light effects a fairly small number

18
00:01:02,152 --> 00:01:06,108
of pixels on the screen, namely whatever area the light sphere covers. This

19
00:01:06,108 --> 00:01:09,022
means that a huge number of lights with a limited radius can be evaluated in

20
00:01:09,022 --> 00:01:13,095
this way. By drawing a sphere, we're telling the GPU which pixels on the screen

21
00:01:13,095 --> 00:01:16,862
are covered by the light and so, should be evaluated. There are variants on

22
00:01:16,862 --> 00:01:20,420
what shapes you draw. A circle, a screen aligned rectangle. Whatever is drawn,

23
00:01:20,420 --> 00:01:23,420
the idea is that the geometry's purpose is to test only the limited set of

24
00:01:23,420 --> 00:01:27,690
pixels potentially in range of the light. This is as opposed to standard

25
00:01:27,690 --> 00:01:31,450
lights, where every light is evaluated for every surface at every pixel. I hope

26
00:01:31,450 --> 00:01:34,967
this give you a flavor of how deferred rendering works. I'm really jumping the

27
00:01:34,967 --> 00:01:38,034
gun, here. You need to know about shader programming to implement these. But

28
00:01:38,034 --> 00:01:41,058
the idea is to treat lights as objects that are rendered into the scene after

29
00:01:41,058 --> 00:01:44,944
all object surface values are recorded. There's some problem cases for

30
00:01:44,944 --> 00:01:47,804
preferred rendering techniques, such as transparency, but it offers a way to

31
00:01:47,804 --> 00:01:50,639
have an incredible number of lights in a scene.
