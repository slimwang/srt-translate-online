1
00:00:00,260 --> 00:00:02,719
Caching refers to storing the result of an operation so

2
00:00:02,719 --> 00:00:07,390
that future request return faster. Basically, if you do something once

3
00:00:07,390 --> 00:00:09,570
you know whether it's a database query or rendering some

4
00:00:09,570 --> 00:00:13,320
HTML or you know, anything that might be slow. You store

5
00:00:13,320 --> 00:00:15,070
the results so you don't have to do the computation

6
00:00:15,070 --> 00:00:18,430
a second time instead you can reference the previous result. So,

7
00:00:18,430 --> 00:00:21,450
when do we cache? We cache things when the underlying

8
00:00:21,450 --> 00:00:26,410
computation is slow, when the underlying computation will run multiple times.

9
00:00:26,410 --> 00:00:29,870
When the output of said computation is the same for

10
00:00:29,870 --> 00:00:32,009
a particular input, so that we know you know, we don't

11
00:00:32,009 --> 00:00:33,760
have to recompute it every time, because it's going to be the

12
00:00:33,760 --> 00:00:38,270
same every time; the output of this computation. And another good

13
00:00:38,270 --> 00:00:40,940
reason you know, for, for when we cache, when you are

14
00:00:40,940 --> 00:00:45,560
hosting provider charges for DB access, which applies to you right

15
00:00:45,560 --> 00:00:48,750
now. Google APP engine, gives you a fixed number of reads

16
00:00:48,750 --> 00:00:51,640
and writes to the data store in a particular day and

17
00:00:51,640 --> 00:00:53,970
if you go over that, you have to pay for it. Even

18
00:00:53,970 --> 00:00:57,050
if your app doesn't get a whole lot of traffic Caching request so

19
00:00:57,050 --> 00:00:59,860
they don't have to hit the database over and over is a

20
00:00:59,860 --> 00:01:03,040
fine way to save some money. And that will be an example we

21
00:01:03,040 --> 00:01:06,600
start with shortly. So, whenever you have a situation where you have

22
00:01:06,600 --> 00:01:07,880
the slow computation that you're running

23
00:01:07,880 --> 00:01:09,820
multiple times, with the same output over

24
00:01:09,820 --> 00:01:13,840
and over, you should cache it. You should store that result somewhere

25
00:01:13,840 --> 00:01:16,830
else. So that you don't have to run a computation over and over.

26
00:01:16,830 --> 00:01:19,570
So let's, let's talk about how that algorithm looks. Let's say

27
00:01:19,570 --> 00:01:22,830
we have a function called db_read(), and this reads from the database.

28
00:01:22,830 --> 00:01:25,970
And it's slow, you know, let's say it takes 100 ms to

29
00:01:25,970 --> 00:01:30,510
run this. This query which is slow for a database query but

30
00:01:30,510 --> 00:01:34,110
not unheard of. And, and you're serving thousands of requests, you know.

31
00:01:34,110 --> 00:01:36,570
If every request that comes in to, to your website has to

32
00:01:36,570 --> 00:01:39,400
hit db-read and that takes 100 milliseconds, that means you can only

33
00:01:39,400 --> 00:01:41,890
do ten requests a second or you start, you know, you start

34
00:01:41,890 --> 00:01:44,130
doing multiple requests at the same time and your database starts to get

35
00:01:44,130 --> 00:01:47,520
pummeled because it's trying to do this complicated query. All at the same time

36
00:01:47,520 --> 00:01:51,380
and, and this 100 milliseconds maybe turns in to 200 or 300 milliseconds,

37
00:01:51,380 --> 00:01:53,940
or 500 milliseconds, who knows, you know. When your database is under a load

38
00:01:53,940 --> 00:01:57,090
it starts to really get angry at you. So, if we wanted to

39
00:01:57,090 --> 00:01:59,320
cached this db read, let's talk about

40
00:01:59,320 --> 00:02:01,080
what this algorithm would look like. Prefer

41
00:02:01,080 --> 00:02:03,740
it a kind of write in, in sitor code here, we will have

42
00:02:03,740 --> 00:02:07,430
something that looks like this. If the request from making is in the cache,

43
00:02:07,430 --> 00:02:10,008
return the cache version of that request, and in this case,

44
00:02:10,008 --> 00:02:13,300
I'm pretending cache is, is like a dictionary and the request

45
00:02:13,300 --> 00:02:15,890
that we're making is the key into this dictionary. And that's

46
00:02:15,890 --> 00:02:18,740
generally the structure of the cache, the cache is basically a large,

47
00:02:18,740 --> 00:02:22,420
like a large hash table a large mapping of, of keys

48
00:02:22,420 --> 00:02:25,230
to values. Now you know all about hash tables a hash table

49
00:02:25,230 --> 00:02:27,680
works perfectly well for this. So, if a request is in

50
00:02:27,680 --> 00:02:33,450
the cache. Returned Cache value of that request, Else start the value

51
00:02:33,450 --> 00:02:35,980
of this DB Read in a variable, put that variable

52
00:02:35,980 --> 00:02:40,110
in the cache for future look ups. And then return that

53
00:02:40,110 --> 00:02:43,320
variable. So basically, instead of calling DB Read on every

54
00:02:43,320 --> 00:02:45,440
request, the first thing we do is check to see if

55
00:02:45,440 --> 00:02:48,120
that request is in our Cache And if it is,

56
00:02:48,120 --> 00:02:50,940
we return the cached value. This is called a cache hit.

57
00:02:50,940 --> 00:02:55,200
And only if this request isn't in our cache do we

58
00:02:55,200 --> 00:02:59,640
actually return our query. And this is called a cache miss.

59
00:02:59,640 --> 00:03:01,680
And what we do on a cache miss is we actually do

60
00:03:01,680 --> 00:03:06,420
operation, and store the result of the operation in our cache, and

61
00:03:06,420 --> 00:03:09,110
then return that result. So future requests will just bounce off the

62
00:03:09,110 --> 00:03:12,390
cache. Hash. Now if you're using a hash table, depending on the

63
00:03:12,390 --> 00:03:14,820
size of that hash table. We're going to probably do a lot better

64
00:03:14,820 --> 00:03:18,250
than 100 milliseconds, we're probably going to be talking about less than 1

65
00:03:18,250 --> 00:03:21,490
millisecond. Which would be you know, quite a big speed improvement. Now

66
00:03:21,490 --> 00:03:24,670
of course this hash table is huge and you're caching lots of things.

67
00:03:24,670 --> 00:03:28,220
You know, hash table have their own Performance characteristics that you'll

68
00:03:28,220 --> 00:03:30,430
have to take into account. But you know, you can get

69
00:03:30,430 --> 00:03:33,610
substantial improvements just by taking the slow pices of your code

70
00:03:33,610 --> 00:03:36,860
and wrapping this simple algorithm around it, which is the focus of

71
00:03:36,860 --> 00:03:41,030
our next quiz. What I'd like you to do is implement

72
00:03:41,030 --> 00:03:43,930
that caching algorithm here in Python. So, what I've given you

73
00:03:43,930 --> 00:03:47,620
is a function called Complex Computation. And this takes two numbers

74
00:03:47,620 --> 00:03:49,770
and it adds them up. But it's going to take half a second

75
00:03:49,770 --> 00:03:53,460
to do so. The time dot sleep function causes Python

76
00:03:53,460 --> 00:03:56,910
to just sleep or wait for however much time you want.

77
00:03:56,910 --> 00:03:58,680
In this case, I have it sleep for half a

78
00:03:58,680 --> 00:04:00,860
second. So, what I want you to do is use a

79
00:04:00,860 --> 00:04:03,830
dictionary as a cache. And it's defined right here as,

80
00:04:03,830 --> 00:04:07,860
called cache. I want you to make this function cache computation.

81
00:04:07,860 --> 00:04:11,460
Use this cache to store the results of calling complex

82
00:04:11,460 --> 00:04:14,960
computation on different inputs. So if we pass in the same

83
00:04:14,960 --> 00:04:20,589
inputs a and b twice, I want the second running of this function to use the

84
00:04:20,589 --> 00:04:22,720
cache. The first one, we'll do the actual

85
00:04:22,720 --> 00:04:26,440
computation. And we'll be grading this by running picking

86
00:04:26,440 --> 00:04:29,460
different values of a and b, seeing how long the first one takes to run and then

87
00:04:29,460 --> 00:04:30,690
seeing how long the second one takes to

88
00:04:30,690 --> 00:04:32,740
run. And the second one should run substantially faster.
