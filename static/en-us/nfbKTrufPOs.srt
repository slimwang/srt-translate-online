1
00:00:00,170 --> 00:00:03,116
So, congratulations, you made it through the end of the Naive Bayes

2
00:00:03,116 --> 00:00:04,050
learning algorithm.

3
00:00:04,050 --> 00:00:05,331
That is quite amazing.

4
00:00:05,331 --> 00:00:08,460
>> That's one algorithm down, two to go.

5
00:00:08,460 --> 00:00:11,580
What we'll do is we'll start a list now of all the things that maybe you

6
00:00:11,580 --> 00:00:15,680
should be thinking about when picking a supervised classification algorithm.

7
00:00:15,680 --> 00:00:18,910
So that you have some basis for starting to make a choice between

8
00:00:18,910 --> 00:00:21,140
the different algorithms that we'll be talking about.

9
00:00:21,140 --> 00:00:24,340
So there are a few things that Naive Bayes does really elegantly.

10
00:00:24,340 --> 00:00:26,660
>> It's actually really easy to implement.

11
00:00:26,660 --> 00:00:32,037
it, it, these were with great, big feature spaces there is between 20,000 and

12
00:00:32,037 --> 00:00:33,940
200,000 words in the English language.

13
00:00:33,940 --> 00:00:36,680
And it, it's really simple to run, it's really efficient.

14
00:00:36,680 --> 00:00:39,530
>> There are a few things that Naive Bayes doesn't do as well that you also want

15
00:00:39,530 --> 00:00:40,700
to be careful of.

16
00:00:40,700 --> 00:00:42,130
>> Yeah, so it can break.

17
00:00:42,130 --> 00:00:43,420
It breaks in funny ways.

18
00:00:43,420 --> 00:00:47,440
So, historically when Google first sent it out, when people searched for

19
00:00:47,440 --> 00:00:51,350
Chicago Bulls, which is a sports team comprised of two words, Chicago Bulls.

20
00:00:52,494 --> 00:00:56,476
Would show many images of bulls, animals, and of cities, like Chicago.

21
00:00:56,476 --> 00:00:58,280
But Chicago Bulls is something succinctly different.

22
00:00:58,280 --> 00:01:00,910
So phrases that encompass multiple words and

23
00:01:00,910 --> 00:01:03,960
have distinctive meanings don't work really well in NaÃ¯ve Bayes.

24
00:01:03,960 --> 00:01:07,130
>> So depending on exactly what the problem is that you're trying to solve and

25
00:01:07,130 --> 00:01:08,790
the data set that you have to solve it,

26
00:01:08,790 --> 00:01:12,140
you shouldn't think of supervised classification algorithms as black boxes.

27
00:01:12,140 --> 00:01:15,550
You should be thinking about them in terms of the theoretical understanding of

28
00:01:15,550 --> 00:01:18,720
how the algorithm works and whether that's right for

29
00:01:18,720 --> 00:01:19,670
the question you're trying to answer.

30
00:01:19,670 --> 00:01:20,800
>> And you should, of course, test it, right?

31
00:01:20,800 --> 00:01:22,680
So we talked about train set or test set.

32
00:01:22,680 --> 00:01:25,230
You can check the performance in test set and see how it works.

33
00:01:25,230 --> 00:01:27,080
>> And if you don't like it might be the wrong algorithm or

34
00:01:27,080 --> 00:01:27,890
the wrong parameters.

35
00:01:27,890 --> 00:01:28,390
>> Exactly
