1
00:00:00,210 --> 00:00:03,620
Before we conclude this lesson I'd like
to spend a little more time to talk

2
00:00:03,620 --> 00:00:05,660
about designing experiments.

3
00:00:05,660 --> 00:00:09,150
It sounds like it's easy,
we just need to run bunch of test cases,

4
00:00:09,150 --> 00:00:11,770
gather the metrics,
and show the results.

5
00:00:11,770 --> 00:00:13,034
Not so fast actually,

6
00:00:13,034 --> 00:00:16,940
you running tests, gathering metrics and
plotting the results.

7
00:00:16,940 --> 00:00:19,410
It's not as straightforward
as it might seem.

8
00:00:19,410 --> 00:00:21,520
There is actually a lot of thought and

9
00:00:21,520 --> 00:00:25,140
planning that should go into
designing relevant experiments.

10
00:00:25,140 --> 00:00:30,140
By relevant experiment, I'm referring to
an experiment that will lead to certain

11
00:00:30,140 --> 00:00:32,610
statements about a solution.

12
00:00:32,610 --> 00:00:35,110
That are credible,
that others will believe in,

13
00:00:35,110 --> 00:00:38,810
and that are also relevant
that they will care for.

14
00:00:38,810 --> 00:00:42,700
For example, the paper we discussed
is full of relevant experiments.

15
00:00:42,700 --> 00:00:47,243
There the authors provided the detailed
descriptions of each of the experiments.

16
00:00:47,243 --> 00:00:49,153
So that we could understand them and

17
00:00:49,153 --> 00:00:52,540
then we could believe that
those results are seen.

18
00:00:52,540 --> 00:00:56,810
And then we were also able to make well
founded statements about flash and

19
00:00:56,810 --> 00:01:00,540
the ambit model versus all of
the other implementations.

20
00:01:00,540 --> 00:01:04,080
Let's continue talking about
the web server as an example for

21
00:01:04,080 --> 00:01:08,410
which we'll try to justify what
makes some experiments relevant.

22
00:01:08,410 --> 00:01:10,900
Well, the clients using the Web Server.

23
00:01:10,900 --> 00:01:12,370
They care for the response time.

24
00:01:12,370 --> 00:01:14,930
How quickly do they get a web page back?

25
00:01:14,930 --> 00:01:18,840
The operators, for instance,
running that Web Server, that website.

26
00:01:18,840 --> 00:01:20,200
We care about throughput,

27
00:01:20,200 --> 00:01:24,610
how many total client requests can see
that webpage over a period of time?

28
00:01:24,610 --> 00:01:29,260
So this illustrates that you will
likely need to justify your solution,

29
00:01:29,260 --> 00:01:33,290
using some criteria that's
relevent to the stakeholders.

30
00:01:33,290 --> 00:01:37,620
For instance, if you can show that your
solution improves both response time and

31
00:01:37,620 --> 00:01:41,480
throughput, everybody is positively
impacted, so that's great.

32
00:01:41,480 --> 00:01:45,250
If you can show that your solution
only improves response time but

33
00:01:45,250 --> 00:01:47,900
doesn't really affect throughput,
well okay.

34
00:01:47,900 --> 00:01:49,210
I'll buy that too.

35
00:01:49,210 --> 00:01:51,180
It serves me some benefit.

36
00:01:51,180 --> 00:01:54,700
If I see a solution that
improves response time and

37
00:01:54,700 --> 00:01:58,070
actually degrades throughput,
that still could be useful.

38
00:01:58,070 --> 00:02:00,810
Perhaps for this improved response time.

39
00:02:00,810 --> 00:02:05,470
I can end up charging clients more that
ultimately will give me the revenue that

40
00:02:05,470 --> 00:02:08,340
I'm losing due to
the negative throughput.

41
00:02:08,340 --> 00:02:11,100
Or maybe I need to define
some experiments in which

42
00:02:11,100 --> 00:02:15,740
I'm trying to understand how is
the response time that the client see,

43
00:02:15,740 --> 00:02:19,590
how is it effected when the overload
of the Web Server increases,

44
00:02:19,590 --> 00:02:21,240
when the request rate increases?

45
00:02:22,530 --> 00:02:25,420
So by understanding the stakeholders and

46
00:02:25,420 --> 00:02:29,550
the goals that I want to meet with
respect to these stakeholders.

47
00:02:29,550 --> 00:02:34,300
I'm able to define what are some metrics
that I need to pay attention to.

48
00:02:34,300 --> 00:02:37,420
And that will give me insight
into useful configurations of

49
00:02:37,420 --> 00:02:39,010
the experiments.

50
00:02:39,010 --> 00:02:42,040
When you're picking metrics,
a rule of thumb should be,

51
00:02:42,040 --> 00:02:46,910
what are some of the standard metrics
that are popular in the target domain?

52
00:02:46,910 --> 00:02:50,980
For instance, for Web Servers, it makes
sense to talk about the client request

53
00:02:50,980 --> 00:02:53,510
rate or the client response time.

54
00:02:53,510 --> 00:02:55,700
This will let you have
a broader audience.

55
00:02:55,700 --> 00:02:59,730
More people will be able to understand
the results and to relate to them,

56
00:02:59,730 --> 00:03:03,850
even if those particular results
don't give you the best punchline.

57
00:03:03,850 --> 00:03:08,950
Then you absolutely have to include
metrics that really provide answers to

58
00:03:08,950 --> 00:03:11,940
questions such as,
why am I doing this work?

59
00:03:11,940 --> 00:03:16,620
What is it that I want to improve or
understand by doing these experiments?

60
00:03:16,620 --> 00:03:18,760
Who is it that cares for this?

61
00:03:18,760 --> 00:03:22,810
Answering these questions implies
what are the metrics that you need to

62
00:03:22,810 --> 00:03:23,490
keep track of.

63
00:03:23,490 --> 00:03:26,630
For instance, if you're
interested in client performance.

64
00:03:26,630 --> 00:03:29,920
Probably the things that you need to
keep track of are things like response

65
00:03:29,920 --> 00:03:32,810
time, or
number of requests that have timed out.

66
00:03:32,810 --> 00:03:36,540
Or if you're interested in
improving the operator costs,

67
00:03:36,540 --> 00:03:41,280
then you worry about things like
throughput, or power costs, and similar.

68
00:03:41,280 --> 00:03:43,210
Once you understand
the relevant metrics,

69
00:03:43,210 --> 00:03:47,160
you need to think about the system
factors that affect those metrics.

70
00:03:47,160 --> 00:03:50,540
One aspect will be things
like system resources.

71
00:03:50,540 --> 00:03:53,990
This will include hardware
resources such as the number and

72
00:03:53,990 --> 00:03:58,910
type of CPUs or amount of memory that's
available on the server machines, and

73
00:03:58,910 --> 00:04:03,840
also the software specific resources
like number of threads or the size

74
00:04:03,840 --> 00:04:08,830
of certain queues or buffer structures
that are available in the program.

75
00:04:08,830 --> 00:04:13,110
Then there are a number of configuration
parameters that define the workload.

76
00:04:13,110 --> 00:04:18,050
Things that make sense for Web Server
include the request rate, the file size,

77
00:04:18,050 --> 00:04:22,990
the access pattern, things that were
varied also in the flesh experiments.

78
00:04:22,990 --> 00:04:26,580
And now that you understand the
configuration space a little bit better,

79
00:04:26,580 --> 00:04:28,070
make some choices.

80
00:04:28,070 --> 00:04:33,340
Choose a subset of the configuration
parameters that probably are most

81
00:04:33,340 --> 00:04:38,110
impactful when it comes to changes in
the metrics that you're observing.

82
00:04:38,110 --> 00:04:41,900
Pick some ranges for
these variable parameters.

83
00:04:41,900 --> 00:04:44,520
These ranges must also be relevent.

84
00:04:44,520 --> 00:04:48,380
Don't show that your server runs well
with one, two, and three threads, so

85
00:04:48,380 --> 00:04:52,780
don't vary the number of threads
in your server configuration.

86
00:04:52,780 --> 00:04:56,380
If you look out and then you see
that real world deployments,

87
00:04:56,380 --> 00:04:59,300
they have servers with thread
counts in the hundreds.

88
00:04:59,300 --> 00:05:01,898
Or don't go and vary the file sizes.

89
00:05:01,898 --> 00:05:04,720
To have sizes of 10000 and
one kilobytes.

90
00:05:04,720 --> 00:05:09,860
If you look at what's happening in
the real world, file sizes range

91
00:05:09,860 --> 00:05:14,650
from maybe from tens of bytes
up to tens of megabytes and

92
00:05:14,650 --> 00:05:16,290
hundreds of megabytes and beyond.

93
00:05:16,290 --> 00:05:20,400
So make sure that the ranges
are representative of reality.

94
00:05:20,400 --> 00:05:24,800
Again, these ranges must somehow
correspond to some realistic scenario

95
00:05:24,800 --> 00:05:26,070
that's relevant.

96
00:05:26,070 --> 00:05:29,540
Otherwise, nobody will care for
your hypothetical results.

97
00:05:30,540 --> 00:05:33,320
That is,
unless your hypothetical results

98
00:05:33,320 --> 00:05:37,700
are concerned with demonstrating
the best or the worst case scenarios.

99
00:05:37,700 --> 00:05:41,380
Best and worst case scenarios
do bring some value, because.

100
00:05:41,380 --> 00:05:44,660
They, in a way they demonstrate
certain limitations, or

101
00:05:44,660 --> 00:05:48,860
certain opportunities that are there,
because of the system that you've

102
00:05:48,860 --> 00:05:51,830
proposed, because of
the solution you have proposed.

103
00:05:51,830 --> 00:05:56,084
So these are the only times where
picking a non realistic workload

104
00:05:56,084 --> 00:05:57,050
makes sense.

105
00:05:57,050 --> 00:05:59,780
Like for instance,
in the flash paper case.

106
00:05:59,780 --> 00:06:04,480
They had an example in which every
single one of the requests was accessing

107
00:06:04,480 --> 00:06:05,860
one, single file.

108
00:06:05,860 --> 00:06:08,740
And there was some value in
the results that were obtained

109
00:06:08,740 --> 00:06:10,360
through that experiment.

110
00:06:10,360 --> 00:06:12,740
For the various factors
that you're considering,

111
00:06:12,740 --> 00:06:14,170
pick some useful combinations.

112
00:06:14,170 --> 00:06:17,970
There will be a lot of
experiments where the results

113
00:06:17,970 --> 00:06:20,310
simply reiterate the same point.

114
00:06:20,310 --> 00:06:23,760
It really doesn't make sense
to make endless such results.

115
00:06:25,060 --> 00:06:29,220
Few are good, it's good to confirm
that some observation is valid, but

116
00:06:29,220 --> 00:06:33,590
including tens of them it
really doesn't make any sense.

117
00:06:33,590 --> 00:06:37,230
A very important point,
compare apples to apples.

118
00:06:37,230 --> 00:06:40,290
For instance let's look
at one bad example.

119
00:06:40,290 --> 00:06:45,690
We have one combination in which we run
an experiment with a large workload.

120
00:06:45,690 --> 00:06:47,230
And a small size of resources.

121
00:06:47,230 --> 00:06:49,560
And then a second experiment,

122
00:06:49,560 --> 00:06:52,580
second run of the experiment in
which we've changed the workload so

123
00:06:52,580 --> 00:06:57,070
now we have a small workload and then
we have also allocated more resources.

124
00:06:57,070 --> 00:06:59,120
So, for instance, more threads.

125
00:06:59,120 --> 00:07:01,150
And then we look at these results and

126
00:07:01,150 --> 00:07:06,460
we see that In the second case,
for the second experimental run.

127
00:07:06,460 --> 00:07:10,850
The performance is better, so
then we may draw a conclusion,

128
00:07:10,850 --> 00:07:14,200
well I've increased the resource size,
it added more threads.

129
00:07:14,200 --> 00:07:18,280
And therefore, my performance
has improved, so I must be

130
00:07:18,280 --> 00:07:22,500
able to conclude that performance
improves when I increase the resources.

131
00:07:22,500 --> 00:07:26,420
That's clearly wrong, I have no idea
whether performance improved because

132
00:07:26,420 --> 00:07:28,380
I've added more resources.

133
00:07:28,380 --> 00:07:30,370
Or because I have changed the workload.

134
00:07:30,370 --> 00:07:35,030
So, I'm using a much smaller
workload in the second case.

135
00:07:35,030 --> 00:07:38,710
This is what we mean by, make sure that
you're comparing apples to apples.

136
00:07:38,710 --> 00:07:42,560
There's no way you can draw a conclusion
between these two experiments.

137
00:07:42,560 --> 00:07:43,990
And what about the competition.

138
00:07:43,990 --> 00:07:46,670
What is the baseline for
the system that you're evaluating?

139
00:07:46,670 --> 00:07:50,610
You should think about experiments
that are able to demonstrate

140
00:07:50,610 --> 00:07:52,170
that the system you're designing,

141
00:07:52,170 --> 00:07:57,170
the solution you're proposing, in some
way improves the state of the art.

142
00:07:57,170 --> 00:08:00,360
Otherwise it's not clear why use yours.

143
00:08:00,360 --> 00:08:03,130
And if it's not really
the state-of-the-art then at least

144
00:08:03,130 --> 00:08:06,350
what's the most common practice,
that should be improved.

145
00:08:06,350 --> 00:08:09,640
And perhaps there's some other
benefits over the state-of-the-art

146
00:08:09,640 --> 00:08:11,090
that are valuable.

147
00:08:11,090 --> 00:08:15,190
Or at least think about evaluating
your system by comparing with some

148
00:08:15,190 --> 00:08:19,500
extreme conditions in terms of
the workload or resource assignment,

149
00:08:19,500 --> 00:08:23,150
so some of the best or
worst case scenarios.

150
00:08:23,150 --> 00:08:26,870
That will provide insight into
some properties of your solution.

151
00:08:26,870 --> 00:08:30,130
Like, how does it scale as
the workload increases, for instance.
