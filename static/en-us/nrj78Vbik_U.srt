1
00:00:00,275 --> 00:00:03,350
Let's look at a single cache
that is 16 kilobytes in size.

2
00:00:04,570 --> 00:00:09,575
Let's look also at a single cache
that is 128 kilobytes in size.

3
00:00:09,575 --> 00:00:14,403
Let's look at no cache, simply we
will just access the main memory, and

4
00:00:14,403 --> 00:00:19,232
let's look at the hierarchy that has
this kind of cache as the first level

5
00:00:19,232 --> 00:00:23,061
cache, and this kind of cache
as the second level cache.

6
00:00:23,061 --> 00:00:27,338
We will look at the the hit time for
this, the hit rate for

7
00:00:27,338 --> 00:00:30,932
all of this, and the overall AMAT.

8
00:00:30,932 --> 00:00:35,160
So a 16 kilobyte cache might
have a hit time of 2 cycles,

9
00:00:36,190 --> 00:00:42,580
a hit rate of 90%, so
it gives us an overall AMAT

10
00:00:42,580 --> 00:00:47,880
of 2 plus 10% of the time
we have the memory latency.

11
00:00:47,880 --> 00:00:51,010
Let's say the memory
latency is 100 cycles.

12
00:00:51,010 --> 00:00:55,075
In that case,
we end up with an overall AMAT of 12,

13
00:00:55,075 --> 00:01:01,470
2 from the hit time and
10 on average from the miss penalties.

14
00:01:01,470 --> 00:01:03,600
Now let's look at the larger cache.

15
00:01:03,600 --> 00:01:07,890
This cache might have a hit
time of 10 cycles, but

16
00:01:07,890 --> 00:01:11,647
a hit rate of maybe 97.5%.

17
00:01:11,647 --> 00:01:15,720
This is a bit high for
such a cache, but let's say it is.

18
00:01:15,720 --> 00:01:20,450
The AMAT when this is used
alone would be 10 plus

19
00:01:20,450 --> 00:01:23,910
the miss rate times the miss penalty,
and

20
00:01:23,910 --> 00:01:29,060
we end up with 12.5, which is a little
bit worse than with a smaller cache.

21
00:01:29,060 --> 00:01:34,860
So having a larger cache alone increases
the hit time, improves the hit rate.

22
00:01:34,860 --> 00:01:37,330
So it may or
may not improve the AMAT, but

23
00:01:37,330 --> 00:01:39,850
either way the AMAT is not
going to improve a lot.

24
00:01:39,850 --> 00:01:43,950
Of course, having a cache is still
lots better than not having a cache.

25
00:01:43,950 --> 00:01:48,270
Not having a cache means that our
memory has a hit time of 100 cycles,

26
00:01:48,270 --> 00:01:50,148
basically the memory latency.

27
00:01:50,148 --> 00:01:53,750
It hits 100% of the time.

28
00:01:53,750 --> 00:02:00,050
So AMAT ends up being 100 plus 0 times
the penalty, because it never misses.

29
00:02:00,050 --> 00:02:04,840
But we still end up with 100 cycles
per axis, which is way too big.

30
00:02:04,840 --> 00:02:08,490
So obviously, having a cache
is better than not having it.

31
00:02:08,490 --> 00:02:11,280
So now let's look at
the cache hierarchy.

32
00:02:11,280 --> 00:02:16,110
The hit time is different depending
on which of the levels we hit in.

33
00:02:16,110 --> 00:02:20,460
The hit time is still going to
be two cycles for a level 1 hit.

34
00:02:20,460 --> 00:02:24,260
For a level 2 hit, however,
we first check in level 1.

35
00:02:24,260 --> 00:02:27,180
So we pay 2 cycles to check.

36
00:02:27,180 --> 00:02:29,330
Then we access L2 and have a hit.

37
00:02:29,330 --> 00:02:35,210
So overall now, it's going to
be 12 cycles for a level 2 hit.

38
00:02:35,210 --> 00:02:40,759
The hit rate is going to be 90% for L1.

39
00:02:40,759 --> 00:02:44,724
It's still the same cache
as if it was alone, and

40
00:02:44,724 --> 00:02:49,751
of all the axises that go from
level 1 to level 2, we will have

41
00:02:49,751 --> 00:02:56,000
some hits because the L2 cache has
this hit rate when working alone.

42
00:02:56,000 --> 00:03:01,240
Of all the processor axises,
it would have a hit on this many, but

43
00:03:01,240 --> 00:03:03,730
of all the processor axises,

44
00:03:03,730 --> 00:03:08,200
those that hit in L1 probably
would also have been hits in L2.

45
00:03:08,200 --> 00:03:16,360
So this cache really has a 75% hit rate
of all the things that go into it.

46
00:03:16,360 --> 00:03:21,170
It would have this hit rate if it was
alone, but the L1 cache is filtering

47
00:03:21,170 --> 00:03:25,780
all of the easy to hit axises,
so the L2 only gets 75%.

48
00:03:25,780 --> 00:03:30,740
Basically it only gets to see kind
of the worst 10% of the axises, and

49
00:03:30,740 --> 00:03:35,490
for those it's only having
a three quarters hit rate.

50
00:03:35,490 --> 00:03:40,460
But the AMAT is now going to be two for
L1 hits

51
00:03:40,460 --> 00:03:46,190
plus 10% of the time we have an L1 miss.

52
00:03:46,190 --> 00:03:52,006
When we do,
we have 10 cycles to axis L2,

53
00:03:52,006 --> 00:03:59,680
plus 25% of those also
end up accessing memory.

54
00:03:59,680 --> 00:04:03,500
So when we compute what this is,
it's 10 plus 25.

55
00:04:03,500 --> 00:04:10,790
So the overall miss penalty for
our level 1 miss is just 35 cycles.

56
00:04:10,790 --> 00:04:15,620
It's much better than what it used
to be when the L1 was working alone.

57
00:04:15,620 --> 00:04:18,660
And we finally end up with 2 plus 3.5,

58
00:04:18,660 --> 00:04:23,390
which gives us an overall
AMAT of 5.5 cycles.

59
00:04:23,390 --> 00:04:28,370
This is much better than either
of the two caches working alone.

60
00:04:28,370 --> 00:04:33,510
And it's much better because
really we are having most

61
00:04:33,510 --> 00:04:39,010
of the axises hit using the hit
latency of the fast cache.

62
00:04:39,010 --> 00:04:44,940
Some axises have a higher hit
latency in the second cache,

63
00:04:44,940 --> 00:04:48,750
and fewer of them made
this huge memory latency.

64
00:04:48,750 --> 00:04:53,790
So this is why cache hierarchies
work better than individual caches,

65
00:04:53,790 --> 00:04:55,070
and why we have them.

66
00:04:55,070 --> 00:05:00,470
It is not enough to simply have
a large cache, if it's also slow.

67
00:05:00,470 --> 00:05:03,420
In that case,
you can combine their good properties so

68
00:05:03,420 --> 00:05:05,820
that most of the time
we get this hit time.

69
00:05:05,820 --> 00:05:08,920
But overall, as far as
the memory axises is concerned,

70
00:05:08,920 --> 00:05:12,020
we really have this hit
rate in the combined cache.
