1
00:00:00,000 --> 00:00:06,000
Now it's called search traditionally, but I think "exploration" is a better name for it.

2
00:00:06,000 --> 00:00:10,000
We start out at home, and in this case our home is where we have two glasses.

3
00:00:10,000 --> 00:00:15,000
Zero and zero are the values for how full the glasses are.

4
00:00:15,000 --> 00:00:17,000
Then we start to explore.

5
00:00:17,000 --> 00:00:21,000
One way we could explore is to fill one of the glasses

6
00:00:21,000 --> 00:00:25,000
Then we're at this state--say we're at 0 and 4--

7
00:00:25,000 --> 00:00:29,000
but we know that there are other actions in which we could explore in other directions.

8
00:00:29,000 --> 00:00:35,000
Now we could take one of the other states and explore from there in other directions.

9
00:00:35,000 --> 00:00:41,000
We have lots of choices going forward of this huge space that we're exploring.

10
00:00:41,000 --> 00:00:45,000
Now, somewhere out in this space--and we don't know which direction it is--

11
00:00:45,000 --> 00:00:53,000
is this goal state, which has 6 and then actually any amount in the other glass.

12
00:00:53,000 --> 00:00:59,000
We're trying to reach that, and we're distinguishing this part of the state space as a goal.

13
00:00:59,000 --> 00:01:06,000
So I drew this as one, but really it's a collection of states in that every state that has 6 on one side

14
00:01:06,000 --> 00:01:12,000
and anything on the other should be considered part of this collection of goals.

15
00:01:12,000 --> 00:01:15,000
We're trying to search forwards towards that.

16
00:01:15,000 --> 00:01:20,000
One reason I like to call it an exploration problem is because we can think of going forward,

17
00:01:20,000 --> 00:01:26,000
exploring a new land, and part of that exploration is that we've got a frontier.

18
00:01:26,000 --> 00:01:30,000
Here's all the states that are the farthest out that we've gone.

19
00:01:30,000 --> 00:01:33,000
If we want to make progress towards the goal,

20
00:01:33,000 --> 00:01:37,000
then we're probably going to have to step from one of the frontier nodes farther out.

21
00:01:37,000 --> 00:01:43,000
We've separated the set of all possible states into the goal state, the frontier states,

22
00:01:43,000 --> 00:01:46,000
and the previously explored states.

23
00:01:46,000 --> 00:01:53,000
Then you can see that the way to make progress is to say let's take one of the frontier states

24
00:01:53,000 --> 00:01:57,000
and expand that, and we have the advantage here of being a computer

25
00:01:57,000 --> 00:01:59,000
that an individual explorer doesn't have.

26
00:01:59,000 --> 00:02:02,000
An individual explorer has to take one path,

27
00:02:02,000 --> 00:02:05,000
and if they decide they've gone in the wrong direction, they have to go all the way back.

28
00:02:05,000 --> 00:02:09,000
A computer can store lots of states in memory.

29
00:02:09,000 --> 00:02:17,000
Computer exploration is more like a collection of explorers all collectively expanding the frontier.

30
00:02:17,000 --> 00:02:23,000
Our next move can be to say we'll take one of these explorers, say the one in this state here,

31
00:02:23,000 --> 00:02:25,000
and say now tell me what's next.

32
00:02:25,000 --> 00:02:28,000
You've got 6 actions from there. Where do they go to?

33
00:02:28,000 --> 00:02:34,000
Maybe some of them explore the world and generate new states that we haven't seen before.

34
00:02:34,000 --> 00:02:39,000
Maybe some of them go to a state that we already know is on the frontier.

35
00:02:39,000 --> 00:02:44,000
Maybe some of them regress backwards into previously explored territory.

36
00:02:44,000 --> 00:02:49,000
But we can keep on going, expanding out our frontier until eventually

37
00:02:49,000 --> 00:02:52,000
the frontier keeps on expanding.

38
00:02:52,000 --> 00:02:55,000
When it overlaps the goal, then we've got a solution.

39
00:02:55,000 --> 00:03:01,000
Now, in exploration problems like this, there are two problems that we have to worry about.

40
00:03:01,000 --> 00:03:08,000
One problem is that there is no solution at all, that the goals are not connected to the to start state.

41
00:03:08,000 --> 00:03:11,000
So there's no path from here to there.

42
00:03:11,000 --> 00:03:15,000
Then what we want to do is do the exploration we need and report back that it's impossible.

43
00:03:15,000 --> 00:03:17,000
We want to find out that it's impossible.

44
00:03:17,000 --> 00:03:23,000
Then the other problem is if there is some path that eventually makes it to the goal,

45
00:03:23,000 --> 00:03:26,000
We want to make sure that we find that in a reasonable amount of time.

46
00:03:26,000 --> 00:03:30,000
That means we want to be efficient about the way we explore the space.

47
00:03:30,000 --> 00:03:34,000
It also means that we don't want to get stuck in an infinite loop.

48
00:03:34,000 --> 00:03:39,000
Now, if there is a finite number of states and they are connected,

49
00:03:39,000 --> 00:03:41,000
then we should be able to find the path.

50
00:03:41,000 --> 00:03:47,000
But if we aren't clever, we may miss the solution even though it's possible to find it.

51
00:03:47,000 --> 00:03:54,000
For example, if we had a strategy that says first I'm going to explore in this direction--

52
00:03:54,000 --> 00:03:58,000
say this is pouring from cup x into cup y--

53
00:03:58,000 --> 00:04:04,000
and then I go in this direction, pouring from cup y back in to cup x,

54
00:04:04,000 --> 00:04:08,000
and then I pour the water back again--so I'm continually just taking water

55
00:04:08,000 --> 00:04:11,000
and pouring it between two different cups back and forth,

56
00:04:11,000 --> 00:04:16,000
those are all legal steps to take, but I'm ending up with an infinitely long path

57
00:04:16,000 --> 00:04:18,000
and I'm not making any progress.

58
00:04:18,000 --> 00:04:22,000
We'd like to come up with a strategy for exploration,

59
00:04:22,000 --> 00:04:28,000
and the strategy corresponds to deciding which path to expand next.

60
00:04:28,000 --> 00:04:31,000
Strategy is always there's some path--let's say this one--

61
00:04:31,000 --> 00:04:34,000
and we say that's the one we're going to explore from next.

62
00:04:34,000 --> 00:04:38,000
To avoid this type of infinite loop, here's some possibilities.

63
00:04:38,000 --> 00:04:42,000
One possibility would be don't reverse an action.

64
00:04:42,000 --> 00:04:49,000
If you come from state A to state B, don't allow the action that goes immediately back to state A.

65
00:04:49,000 --> 00:04:54,000
Another strategy would be to say always take the shortest path first.

66
00:04:54,000 --> 00:04:56,000
Out of all the paths that you've built so far,

67
00:04:56,000 --> 00:04:59,000
when we go to choose which one we're going to expand next,

68
00:04:59,000 --> 00:05:02,000
always choose one of the shortest ones.

69
00:05:02,000 --> 00:05:07,000
That way we might start to build up an infinitely long path,

70
00:05:07,000 --> 00:05:12,000
but at least we won't continue it. First we'll do another one before we do that one.

71
00:05:12,000 --> 00:05:15,000
Then another strategy would be don't re-explore.

72
00:05:15,000 --> 00:05:20,000
That is, if we're on the frontier--let's say we're here on the frontier--

73
00:05:20,000 --> 00:05:26,000
and we have a move that moves us back out of the frontier into the previously explored zone,

74
00:05:26,000 --> 00:05:28,000
then we should not allow that path.

75
00:05:28,000 --> 00:05:33,000
My question is check all the strategies that would eventually lead us to the goal.

76
00:05:33,000 --> 00:05:36,000
Don't worry about the efficiency of getting to the goal,

77
00:05:36,000 --> 99:59:59,999
but which one will eventually get us there and won't get stuck in an infinite loop.
