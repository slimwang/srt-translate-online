1
00:00:00,560 --> 00:00:03,960
Okay. So here's some practical matters, Michael. I mentioned

2
00:00:03,960 --> 00:00:06,560
one of them before, and that is that mimic

3
00:00:06,560 --> 00:00:10,670
does well with structure. When the optimal values that

4
00:00:10,670 --> 00:00:13,570
you care about depend only on the structure, as

5
00:00:13,570 --> 00:00:16,020
opposed to specific values, mimic tends to do pretty

6
00:00:16,020 --> 00:00:20,140
well. By contrast Randomize hill climbing, genetic algorithms. These

7
00:00:20,140 --> 00:00:22,540
other things that we've looked at before can sometimes

8
00:00:22,540 --> 00:00:26,630
get confused by two different values that are both optima

9
00:00:26,630 --> 00:00:29,370
but look very different from one another. Where it's the

10
00:00:29,370 --> 00:00:32,980
structure that matters and not the actual values. So, the chain

11
00:00:32,980 --> 00:00:35,570
example before where you had alternating values as one of those

12
00:00:35,570 --> 00:00:39,810
cases where it's easy for randomized algorithms that only look for

13
00:00:39,810 --> 00:00:42,480
point values to get confused. 'because their basically being drawn

14
00:00:42,480 --> 00:00:46,220
in multiple directions at once. The quiz also brought up another

15
00:00:46,220 --> 00:00:48,630
point which is worth mentioning here was that mimic and with

16
00:00:48,630 --> 00:00:52,485
anything that tries to do this kind of search through probability

17
00:00:52,485 --> 00:00:55,770
[UNKNOWN] is that it's an issue of representing everything.

18
00:00:55,770 --> 00:00:57,380
That is it's not enough just to be able to

19
00:00:57,380 --> 00:01:00,900
represent a probability distribution of the [UNKNOWN]. You really

20
00:01:00,900 --> 00:01:03,430
want to be able to represent everything in between as

21
00:01:03,430 --> 00:01:07,890
you move through probability space toward your answer. This

22
00:01:07,890 --> 00:01:11,990
is the universal symbol for moving through probability space. You

23
00:01:11,990 --> 00:01:15,480
don't just want to represent here at the end and

24
00:01:15,480 --> 00:01:17,620
here at the beginning which is pretty easy because uniform

25
00:01:17,620 --> 00:01:22,440
distribution, but can you represent this point? Can you represent this point?

26
00:01:22,440 --> 00:01:25,860
And if you can't are you going to end up getting stuck. And

27
00:01:25,860 --> 00:01:29,950
actually turns out that mimic can get stuck in local optimal though

28
00:01:29,950 --> 00:01:34,014
it typically does not optima because you get randomize your search for optima.

29
00:01:34,014 --> 00:01:34,460
>> Hm. I see.

30
00:01:34,460 --> 00:01:38,000
>> But the problem of local optima is still a problem of local

31
00:01:38,000 --> 00:01:42,640
optima. Now, when I say something like you get randomized restarts for free,

32
00:01:42,640 --> 00:01:45,450
I'm actually cheating a little bit and hiding something which is

33
00:01:45,450 --> 00:01:48,130
a little bit more important, which is what you really get

34
00:01:48,130 --> 00:01:52,230
for free is probability theory. So there's a hundred, literally, hundreds

35
00:01:52,230 --> 00:01:55,650
of years of work on how to think about representing probability distributions

36
00:01:55,650 --> 00:01:57,500
and what you can do with them and there are terms

37
00:01:57,500 --> 00:02:00,680
like important sampling and rejection sampling And all these kinds of

38
00:02:00,680 --> 00:02:04,090
tools that we have for representing probability distributions that you ca

39
00:02:04,090 --> 00:02:08,139
actually inherit with something like Mimic for dealing with these painful cases

40
00:02:08,139 --> 00:02:10,300
where you might not be able to represent distributions.

41
00:02:10,300 --> 00:02:14,800
>> But the single most important thing to me about Mimic or what to get out

42
00:02:14,800 --> 00:02:17,990
of here is that representing structure does matter.

43
00:02:17,990 --> 00:02:19,920
But you pay a price. And that price

44
00:02:19,920 --> 00:02:23,050
basically boils down to, time. So the question

45
00:02:23,050 --> 00:02:27,800
we might ask ourselves, is, what is the

46
00:02:27,800 --> 00:02:31,950
sort of practical time complexity of mimic? And,

47
00:02:31,950 --> 00:02:34,720
it really boils down to something very simple.

48
00:02:34,720 --> 00:02:38,240
Let me just share a fact with you Michael. Okay. I

49
00:02:38,240 --> 00:02:41,470
have run this algorithm on many, many, many examples and I've

50
00:02:41,470 --> 00:02:43,100
compared it to simulated [INAUDIBLE].

51
00:02:43,100 --> 00:02:45,030
I've compared it to [INAUDIBLE] algorithms.

52
00:02:45,030 --> 00:02:47,390
I've compared it to randomized hill climbing. And it works pretty

53
00:02:47,390 --> 00:02:49,360
well for the sorts of examples I've come up with. And

54
00:02:49,360 --> 00:02:52,100
here's a little fact that I just want to give you.

55
00:02:52,100 --> 00:02:56,400
Mimic tends to run orders of magnitude fewer iterations. And I'm

56
00:02:56,400 --> 00:02:59,750
not exaggerating here; I mean that if I run Simulated Annealing,

57
00:02:59,750 --> 00:03:03,510
it might take 100,000 iterations for something like

58
00:03:03,510 --> 00:03:08,420
Simulated Annealing, but for Mimic, it might take only

59
00:03:08,420 --> 00:03:11,640
a hundred. And this is consistently true, so

60
00:03:11,640 --> 00:03:14,110
it turns out that that's not good enough. It

61
00:03:14,110 --> 00:03:15,860
turns out that the fact that Mimic can

62
00:03:15,860 --> 00:03:18,850
do something in three, four, five, six, seven orders

63
00:03:18,850 --> 00:03:21,580
of magnitude fewer iterations Is it an argument

64
00:03:21,580 --> 00:03:23,230
for always using it? Can you imagine one now?

65
00:03:23,230 --> 00:03:25,220
>> because it might give a worse answer?

66
00:03:25,220 --> 00:03:27,360
>> Well, in practice it doesn't. So, these are

67
00:03:27,360 --> 00:03:31,260
cases where both simulated [UNKNOWN] and mimic, or randomized hill

68
00:03:31,260 --> 00:03:34,780
climbing or genetic algorithms actually eventually do find the answer.

69
00:03:34,780 --> 00:03:37,740
Mimic just finds it in orders of magnitude, fewer iterations.

70
00:03:38,770 --> 00:03:40,370
>> But you're counting iterations.

71
00:03:40,370 --> 00:03:40,563
>> Mm-hm.

72
00:03:40,563 --> 00:03:42,590
>> You didn't control for the fact that Different

73
00:03:42,590 --> 00:03:45,380
algorithms, can take different times for a single iteration.

74
00:03:45,380 --> 00:03:47,640
>> That's exactly right. So, what do you think?

75
00:03:47,640 --> 00:03:50,190
If I were to compare simulated annealing to mimic,

76
00:03:50,190 --> 00:03:53,380
which do you think take, the, takes more time for any given iteration?

77
00:03:53,380 --> 00:03:55,510
>> Well simulated annealing just does this little tiny

78
00:03:55,510 --> 00:03:57,660
step, right? It like, computes a bunch of neighbors

79
00:03:57,660 --> 00:04:00,240
and then does a probability comparrison, and then, takes

80
00:04:00,240 --> 00:04:03,800
a step. Mimic is drawing this sample, estimating a

81
00:04:03,800 --> 00:04:07,190
bunch of parameters, then yeah. I guess the other

82
00:04:07,190 --> 00:04:10,660
way around. It's drawing from a distribution. It's computing

83
00:04:10,660 --> 00:04:12,980
which things are say above the median performance, and

84
00:04:12,980 --> 00:04:15,380
then it's re-estimating a new distribution. And then that's

85
00:04:15,380 --> 00:04:17,390
the end of the iteration. Depending on how many samples

86
00:04:17,390 --> 00:04:19,420
it takes to do that, it's, it could take a

87
00:04:19,420 --> 00:04:23,330
very long time, and in particular, it's going to always be

88
00:04:23,330 --> 00:04:25,390
a lot more samples than what simulated annealing is doing.

89
00:04:25,390 --> 00:04:29,560
>> Almost certainly. So, when would you think that MIMIC would still be worth

90
00:04:29,560 --> 00:04:31,890
using in a case like that, where we know that we can get to the

91
00:04:31,890 --> 00:04:34,290
answer, but simulated annealing will take orders

92
00:04:34,290 --> 00:04:37,250
of magnitude more iterations, MIMIC will take

93
00:04:37,250 --> 00:04:40,440
fewer iterations? So when would it still be worth it to take the one with

94
00:04:40,440 --> 00:04:43,070
fewer iterations even though east, each iteration is

95
00:04:43,070 --> 00:04:46,870
expensive? Prints algorithm, quadratic this that and the other.

96
00:04:46,870 --> 00:04:50,410
>> Oh yeah, grab at that part, hm.
