1
00:00:00,090 --> 00:00:01,780
What currently works?

2
00:00:01,780 --> 00:00:04,390
Well actually, let's talk a little
bit about what used to work, well,

3
00:00:04,390 --> 00:00:07,240
still does, what worked a while ago,
and what's working now.

4
00:00:07,240 --> 00:00:09,560
So what worked sort of say yesterday?

5
00:00:09,560 --> 00:00:12,700
Okay.
Yesterday being proverbially not today.

6
00:00:12,700 --> 00:00:15,550
All right, so
things like reading license plates,

7
00:00:15,550 --> 00:00:18,640
well that's pretty easy
because it's a fixed font.

8
00:00:18,640 --> 00:00:23,295
Zip codes, numbers on checks,
those are getting much better, and

9
00:00:23,295 --> 00:00:26,790
handwritten recognition of
digits has gotten pretty good.

10
00:00:26,790 --> 00:00:28,380
Fingerprint recognition.

11
00:00:28,380 --> 00:00:31,200
The analysis of those patterns,
because the patterns share certain

12
00:00:31,200 --> 00:00:34,620
types of characteristics, and
we could find those characteristics.

13
00:00:34,620 --> 00:00:39,090
Face detection, but you'll notice that
here the thing knows who I am, but

14
00:00:39,090 --> 00:00:41,030
it hasn't yet figured out who Megan is.

15
00:00:41,030 --> 00:00:41,560
Right?

16
00:00:41,560 --> 00:00:43,790
Today we do recognition.

17
00:00:43,790 --> 00:00:44,920
By the way you know,

18
00:00:44,920 --> 00:00:49,220
these days typically when you pop-up or
put an image let's say on to Facebook or

19
00:00:49,220 --> 00:00:53,270
some other thing, it'll suggest you
the names of the people that are there.

20
00:00:53,270 --> 00:00:55,710
And that means that it's
found the faces, and

21
00:00:55,710 --> 00:00:57,810
it's also recognized who they are.

22
00:00:57,810 --> 00:01:01,531
Now, it doesn't searches
database of everybody,

23
00:01:01,531 --> 00:01:04,560
it only searches your friends.

24
00:01:04,560 --> 00:01:06,330
Right?
So it doesn't have to try to recognize

25
00:01:06,330 --> 00:01:10,990
this as anybody on the planet, just
the five friends that I happen to have.

26
00:01:10,990 --> 00:01:11,580
Right?

27
00:01:11,580 --> 00:01:14,640
So then you might ask, well, how does
it know the picture of those friends?

28
00:01:14,640 --> 00:01:17,960
Well, other people have
tagged Megan in images.

29
00:01:20,720 --> 00:01:23,895
Every time you tag an image with a face,
person's name,

30
00:01:23,895 --> 00:01:27,170
you're actually telling Google, or

31
00:01:27,170 --> 00:01:31,750
whoever, or Facebook, or whoever you're
doing, how to recognize that person.

32
00:01:32,950 --> 00:01:36,610
So without meaning, making it sound
nefarious, it is the case that every

33
00:01:36,610 --> 00:01:41,470
time you tag somebody else in a picture,
you're making it that much easier for

34
00:01:41,470 --> 00:01:45,480
computers to find that
person in other images.

35
00:01:45,480 --> 00:01:47,010
You are teaching.

36
00:01:47,010 --> 00:01:53,170
You are not tagging, you are teaching
the system what Megan looks like.

37
00:01:53,170 --> 00:01:54,012
So just, just,

38
00:01:54,012 --> 00:01:58,160
just think about that every time
you identify people in an image.

39
00:01:58,160 --> 00:01:59,950
We've actually talked
about sift features and

40
00:01:59,950 --> 00:02:03,690
using the location of sift features
to recognize objects and, you know,

41
00:02:03,690 --> 00:02:06,430
sort of flat textured things
like the book covers.

42
00:02:06,430 --> 00:02:07,080
All right.

43
00:02:07,080 --> 00:02:07,940
Now what just happened?

44
00:02:07,940 --> 00:02:12,230
This is GoogleNet 2014,
which was part of a competition.

45
00:02:12,230 --> 00:02:16,070
And you can see here that
given this image, okay,

46
00:02:16,070 --> 00:02:18,360
it labels the monitor, the bookshelf.

47
00:02:18,360 --> 00:02:20,870
It even labels this dom,
this, it says domestic cat.

48
00:02:20,870 --> 00:02:23,690
And it looks to me like this
cat is jumping in the air, so

49
00:02:23,690 --> 00:02:24,880
that's pretty cool.

50
00:02:24,880 --> 00:02:29,900
What makes this picture hard, of course
is the very intense color variation.

51
00:02:29,900 --> 00:02:33,480
So it was able to find, just basically
through the color and texture,

52
00:02:33,480 --> 00:02:35,000
cause that's the only
thing that's there,

53
00:02:35,000 --> 00:02:37,240
the fact that there were oranges and
bananas there.

54
00:02:37,240 --> 00:02:41,030
So this is a pretty intriguing result,
and then here's a result that,

55
00:02:42,210 --> 00:02:45,560
calls into question
the importance of context.

56
00:02:45,560 --> 00:02:48,300
And maybe what it means is
that context doesn't matter

57
00:02:48,300 --> 00:02:50,090
when things are very clear.

58
00:02:50,090 --> 00:02:50,650
All right?

59
00:02:50,650 --> 00:02:52,424
So I love this picture.

60
00:02:52,424 --> 00:02:56,160
I'm not sure you can read this, but
it says hat with wide brim on the top,

61
00:02:56,160 --> 00:02:58,410
and it says dog on the bottom.

62
00:02:58,410 --> 00:03:02,840
Now, I don't know how many pictures
there are of dogs with hats and

63
00:03:02,840 --> 00:03:04,490
wide brims wearing them.

64
00:03:04,490 --> 00:03:06,830
What scares me is,
there might be tens of thousands,

65
00:03:06,830 --> 00:03:08,970
because people have way too much
time on their hands or something.

66
00:03:08,970 --> 00:03:09,680
I don't know.

67
00:03:09,680 --> 00:03:14,500
But, it is an impressive result that it
was able to recognize the hat on top of

68
00:03:14,500 --> 00:03:17,970
the dog, which you have to believe
is not a likely position for a hat.
