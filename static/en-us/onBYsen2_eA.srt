1
00:00:00,270 --> 00:00:04,250
Okay Michael, so if you go all
the way back to the very first slide,

2
00:00:04,250 --> 00:00:06,000
when we started this conversation.

3
00:00:06,000 --> 00:00:09,110
The slide said something about
generalizing generalizing.

4
00:00:09,110 --> 00:00:12,070
But one of the words that was
written on there was scalability.

5
00:00:12,070 --> 00:00:15,790
So one of the things that we've been
talking about, sometimes explicitly,

6
00:00:15,790 --> 00:00:20,740
sometimes implicitly, is this notion
of getting scale to actually happen.

7
00:00:20,740 --> 00:00:23,700
So just because I think it's
important to think about scale

8
00:00:23,700 --> 00:00:25,220
more than in terms of abstraction.

9
00:00:25,220 --> 00:00:29,622
I just want to take a moment to talk
about a algorithmic approach to getting

10
00:00:29,622 --> 00:00:30,688
scaling to work.

11
00:00:30,688 --> 00:00:33,609
That's different from just doing
abstraction of the sort that

12
00:00:33,609 --> 00:00:34,750
we've done before.

13
00:00:34,750 --> 00:00:37,590
Although it's going to turn out that
all the things that we've done with our

14
00:00:37,590 --> 00:00:42,480
abstraction will actually work in this
new algorithmic view of scalability.

15
00:00:42,480 --> 00:00:44,000
That seem interesting?

16
00:00:44,000 --> 00:00:45,140
>> Yeah that would be really helpful.

17
00:00:45,140 --> 00:00:46,570
>> Cool let's do that, all right, so

18
00:00:46,570 --> 00:00:49,160
here's a particular algorithm
that I want to introduce.

19
00:00:49,160 --> 00:00:53,210
It's called Monte Carlo Tree Search,
and there are four words there, and

20
00:00:53,210 --> 00:00:54,580
there's two different parts.

21
00:00:54,580 --> 00:00:59,490
So for the beginning I just want to
concentrate on the tree search part, and

22
00:00:59,490 --> 00:01:02,700
then tell you what I mean
by the Monte Carlo part.

23
00:01:02,700 --> 00:01:06,417
So, when I use this picture on the
right, the little tree, all I'm trying

24
00:01:06,417 --> 00:01:10,028
to get you to think about with this
tree, is what we've done in the past.

25
00:01:10,028 --> 00:01:14,788
Say in an AI course, where you've
got nodes representing states.

26
00:01:14,788 --> 00:01:18,438
There are actions that you might take
that would get you to other states.

27
00:01:18,438 --> 00:01:22,290
And then more actions to get other
states and so on and so forth.

28
00:01:22,290 --> 00:01:25,790
But this particular tree has
a nice little form that's kind of

29
00:01:25,790 --> 00:01:29,580
hidden by the edges and the nodes, and
I want to harp on that for a little bit.

30
00:01:29,580 --> 00:01:32,680
And I think it would help if you
understand the algorithm that I'm trying

31
00:01:32,680 --> 00:01:34,590
to get through on this data structure.

32
00:01:34,590 --> 00:01:36,130
So the algorithm is written on the left,
and

33
00:01:36,130 --> 00:01:38,160
it's a big loop loop
loop loop loop loop loop.

34
00:01:38,160 --> 00:01:41,799
And it works like this, there are four
steps, the first step is selection.

35
00:01:42,870 --> 00:01:45,170
And I'll define what all
these things mean in but

36
00:01:45,170 --> 00:01:48,540
a moment, but I just want to go through
at a high level what each one is.

37
00:01:48,540 --> 00:01:50,480
So the first one is selection.

38
00:01:50,480 --> 00:01:54,701
And selection is basically
the way in which you're going to

39
00:01:54,701 --> 00:01:58,508
decide what actions to take
from a particular state.

40
00:01:58,508 --> 00:02:01,390
What's going to happen is you're
going to take a bunch of actions and

41
00:02:01,390 --> 00:02:03,738
eventually going to get to
some point in this tree here.

42
00:02:03,738 --> 00:02:06,624
Of possible states and
actions you might see,

43
00:02:06,624 --> 00:02:10,400
where you don't know enough to
know how to make a selection.

44
00:02:11,590 --> 00:02:14,860
Once you're at a place where you don't
exactly know how you should make

45
00:02:14,860 --> 00:02:18,300
a selection, the idea is that you're
going to expand the tree there.

46
00:02:19,620 --> 00:02:23,950
And then do simulation to figure out
what it is you ought to be doing

47
00:02:23,950 --> 00:02:25,610
to make selections.

48
00:02:25,610 --> 00:02:28,470
And the way that's going to happen,
is you're going to estimate

49
00:02:28,470 --> 00:02:33,850
from that expanded set of nodes the true
value of taking actions in those states.

50
00:02:33,850 --> 00:02:39,330
And then in a very kind of,
in a very Bellman equation way,

51
00:02:39,330 --> 00:02:41,820
you're going to back up what you
learned through your simulation.

52
00:02:41,820 --> 00:02:45,520
And then that will allow you
to select what to do next.

53
00:02:45,520 --> 00:02:47,020
And you'll just keep doing that over and

54
00:02:47,020 --> 00:02:50,590
over and over again making selections
where you know what to do.

55
00:02:50,590 --> 00:02:53,940
Expanding, simulating the world for
a little while, so

56
00:02:53,940 --> 00:02:58,150
that you learn what to do, and then make
those decisions, and so on and so forth.

57
00:02:58,150 --> 00:02:59,670
So does that makes sense
a very high level?

58
00:02:59,670 --> 00:03:01,230
See what I'm trying to accomplish here?

59
00:03:01,230 --> 00:03:02,210
>> Yeah I think so.

60
00:03:02,210 --> 00:03:03,900
>> Okay.
>> It reminds me of a lot of other

61
00:03:03,900 --> 00:03:06,550
kinds of tree search that
I've seen in AI classes.

62
00:03:06,550 --> 00:03:07,480
>> Like what?

63
00:03:07,480 --> 00:03:09,820
>> A star is a kind of tree search,

64
00:03:09,820 --> 00:03:11,490
a game tree search is
a kind of tree search.

65
00:03:11,490 --> 00:03:16,890
They have similar pictures where
you repeatedly expand nodes and

66
00:03:18,070 --> 00:03:19,840
get estimates of values.

67
00:03:19,840 --> 00:03:22,108
>> Right, and in fact I like the game
trees or the games search one.

68
00:03:22,108 --> 00:03:25,412
This is not game search because we're
living in an MVP, and it's just us, and

69
00:03:25,412 --> 00:03:27,278
so we're not playing
against an opponent.

70
00:03:27,278 --> 00:03:30,050
But something very nice
about that particular one,

71
00:03:30,050 --> 00:03:32,258
is the way it works in
that world often is.

72
00:03:32,258 --> 00:03:35,143
You have a particular way of
figuring out what action to take or

73
00:03:35,143 --> 00:03:38,208
you sort of expand and do a search
among a bunch of possibilities.

74
00:03:38,208 --> 00:03:40,597
And then eventually you run out of time,
and so

75
00:03:40,597 --> 00:03:44,590
you have to decide what the value is or
whatever leaf nodes you've gotten to.

76
00:03:44,590 --> 00:03:48,570
And the way you do that is use
something like an evaluation function,

77
00:03:48,570 --> 00:03:51,040
which tells you how good
we think this node is.

78
00:03:51,040 --> 00:03:53,550
And that's just what you
what you've got to work on.

79
00:03:53,550 --> 00:03:54,250
And you use that and

80
00:03:54,250 --> 00:03:58,340
you back up the values, that helps you
to make a decision about what to do.

81
00:03:58,340 --> 00:04:01,220
And then you make a decision,
then your opponent makes a decision,

82
00:04:01,220 --> 00:04:03,440
you end up in a state, and
you do it all over again.

83
00:04:03,440 --> 00:04:06,918
Basically you search out as far as
you have time to search out for.

84
00:04:06,918 --> 00:04:11,564
When you run out of time, you use some
estimate that you got from somewhere of

85
00:04:11,564 --> 00:04:14,478
how good the node is, and
then you back that up.

86
00:04:14,478 --> 00:04:16,860
And that's basically what
we're going to be doing here,

87
00:04:16,860 --> 00:04:18,730
except we have another wrinkle.

88
00:04:18,730 --> 00:04:21,670
And the wrinkle here is where
the Monte Carlo part comes in.

89
00:04:21,670 --> 00:04:23,538
So the tree search is very standard.

90
00:04:23,538 --> 00:04:26,543
The Monte Carlo part is,
well, we've got randomness,

91
00:04:26,543 --> 00:04:29,307
we've got stochasticity
in our transition model.

92
00:04:29,307 --> 00:04:32,127
And so we're going to have to
come up with some way to do this

93
00:04:32,127 --> 00:04:34,298
estimation that takes that into account.

94
00:04:34,298 --> 00:04:36,830
And that's where the simulation
is going to come from.

95
00:04:36,830 --> 00:04:39,120
All right, so
let's break that up in the little parts.

96
00:04:39,120 --> 00:04:40,590
Actually that's a lot of words,

97
00:04:40,590 --> 00:04:44,520
but I think walking through this
picture might help a little bit.
