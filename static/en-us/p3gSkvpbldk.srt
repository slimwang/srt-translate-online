1
00:00:00,025 --> 00:00:04,844
Well, one of the most direct effects of this universality finding was, it

2
00:00:04,844 --> 00:00:12,390
really opened up research on emotion in the face, and emotion more generally.

3
00:00:12,390 --> 00:00:15,888
Because for much of the 20th century, people had not studied emotion because it

4
00:00:15,888 --> 00:00:19,188
was considered something inherently subjective.

5
00:00:19,188 --> 00:00:19,619
>> Right.

6
00:00:19,619 --> 00:00:22,667
>> That you could not measure. And is, and if you think about what's been going on

7
00:00:22,667 --> 00:00:26,850
in psychology during this time, behaviorism, everything has to be observable.

8
00:00:26,850 --> 00:00:31,437
How could you study something as private as an, as an emotion? This finding on

9
00:00:31,437 --> 00:00:35,272
the face, suddenly suggested, which earlier research and psychology had not

10
00:00:35,272 --> 00:00:39,225
suggested, that there was reliable information about emotion in an observable

11
00:00:39,225 --> 00:00:45,460
immortality/g, in the face. So, it became clear that we could study emotions

12
00:00:45,460 --> 00:00:47,632
from the outside not just.

13
00:00:47,632 --> 00:00:48,185
>> Right.

14
00:00:48,185 --> 00:00:52,353
>> From the inside. And in order to kind of, potentatiate this work, make it more

15
00:00:52,353 --> 00:00:56,433
likely, Eckman and Freezen developed a measurement tool to enable the objective

16
00:00:56,433 --> 00:01:03,095
studying of facial feature from the outside. They developed. The Facial Action

17
00:01:03,095 --> 00:01:09,274
Coding System, the acronym for that is FACS, or FACS. Which is an elaborate,

18
00:01:09,274 --> 00:01:13,837
detailed observational system. Observational meaning it relies on human

19
00:01:13,837 --> 00:01:19,860
observation, to code all observable facial movement. Without saying, what it

20
00:01:19,860 --> 00:01:24,666
is, so it's purely descriptive. And that really opened up an enormous amount of

21
00:01:24,666 --> 00:01:28,552
opportunity in emotion research to set emotional behavior objectively to do it

22
00:01:28,552 --> 00:01:33,562
without drawing people's attention to it. You know, because you could video

23
00:01:33,562 --> 00:01:36,075
record and then code the behavior later.

24
00:01:36,075 --> 00:01:39,854
>> Each emotional expression has a unique pattern of facial.

25
00:01:39,854 --> 00:01:43,330
>> Right, but it's important to understand that facts is not just for emotion.

26
00:01:43,330 --> 00:01:47,670
Facts is for describing facial movement. You can see which actions occur

27
00:01:47,670 --> 00:01:51,994
together to describe any expression on the face. So, I'm going to give another

28
00:01:51,994 --> 00:01:56,642
little demonstration right now. Let me back up. FACS, describes all facial

29
00:01:56,642 --> 00:02:02,814
muscle actions in terms of arbitrary action units. So it separates all facial

30
00:02:02,814 --> 00:02:07,035
behavior in terms of what each muscle does. So if I lift the inner corner of

31
00:02:07,035 --> 00:02:12,128
the eyebrow. That's one action. Each action has an arbitrary numeric code. So

32
00:02:12,128 --> 00:02:19,400
this is action unit one. This is two. This is four. This is five. This is six.

33
00:02:19,400 --> 00:02:22,564
I could go through the whole face. There are 44 different action units to

34
00:02:22,564 --> 00:02:26,640
describe. The individual components of facial action, and then you can, see

35
00:02:26,640 --> 00:02:31,650
whatever the face does and describe it in terms of these components. So, if I

36
00:02:31,650 --> 00:02:39,684
take one of the, emotion expressions that I modeled earlier, like anger. This

37
00:02:39,684 --> 00:02:44,087
has the brow lower, which is actually unit four. Lifting the upper eyelid is

38
00:02:44,087 --> 00:02:49,295
action unit five, tightening the lower eyelid is seven, pressing the lips

39
00:02:49,295 --> 00:02:54,251
together and pushing the chin up is 17 and 24 so we have a 4, 5, 7,17 and 24,

40
00:02:54,251 --> 00:03:00,612
so you can describe any facial action.

41
00:03:00,612 --> 00:03:00,964
>> Right.

42
00:03:00,964 --> 00:03:05,122
>> And one of the interesting applications of the facial action code in system has

43
00:03:05,122 --> 00:03:10,527
been in computer animation. In fact its become the gold standard in on the

44
00:03:10,527 --> 00:03:14,929
visual effects industry for developing virtual beings, virtual actors you know

45
00:03:14,929 --> 00:03:18,525
it was used in Avatar, it was used in, in Harry Porter was used in, in any

46
00:03:18,525 --> 00:03:23,895
animated creature they use the action units.

47
00:03:23,895 --> 00:03:24,015
>> Yeah.

48
00:03:24,015 --> 00:03:26,074
>> As the basis for animating our faces.

49
00:03:26,074 --> 00:03:29,194
>> So, in fact, yeah, that leads to my next question, which is can you tell us

50
00:03:29,194 --> 00:03:32,678
something about how you've applied FACS or Facial Action Coding Systems in your

51
00:03:32,678 --> 00:03:34,745
own work?

52
00:03:34,745 --> 00:03:38,573
>> It's been really interesting because my original intent was to study emotion,

53
00:03:38,573 --> 00:03:43,405
and that's why I got into studying the face. So, I've applied FACS to my own

54
00:03:43,405 --> 00:03:47,053
research on emotion where I've looked at things like the role of anger and

55
00:03:47,053 --> 00:03:52,361
heart disease but that was my dissertation research. I've also looked at the

56
00:03:52,361 --> 00:03:55,497
relationship between facial expression and people's reports of emotional

57
00:03:55,497 --> 00:04:00,705
experience. And how emotions change as a function of more recently meditation

58
00:04:00,705 --> 00:04:07,000
training. So that's in my research but as a result of becoming expert in facts.

59
00:04:07,000 --> 00:04:09,624
I've learned that a lot of people are interested in this measurement tool for

60
00:04:09,624 --> 00:04:13,562
other reasons. So I've trained animators. Like people who do visual effects

61
00:04:13,562 --> 00:04:18,425
animation. I worked on the television show "Lie to Me" which was on from 2009

62
00:04:18,425 --> 00:04:26,286
to 2011 on FOX. And this was a drama based on, Really, Paul Eckman's career. So

63
00:04:26,286 --> 00:04:30,738
that the lead character in that, was a deception detection expert. And the

64
00:04:30,738 --> 00:04:34,515
field of deception detection depends a lot on facial movement detection. So I

65
00:04:34,515 --> 00:04:37,980
was a scientifical consultant on that show, reading scripts, coaching the

66
00:04:37,980 --> 00:04:41,900
actors, etcetera. So it's really run the gamut it from basic research to

67
00:04:41,900 --> 00:04:46,913
something really applied, like in the entertainment industry. And, sort of a, a

68
00:04:46,913 --> 00:04:50,477
continuous thing throughout all of those is, is facts, the facial measurement

69
00:04:50,477 --> 00:04:54,749
and, and the kinds of people I've trained in that, in that.

70
00:04:54,749 --> 00:04:55,351
>> Right.

71
00:04:55,351 --> 00:04:55,557
>> Yeah.

72
00:04:55,557 --> 00:04:55,789
>> Great.

73
00:04:55,789 --> 00:04:59,199
>> Well thank you, I hope you've enjoyed this, and also see how psychology can

74
00:04:59,199 --> 00:05:04,204
applied in a lot of different areas and ways that you may not have expected.
