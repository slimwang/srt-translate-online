1
00:00:00,320 --> 00:00:02,460
So let's take a look at an example of using

2
00:00:02,460 --> 00:00:05,900
the aggregation framework. To answer some questions about our data,

3
00:00:07,120 --> 00:00:10,180
let's find out how we could use the aggregation framework,

4
00:00:10,180 --> 00:00:13,990
to determine which user in our data set, has produced the

5
00:00:13,990 --> 00:00:17,371
most tweets. Now, let's talk about the process we would

6
00:00:17,371 --> 00:00:20,090
like the database to perform for us. So given the

7
00:00:20,090 --> 00:00:22,320
way our data is laid out, the first thing we're

8
00:00:22,320 --> 00:00:25,820
going to want to do is group the tweets by user.

9
00:00:25,820 --> 00:00:28,630
Remember, each tweet, has the user as

10
00:00:28,630 --> 00:00:31,130
a field within it. Then we're going to want to

11
00:00:31,130 --> 00:00:35,670
count each user's tweets, and finally, select the

12
00:00:35,670 --> 00:00:39,450
user with the most tweets. Now, let's rethink

13
00:00:39,450 --> 00:00:42,330
this third step. What's probably going to be

14
00:00:42,330 --> 00:00:45,400
most valuable, is not just seeing the one

15
00:00:45,400 --> 00:00:49,700
person who's tweeted the most, but instead, counting

16
00:00:49,700 --> 00:00:52,140
the number of tweets for each user, and

17
00:00:52,140 --> 00:00:55,760
then sorting them. If we sort into descending order,

18
00:00:55,760 --> 00:00:57,930
the person at the top, will be the one

19
00:00:57,930 --> 00:01:01,270
with the most tweets. So our process is really

20
00:01:01,270 --> 00:01:04,720
group all tweets by user, count each user's tweets,

21
00:01:04,720 --> 00:01:08,500
sort into descending order, and then, select the user

22
00:01:08,500 --> 00:01:12,160
at the top. Okay. So, with this process outlined,

23
00:01:12,160 --> 00:01:13,820
let's take a look at how we would express

24
00:01:13,820 --> 00:01:17,240
this in the aggregation framework. And, we'll use this as

25
00:01:17,240 --> 00:01:20,220
an example, to launch our exploration of the

26
00:01:20,220 --> 00:01:23,840
aggregation framework in MongoDB. Okay. So, aggregation queries

27
00:01:23,840 --> 00:01:28,440
in MongoDB are issued using the aggregate command.

28
00:01:28,440 --> 00:01:30,250
And, we'll talk about this in just a

29
00:01:30,250 --> 00:01:33,950
bit. But aggregations are done with a pipeline.

30
00:01:33,950 --> 00:01:35,500
And a pipeline is essentially a series of

31
00:01:35,500 --> 00:01:39,130
stages, that are included as elements of an

32
00:01:39,130 --> 00:01:42,510
array, that's passed through aggregate as a parameter.

33
00:01:42,510 --> 00:01:48,000
Okay, so the first thing we need to do is group. Now, here we're going to use

34
00:01:48,000 --> 00:01:50,760
the group operator in this first stage of our

35
00:01:50,760 --> 00:01:54,070
aggregation pipeline. And the way we're going to group,

36
00:01:54,070 --> 00:01:58,160
is based on a user's screen name. Let's briefly

37
00:01:58,160 --> 00:01:59,830
go back, and take a look at the data.

38
00:02:01,200 --> 00:02:04,110
Remember that, all of our tweets have a user

39
00:02:04,110 --> 00:02:07,860
field. And that user field is actually a nested

40
00:02:07,860 --> 00:02:11,280
document, that contains a screen name. Okay, so

41
00:02:11,280 --> 00:02:14,560
if we go back to our aggregation query, we

42
00:02:14,560 --> 00:02:15,880
can see that we're saying for the user

43
00:02:15,880 --> 00:02:20,270
sub document, I want the screen name field. Okay,

44
00:02:20,270 --> 00:02:22,940
so what's this about? Well, this isn't an

45
00:02:22,940 --> 00:02:26,600
operator. Instead, what this means is, so even though

46
00:02:26,600 --> 00:02:30,760
it's inside quotes, don't interpret this as a string.

47
00:02:30,760 --> 00:02:35,200
That is to say, don't make the ID user.screen_name.

48
00:02:35,200 --> 00:02:39,320
Rather, group together all documents where the value of

49
00:02:39,320 --> 00:02:42,520
screen name for the user sub document. That's what

50
00:02:42,520 --> 00:02:45,520
this dollar says should happen here. Where the value

51
00:02:45,520 --> 00:02:49,116
of this is the same. So, all tweets that

52
00:02:49,116 --> 00:02:51,700
have this, the same value for this field will

53
00:02:51,700 --> 00:02:55,090
be grouped together. And then we need an accumulator

54
00:02:55,090 --> 00:02:57,100
of some kind. There are a number of different

55
00:02:57,100 --> 00:03:00,880
accumulator operators that we can use. What this means is,

56
00:03:00,880 --> 00:03:03,480
for every document that has the same

57
00:03:03,480 --> 00:03:08,480
value for this field, increment this value, count,

58
00:03:08,480 --> 00:03:11,240
by one. That's the semantics of this.

59
00:03:11,240 --> 00:03:15,630
So, this accomplishes those first 2 steps that

60
00:03:15,630 --> 00:03:21,170
we talked about here, group tweets by user, and count each user's tweets. Then

61
00:03:21,170 --> 00:03:25,740
the next thing that's going to happen, is we'll simply do a sort. And this says,

62
00:03:25,740 --> 00:03:28,820
sort based on the count of the documents that are

63
00:03:28,820 --> 00:03:32,650
passed into this stage, and sort into descending order. Okay,

64
00:03:32,650 --> 00:03:34,580
what do I mean by the documents passed into this

65
00:03:34,580 --> 00:03:38,410
stage? Well, the reason why this is called a pipeline, is

66
00:03:38,410 --> 00:03:41,850
because each stage receives a set of input documents and

67
00:03:41,850 --> 00:03:43,640
produces a set of output documents, so we'll talk a

68
00:03:43,640 --> 00:03:46,530
little bit more about that later. The input documents to

69
00:03:46,530 --> 00:03:51,240
this stage that uses this sort operator, are the documents output,

70
00:03:51,240 --> 00:03:55,640
by the stage that uses the group operator. So

71
00:03:55,640 --> 00:03:58,580
what we end up with, for this stage, is a

72
00:03:58,580 --> 00:04:01,270
bunch of documents that have a underscore ID field,

73
00:04:01,270 --> 00:04:05,270
and account field. And this stage of the pipeline, is

74
00:04:05,270 --> 00:04:08,620
going to sort those documents, based on the value

75
00:04:08,620 --> 00:04:11,592
of their count field. Okay, now, if you didn't catch

76
00:04:11,592 --> 00:04:13,970
all that, don't worry about it. Because we are

77
00:04:13,970 --> 00:04:16,510
going to dive into all the bits and pieces here,

78
00:04:16,510 --> 00:04:19,279
as we move through this lesson. Let's go ahead and run

79
00:04:19,279 --> 00:04:22,269
this code, and see what it produces. Now I'm simply going to

80
00:04:22,269 --> 00:04:25,340
pipe this to the system program less, so that I can

81
00:04:25,340 --> 00:04:29,670
see the very top of the results that are produced. Okay? The

82
00:04:29,670 --> 00:04:33,200
results from an aggregation query are always a single document. It

83
00:04:33,200 --> 00:04:35,930
is the result field of that return document that we're interested

84
00:04:35,930 --> 00:04:38,890
in. And here we can see that what was outputted, are

85
00:04:38,890 --> 00:04:41,560
exactly the documents that were passed to the sort stage or our

86
00:04:41,560 --> 00:04:44,630
aggregation query. They each have an underscore ID field, and

87
00:04:44,630 --> 00:04:47,080
a count associated with them. And they've been sorted into

88
00:04:47,080 --> 00:04:50,830
descending order. Now, note that there's only 8. Or rather,

89
00:04:50,830 --> 00:04:52,725
that the maximum number of tweets for an individual user is

90
00:04:52,725 --> 00:04:55,730
8, okay? This data set is a snapshot from a

91
00:04:55,730 --> 00:04:59,080
relatively short period of time. So that's why these counts are

92
00:04:59,080 --> 00:05:02,600
fairly small. As we move through this lesson, we'll take

93
00:05:02,600 --> 00:05:06,770
a closer look at the aggregation pipeline, at what it means

94
00:05:06,770 --> 00:05:10,370
to have stages within that pipeline, and at the various aggregation

95
00:05:10,370 --> 00:05:14,130
operators that are available to us, as well as other operators,

96
00:05:14,130 --> 00:05:17,040
such as accumulator operators, that we can use in the group

97
00:05:17,040 --> 00:05:21,140
stage, and other sorts of operators we use elsewhere in aggregation queries.
