1
00:00:00,480 --> 00:00:02,340
Okay Michael. So let's try to be a little bit

2
00:00:02,340 --> 00:00:05,580
more detailed about, kind of, the mechanics of how you, how

3
00:00:05,580 --> 00:00:09,710
you would make this work. The algorithms for finding Independent Components

4
00:00:09,710 --> 00:00:12,100
Analysis, are in all the reading. But, I do think it's

5
00:00:12,100 --> 00:00:14,420
pretty easy to kind of get lost. If you don't, sort

6
00:00:14,420 --> 00:00:17,170
of, turn these matrices into actual numbers. So, let me just,

7
00:00:17,170 --> 00:00:18,880
sort of, give you a quick example of how we would

8
00:00:18,880 --> 00:00:21,770
do this specific thing here. And see if that helps, okay?

9
00:00:21,770 --> 00:00:22,746
>> Mm-hm.

10
00:00:22,746 --> 00:00:25,490
>> Okay. So, how would you go about turning

11
00:00:25,490 --> 00:00:27,760
this into a problem that something like, you

12
00:00:27,760 --> 00:00:30,670
know, an actual algorithm that uses numbers could

13
00:00:30,670 --> 00:00:32,940
do. Well, it turns out it's fairly straightforward.

14
00:00:32,940 --> 00:00:34,910
And let's just take this, this particular example

15
00:00:34,910 --> 00:00:37,920
here, with people talking into a microphone. Basically

16
00:00:37,920 --> 00:00:40,720
you create a matrix. Which are samples of

17
00:00:40,720 --> 00:00:42,720
all of the sounds. So, in our original

18
00:00:42,720 --> 00:00:46,110
space, we have, you know, this handsome person here.

19
00:00:48,630 --> 00:00:51,380
We have this other, let's say, similarly handsome but in a

20
00:00:51,380 --> 00:00:55,400
different way person here, and we have this other person, with

21
00:00:55,400 --> 00:00:59,680
my poor attempt to draw hair over here, and they're talking.

22
00:00:59,680 --> 00:01:02,700
Well, what we end up doing is we basically take the sound

23
00:01:02,700 --> 00:01:05,010
wave and we sample it. And what does it mean to

24
00:01:05,010 --> 00:01:08,700
sample it? Well, you know, you represent sound in a computer as

25
00:01:08,700 --> 00:01:11,150
a sequence of numbers, just like you represent pictures as a

26
00:01:11,150 --> 00:01:13,780
sequence of numbers, and in fact, you represent words as a sequence

27
00:01:13,780 --> 00:01:16,330
of numbers. And so we basically turn these sound waves

28
00:01:16,330 --> 00:01:18,900
into a matrix full of values. So, as I described

29
00:01:18,900 --> 00:01:22,410
before, Michael, each one of these microphones. Is actually getting

30
00:01:22,410 --> 00:01:25,570
a linear combination of speech from each of these three

31
00:01:25,570 --> 00:01:28,970
individuals. So if we think of microphone one, it is

32
00:01:28,970 --> 00:01:32,520
seeing some kind of sound wave, which is again a

33
00:01:32,520 --> 00:01:35,540
linear combination from each of these people generating a sound

34
00:01:35,540 --> 00:01:40,160
wave. The same is true for microphone two and similarly.

35
00:01:40,160 --> 00:01:43,670
For microphone three. Now, of course, we're talking about recording

36
00:01:43,670 --> 00:01:46,240
these and we're thinking about computer programs, which means we take

37
00:01:46,240 --> 00:01:49,890
this continuous sound wave and we sample it at a very

38
00:01:49,890 --> 00:01:52,530
fast rate. And what we end up with is a sequence

39
00:01:52,530 --> 00:01:56,750
of numbers that represent the particular pressure that we're getting

40
00:01:56,750 --> 00:02:00,360
in these sound waves. So, these sound waves get converted into

41
00:02:00,360 --> 00:02:02,830
a sequence of numbers and I'm just going to make up some

42
00:02:02,830 --> 00:02:05,900
numbers for this. And now what we have is a matrix

43
00:02:05,900 --> 00:02:09,690
where each row represents a feature in our original feature space.

44
00:02:09,690 --> 00:02:12,230
And by original here, I mean, the feature space that we

45
00:02:12,230 --> 00:02:17,594
see each of our microphones and every column represents a sample. Say

46
00:02:17,594 --> 00:02:23,180
at time0, time1, time2, and so on. Does that make sense?

47
00:02:23,180 --> 00:02:27,060
>> Yes. And so, since each of these is a linear combination

48
00:02:27,060 --> 00:02:31,100
of these voices we get here. Our goal is to find a projection

49
00:02:31,100 --> 00:02:33,350
like we did before and the original definition of the

50
00:02:33,350 --> 00:02:37,590
problem, such that if we projected this on to here, we

51
00:02:37,590 --> 00:02:41,440
would end up with a new feature space that corresponds individually

52
00:02:41,440 --> 00:02:43,570
to each of these people. And you could do this with

53
00:02:43,570 --> 00:02:45,320
anything, it doesn't have to be sounds, but if we think

54
00:02:45,320 --> 00:02:49,450
about the. Adhoc query problem that we went through earlier, each

55
00:02:49,450 --> 00:02:53,540
of these would be words, and say their presence of words

56
00:02:53,540 --> 00:02:56,350
would be your features, and each of these columns would be

57
00:02:56,350 --> 00:02:58,550
documents, say. And the goal would be to find

58
00:02:58,550 --> 00:03:01,450
a projection given a set of documents that allowed

59
00:03:01,450 --> 00:03:04,620
us to recover some underlying structure that was useful

60
00:03:04,620 --> 00:03:09,010
for classification, or for information retrieval. Does that make sense?

61
00:03:09,010 --> 00:03:10,930
>> Yeah. And can you say, what does

62
00:03:10,930 --> 00:03:14,320
it mean for that sequence to have mutual information?

63
00:03:15,730 --> 00:03:19,050
>> so as you recall. Because I know that you listen to Push Cars.

64
00:03:21,090 --> 00:03:24,060
A discussion about mutual information and entropy and so

65
00:03:24,060 --> 00:03:27,990
forth. All mutual information is is a measure of

66
00:03:27,990 --> 00:03:30,429
how much one variable tells you about another variable.

67
00:03:31,540 --> 00:03:35,460
And, the assumption here is that each of these people

68
00:03:35,460 --> 00:03:38,950
talking has no mutual information. That is, they're talking

69
00:03:38,950 --> 00:03:41,790
independently of one another, or the sounds that are coming

70
00:03:41,790 --> 00:03:44,110
out of their mouths, don't allow us to predict

71
00:03:44,110 --> 00:03:46,340
the sounds that are going to come out of another

72
00:03:46,340 --> 00:03:48,610
persons mouth. So it may mean that these people are

73
00:03:48,610 --> 00:03:50,960
talking to one another as we often do, Charles might

74
00:03:50,960 --> 00:03:52,880
be talking to Michael, who's talking to push cars, who's

75
00:03:52,880 --> 00:03:56,510
talking back to Michael, who's talking. To Charles, but the exact

76
00:03:56,510 --> 00:03:59,550
sound waves that we see are actually independent of one

77
00:03:59,550 --> 00:04:03,750
another. So if that turns out to be true, what independent

78
00:04:03,750 --> 00:04:06,380
component analysis is trying to do is trying to recover

79
00:04:06,380 --> 00:04:11,080
features, in this case. It turns out the corresponding individual speakers,

80
00:04:11,080 --> 00:04:13,190
such that their sound waves, or the values

81
00:04:13,190 --> 00:04:16,820
that you see, are statistically independent of one another.

82
00:04:16,820 --> 00:04:19,610
Okay? And that's what this does. But, since

83
00:04:19,610 --> 00:04:22,450
we can always come up with arbitrary projections that

84
00:04:22,450 --> 00:04:25,600
are statistically independent, it's important that whatever our

85
00:04:25,600 --> 00:04:30,340
new transformation gives us. It actually has some relationship

86
00:04:30,340 --> 00:04:33,950
with the original values that we saw. So some

87
00:04:33,950 --> 00:04:36,230
how we want to be able to learn from this,

88
00:04:36,230 --> 00:04:38,520
into this in a way that we don't lose any

89
00:04:38,520 --> 00:04:41,170
information. In much the same way that PCA was trying to

90
00:04:41,170 --> 00:04:44,190
minimize the loss of information, and so we not only want

91
00:04:44,190 --> 00:04:47,300
each of the individual new features, in this case people to

92
00:04:47,300 --> 00:04:50,270
be statistically independent, we want the amount of data that we

93
00:04:50,270 --> 00:04:52,960
get from these people. Compared to the amount of data that

94
00:04:52,960 --> 00:04:56,400
we got originally from the microphones, to actually strongly predict one

95
00:04:56,400 --> 00:05:01,750
another. And if the mutual information between the microphones and our

96
00:05:01,750 --> 00:05:05,360
candidates for the people's voices have high mutual information, then

97
00:05:05,360 --> 00:05:07,870
it means that we haven't lost anything. And so those

98
00:05:07,870 --> 00:05:11,390
two things together, those two constraints. Forces into a situation

99
00:05:11,390 --> 00:05:14,940
where, if this model is true, we construct the original voices.
