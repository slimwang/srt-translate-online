1
00:00:00,380 --> 00:00:02,890
We're not going to get a chance to talk
about a lot of the details on this

2
00:00:02,890 --> 00:00:06,970
though it's just a great example of
reinforcement learning applied to

3
00:00:06,970 --> 00:00:09,730
a difficult problem and
clever engineering tricks.

4
00:00:09,730 --> 00:00:13,340
The one thing that's worth noting
is that in addition to using deep

5
00:00:13,340 --> 00:00:15,750
nets which are kind of
in vogue at the moment,

6
00:00:15,750 --> 00:00:19,530
they also did a couple other things in
changing the way that training happened.

7
00:00:19,530 --> 00:00:21,630
That I think were really,
really important for

8
00:00:21,630 --> 00:00:23,660
getting the kinds of
results that they got.

9
00:00:23,660 --> 00:00:26,210
And so it wasn't just a matter of hey,
let's just use Deep Nets.

10
00:00:26,210 --> 00:00:29,380
It was like Deep Nets plus
really careful training so

11
00:00:29,380 --> 00:00:32,159
that you don't get these kinds
of catastrophic death spirals,

12
00:00:32,159 --> 00:00:35,160
like again what my students and I have
tended to see when we try this stuff.

13
00:00:35,160 --> 00:00:39,350
So this kind of doesn't
work successes story,

14
00:00:39,350 --> 00:00:41,520
is not really the end of the story.

15
00:00:41,520 --> 00:00:44,690
In the sense that, well, so
we assign some some reading.

16
00:00:44,690 --> 00:00:47,680
I think these were reading
associated with this current lesson.

17
00:00:47,680 --> 00:00:49,500
Three papers, Tesauro,
Boyan and Moore and

18
00:00:49,500 --> 00:00:53,360
Sutton which kind of tell
an interesting story which is, I think,

19
00:00:53,360 --> 00:00:57,560
a really nice summary of what
the state of the art is here.

20
00:00:57,560 --> 00:01:00,130
So, Gerry Tesauro got
TD-Gammon to work really well.

21
00:01:00,130 --> 00:01:02,140
So that's a three layer
back prop net for

22
00:01:02,140 --> 00:01:05,690
learning to choose moves in
Backgammon and it worked great.

23
00:01:05,690 --> 00:01:07,340
So everybody thought,
hey everything works great.

24
00:01:07,340 --> 00:01:10,090
So then Boyan and Moore wrote
a paper where they showed that

25
00:01:10,090 --> 00:01:14,410
there's some very simple examples
where things ought to work well but

26
00:01:14,410 --> 00:01:17,430
they need not,
they can actually work extremely poorly.

27
00:01:17,430 --> 00:01:20,040
Using this general approach
of substituting in

28
00:01:20,040 --> 00:01:24,280
a function approximator for a Q
function can lead to terrible results.

29
00:01:24,280 --> 00:01:25,506
So, it need not work.

30
00:01:25,506 --> 00:01:30,240
Then Sutton had a reply to that where
he published a paper that said, yeah,

31
00:01:30,240 --> 00:01:32,850
but you can,
you can do it if you do it right.

32
00:01:32,850 --> 00:01:35,990
So, he actually replicated
the same results that Boyan and

33
00:01:35,990 --> 00:01:39,710
Moore showed, not working and showed
that if you change the way the training

34
00:01:39,710 --> 00:01:42,190
happens you can get those
particular things to work, but

35
00:01:42,190 --> 00:01:46,085
this really is just, the argument is it
need not work, but it need not not work.

36
00:01:46,085 --> 00:01:49,620
[LAUGH] Which is not really
a very strong kind of guarantee.

37
00:01:49,620 --> 00:01:51,880
It's not like it has to work or
it has to not work.

38
00:01:51,880 --> 00:01:55,940
So this is kind of where we are now
in terms of our understanding.

39
00:01:55,940 --> 00:01:57,620
>> So
what's the Pollack thing at the bottom?

40
00:01:57,620 --> 00:01:58,240
>> Pollack?

41
00:01:58,240 --> 00:02:00,030
Sorry, so yes.

42
00:02:00,030 --> 00:02:03,390
I just wanted to point out that
why did backgammon work so well?

43
00:02:03,390 --> 00:02:06,630
It might not have just been the fact
that it was reinforcement learning,

44
00:02:06,630 --> 00:02:10,100
it might have been, well backgammon is
kind of a good thing to learn this way.

45
00:02:10,100 --> 00:02:14,810
So, Jordan Pollack had a paper where he
showed that genetic algorithms can also

46
00:02:14,810 --> 00:02:17,460
do particularly well in
backgammon in particular.

47
00:02:17,460 --> 00:02:19,940
So, it might not have been
that Jerry Tesauro discovered

48
00:02:19,940 --> 00:02:21,330
that TD is really great,

49
00:02:21,330 --> 00:02:25,270
he might have discovered that backgammon
is really great as a test bed for TD.

50
00:02:25,270 --> 00:02:26,398
>> Yeah, I remember that.

51
00:02:26,398 --> 00:02:28,976
In fact the argument that Jordan
made was that because it's so

52
00:02:28,976 --> 00:02:31,209
random it forces you to do
all kinds of exploration and

53
00:02:31,209 --> 00:02:33,008
keep you from falling
into certain traps.

54
00:02:33,008 --> 00:02:39,076
That made generalization powerful and
in fact if we compared to Isabelle's

55
00:02:39,076 --> 00:02:46,040
master thesis work on something that you
thought was simpler, like tic tac toe.

56
00:02:46,040 --> 00:02:49,230
It actually doesn't do terribly well on
tic tac toe, and that's because it's so

57
00:02:49,230 --> 00:02:51,580
deterministic there's huge
chunks of the state space,

58
00:02:51,580 --> 00:02:55,310
you kind of never see even when you're
trying to do this generalization.

59
00:02:55,310 --> 00:02:55,940
>> Yeah.
Okay.

60
00:02:55,940 --> 00:02:59,900
And I would summarize that by saying
that nearby states in tic tac toe don't

61
00:02:59,900 --> 00:03:01,490
necessarily have nearby values.

62
00:03:01,490 --> 00:03:04,840
You just move one x to
a different place on the grid.

63
00:03:04,840 --> 00:03:06,926
And the whole gameplay
is very very different.

64
00:03:06,926 --> 00:03:09,760
Backgammon, because it has such
a tremendously influential random

65
00:03:09,760 --> 00:03:10,580
component.

66
00:03:10,580 --> 00:03:13,450
If you move one piece,
it can change things but

67
00:03:13,450 --> 00:03:15,750
it's not going to change
things you know night and day,

68
00:03:15,750 --> 00:03:19,550
it's going to change things gradually
and so that kind of gradualness means

69
00:03:19,550 --> 00:03:22,890
that function approximation is probably
going to, well could at least work out.

70
00:03:22,890 --> 00:03:24,800
>> Maybe,
it's certainly a good argument.
