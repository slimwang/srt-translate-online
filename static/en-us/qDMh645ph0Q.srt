1
00:00:00,170 --> 00:00:02,570
>> So, we've answered the thing about continuous attributes.

2
00:00:02,570 --> 00:00:05,670
Now, here's another thing. When do we really stop?

3
00:00:05,670 --> 00:00:09,040
>> When we get all the answers right. When

4
00:00:09,040 --> 00:00:14,365
all the training examples are in the right category. Class.

5
00:00:14,365 --> 00:00:15,090
>> Right, so the the answer in

6
00:00:15,090 --> 00:00:18,490
the algorithm is when everything is classified correctly.

7
00:00:20,570 --> 00:00:23,840
That's a pretty good answer, Michael. But what if we have

8
00:00:23,840 --> 00:00:27,000
noise in our data? What if it's the case that we

9
00:00:27,000 --> 00:00:31,290
have two examples of the same object, the same instance, but

10
00:00:31,290 --> 00:00:33,620
they have two different labels? Then this will never be the case.

11
00:00:33,620 --> 00:00:38,720
>> Oh. So, then our algorithm goes into an infinite loop.

12
00:00:38,720 --> 00:00:40,480
>> Which seems like a bad idea.

13
00:00:40,480 --> 00:00:41,540
>> So we could have, we could, we could

14
00:00:41,540 --> 00:00:44,643
just say, or we've run out of attributes. [LAUGH]

15
00:00:44,643 --> 00:00:45,650
>> [LAUGH] Or we've run out

16
00:00:45,650 --> 00:00:46,970
of attributes. That's one way of doing

17
00:00:46,970 --> 00:00:48,450
it. In fact, that, that was, that's going to

18
00:00:48,450 --> 00:00:50,150
have to happen at some point, right?

19
00:00:50,150 --> 00:00:52,690
That's probably a slightly better answer. Although that

20
00:00:52,690 --> 00:00:55,610
doesn't help us in the case where we have continuous attributes and we might ask

21
00:00:55,610 --> 00:00:57,480
an infinite number of questions. So we probably

22
00:00:57,480 --> 00:01:00,880
need a slightly better criteria. Don't you think?

23
00:01:00,880 --> 00:01:01,950
>> Hm.

24
00:01:01,950 --> 00:01:05,860
>> So, what got us down this path, was thinking about what happens

25
00:01:05,860 --> 00:01:10,420
if we have noise. Why would we be worried about having noise anyway?

26
00:01:10,420 --> 00:01:11,110
>> Noise anyway.

27
00:01:11,110 --> 00:01:15,210
Well, I guess the training data might have gotten corrupted

28
00:01:15,210 --> 00:01:18,420
a little bit or maybe somebody copied something down wrong.

29
00:01:18,420 --> 00:01:21,470
>> Right, so since that's always a possibility,

30
00:01:21,470 --> 00:01:25,540
does it really make sense to trust the

31
00:01:25,540 --> 00:01:27,780
data completely, and go all the way to

32
00:01:27,780 --> 00:01:33,480
the point where we perfectly classify the training data?

33
00:01:33,480 --> 00:01:36,270
>> But Charles, if we can't trust our data, what can we trust?

34
00:01:36,270 --> 00:01:40,100
>> Well, we can trust our data, but we want to verify. [LAUGH]

35
00:01:40,100 --> 00:01:43,160
The whole point is generalization. And if it's possible for us to have

36
00:01:43,160 --> 00:01:46,260
a little bit of noise in the data, an error here or there,

37
00:01:46,260 --> 00:01:49,190
then we want to have some way to deal to handle that possibility, right?

38
00:01:49,190 --> 00:01:50,340
>> I guess so.

39
00:01:50,340 --> 00:01:52,060
>> So, what will we do?

40
00:01:52,060 --> 00:01:55,790
>> [LAUGH] I mean, we actually have a name for this, right? When you get

41
00:01:55,790 --> 00:01:58,750
really, really, really good at classifying your training

42
00:01:58,750 --> 00:02:01,270
data, but it doesn't help you to generalize,

43
00:02:01,270 --> 00:02:02,880
we have a name for that.

44
00:02:02,880 --> 00:02:05,910
>> Right. That sounds like overfitting.

45
00:02:05,910 --> 00:02:08,324
>> Exactly. We have to worry about overfitting.

46
00:02:09,410 --> 00:02:11,890
So you can overfit with the decision tree too?

47
00:02:11,890 --> 00:02:13,910
>> Yeah. What, you don't believe that?

48
00:02:13,910 --> 00:02:17,490
>> No, no, no. I was, I was being naive, I was being,

49
00:02:17,490 --> 00:02:19,685
I know that you can overfit a decision tree. [LAUGH] I was just.

50
00:02:19,685 --> 00:02:21,610
>> [LAUGH] Yeah but your [SOUND] is the [SOUND] that

51
00:02:21,610 --> 00:02:23,050
you use when you're, when you're like, I don't believe what

52
00:02:23,050 --> 00:02:24,500
you just said Charles, but I'm going to go along with

53
00:02:24,500 --> 00:02:26,370
it anyway, because I have to get off the phone soon.

54
00:02:26,370 --> 00:02:30,730
>> [LAUGH] Fair enough. I'll try to,

55
00:02:30,730 --> 00:02:32,770
I'll try to have a different personality then.

56
00:02:32,770 --> 00:02:35,380
>> [LAUGH] Okay, step one, have a

57
00:02:35,380 --> 00:02:39,010
different personality with maximal information gain. Okay, so

58
00:02:39,010 --> 00:02:42,550
we don't want to, we don't want to overfit. So we need to come up with some

59
00:02:42,550 --> 00:02:47,210
way of overfitting. Now the way you overfit in a decision tree is basically by

60
00:02:47,210 --> 00:02:48,700
having a tree that's too big, it's

61
00:02:48,700 --> 00:02:54,220
too complicated. All right. Violates Occam's Razor. So,

62
00:02:54,220 --> 00:02:58,980
what's a kind of, let's say, modification to something like ID3

63
00:02:58,980 --> 00:03:02,520
to our decision tree algorithm that will help us to avoid overfitting?

64
00:03:02,520 --> 00:03:04,260
>> Well last time we talked about overfitting,

65
00:03:04,260 --> 00:03:06,910
we said cross-validation was a good way of dealing

66
00:03:06,910 --> 00:03:09,400
with it, which, it allowed us to choose

67
00:03:09,400 --> 00:03:13,060
from among the different, say degrees of the polynomial.

68
00:03:13,060 --> 00:03:13,260
>> Right.

69
00:03:13,260 --> 00:03:15,870
>> So maybe we could do something like that?

70
00:03:15,870 --> 00:03:19,390
I don't know. Try all the different trees and,

71
00:03:19,390 --> 00:03:20,830
see which one has the lowest cross

72
00:03:20,830 --> 00:03:23,790
validation error? Maybe there's too many trees.

73
00:03:23,790 --> 00:03:25,580
>> Maybe, but that's a perfectly reasonable thing to do,

74
00:03:25,580 --> 00:03:27,610
right? You take out a validation set. You build a

75
00:03:27,610 --> 00:03:29,830
decision tree, and you test it on the, on the

76
00:03:29,830 --> 00:03:32,900
validation set and you pick whichever one has the lowest error

77
00:03:32,900 --> 00:03:35,440
in the validation sect, that's one way to avoid it.

78
00:03:35,440 --> 00:03:37,890
And then you have, don't have to worry about this question

79
00:03:37,890 --> 00:03:41,000
about stopping, you just grow the tree on the training

80
00:03:41,000 --> 00:03:44,980
set minus the validation set until it does well on that.

81
00:03:44,980 --> 00:03:46,776
And you check it against the crossvalid, you check it against

82
00:03:46,776 --> 00:03:50,092
the validation set, and you pick the best one. That's one way

83
00:03:50,092 --> 00:03:53,290
of doing it, and that would work perfectly fine. There is

84
00:03:53,290 --> 00:03:57,170
another way you can do it that's more efficient. Which is, you

85
00:03:57,170 --> 00:04:00,980
do the same idea validation, except that you hold out a

86
00:04:00,980 --> 00:04:05,110
set and as you, everytime you decide whether to expand the tree

87
00:04:05,110 --> 00:04:07,570
or not, you check to see how this would do so

88
00:04:07,570 --> 00:04:10,620
far in the validation set. And if the error is low enough,

89
00:04:10,620 --> 00:04:14,020
then you stop expanding the tree. That's one way of doing it.

90
00:04:14,020 --> 00:04:16,399
>> So is there, is there a problem in terms of, I mean if

91
00:04:16,399 --> 00:04:21,360
we're expanding the tree depth for search wise, we could be at, you know,

92
00:04:21,360 --> 00:04:23,710
we could be looking at one tiny little split on one side of the

93
00:04:23,710 --> 00:04:26,530
tree before we even look at any, anything on the other side of the tree.

94
00:04:26,530 --> 00:04:29,230
>> That's a fine point. So how would you fix that?

95
00:04:29,230 --> 00:04:30,870
>> Maybe expand breadth first?

96
00:04:30,870 --> 00:04:35,610
>> Yeah, that would probably do it. Anything else you could think of? Well,

97
00:04:35,610 --> 00:04:38,059
so, you could do pruning, right? You could go ahead and

98
00:04:38,059 --> 00:04:40,399
do the tree as if you didn't have to worry about

99
00:04:40,399 --> 00:04:43,699
over-fitting, and once you have the full tree built, you could

100
00:04:43,699 --> 00:04:46,325
then do a kind of, you could do pruning. You could

101
00:04:46,325 --> 00:04:48,845
go to the leaves of the tree and say, well, what

102
00:04:48,845 --> 00:04:51,814
if I collapse these leaves back up into the tree? How

103
00:04:51,814 --> 00:04:56,850
does that create error on my validation set? And if the

104
00:04:56,850 --> 00:05:00,660
error is too big, then you don't do it. And if it's

105
00:05:00,660 --> 00:05:02,150
very small, then you go ahead and do

106
00:05:02,150 --> 00:05:04,460
it. And that should help you with overfitting.

107
00:05:04,460 --> 00:05:06,800
So, that whole class of ways of doing

108
00:05:06,800 --> 00:05:09,880
it, is called pruning. And there's a whole bunch

109
00:05:09,880 --> 00:05:12,270
of different ways you might prune. But pruning,

110
00:05:12,270 --> 00:05:14,140
itself, is one way of dealing with overfitting,

111
00:05:14,140 --> 00:05:16,050
and giving you a smaller tree. And it's

112
00:05:16,050 --> 00:05:18,690
a very simple addition to the standard ID3 algorithm.
