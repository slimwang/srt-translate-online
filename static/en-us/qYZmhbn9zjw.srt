1
00:00:00,460 --> 00:00:04,930
We can build queries of knowledge based AI at many levels of instructions.

2
00:00:04,930 --> 00:00:09,010
This is the scale here, low level to high level. At one level,

3
00:00:09,010 --> 00:00:13,070
we can build queries at hardware level. So we can talk about a brain or

4
00:00:13,070 --> 00:00:19,050
transistor sort of microchip. At the next level, we can talk about the kinds

5
00:00:19,050 --> 00:00:22,925
of methods and the kinds of representations we have been talking about,

6
00:00:22,925 --> 00:00:26,360
means-ends analysis that has an algorithm associated with it, or

7
00:00:26,360 --> 00:00:30,590
semantic network that's a knowledge representation in some symbolic form.

8
00:00:30,590 --> 00:00:34,740
At a yet higher level, we can talk about knowledge and

9
00:00:34,740 --> 00:00:39,990
tasks. So, the question here becomes what exactly is the task the decision

10
00:00:39,990 --> 00:00:44,420
maker has to make? What exactly is the knowledge the decision maker has?

11
00:00:44,420 --> 00:00:47,440
So, when David was giving his answer about what the pitcher might do in

12
00:00:47,440 --> 00:00:51,970
the situation I showed you earlier, David was clearly using a lot of knowledge,

13
00:00:51,970 --> 00:00:55,580
and he was trying to use this knowledge toward to a particular task. Now,

14
00:00:55,580 --> 00:01:00,840
in the history of AI, David Mark talked about three levels, the level of tasks,

15
00:01:00,840 --> 00:01:04,080
which he called the [UNKNOWN] theory, the level of algorithms and

16
00:01:04,080 --> 00:01:09,480
the level of implementation. And [INAUDIBLE] talked also about multiple levels.

17
00:01:09,480 --> 00:01:13,370
He was talking about the knowledge level, the symbol level and lower levels like

18
00:01:13,370 --> 00:01:18,010
the hardware. The various levels are connected with each other. So I might think

19
00:01:18,010 --> 00:01:23,280
that, the hardware level is a level for implementing what is happening

20
00:01:23,280 --> 00:01:27,620
at the algorithm level. And the algorithm level provides and architecture for

21
00:01:27,620 --> 00:01:32,370
implementing what is happening at the task level. In the opposite direction,

22
00:01:32,370 --> 00:01:37,690
I might think that the task level provides the content of what needs to be

23
00:01:37,690 --> 00:01:42,650
represented or manipulated at the algorithm level. And the algorithm and

24
00:01:42,650 --> 00:01:46,940
symbol level provide the content for what needs to be manipulated at processor,

25
00:01:46,940 --> 00:01:51,990
the hardware level. So as an example, one might say, we're representing this

26
00:01:51,990 --> 00:01:56,560
in a form of a semantic network, fair enough. But, what exactly are you going to

27
00:01:56,560 --> 00:02:00,010
represent in a semantic network? That's going to come from the knowledge level.

28
00:02:00,010 --> 00:02:04,040
It is the knowledge level that tells us, what is the content of the knowledge

29
00:02:04,040 --> 00:02:08,680
that is required to play baseball? Once you have the content of knowledge,

30
00:02:08,680 --> 00:02:12,740
you can perhaps implement it in many different ways. One way is through semantic

31
00:02:12,740 --> 00:02:17,000
network. Similarly, once you know what kind of decision you have to make,

32
00:02:17,000 --> 00:02:20,660
and what a decision-making process might look like overall,

33
00:02:20,660 --> 00:02:25,130
there might be many different methods of making that particular decision. Just

34
00:02:25,130 --> 00:02:28,540
like we can build a relationship between the task level and the algorithm level,

35
00:02:28,540 --> 00:02:31,010
a similar relationship exists between the algorithm level and

36
00:02:31,010 --> 00:02:36,520
the hardware level. This is an important point, so let me take another example.

37
00:02:36,520 --> 00:02:42,200
All of you are familiar with your standard smartphone. Let us suppose that I

38
00:02:42,200 --> 00:02:46,820
was coming from Mars, I was a Martian. And I did not know how your mobile phone

39
00:02:46,820 --> 00:02:51,620
works. So I would ask you, well, how, exactly, does your mobile phone work? And

40
00:02:51,620 --> 00:02:54,950
you might give an account of how the phone works at that level of distraction.

41
00:02:54,950 --> 00:02:58,190
There will be a legitimate account, you have somewhere else for

42
00:02:58,190 --> 00:03:01,730
give an account of how the smartphone works at a, at a level of tasks and

43
00:03:01,730 --> 00:03:05,930
knowledge. This person might say, well, a phone allows you to communicate with

44
00:03:05,930 --> 00:03:10,760
other people at long distances. How that is implemented is a different matter.

45
00:03:10,760 --> 00:03:14,780
Now you will see, I'm sure, that all three of these interpretations,

46
00:03:14,780 --> 00:03:18,160
all three of these descriptions are legitimate and valid.

47
00:03:18,160 --> 00:03:23,220
You will see also, that we really need all three of these levels of description.

48
00:03:23,220 --> 00:03:26,622
We do need to understand what this smartphone does, and that kind of

49
00:03:26,622 --> 00:03:31,366
knowledge it uses to do it. We do need to understand what kind of algorithm and

50
00:03:31,366 --> 00:03:35,431
knowledge presentations it uses, and what kind of hardware implements all of

51
00:03:35,431 --> 00:03:40,320
this. Now, you can do a similar kind of analysis for other kinds of devices.

52
00:03:40,320 --> 00:03:45,250
Let's say, like your calculator. Could we do a similar kind of analysis for

53
00:03:45,250 --> 00:03:49,090
intelligent agents? Are these different layers also meaningful for

54
00:03:49,090 --> 00:03:53,330
analyzing what happens in cognitive systems, whether they are natural or

55
00:03:53,330 --> 00:03:57,740
artificial? And at what layer should we be building a theory?

56
00:03:57,740 --> 00:04:02,660
Our hypothesis is, that these three layers are also useful for trying to

57
00:04:02,660 --> 00:04:07,000
analyze how cognitive systems might work, but natural cognitive systems and

58
00:04:07,000 --> 00:04:12,060
artificial cognitive systems. Further, our hypothesis is that we want to

59
00:04:12,060 --> 00:04:16,089
build theories at all three of these different level, levels of abstraction,

60
00:04:16,089 --> 00:04:20,380
not at any one of them. In fact, their constraint's flowing in both directions.

61
00:04:20,380 --> 00:04:23,610
If we know about what kind of tasks we want to do and what kind of knowledge we

62
00:04:23,610 --> 00:04:28,580
want to use, then that tells us something about what kind of algorithms we

63
00:04:28,580 --> 00:04:31,280
need to and what kind of knowledge representations we need.

64
00:04:31,280 --> 00:04:34,853
And that tells us something about what kind of hardware we need. In the other

65
00:04:34,853 --> 00:04:38,750
direction, if we know what kind of hardware we have that imposes constraints and

66
00:04:38,750 --> 00:04:42,595
provide [UNKNOWN] for what kind algorithms and knowledge representations can be

67
00:04:42,595 --> 00:04:45,780
there, which then provides accordance within constraints. Well,

68
00:04:45,780 --> 00:04:49,600
what kinds of tasks can be done and what kind of knowledge can be used.

69
00:04:49,600 --> 00:04:53,660
In this class, we'll be concerned mostly with the top two layers,

70
00:04:53,660 --> 00:04:57,050
although I allude occasionally to the third layer as well.

71
00:04:57,050 --> 00:05:01,290
A lot of work in AI is at the top two layers of abstraction.
