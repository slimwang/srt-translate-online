1
00:00:00,000 --> 00:00:06,000
The answer is here he's eaten 1, here he's eaten 0, and here he's eaten 1.

2
00:00:06,000 --> 00:00:11,000
That's fine. The problem arises when we start backing up these numbers.

3
00:00:11,000 --> 00:00:17,000
If these are max nodes, we've skipped the opponent's moves, which are the min nodes.

4
00:00:17,000 --> 00:00:20,000
We're only looking at the maxes.

5
00:00:20,000 --> 00:00:25,000
The max of 1 is 1, so this would also get an evaluation of 1.

6
00:00:25,000 --> 00:00:31,000
The max of 0 and 1 is 1, so this would also get an evaluation of 1.

7
00:00:31,000 --> 00:00:35,000
This final node would be the max of 1 and 1, so that's also 1.

8
00:00:35,000 --> 00:00:39,000
But now when we go to apply the policy, if we're in this position,

9
00:00:39,000 --> 00:00:44,000
using these evaluation functions, both of these moves are equally good.

10
00:00:44,000 --> 00:00:48,000
The Pacman might choose this one,

11
00:00:48,000 --> 00:00:52,000
choosing at random or choosing by some predefined ordering.

12
00:00:52,000 --> 00:00:55,000
Then he'd end up in this state. So far he hasn't eaten anything.

13
00:00:55,000 --> 00:00:59,000
But this state is just as good because he knows in two moves he can eat one particle

14
00:00:59,000 --> 00:01:04,000
going this way just as well as in two moves he can eat one particle going this way.

15
00:01:04,000 --> 00:01:08,000
Now he's in this state, but notice that this state is symmetric to this one.

16
00:01:08,000 --> 00:01:12,000
On his next turn, if we did another depth-two search,

17
00:01:12,000 --> 00:01:14,000
he might just as well go back one position.

18
00:01:14,000 --> 00:01:19,000
He would be stuck going back and forth between these two states,

19
00:01:19,000 --> 00:01:24,000
because either one of those, if you look ahead only two, is equally good.

20
00:01:24,000 --> 00:01:28,000
You have to look ahead one, two, three, four moves to know

21
00:01:28,000 --> 00:01:31,000
that one of them is better than the other.

22
00:01:31,000 --> 00:01:34,000
This is known as the horizon effect.

23
00:01:34,000 --> 00:01:39,000
The idea is that when we cut off search we're specifying a horizon

24
00:01:39,000 --> 00:01:41,000
beyond which the agent can't see.

25
00:01:41,000 --> 00:01:45,000
If a good thing or a bad thing happens beyond the horizon, we don't see that.

26
00:01:45,000 --> 00:01:50,000
All we see is whatever is reflected in the evaluation function.

27
00:01:50,000 --> 00:01:54,000
If the evaluation function is imperfect, we don't see beyond the horizon,

28
00:01:54,000 --> 99:59:59,999
and we can make mistakes.
