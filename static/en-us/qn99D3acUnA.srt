1
00:00:00,130 --> 00:00:03,370
The answer is, all choices are true except for the

2
00:00:03,370 --> 00:00:06,030
first one. The reason the first one's not true, is

3
00:00:06,030 --> 00:00:08,220
this really doesn't take long to compute. We only need

4
00:00:08,220 --> 00:00:11,460
to look at one letter and do a simple modular computation,

5
00:00:11,460 --> 00:00:14,710
that's very efficient. But the other three reasons are true

6
00:00:14,710 --> 00:00:17,960
and we'll go through each of these showing what happens

7
00:00:17,960 --> 00:00:21,430
looking at how things evaluate in the Python Interpreter. So

8
00:00:21,430 --> 00:00:25,500
the first correct reason is that it produces an error for

9
00:00:25,500 --> 00:00:28,350
one input keyword. When we write code we should think

10
00:00:28,350 --> 00:00:31,880
about whether it works for all possible inputs. And the one

11
00:00:31,880 --> 00:00:35,230
that's usually the trickiest to think about is the boundary case.

12
00:00:35,230 --> 00:00:38,770
For a string, that's often the empty string. So, if we

13
00:00:38,770 --> 00:00:42,110
pass in a string with no characters in it, which

14
00:00:42,110 --> 00:00:44,990
is a perfectly valid string, we'll then, when we try to

15
00:00:44,990 --> 00:00:48,200
index element zero, that would be an error. So let's see

16
00:00:48,200 --> 00:00:51,020
what happens when we try that in the Python Shell. So

17
00:00:51,020 --> 00:00:56,240
we'll try to evaluate bad_hash_string, passing in the keyword the

18
00:00:56,240 --> 00:00:59,250
empty string, which is a perfectly valid string. And lets see

19
00:00:59,250 --> 00:01:01,530
there are 100 buckets. And we do get an error,

20
00:01:01,530 --> 00:01:03,340
we get the error that the string index is out of

21
00:01:03,340 --> 00:01:06,690
range because we tried to access the character at position

22
00:01:06,690 --> 00:01:09,640
zero, but there is no character at position zero in the

23
00:01:09,640 --> 00:01:13,200
empty string. So to understand the other two reasons, I have

24
00:01:13,200 --> 00:01:16,720
defined a procedure called test hash function. It takes three inputs.

25
00:01:16,720 --> 00:01:19,410
The first input is a function, so we can pass functions around,

26
00:01:19,410 --> 00:01:22,400
just like any other value, so what we're going to pass in for this,

27
00:01:22,400 --> 00:01:25,430
is the bad_hash_string function that we've defined, but we can also use

28
00:01:25,430 --> 00:01:28,780
it to test other hash functions, which we'll see later. We're going to pass

29
00:01:28,780 --> 00:01:31,730
in a list of keys, those are the keywords for the hash

30
00:01:31,730 --> 00:01:34,000
table, and we're going to pass in the size, this is the number of

31
00:01:34,000 --> 00:01:37,760
buckets. What we do in test hash function, is we're going to keep

32
00:01:37,760 --> 00:01:41,710
results as a list of the number of times each bucket is used.

33
00:01:41,710 --> 00:01:46,410
So initially, they're all zeroes. And we initialize it with zero

34
00:01:46,410 --> 00:01:49,820
times the size. We're going to use keys used as a list

35
00:01:49,820 --> 00:01:52,430
of the keys that have already been used. We don't want to

36
00:01:52,430 --> 00:01:55,490
count a duplicate key more than once. So now we're going to

37
00:01:55,490 --> 00:01:57,730
loop through the keys. We're going to check if a key

38
00:01:57,730 --> 00:02:01,140
was used already, and if the key was not used, then

39
00:02:01,140 --> 00:02:04,340
we're going to figure out by calling the hash function where

40
00:02:04,340 --> 00:02:06,870
that key would hash to. So, if we passed in that

41
00:02:06,870 --> 00:02:08,910
hash string, that would be the function here.

42
00:02:08,910 --> 00:02:11,330
And we're calling that passing in the keyword, and

43
00:02:11,330 --> 00:02:13,960
the number of buckets. We're storing the result in

44
00:02:13,960 --> 00:02:18,250
the variable hv. And then we're increasing the value

45
00:02:18,250 --> 00:02:21,300
of the element at results position hv, by

46
00:02:21,300 --> 00:02:24,510
what? And this is a short-hand syntax, means the

47
00:02:24,510 --> 00:02:28,880
same thing as doing a new assignment where we're

48
00:02:28,880 --> 00:02:32,460
assigning two results hv, the value currently end results

49
00:02:32,460 --> 00:02:37,340
hv plus one, and then we're adding the word that

50
00:02:37,340 --> 00:02:39,340
we just used to the list of keys used, so

51
00:02:39,340 --> 00:02:41,790
we don't use it again. This is similar to what

52
00:02:41,790 --> 00:02:44,430
we did in the web crawler, to avoid crawling the

53
00:02:44,430 --> 00:02:46,694
same page more than once. And if end will return

54
00:02:46,694 --> 00:02:49,585
the results. So what we'll have as the result of

55
00:02:49,585 --> 00:02:54,020
test_hash_function, is a list where the values in that list

56
00:02:54,020 --> 00:02:57,690
are numbers, giving the number of times a key hashes

57
00:02:57,690 --> 00:03:00,950
to that bucket. So let's try this with

58
00:03:00,950 --> 00:03:04,550
an example using the bad_hash_string function. So to test

59
00:03:04,550 --> 00:03:07,190
our hash function, we need some content. We

60
00:03:07,190 --> 00:03:09,660
need content that represents the kind of words that

61
00:03:09,660 --> 00:03:11,210
we think we're going to be using the hash

62
00:03:11,210 --> 00:03:14,610
table on. I've picked this one, which, perhaps is

63
00:03:14,610 --> 00:03:18,850
represented, perhaps not. And what's there at that link,

64
00:03:18,850 --> 00:03:22,750
is Gutenberg's text of The Adventures of Sherlock Holmes.

65
00:03:22,750 --> 00:03:28,710
And you can see from the scroll bar, it's quite long. So this is all the text

66
00:03:28,710 --> 00:03:35,096
there is. And so on. So, we're going to get all the words on this page using

67
00:03:35,096 --> 00:03:38,368
getpage. We're going to split them into words like

68
00:03:38,368 --> 00:03:40,272
we were doing in the crawler, and we'll

69
00:03:40,272 --> 00:03:42,660
store that in the [INAUDIBLE] words. And the

70
00:03:42,660 --> 00:03:47,860
length of that is over 100,000 words. Now they're

71
00:03:47,860 --> 00:03:49,780
not all unique, so the number of entries in our

72
00:03:49,780 --> 00:03:52,610
hash table will be smaller then that. But let's see

73
00:03:52,610 --> 00:03:55,430
how the distribution is for those words. So we'll use

74
00:03:55,430 --> 00:03:58,440
the test_hash_function that we defined,

75
00:03:58,440 --> 00:04:01,540
passing in bad_hash_string, the words that

76
00:04:01,540 --> 00:04:04,650
we got from Sherlock Holmes, and we'll pick, for now

77
00:04:04,650 --> 00:04:08,060
we'll use size 12, definitely too small, but that'll give

78
00:04:08,060 --> 00:04:10,030
us a good sense of how the distribution goes for

79
00:04:10,030 --> 00:04:12,960
a small number of buckets. So now we have the result.

80
00:04:12,960 --> 00:04:16,459
Let's look at what the counts are. And

81
00:04:16,459 --> 00:04:20,260
you can see, we've got 12 entries, which corresponds

82
00:04:20,260 --> 00:04:22,560
to the number of buckets. And they vary quite

83
00:04:22,560 --> 00:04:27,580
a bit. The smallest one has only 754 elements.

84
00:04:27,580 --> 00:04:30,140
The largest one has over 2000. So the gap

85
00:04:30,140 --> 00:04:33,210
between the smallest and largest is nearly a factor

86
00:04:33,210 --> 00:04:35,440
of three. If our hash function was good, we

87
00:04:35,440 --> 00:04:37,800
will want these to be about the same size.

88
00:04:37,800 --> 00:04:41,230
Here's what that looks like graphically. We have our twelve buckets.

89
00:04:41,230 --> 00:04:44,730
The ones that are red, are too full. The ones that are

90
00:04:44,730 --> 00:04:47,510
blue, are not full enough. We would like this to be a

91
00:04:47,510 --> 00:04:51,420
fairly flat graph, distributing all of the words evenly between the buckets.
