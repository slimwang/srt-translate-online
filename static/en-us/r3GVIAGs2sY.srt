1
00:00:00,140 --> 00:00:01,930
Okay Michael so this wraps up all this

2
00:00:01,930 --> 00:00:04,950
Bayesian Learning stuff. What have we learned today?

3
00:00:04,950 --> 00:00:06,450
>> We did Bayes rule.

4
00:00:06,450 --> 00:00:09,740
>> We learned Bayes rule. We even learned how to derive Bayes rule.

5
00:00:09,740 --> 00:00:11,710
>> And it was super useful because it

6
00:00:11,710 --> 00:00:13,920
lets you swap, kind of, causes and effect.

7
00:00:13,920 --> 00:00:15,880
>> So I like the way you put that, Michael that

8
00:00:15,880 --> 00:00:19,310
we're swapping causes and effects. Sort of mathematically when we think about

9
00:00:19,310 --> 00:00:22,170
Bayes rule, what that really lets us do is. Instead of

10
00:00:22,170 --> 00:00:25,480
having to compute the probably of a hypothesis given the data We

11
00:00:25,480 --> 00:00:27,170
instead view to compute the probability of the

12
00:00:27,170 --> 00:00:30,130
data given the hypothesis, which is typically a

13
00:00:30,130 --> 00:00:35,660
much easier thing to do. And what makes it of course Bayes rule in general is

14
00:00:35,660 --> 00:00:38,150
that you weight that by the prior probability

15
00:00:38,150 --> 00:00:40,620
over the hypothesis. Which in fact is one

16
00:00:40,620 --> 00:00:42,580
of the important things that we learned which

17
00:00:42,580 --> 00:00:45,680
is that priors matter. So anything else we learned?

18
00:00:45,680 --> 00:00:51,500
>> Yep, we did the MAP hypothesis, Maximum a posteriori. Right.

19
00:00:51,500 --> 00:00:54,630
We learned about HMap, and we also learned about HML.

20
00:00:54,630 --> 00:00:59,560
>> ML, right. The maximum likelihood hypothesis. > Right. And what's the

21
00:00:59,560 --> 00:01:01,220
maximum likelihood hypothesis? How's it relate

22
00:01:01,220 --> 00:01:03,510
to the maximum a posteriori hypothesis?

23
00:01:03,510 --> 00:01:06,970
>> It's the MAP that you get when the prior is uniform.

24
00:01:06,970 --> 00:01:08,970
>> Right. Alright. And we, oh, we

25
00:01:08,970 --> 00:01:12,510
connected up maximum a posteriori and least squares.

26
00:01:12,510 --> 00:01:16,530
>> Yeah, that was pretty, I really liked that. So, we basically der, we

27
00:01:16,530 --> 00:01:20,010
deroved. We derived a bunch of things we'd

28
00:01:20,010 --> 00:01:22,330
been doing before. And short of showed that

29
00:01:22,330 --> 00:01:23,760
there's actually a good argument for them. At

30
00:01:23,760 --> 00:01:26,020
least if you're Bayesian. There are good arguments for

31
00:01:26,020 --> 00:01:29,120
doing some doing sum of squares. There are good

32
00:01:29,120 --> 00:01:32,060
arguments for Occam's Razor. We'd actually be able

33
00:01:32,060 --> 00:01:34,110
to give real justification for doing them other

34
00:01:34,110 --> 00:01:35,790
than, well sure it makes us one of them.

35
00:01:35,790 --> 00:01:39,170
>> Right so that includes the minimum description length story.

36
00:01:39,170 --> 00:01:40,185
>> Mm-hm.

37
00:01:40,185 --> 00:01:41,320
>> And then finally,

38
00:01:41,320 --> 00:01:45,850
you told me that was all a lie, and you said that really what you want to do

39
00:01:45,850 --> 00:01:48,820
is this other kind of way of picking that

40
00:01:48,820 --> 00:01:51,830
actually factors in the probability of all the different hypotheses

41
00:01:51,830 --> 00:01:55,580
and having them essentially vote. Right. What we really

42
00:01:55,580 --> 00:01:59,690
care about, is classification. We're learning in the end and

43
00:01:59,690 --> 00:02:02,300
so we also learned about Bayes classifiers. So in

44
00:02:02,300 --> 00:02:07,180
fact, what we described before, which is voting of hypothesis.

45
00:02:07,180 --> 00:02:11,260
Turns out to be the Bayes optimal classifier. I

46
00:02:11,260 --> 00:02:14,360
didn't say that, but it is very important to note.

47
00:02:14,360 --> 00:02:16,060
In fact, what you should be noting there is

48
00:02:16,060 --> 00:02:18,040
not only is it the Bayes optimal classifier, it's the

49
00:02:18,040 --> 00:02:21,780
Bayes optimal classifier. And what that means is that

50
00:02:21,780 --> 00:02:26,400
on average you cannot do any better than basically doing

51
00:02:26,400 --> 00:02:29,550
a weighted vote of all the hypotheses according to

52
00:02:29,550 --> 00:02:32,210
the probability of the hypothesis given the data. You cannot

53
00:02:32,210 --> 00:02:33,940
do any better than this on average. So

54
00:02:33,940 --> 00:02:36,960
again, what Bayesian learning gives us and what Bayesian

55
00:02:36,960 --> 00:02:39,480
classification gives us is a way of talking

56
00:02:39,480 --> 00:02:43,240
about optimality and gold standards. What'd you think, Michael?

57
00:02:43,240 --> 00:02:44,450
>> That's really neat.

58
00:02:44,450 --> 00:02:45,990
>> I like it. I mean, I have to tell

59
00:02:45,990 --> 00:02:48,830
you, I really think that this stuff is kind of cool.

60
00:02:48,830 --> 00:02:51,140
It's always nice to be able to take things that actually

61
00:02:51,140 --> 00:02:55,080
work and explain them according to some framework, some underlying theory.

62
00:02:55,080 --> 00:02:57,390
>> I wonder though, it seems like

63
00:02:57,390 --> 00:03:02,280
all these Bayesian equations lead us to the question, of how we actually infere

64
00:03:02,280 --> 00:03:06,360
probabilities from various different quantities and observations.

65
00:03:06,360 --> 00:03:07,780
So is there a way to do that?

66
00:03:07,780 --> 00:03:13,330
>> So I think the answer is yes. And maybe you should

67
00:03:13,330 --> 00:03:15,140
go figure it out and then tell me about it next time.

68
00:03:15,140 --> 00:03:18,550
>> Okay. [LAUGH] All right, as you wish.

69
00:03:18,550 --> 00:03:19,950
>> As you wish.

70
00:03:19,950 --> 00:03:20,910
>> Stay tuned.

71
00:03:20,910 --> 00:03:22,470
>> Anyway, this has been a lot of fun, Michael.

72
00:03:22,470 --> 00:03:23,270
I will talk to you later.

73
00:03:23,270 --> 00:03:23,860
>> Thanks.

74
00:03:23,860 --> 00:03:24,590
>> Bye.
