1
00:00:00,000 --> 00:00:03,000
In case A, the gradient is negative.

2
00:00:03,000 --> 00:00:06,000
If you move to the right in the X space,

3
00:00:06,000 --> 00:00:09,000
then your loss decreases.

4
00:00:09,000 --> 00:00:12,000
In B, it's about zero.

5
00:00:12,000 --> 00:00:15,000
In C, it's pointing up; it's positive.

6
00:00:15,000 --> 00:00:18,000
So if you apply the rule over here,

7
00:00:18,000 --> 00:00:21,000
if you were to start at A as your W-zero,

8
00:00:21,000 --> 00:00:23,000
then your gradient is negative.

9
00:00:23,000 --> 00:00:26,000
Therefore, you would add something to the value of W.

10
00:00:26,000 --> 00:00:29,000
You move to the right, and your loss has decreased.

11
00:00:29,000 --> 00:00:31,000
You do this until you find yourself

12
00:00:31,000 --> 00:00:34,000
with what's called a local minimum, where B resides.

13
00:00:34,000 --> 00:00:37,000
In this instance over here, gradient descent starting at A

14
00:00:37,000 --> 00:00:39,000
would not get you to the global minimum,

15
00:00:39,000 --> 00:00:42,000
which sits over here because there's a bump in between.

16
00:00:42,000 --> 99:59:59,999
Gradient methods are known to be subject to local minimum.
