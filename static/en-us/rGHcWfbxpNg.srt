1
00:00:00,000 --> 00:00:05,000
Another question on the forum related to the use of lexer states.

2
00:00:05,000 --> 00:00:10,000
A lexer state like I'm in a comment or I'm not is actually

3
00:00:10,000 --> 00:00:14,000
more of a convenience function for allowing us to have different rules

4
00:00:14,000 --> 00:00:17,000
depending on where we are.

5
00:00:17,000 --> 00:00:21,000
In normal code for HTML or JavaScript, we want to recognize things like

6
00:00:21,000 --> 00:00:24,000
angle brackets, because they might be a part of tags

7
00:00:24,000 --> 00:00:28,000
or they might be the less than or greater than sign in a JavaScript mathematical computation.

8
00:00:28,000 --> 00:00:32,000
But inside a comment, they don't mean anything special at all.

9
00:00:32,000 --> 00:00:34,000
You want to just skip over them, because that's some documentation

10
00:00:34,000 --> 00:00:37,000
the programmer wrote down for later maintenance.

11
00:00:37,000 --> 00:00:41,000
So we used exclusive states like I'm in a comment or I'm not

12
00:00:41,000 --> 00:00:44,000
to have different rules depending on where we are.

13
00:00:44,000 --> 00:00:48,000
A totally legitimate question is: Are we going to use these exclusive states

14
00:00:48,000 --> 00:00:53,000
to have one lexer for HTML and another for JavaScript

15
00:00:53,000 --> 00:00:55,000
when we write our final web browser?

16
00:00:55,000 --> 00:00:57,000
This is a great question.

17
00:00:57,000 --> 00:01:02,000
It's going to turn out that we're not going to use explicit states,

18
00:01:02,000 --> 00:01:05,000
but we are going to use exactly the same concept.

19
00:01:05,000 --> 00:01:09,000
If you think about it under the hood, lexer states are really just a cute way

20
00:01:09,000 --> 00:01:12,000
of giving you two different finite state machines--

21
00:01:12,000 --> 00:01:14,000
two different sets of regular expressions--

22
00:01:14,000 --> 00:01:17,000
one for in comments and one for not, for example.

23
00:01:17,000 --> 00:01:23,000
We will do the same thing just by writing two different sets of token definition files.

24
00:01:23,000 --> 00:01:27,000
Here's one for HTML, and here's another one for JavaScript.

25
00:01:27,000 --> 00:01:32,000
We'll start with the entire web page that we download from a web server somewhere,

26
00:01:32,000 --> 00:01:36,000
and we will feed that to our HTML lexer and parser.

27
00:01:36,000 --> 00:01:39,000
Some parts of the web page will be embedded JavaScript,

28
00:01:39,000 --> 00:01:42,000
and we'll see this in great detail in later units.

29
00:01:42,000 --> 00:01:45,000
We will gather up those strings and keep them safe.

30
00:01:45,000 --> 00:01:51,000
And when it comes time to interpret them, we will pass them to another lexer,

31
00:01:51,000 --> 00:01:56,000
this time a JavaScript lexer, that will interpret that substring as JavaScript.

32
00:01:56,000 --> 00:02:01,000
And this is one of the great joys, really, of computer science--turtles all the way down,

33
00:02:01,000 --> 00:02:05,000
or nested Russian dolls--once you've learned a particular concept,

34
00:02:05,000 --> 00:02:10,000
like how to make a lexer, you can often nest it or have multiple of them at the same time.

35
00:02:10,000 --> 00:02:13,000
Once we know how to make a lexer for HTML,

36
00:02:13,000 --> 00:02:17,000
nothing stops us from making a lexer for JavaScript

37
00:02:17,000 --> 00:02:19,000
and having them both running as part of the same program.

38
00:02:19,000 --> 00:02:21,000
And that's what we'll do.

39
00:02:21,000 --> 00:02:24,000
So officially we won't be using exclusive lexer states,

40
00:02:24,000 --> 99:59:59,999
but we will end up with multiple different finite state machines used for lexing under the hood.
