1
00:00:00,330 --> 00:00:03,120
Here is one way in which
an intelligent agent can work and

2
00:00:03,120 --> 00:00:07,110
accomplish environment with a large
number of perception actions possible

3
00:00:07,110 --> 00:00:10,520
and yet do so relatively efficiently.

4
00:00:10,520 --> 00:00:13,170
Suppose that this 2 to
the power n percepts,

5
00:00:13,170 --> 00:00:17,480
could be mapped into k concepts
where each of these k concept

6
00:00:17,480 --> 00:00:20,760
is an equivalence class with a large
number of these combinations.

7
00:00:20,760 --> 00:00:25,730
So 2 to the power of n may be very, very
large, but k is a much smaller number.

8
00:00:25,730 --> 00:00:29,250
So these concepts are now equivalence
classes or these percepts.

9
00:00:30,430 --> 00:00:35,440
So now instead of indexing my actions
on the combinations of percepts,

10
00:00:35,440 --> 00:00:39,820
I index my actions on the equivalence
classes that are called concepts, and

11
00:00:39,820 --> 00:00:41,630
this happens all the time.

12
00:00:41,630 --> 00:00:45,860
You go to a doctor, for example and you
may go with some signs and symptoms and

13
00:00:45,860 --> 00:00:50,050
the doctor says, well, I have to decide
whether I'll give you a blue liquid or

14
00:00:50,050 --> 00:00:52,730
a red liquid, assume that those
are the actions possible.

15
00:00:52,730 --> 00:00:55,860
And the actions are now indexed,
not as the signs and symptoms or

16
00:00:55,860 --> 00:00:58,750
the combination of signs and symptoms,
which are potentially very large for

17
00:00:58,750 --> 00:01:03,380
human beings, but it's a small number
of concepts, the number of diseases,

18
00:01:03,380 --> 00:01:06,810
which compared to all the combinations
of signs and symptoms, is much smaller.

19
00:01:07,850 --> 00:01:10,930
>> Another example of this that
would come from computer programming

20
00:01:10,930 --> 00:01:13,990
would be that we might have a small
number of different ways in which

21
00:01:13,990 --> 00:01:18,020
a computer program can go wrong,
by a large number of different percepts

22
00:01:18,020 --> 00:01:20,170
that tell us what has
actually gone wrong.

23
00:01:20,170 --> 00:01:23,640
So, for example in my percepts, I might
have whether or not I received a null

24
00:01:23,640 --> 00:01:27,520
pointer error, whether or not I received
a memory allocation error, whether or

25
00:01:27,520 --> 00:01:31,420
not I received an index larger
than size of an array error.

26
00:01:31,420 --> 00:01:34,160
All of those are different percepts
I might have, but it might map

27
00:01:34,160 --> 00:01:37,090
the same underlying concept or something
that has not yet been initialized.

28
00:01:37,090 --> 00:01:40,680
So I'm taking the number of things that
I can actually see and mapping them to

29
00:01:40,680 --> 00:01:44,520
a smaller number of ways in which
the program can actually go wrong.

30
00:01:44,520 --> 00:01:47,960
Then instead of having to map each
individual percept to some number of

31
00:01:47,960 --> 00:01:52,350
actions, I know that if my error is
that something has not been initialized

32
00:01:52,350 --> 00:01:53,970
I need to find what hasn't
been initialized and

33
00:01:53,970 --> 00:01:56,890
there's a much smaller list of
actions involved looking at each

34
00:01:56,890 --> 00:02:00,840
individual variable and seeing where
the initialization has not taken place.

35
00:02:00,840 --> 00:02:03,300
>> Now we understand
why classification is

36
00:02:03,300 --> 00:02:06,710
such an often-studied topic
in artificial intelligence.

37
00:02:06,710 --> 00:02:09,788
Almost every school of artificial
intelligence has studied

38
00:02:09,788 --> 00:02:11,810
classification extensively.

39
00:02:11,810 --> 00:02:15,190
If there were no concept we were
mapping this two to the power

40
00:02:15,190 --> 00:02:20,460
n combinations of percepts and use two
to the power m combinations of actions,

41
00:02:20,460 --> 00:02:25,050
then we could think of an intelligent
agent as one large, giant table.

42
00:02:25,050 --> 00:02:29,490
The rows of the table are all the two
to the n combinations of percepts

43
00:02:29,490 --> 00:02:33,808
that will be that many rows and the
columns are through the power m actions.

44
00:02:33,808 --> 00:02:38,270
Given a percept, I know exactly what
action to take if they would tell you

45
00:02:38,270 --> 00:02:40,870
that, and
it's going to be a very large table.

46
00:02:40,870 --> 00:02:41,980
We don't know how to use it,

47
00:02:41,980 --> 00:02:46,020
it will be very costly to use it, and
we don't know how to build such a table.

48
00:02:47,480 --> 00:02:51,960
What classification is doing is,
it is breaking that large table

49
00:02:51,960 --> 00:02:56,400
into a large number of small tables,
and that's the power of knowledge.

50
00:02:56,400 --> 00:03:00,140
When you have knowledge,
you can take some complex problem, and

51
00:03:00,140 --> 00:03:02,750
break it into a large number of smaller,
simpler problems.
