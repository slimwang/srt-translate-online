1
00:00:00,520 --> 00:00:03,880
Let's look at identifying
duplicate records in ULTIRX.

2
00:00:03,880 --> 00:00:08,080
We're going to start with a dataset
that has names and phone numbers in it.

3
00:00:08,080 --> 00:00:11,160
Phone numbers can move from
one person to the next and

4
00:00:11,160 --> 00:00:16,120
datasets can lag in terms of updating
new phone numbers to the right people.

5
00:00:16,120 --> 00:00:19,800
So in this dataset, it would be nice
to know which phone numbers have

6
00:00:19,800 --> 00:00:22,080
been associated with
more than one person.

7
00:00:23,230 --> 00:00:26,260
One way we can do this is
to use the summarize tool.

8
00:00:26,260 --> 00:00:28,160
When we add the summarize tool,

9
00:00:28,160 --> 00:00:32,200
we highlight the phone field,
select add and group by.

10
00:00:33,360 --> 00:00:37,310
When we run ULTRIX, we get a unique
list of the phone numbers.

11
00:00:37,310 --> 00:00:41,870
If we look in the messages, we can
see that 14 records were summarized

12
00:00:41,870 --> 00:00:45,620
to 11 groups, so
we know that there are duplicates.

13
00:00:45,620 --> 00:00:48,870
To expose which phone number have
duplicates, we can go back to

14
00:00:48,870 --> 00:00:54,900
the summarize tool, highlight the phone
field, go to add, and select count.

15
00:00:54,900 --> 00:00:58,385
After we run the workflow, it will
show the count of the records for

16
00:00:58,385 --> 00:01:03,040
each phone number, and which phone
numbers are in the data multiple times.

17
00:01:03,040 --> 00:01:07,229
If we want to see the names
associated with these phone numbers,

18
00:01:07,229 --> 00:01:12,130
we could add this as an additional field
in the summarize tool by selecting

19
00:01:12,130 --> 00:01:15,152
contact, add, string, and concatenate.

20
00:01:15,152 --> 00:01:17,723
[BLANK_AUDIO]

21
00:01:17,723 --> 00:01:21,690
The result is a list of
names separated by commas.

22
00:01:21,690 --> 00:01:24,715
If we had thousands or
millions of records, and

23
00:01:24,715 --> 00:01:28,723
we wanted to identify the duplicates,
we may just want to filter

24
00:01:28,723 --> 00:01:32,219
out the duplicates from the list and
review that list.

25
00:01:32,219 --> 00:01:36,670
To do that we add the filter
tool after the summarize.

26
00:01:36,670 --> 00:01:40,200
We select the count field,
and say greater than one.

27
00:01:42,370 --> 00:01:47,520
Out of the true side is a list where
there was the same phone number for

28
00:01:47,520 --> 00:01:49,040
more than one record.

29
00:01:49,040 --> 00:01:52,300
There's another way that you can
find duplicates in your data though.

30
00:01:52,300 --> 00:01:55,270
The unique tool does exactly this, but

31
00:01:55,270 --> 00:01:58,220
it pulls through all of
the fields in your data.

32
00:01:58,220 --> 00:02:01,030
We select the unique tool from
the preparation category.

33
00:02:02,240 --> 00:02:07,760
Connect it to the input text, and
choose the phone number as the field

34
00:02:07,760 --> 00:02:10,080
that we're going to
identify duplicates for.

35
00:02:11,110 --> 00:02:11,830
Run the workflow.

36
00:02:13,170 --> 00:02:17,630
On the U side are all of the records
that are unique records.

37
00:02:17,630 --> 00:02:22,110
And on the duplicate side are the three
records that are duplicates

38
00:02:22,110 --> 00:02:23,640
of records on the unique side.
