1
00:00:00,000 --> 00:00:03,000
Now I want take a second to convince ourselves

2
00:00:03,000 --> 00:00:06,000
this is indeed the maximum likelihood estimate

3
00:00:06,000 --> 00:00:09,000
of the mean and the variance.

4
00:00:09,000 --> 00:00:12,000
Suppose our data looks like this--

5
00:00:12,000 --> 00:00:15,000
There's "M" data points.

6
00:00:15,000 --> 00:00:18,000
And the probability of those data points

7
00:00:18,000 --> 00:00:22,000
for any Gaussian model--mu and sigma squared

8
00:00:22,000 --> 00:00:29,000
is the product of any individual of data likelihood--x,i.

9
00:00:29,000 --> 00:00:34,000
And if you plug in our Gaussian formula, you get the following--

10
00:00:34,000 --> 00:00:37,000
This is the normalizer multiplied "M" times

11
00:00:37,000 --> 00:00:43,000
where the square root is now drawn into the half over here,

12
00:00:43,000 --> 00:00:45,000
and here is our joint exponential.

13
00:00:45,000 --> 00:00:49,000
We took the product of the individual exponentials

14
00:00:49,000 --> 00:00:53,000
and moved it up straight in here where it becomes a sum.

15
00:00:53,000 --> 00:00:58,000
So the best estimates for mu and sigma squared

16
00:00:58,000 --> 00:01:01,000
are those that maximize this entire expression over here

17
00:01:01,000 --> 00:01:05,000
for given data set X1 to Xm.

18
00:01:05,000 --> 00:01:08,000
So we seek to maximize this over the unknown parameters

19
00:01:08,000 --> 00:01:10,000
mu and sigma squared.

20
00:01:10,000 --> 00:01:12,000
And now I will apply a trick.

21
00:01:12,000 --> 00:01:14,000
Instead of maximizing this expression,

22
00:01:14,000 --> 00:01:17,000
I will maximize the logarithm of this expression.

23
00:01:17,000 --> 00:01:19,000
The logarithm is a monotonic function.

24
00:01:19,000 --> 00:01:23,000
So let's maximize instead the logarithm

25
00:01:23,000 --> 00:01:27,000
where this expression over here resolves to this expression over here.

26
00:01:27,000 --> 00:01:32,000
The multiplication becomes a minus sign from over here,

27
00:01:32,000 --> 00:01:35,000
and this is the argument inside the exponent

28
00:01:35,000 --> 00:01:37,000
written slightly differently,

29
00:01:37,000 --> 00:01:40,000
but pulling the 2 sigma squared to the left.

30
00:01:40,000 --> 00:01:42,000
So let's maximize this one instead.

31
00:01:42,000 --> 00:01:45,000
The maximum was obtained where the first

32
00:01:45,000 --> 00:01:48,000
derivative is zero.

33
00:01:48,000 --> 00:01:51,000
If we do this for our variable mu,

34
00:01:51,000 --> 00:01:53,000
we take the "log f" expression and

35
00:01:53,000 --> 00:01:56,000
complete the derivative for spectrum mu,

36
00:01:56,000 --> 00:01:58,000
we get following--

37
00:01:58,000 --> 00:02:01,000
This expression does not depend on mu at all, so it falls out.

38
00:02:01,000 --> 00:02:05,000
And we can still get this expression over here, which we've set to zero.

39
00:02:05,000 --> 00:02:11,000
And now we can multiply everything by sigma squared next to zero,

40
00:02:11,000 --> 00:02:15,000
and then bring the Xi to the right and the mu to the left.

41
00:02:15,000 --> 00:02:24,000
The sum over all "E" of the mu is mu equals sum over i, xi.

42
00:02:24,000 --> 00:02:31,000
Hence, we proved that the mean is indeed the maximum likelihood estimate

43
00:02:31,000 --> 00:02:33,000
for the Gaussian.

44
00:02:33,000 --> 00:02:38,000
This is now easily repeated for the variance.

45
00:02:38,000 --> 00:02:41,000
If you compute the derivative of this expression over here

46
00:02:41,000 --> 00:02:43,000
with respect to the variance,

47
00:02:43,000 --> 00:02:48,000
we get minus "m" over sigma, which happens to be the derivative

48
00:02:48,000 --> 00:02:50,000
of this expression over here.

49
00:02:50,000 --> 00:02:53,000
Keep in mind that the derivative of

50
00:02:53,000 --> 00:02:57,000
a logarithm stresses internal argument

51
00:02:57,000 --> 00:03:01,000
times by chain rule--the derivative of the internal argument,

52
00:03:01,000 --> 00:03:05,000
which if you work out becomes this expression over here.

53
00:03:05,000 --> 00:03:08,000
And this guy over here changes signs

54
00:03:08,000 --> 00:03:10,000
but becomes the following.

55
00:03:10,000 --> 00:03:13,000
And again, you move this guy to the left side,

56
00:03:13,000 --> 00:03:18,000
multiply by sigma cubed, and divide by "m".

57
00:03:18,000 --> 00:03:22,000
So we get the following result over here.

58
00:03:22,000 --> 00:03:25,000
You might take a moment to verify these steps over here,

59
00:03:25,000 --> 00:03:27,000
I was a little bit fast,

60
00:03:27,000 --> 00:03:32,000
but this is relatively straight forward mathematics.

61
00:03:32,000 --> 00:03:34,000
And if you will verify them,

62
00:03:34,000 --> 00:03:36,000
you will find that the maximum likelihood estimate

63
00:03:36,000 --> 00:03:39,000
for sigma squared is the average

64
00:03:39,000 --> 00:03:43,000
deviation of data points from the mean mu.

65
00:03:43,000 --> 00:03:45,000
This gives us a very nice basis to fit

66
00:03:45,000 --> 00:03:48,000
Gaussians to data points.

67
00:03:48,000 --> 00:03:52,000
So keeping these formulas in mind, here's a quick quiz,

68
00:03:52,000 --> 00:03:58,000
which I ask you to actually calculate the mean and variance for a data sequence.

69
00:03:58,000 --> 00:04:02,000
So suppose the data you observe is 3, 4, 5, 6, and 7.

70
00:04:02,000 --> 00:04:04,000
There is 5 data points.

71
00:04:04,000 --> 00:04:07,000
Compute for me the mean and the variance

72
00:04:07,000 --> 99:59:59,999
using the maximum likelihood estimator I just gave you.
