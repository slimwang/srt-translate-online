1
00:00:00,400 --> 00:00:04,553
So Raid 0 uses a technique called
striping to improve performance.

2
00:00:04,553 --> 00:00:08,610
So if we have one disk,
it will have a Track 0,

3
00:00:08,610 --> 00:00:13,490
Track 1, Track 2, et cetera,
and the problem is that

4
00:00:13,490 --> 00:00:18,280
while the head is positioned to read
Track 0, it cannot be reading Track 1,

5
00:00:18,280 --> 00:00:22,150
and also its very far away from
all of these other tracks.

6
00:00:22,150 --> 00:00:26,530
So what happens is really, we have to
serialize accesses to all of the tracks.

7
00:00:26,530 --> 00:00:29,380
If we need to read Tracks 0,

8
00:00:29,380 --> 00:00:32,229
17 and 27, we will have to decide
in what order we access them.

9
00:00:32,229 --> 00:00:35,880
But for each of these accesses,
we move the we read the track.

10
00:00:35,880 --> 00:00:37,640
We move on to something else.

11
00:00:37,640 --> 00:00:42,630
So we cannot get more performance
than just reading one track at a time

12
00:00:42,630 --> 00:00:44,970
at the current rotational
speed of the disk.

13
00:00:44,970 --> 00:00:48,670
What rate 0 does is it
takes two disks and

14
00:00:48,670 --> 00:00:54,360
makes them look like this one disk,
by putting the original Track 0 here,

15
00:00:54,360 --> 00:00:59,770
Track 1 here, Track 2 here,
Track 3 here, and so on.

16
00:00:59,770 --> 00:01:05,180
So the idea is that now each of
these tracks is called a stripe now,

17
00:01:05,180 --> 00:01:09,680
and we're going to put stripe 0 really
here, stripe 1 here, and so on.

18
00:01:09,680 --> 00:01:15,520
So Track 0 of the first disk gets
Track 0 from the overall large disk.

19
00:01:15,520 --> 00:01:18,810
Track 0 here, however,
gets the stripe zero.

20
00:01:18,810 --> 00:01:24,870
So instead of calling this tracks,
we call them stripes to avoid confusion

21
00:01:24,870 --> 00:01:30,080
between what's a track on a physical
disk and these things that

22
00:01:30,080 --> 00:01:35,070
really are tracks that would belong
to a fake disk that we don't really

23
00:01:35,070 --> 00:01:38,999
have because really these two disks
are pretending to be this one disk.

24
00:01:40,010 --> 00:01:42,050
As far as performance is concerned,

25
00:01:42,050 --> 00:01:45,260
we get twice the data throughput
if we have two discs.

26
00:01:45,260 --> 00:01:45,910
Why?

27
00:01:45,910 --> 00:01:48,640
Well, because, while the first
disk is reading some data,

28
00:01:48,640 --> 00:01:50,730
the second could be reading data, too.

29
00:01:50,730 --> 00:01:52,330
And because controllers and

30
00:01:52,330 --> 00:01:55,630
buses today are faster than
what the disk can get to.

31
00:01:55,630 --> 00:01:58,960
Effectively we can transfer
twice the amount of data

32
00:01:58,960 --> 00:02:01,740
assuming that those disks
are actually transferring the data.

33
00:02:01,740 --> 00:02:03,040
You can be unlucky and

34
00:02:03,040 --> 00:02:07,110
all the data you want is on the stripes
that are placed in this disk in which

35
00:02:07,110 --> 00:02:10,840
case you're going to get only
the data throughput of a single disk.

36
00:02:10,840 --> 00:02:15,740
But on average we tend to get almost
twice the throughput of a single disk

37
00:02:15,740 --> 00:02:18,730
by splitting the data
across two disks like this.

38
00:02:18,730 --> 00:02:20,780
As far as latency is concerned,

39
00:02:20,780 --> 00:02:24,070
because we have more throughput
we get less curing delay.

40
00:02:24,070 --> 00:02:27,260
Normally we would be able to handle
requests one at a time here.

41
00:02:27,260 --> 00:02:30,270
Now we can actually in
parallel do two requests.

42
00:02:30,270 --> 00:02:34,150
So in the queue,
we get faster to the requests

43
00:02:34,150 --> 00:02:38,560
by basically handling
previous requests faster.

44
00:02:38,560 --> 00:02:40,850
But what about reliability?

45
00:02:40,850 --> 00:02:44,000
Unfortunately, it gets
worse than one disk.
