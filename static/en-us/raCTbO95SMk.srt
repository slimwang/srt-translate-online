1
00:00:00,150 --> 00:00:02,730
All right, now stationary policy,
which sometimes in the literature is

2
00:00:02,730 --> 00:00:05,390
referred to as the universal plan,
is actually

3
00:00:05,390 --> 00:00:10,510
what we talked about in the context of
MDPs, so mapping from states to actions.

4
00:00:10,510 --> 00:00:13,380
And this is a very
powerful sort of thing

5
00:00:13,380 --> 00:00:15,490
because it can handle
stochasticity really well.

6
00:00:15,490 --> 00:00:18,990
Every time you take a transition, you go
back to your table, you go back to your

7
00:00:18,990 --> 00:00:21,780
policy to say, all right,
here's the state that I ended up in.

8
00:00:21,780 --> 00:00:24,090
What's the right thing to do from here?

9
00:00:24,090 --> 00:00:26,910
It is kind of hard to convey
these to people, though.

10
00:00:26,910 --> 00:00:28,500
Do you see why that might be?

11
00:00:28,500 --> 00:00:32,250
>> Yeah, so
one way it might be is because,

12
00:00:32,250 --> 00:00:36,060
I will claim that a stationary policy or
universal plan is just

13
00:00:36,060 --> 00:00:40,490
a conditional plan where you have
an if at every single possible state.

14
00:00:40,490 --> 00:00:43,600
>> That's true but it's actually
a little bit more constrained than that.

15
00:00:43,600 --> 00:00:47,160
Which is it's the same if
at every possible state.

16
00:00:47,160 --> 00:00:47,660
>> Right.

17
00:00:48,940 --> 00:00:50,430
>> So no matter where you came from,

18
00:00:50,430 --> 00:00:53,998
no matter what you were in the middle of
doing, once you discover where you are,

19
00:00:53,998 --> 00:00:56,627
that's going to determine what
your next step's going to be.

20
00:00:56,627 --> 00:01:00,936
>> Right, and
that's a lot of if statements.

21
00:01:00,936 --> 00:01:02,428
>> It's a lot of if statements, yeah.

22
00:01:02,428 --> 00:01:03,915
And right, so if you try to convey it,

23
00:01:03,915 --> 00:01:06,980
you have to actually tell someone
what all those if statements are.

24
00:01:06,980 --> 00:01:09,470
It's sort of like if I want to
give you directions to my house.

25
00:01:09,470 --> 00:01:13,030
A plan might say go left,
go right, go left.

26
00:01:13,030 --> 00:01:16,310
Go down until you get to Maple Street,
make a right.

27
00:01:16,310 --> 00:01:20,890
A conditional plan might say
something like, go to the highway.

28
00:01:20,890 --> 00:01:24,990
If you get there and it's crowded,
then go these back roads, otherwise,

29
00:01:24,990 --> 00:01:25,658
go on the highway.

30
00:01:25,658 --> 00:01:30,080
[LAUGH] And a policy would say
something like, for every location

31
00:01:30,080 --> 00:01:32,670
in my neighborhood, here's
the direction that you should turn.

32
00:01:34,540 --> 00:01:37,880
And yeah, and
that's going to be very large.

33
00:01:37,880 --> 00:01:38,830
>> Right.

34
00:01:38,830 --> 00:01:40,230
And in some ways not very useful.

35
00:01:41,980 --> 00:01:44,618
>> Well, [LAUGH] define useful, right?

36
00:01:44,618 --> 00:01:47,397
So it's very useful in the sense
that it is very powerful and

37
00:01:47,397 --> 00:01:49,352
it can handle any kind of stochasticity.

38
00:01:49,352 --> 00:01:55,539
And there's always an optimal
stationary policy for any MDP.

39
00:01:55,539 --> 00:01:57,580
>> Okay.
>> So that's a really nice property.

40
00:01:57,580 --> 00:02:00,132
You never have to look beyond the
stationary policies to find something

41
00:02:00,132 --> 00:02:01,260
that's optimal.

42
00:02:01,260 --> 00:02:02,960
>> Okay, so
then I take back what I said.

43
00:02:02,960 --> 00:02:05,990
It's not that it's not useful,
it's that, in fact it's very useful.

44
00:02:05,990 --> 00:02:10,834
It's that it's not very compact, or
as you have up there, it's very large.

45
00:02:10,834 --> 00:02:13,577
>> Very large.
>> So you have to say a lot.

46
00:02:13,577 --> 00:02:15,750
>> Yeah, so that's exactly right.

47
00:02:15,750 --> 00:02:16,520
All right, but now for

48
00:02:16,520 --> 00:02:19,040
the learning algorithm, it could
mean that it has to learn a lot.

49
00:02:19,040 --> 00:02:22,260
It has to discover what a reasonable
thing to do is in every one of its

50
00:02:22,260 --> 00:02:23,350
possible states.

51
00:02:23,350 --> 00:02:26,370
So that could actually make
the learning problem difficult.

52
00:02:26,370 --> 00:02:28,490
But anyway, I just wanted to
at least raise this issue.

53
00:02:28,490 --> 00:02:31,950
We're going to be focused, almost
entirely, on these stationary policies.

54
00:02:31,950 --> 00:02:33,640
Because they do allow for

55
00:02:33,640 --> 00:02:36,830
the possibility of expressing
that optimal behavior.

56
00:02:36,830 --> 00:02:37,330
>> Cool.
