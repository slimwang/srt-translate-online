1
00:00:00,000 --> 00:00:03,000
You've now seen a bunch of these token definitions,

2
00:00:03,000 --> 00:00:05,000
one for words, one for strings.

3
00:00:05,000 --> 00:00:10,000
A lexical analyzer or lexer--this is a term of art--

4
00:00:10,000 --> 00:00:13,000
is just a collection of such tokens.

5
00:00:13,000 --> 00:00:16,000
You tell me what makes a word, what makes a string,

6
00:00:16,000 --> 00:00:18,000
what makes a number, what makes white space.

7
00:00:18,000 --> 00:00:21,000
You put it all together, and the result is a lexer,

8
00:00:21,000 --> 00:00:25,000
something that splits a string into exactly

9
00:00:25,000 --> 00:00:29,000
the token definitions you've given it.

10
00:00:29,000 --> 00:00:33,000
For example, once I put these 3 rules together,

11
00:00:33,000 --> 00:00:37,000
they become a lexer, or lexical analyzer.

12
00:00:37,000 --> 00:00:40,000
And in fact, suppose we passed to this lexical analyzer

13
00:00:40,000 --> 00:00:46,000
the input string 33 is less than 55.

14
00:00:46,000 --> 00:00:50,000
Oh, gentle student, tell to me which one of these

15
00:00:50,000 --> 00:00:54,000
token output sequences could result.

16
00:00:54,000 --> 00:00:57,000
In this multiple choice quiz,

17
00:00:57,000 --> 00:01:01,000
indicate which of these 3 possible output lists

18
00:01:01,000 --> 00:01:05,000
could correspond to the values of the tokens

19
00:01:05,000 --> 00:01:08,000
extracted from this input string using these rules.

20
00:01:08,000 --> 99:59:59,999
Let's put it all together.
