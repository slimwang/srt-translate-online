1
00:00:00,070 --> 00:00:03,673
Alright. So, let's pull all this together and look at an example of something

2
00:00:03,673 --> 00:00:09,079
that was really hard to do before and is now shockingly easy with dynamic parallelism.

3
00:00:09,079 --> 00:00:14,784
So, if you remember from one of your earlier lectures, quicksort is what's called a divide and conquer algorithm.

4
00:00:14,784 --> 00:00:18,422
It works my partitioning an array of data into two pieces.

5
00:00:18,422 --> 00:00:22,024
Partitioning based on what's less than or greater than a pivot value.

6
00:00:22,024 --> 00:00:27,146
You then call quicksort on each sub-partition, which is why it's a recursive algorithm.

7
00:00:27,146 --> 00:00:31,944
These sub-partitions then get re-partitioned over and over again, recursively,

8
00:00:31,974 --> 00:00:36,238
and so you end up at the end with single values, and you're done.

9
00:00:36,254 --> 00:00:41,149
Two important things to notice at first that the sub-partitions aren't usually the same size,

10
00:00:41,149 --> 00:00:44,978
and second that some branches go deeper than others.

11
00:00:44,978 --> 00:00:47,562
This means that the number of elements to be sorted is

12
00:00:47,562 --> 00:00:51,049
different each time and so the decision on whether I need to sub-sort can only

13
00:00:51,049 --> 00:00:54,031
be made after I've done the partitioning.

14
00:00:54,031 --> 00:00:57,935
That's what makes it hard to implement on a GPU because after each step,

15
00:00:57,935 --> 00:01:02,977
I need to communicate back to the host CPU all the information about what I want to launch next.

16
00:01:02,977 --> 00:01:08,171
That's a lot of communication at each level of the algorithm and it gets pretty complicated to manage.

17
00:01:08,171 --> 00:01:13,850
But even worse, I end up launching each stage of the sort as a wave of kernels.

18
00:01:13,850 --> 00:01:16,780
As these things partition down further and further,

19
00:01:16,780 --> 00:01:19,449
the number of kernels that I have to launch gets larger and larger,

20
00:01:19,449 --> 00:01:23,753
and the only way to manage them is to launch them wave after wave.

21
00:01:23,753 --> 00:01:29,526
What that means is that I end up waiting as long as the longest operation in a wave,

22
00:01:29,526 --> 00:01:34,705
even if my shorter ones have already finished, before I can move on to the next stage.
