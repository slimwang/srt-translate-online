1
00:00:00,260 --> 00:00:06,070
This next material is bonus. It's optional but it's really cool and it will

2
00:00:06,070 --> 00:00:10,370
only take a few minutes to go through. So far we've only used one predictor

3
00:00:10,370 --> 00:00:15,390
variable. In the case before, the predictor was the distance traveled, and we

4
00:00:15,390 --> 00:00:19,490
were using that to predict the flight cost. But often times there are many

5
00:00:19,490 --> 00:00:23,390
factors that can predict the dependent variable. When we use multiple

6
00:00:23,390 --> 00:00:28,390
predictors, we're doing multiple regression. The purpose is to explain more of

7
00:00:28,390 --> 00:00:35,750
the variation in y. Basically we regress y on predictor 1, predictor 2, all the

8
00:00:35,750 --> 00:00:39,960
way to however many predictors we want. Why don't we do a simple linear

9
00:00:39,960 --> 00:00:43,905
regression for each one? The reason we just have one equation is not only

10
00:00:43,905 --> 00:00:49,410
because it's easier but also because when we include several predictors, we can

11
00:00:49,410 --> 00:00:54,020
calculate the relationship that each predictor has with y independently of the

12
00:00:54,020 --> 00:00:58,740
other predictors. For example, in my master's thesis, I wanted to look at

13
00:00:58,740 --> 00:01:03,350
things that impact student effort in math class. Remember that effort is the

14
00:01:03,350 --> 00:01:06,870
construct. So I measured this by things like whether or not they did their

15
00:01:06,870 --> 00:01:11,470
homework and time spent studying. A lot of things can influence effort.

16
00:01:11,470 --> 00:01:16,300
Specifically, I was interested in how much students value mathematics. Did they

17
00:01:16,300 --> 00:01:20,500
believe that math will help them in their careers? And also how much they enjoy

18
00:01:20,500 --> 00:01:25,420
math class. And their relationship with their teachers. It's possible that

19
00:01:25,420 --> 00:01:29,050
having a good relationship with their teachers can make them enjoy school more.

20
00:01:29,050 --> 00:01:33,570
And if they enjoy school more, they'll put forth more effort. Or maybe students

21
00:01:33,570 --> 00:01:38,265
place value on subjects that they enjoy. When we include all of these as

22
00:01:38,265 --> 00:01:43,660
predictors we no longer have a simple slope. Instead we get regression

23
00:01:43,660 --> 00:01:48,720
coefficients for each predictor variable. These will be numbers. Just like how

24
00:01:48,720 --> 00:01:54,155
before when we had one variable we found the slope and that was our regression

25
00:01:54,155 --> 00:01:58,960
coefficient. In this case we'll have three. These coefficients tell us the rate

26
00:01:58,960 --> 00:02:04,880
of change in y, given a one unit change in each respective variable holding the

27
00:02:04,880 --> 00:02:09,586
others constant. In other words we see the mathematical influence of one

28
00:02:09,586 --> 00:02:13,999
variable while statistically controlling for the influence of the other

29
00:02:13,999 --> 00:02:18,220
variables. We could go into more details but we won't. Multiple regression is

30
00:02:18,220 --> 00:02:22,760
not usually covered in elementary statistics courses. But it's still valuable

31
00:02:22,760 --> 00:02:26,990
to know about, and be able to interpret. Apart from the regression

32
00:02:26,990 --> 00:02:31,610
coefficients, most programs that conduct multiple regression will also provide

33
00:02:31,610 --> 00:02:36,520
a multiple correlation coefficient called r. This is similar to interpretation

34
00:02:36,520 --> 00:02:41,720
to Pierson's r. But it involves one outcome or response variable and more than

35
00:02:41,720 --> 00:02:46,310
one predictor variable. This tells us the strength of the relationship between

36
00:02:46,310 --> 00:02:51,585
y and the combined set of predictors. Usually we're more interested in r

37
00:02:51,585 --> 00:02:57,020
squared, which tells us the proportion of variability in y explained by our set

38
00:02:57,020 --> 00:02:57,960
of predictors.
