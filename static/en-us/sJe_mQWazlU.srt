1
00:00:00,310 --> 00:00:06,010
Don, I want to start off by thanking you
for taking the time to be with us today.

2
00:00:06,010 --> 00:00:10,300
I know the students are going to learn
an awful lot by hearing from you,

3
00:00:10,300 --> 00:00:13,600
and I know you're very busy so
I really appreciate it.

4
00:00:13,600 --> 00:00:14,220
>> My pleasure.

5
00:00:14,220 --> 00:00:16,760
I wish we could share a glass
of wine at the same time, but

6
00:00:16,760 --> 00:00:18,610
anyway, we'll proceed.

7
00:00:18,610 --> 00:00:20,270
>> Well if we can figure
out how to do that you and

8
00:00:20,270 --> 00:00:21,940
I will probably get very rich.

9
00:00:21,940 --> 00:00:24,650
>> Well, we've got a lot of wine
up here in Charlotteville, so

10
00:00:24,650 --> 00:00:25,840
I always try to help the locals.

11
00:00:26,850 --> 00:00:27,350
>> Yes you do.

12
00:00:29,260 --> 00:00:34,330
So, Don you've been a thought
leader in informatics for years.

13
00:00:34,330 --> 00:00:39,190
You've chaired most of the important
IOM Reports that I've alluded to

14
00:00:39,190 --> 00:00:43,060
throughout the course, so
you have a unique perspective.

15
00:00:43,060 --> 00:00:46,760
Where do you think we are today on
transforming our health care system,

16
00:00:46,760 --> 00:00:48,550
particularly through
the use of health IT?

17
00:00:49,810 --> 00:00:52,060
And what are your hopes for the future?

18
00:00:52,060 --> 00:00:55,420
>> Well, it's really been exciting
to have been involved in this.

19
00:00:55,420 --> 00:00:58,400
I guess the only thing that's
frustrating is that I'm

20
00:00:58,400 --> 00:01:03,150
not getting younger because I
think it still has to play out.

21
00:01:03,150 --> 00:01:06,250
But we are really I think
making terrific progress.

22
00:01:06,250 --> 00:01:11,540
When you consider that the 1991 report
on a computer based patient record

23
00:01:11,540 --> 00:01:16,820
was called an essential technology for
health care and that it took

24
00:01:16,820 --> 00:01:21,720
until just 2009 for
the high tech legislation to really

25
00:01:21,720 --> 00:01:27,090
make this a national kind of development
with meaningful use and so forth.

26
00:01:27,090 --> 00:01:30,210
So clearly, these have been
really momentous times, and

27
00:01:30,210 --> 00:01:35,110
it's exciting to me to see that we
are way past the early majority.

28
00:01:35,110 --> 00:01:37,660
We're into the late majority
of people now doing this

29
00:01:37,660 --> 00:01:39,280
both in hospitals and practices.

30
00:01:39,280 --> 00:01:44,480
So having said that, I don't know if
you saw, I can send you the reference.

31
00:01:44,480 --> 00:01:47,500
But I had a paper with a couple
colleagues this years.

32
00:01:47,500 --> 00:01:49,380
The way it was finally broken,
where are we now,

33
00:01:49,380 --> 00:01:51,710
that spoke to some of the issues.

34
00:01:51,710 --> 00:01:52,970
And there are a lot of issues out there.

35
00:01:52,970 --> 00:01:56,200
There's not the interoperability
that we need.

36
00:01:56,200 --> 00:01:59,440
There's not the functionality that
we need from the point of view of

37
00:02:00,600 --> 00:02:04,680
even physicians, let alone all
the other members of the health team.

38
00:02:04,680 --> 00:02:07,590
So it's a glass half full,
half empty kind of thing.

39
00:02:07,590 --> 00:02:11,590
But actually I think it's
really in a good spot.

40
00:02:11,590 --> 00:02:13,920
Some of where we are though is,
of course,

41
00:02:13,920 --> 00:02:19,240
we mostly have been using health IT
in terms of say computer technology.

42
00:02:19,240 --> 00:02:23,230
And I think increasingly now we're
using communications technology.

43
00:02:23,230 --> 00:02:24,310
And all these things are new,

44
00:02:24,310 --> 00:02:28,540
from the time the study was done and
it moved forward.

45
00:02:28,540 --> 00:02:31,750
So, we're always going to be
in the situation of trying to

46
00:02:32,790 --> 00:02:38,030
both keep up with where
the technology and opportunities go.

47
00:02:38,030 --> 00:02:43,630
But a lot of progress has been made, and
I think what I'm excited about, to talk

48
00:02:43,630 --> 00:02:48,620
about also, is where some of the pinch
points are and where we can go next.

49
00:02:48,620 --> 00:02:53,270
>> Well, I will certainly post that
paper for the students to read.

50
00:02:56,100 --> 00:03:01,410
As we look at a health care system that
is increasingly using digital records

51
00:03:01,410 --> 00:03:06,740
instead of paper, the research community
is very excited about the prospect of

52
00:03:06,740 --> 00:03:11,970
having access to huge amounts of digital
data to study it, to help improve care,

53
00:03:11,970 --> 00:03:16,380
gain new knowledge, and maybe even
improve the healthcare system itself.

54
00:03:16,380 --> 00:03:21,065
But I don't have to tell you, getting
to that data is often a very difficult,

55
00:03:21,065 --> 00:03:26,420
time-consuming process, mostly because
of concerns about patient privacy.

56
00:03:27,700 --> 00:03:31,170
Some people feel maybe the pendulum
has swung too far on that, and

57
00:03:31,170 --> 00:03:34,600
we're actually harming our ability
to use digital data as a result.

58
00:03:34,600 --> 00:03:35,690
What's your view?

59
00:03:35,690 --> 00:03:38,430
>> Well, in fact, I am one of
those people who believe that.

60
00:03:38,430 --> 00:03:43,080
Some of the issues are not necessarily
the HIPAA legislation per se.

61
00:03:43,080 --> 00:03:49,202
But clearly I think HHS has not in fact
creatively tried to manage to this,

62
00:03:49,202 --> 00:03:53,090
to balance these competitive goods.

63
00:03:53,090 --> 00:03:54,670
Privacy's a good thing.

64
00:03:54,670 --> 00:03:57,540
But too much privacy and
obviously you can't have knowledge,

65
00:03:57,540 --> 00:04:01,560
you can't run a government,
you can't run research and so forth.

66
00:04:01,560 --> 00:04:05,430
And I think that the principle problem
with HIPPA was that it was built in

67
00:04:05,430 --> 00:04:08,930
an era, and it was all pre-Internet.

68
00:04:08,930 --> 00:04:11,780
So the fact that you could
do data analytics and

69
00:04:11,780 --> 00:04:16,529
do translational bioinfomatics and
the human genome and proteomics and

70
00:04:16,529 --> 00:04:20,120
epigenetics with
epidemiologic data as well.

71
00:04:20,120 --> 00:04:25,660
Let alone using it to improve health
care systems with clinical alerts and

72
00:04:25,660 --> 00:04:30,170
even community health approaches using
public health dimensions to this.

73
00:04:30,170 --> 00:04:32,000
All of that was well before HIPAA.

74
00:04:32,000 --> 00:04:37,860
So, candidly, I've been spending
hours up on the hill with energy and

75
00:04:37,860 --> 00:04:42,730
commerce staff to try to see if we can,
as part of their initiative

76
00:04:43,840 --> 00:04:49,590
to improve, really cures is where
they're wanting to go, but care as well.

77
00:04:49,590 --> 00:04:53,750
See how we can hopefully make some
reforms in these things because right

78
00:04:53,750 --> 00:04:59,130
now it's not only a problem for research
it's also a problem for education too.

79
00:04:59,130 --> 00:05:04,800
I hear issues where pharmacy
students are interested in trying

80
00:05:04,800 --> 00:05:08,570
to learn how to do data mining and
looking at drug use and so

81
00:05:09,570 --> 00:05:14,870
forth can't get to the record data at
some schools for some various reasons.

82
00:05:14,870 --> 00:05:18,093
As I say, the issue is not only
the legislation which was built for

83
00:05:18,093 --> 00:05:19,020
a different era.

84
00:05:19,020 --> 00:05:24,710
Mostly clinical trials where
the patient was at risk, to secure use

85
00:05:24,710 --> 00:05:29,400
of these data for data analytics where,
honestly, the risks are extremely small.

86
00:05:30,400 --> 00:05:35,710
And I think, actually, if you look
at hospitals around the country

87
00:05:35,710 --> 00:05:40,930
that are doing research, most patients
actually overwhelmly want doctors to do,

88
00:05:40,930 --> 00:05:43,380
and other health professionals,
to do this research, and

89
00:05:43,380 --> 00:05:46,560
in fact actually sort of assumed
that we already were doing it.

90
00:05:46,560 --> 00:05:49,630
So, we really clearly
have some issues here.

91
00:05:50,870 --> 00:05:55,270
And there've been cultural issues where
not all scientists have eagerly wanted

92
00:05:55,270 --> 00:06:00,050
to share data, but I think the Clinical
Translational Science Awards have really

93
00:06:00,050 --> 00:06:01,740
cracked into that.

94
00:06:01,740 --> 00:06:06,800
Plus, what has happened in the last
100 years is the human species

95
00:06:06,800 --> 00:06:11,930
has not only been very productive, but
they've been very reproductive too.

96
00:06:11,930 --> 00:06:15,230
And as a result of that the human
genome's gotten more complicated.

97
00:06:15,230 --> 00:06:17,440
So if we're going to
really crack these things,

98
00:06:17,440 --> 00:06:22,380
which we can,
we really need very big data sets.

99
00:06:22,380 --> 00:06:25,530
And you can't aggregate those, in fact,

100
00:06:25,530 --> 00:06:30,400
where you talk to a group of patients or
patient advocates with one problem

101
00:06:30,400 --> 00:06:35,170
because a lot of these
are multidimensional kinds of problems.

102
00:06:35,170 --> 00:06:36,030
In fact most of them are.

103
00:06:36,030 --> 00:06:42,140
They're not single, single chain or
single issue, single dimensional issues.

104
00:06:42,140 --> 00:06:44,750
So anyway, tremendous opportunities, but

105
00:06:44,750 --> 00:06:49,650
also candidly we are leaving a huge
amount of discovery on the table.

106
00:06:49,650 --> 00:06:54,880
Example, another quick example, HIPPA
says you can use personal health data,

107
00:06:54,880 --> 00:06:57,919
identifiable data for
doing quality studies in a hospital.

108
00:06:58,920 --> 00:07:02,822
But if you find something that really
you'd like to share with your neighbors

109
00:07:02,822 --> 00:07:06,424
and colleagues and publish it, you
gotta go all the way back to an IRB and

110
00:07:06,424 --> 00:07:07,380
start all over.

111
00:07:07,380 --> 00:07:10,892
Well, busy people may not
want to mess with that now, and

112
00:07:10,892 --> 00:07:14,180
some big institutions,
they spend a lot of money and

113
00:07:14,180 --> 00:07:18,540
extra effort to help facilitate
people being able to deal with that.

114
00:07:18,540 --> 00:07:23,084
But, we can't afford to lose that
wherever it is, smaller institutions or

115
00:07:23,084 --> 00:07:24,510
larger institutions.

116
00:07:24,510 --> 00:07:25,740
So, we've gotta work smarter.

117
00:07:25,740 --> 00:07:26,760
We can't work harder.

118
00:07:26,760 --> 00:07:31,320
I think the government's not going to
throw more money at health care.

119
00:07:31,320 --> 00:07:37,030
That's, I think, becoming increasingly
relevant for both research as well.

120
00:07:37,030 --> 00:07:40,310
So we've gotta get better data
liquidity, as the term is called, and

121
00:07:40,310 --> 00:07:42,970
let it move around for
care, for research, and

122
00:07:42,970 --> 00:07:47,540
then also ultimately then for
population health.

123
00:07:47,540 --> 00:07:50,590
>> Well, you've mentioned
patients a number of times.

124
00:07:50,590 --> 00:07:54,820
And I think most people would agree
that patients are the ultimate

125
00:07:54,820 --> 00:07:57,380
decider when it comes to
the use of their data.

126
00:07:59,050 --> 00:08:03,230
And a number of people have suggested
that patients create their own data

127
00:08:03,230 --> 00:08:09,000
repositories that might be housed in a
PHR or some other tool specifically for

128
00:08:09,000 --> 00:08:12,600
the purpose of mediating
the sharing of their data.

129
00:08:12,600 --> 00:08:15,020
Do you think this is
an inevitable development?

130
00:08:15,020 --> 00:08:18,300
Do you think it's a good
development if it happens?

131
00:08:18,300 --> 00:08:22,040
Might that be the way to increase
the accessibility of clinical data for

132
00:08:22,040 --> 00:08:24,000
research and other purposes?

133
00:08:24,000 --> 00:08:27,200
>> Well, if it were the only
approach I'd be strongly against

134
00:08:27,200 --> 00:08:31,510
it mostly because that we
know at least 25% of people

135
00:08:31,510 --> 00:08:33,799
really don't care if their
data are used for anything.

136
00:08:33,799 --> 00:08:36,820
But they don't want to be
bothered to be asked about it.

137
00:08:36,820 --> 00:08:40,634
So anytime you're carving out
25% of the population, and

138
00:08:40,634 --> 00:08:44,320
keep in mind the population
may be split differently.

139
00:08:44,320 --> 00:08:49,510
For example, a number of years ago
Minnesota passed a law that said you

140
00:08:49,510 --> 00:08:53,780
had to get people's permission to use
their data, and it turned out Rochester

141
00:08:53,780 --> 00:08:58,560
was doing a lot of work also in breast
cancer, particularly in younger women.

142
00:08:58,560 --> 00:09:01,210
Well, in Minnesota,
it was very disproportionately

143
00:09:01,210 --> 00:09:04,645
young women who decided to opt
out of having their data shared.

144
00:09:04,645 --> 00:09:07,470
Well as a result of that

145
00:09:07,470 --> 00:09:11,150
nobody could do research because their
sample sizes weren't big enough.

146
00:09:11,150 --> 00:09:13,870
And obviously I think
that's the challenge.

147
00:09:13,870 --> 00:09:18,470
It sounds kind of good from
a patient autonomy point of view.

148
00:09:18,470 --> 00:09:22,990
But I don't think it's any way to get
discovery in an era where big data

149
00:09:22,990 --> 00:09:26,539
where you really can try to get to the
core of things and create real cures.

150
00:09:27,730 --> 00:09:30,380
Now, if you're talking
about certain areas,

151
00:09:30,380 --> 00:09:33,840
I'm not saying that it's
a uniformly bad idea, but

152
00:09:33,840 --> 00:09:38,770
if you only had one arrow you could
shoot, frankly I think we need to decide

153
00:09:38,770 --> 00:09:42,990
that as a society, we care enough about
each other that we're going to share

154
00:09:42,990 --> 00:09:47,050
our data to cure things so all of us
can live longer and live better lives.

155
00:09:47,050 --> 00:09:50,420
And also, by the way,
have a cheaper health care system,

156
00:09:50,420 --> 00:09:52,040
which we clearly need as well.

157
00:09:52,040 --> 00:09:56,130
So, I don't know if that's responsive,
but that's a quick answer.

158
00:09:56,130 --> 00:09:58,720
>> No, that's a great answer.

159
00:09:58,720 --> 00:10:03,950
Well, Don, I think the students have
really gotten some tremendous insights

160
00:10:03,950 --> 00:10:08,940
here from someone who's been obviously
one of the great thinkers about this for

161
00:10:08,940 --> 00:10:13,990
many decades now, and I appreciate you
sharing those insights with the students

162
00:10:13,990 --> 00:10:15,840
and taking the time with us.

163
00:10:15,840 --> 00:10:16,560
Thank you very much.

164
00:10:16,560 --> 00:10:18,490
>> Well you're very gracious.

165
00:10:18,490 --> 00:10:20,540
I enjoy when we can get together and

166
00:10:20,540 --> 00:10:23,170
obviously hope that it can
happen more often in the future.

167
00:10:23,170 --> 00:10:27,420
If a particular student does have
a question that they'd care to

168
00:10:27,420 --> 00:10:32,054
write to me about, I'm not saying how
quickly I'd get back to them, but

169
00:10:32,054 --> 00:10:35,640
detmer@virginia.edu and
I'd try to respond.

170
00:10:35,640 --> 00:10:41,960
And I'll also send a few references to
you that might be potentially useful.

171
00:10:41,960 --> 00:10:43,350
>> All right, well thank you very much.

172
00:10:43,350 --> 00:10:44,000
>> Yeah, thank you.

173
00:10:44,000 --> 00:10:44,500
Have a good day.
