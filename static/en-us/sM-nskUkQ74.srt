1
00:00:00,610 --> 00:00:02,660
So what is the correspondence problem?

2
00:00:02,660 --> 00:00:07,240
Well, basically the epipolar constraint constrains what our solution is but

3
00:00:07,240 --> 00:00:11,140
it doesn't solve our solution so here we have a bunch of points in

4
00:00:11,140 --> 00:00:15,260
the left image and we know they lie along the epipolar line in the right image,

5
00:00:15,260 --> 00:00:17,780
but the question is what are the matches?

6
00:00:17,780 --> 00:00:19,374
And here in hypothesis 1, 2,

7
00:00:19,374 --> 00:00:23,680
and 3, col coded in grey here, you can see these are different possible matches.

8
00:00:23,680 --> 00:00:25,770
And so for each point in the left image,

9
00:00:25,770 --> 00:00:29,730
we have to decide what the match is in the right image or vice versa.

10
00:00:29,730 --> 00:00:32,080
So, to help solve the correspondence problem,

11
00:00:32,080 --> 00:00:34,275
what we need are some additional constraints.

12
00:00:34,275 --> 00:00:36,520
The epipolar constraint was a hard constraint, that is,

13
00:00:36,520 --> 00:00:40,720
it must be true, it's enforced by the camera jet, the relative camera geometry.

14
00:00:40,720 --> 00:00:44,910
But there are other types of constraints, which we might call soft constraints.

15
00:00:44,910 --> 00:00:48,140
One is similarity, which says that pixels in the left image should look

16
00:00:48,140 --> 00:00:51,590
about like that fixes the right image if you have the right match.

17
00:00:51,590 --> 00:00:53,554
Uniqueness says that there's up to no,

18
00:00:53,554 --> 00:00:56,680
no more than one match at a left pixel in the right image.

19
00:00:56,680 --> 00:01:01,440
Ordering says if pixels go abc in the left image they go abc in the right.

20
00:01:01,440 --> 00:01:03,140
And disparity gradient is limited.

21
00:01:03,140 --> 00:01:05,900
That means that the depth doesn't change too quickly.

22
00:01:05,900 --> 00:01:07,220
We'll talk about some of these today but

23
00:01:07,220 --> 00:01:09,372
where we're going to start with is similarity.

24
00:01:09,372 --> 00:01:12,550
Similarity is essentially saying that the image patch

25
00:01:12,550 --> 00:01:14,970
from the left should match the image patch from the right.

26
00:01:16,070 --> 00:01:19,430
So, to find matches in the image pair we're going to assume,

27
00:01:19,430 --> 00:01:23,000
first of all that most points that are visible in one view are also going to be

28
00:01:23,000 --> 00:01:23,640
visible in the other.

29
00:01:23,640 --> 00:01:25,100
So we'll go looking for them.

30
00:01:25,100 --> 00:01:29,380
And that the image regions for the matches are similar in appearance.

31
00:01:29,380 --> 00:01:31,760
So here's how we're going to do the dense correspondence.

32
00:01:31,760 --> 00:01:34,540
Dense correspondence meaning we're finding match everywhere.

33
00:01:34,540 --> 00:01:37,070
For every pixel, let's say in the left image,

34
00:01:37,070 --> 00:01:39,962
we're going to take a little window around that pixel.

35
00:01:39,962 --> 00:01:44,410
We're going to compare it with every pixel, slash window, in the right image.

36
00:01:44,410 --> 00:01:49,220
And we're going to just pick the position that is either the most similar, or

37
00:01:49,220 --> 00:01:50,520
the least dissimilar, and

38
00:01:50,520 --> 00:01:54,650
that best match, that's what we're going to assume is our corresponding point.

39
00:01:54,650 --> 00:01:56,880
So, here's a very simple illustration.

40
00:01:56,880 --> 00:01:59,540
So I have a scan line across both images, and

41
00:01:59,540 --> 00:02:02,420
we're assuming parallel scan lines for now.

42
00:02:02,420 --> 00:02:05,290
And I've got my window in my left image, and

43
00:02:05,290 --> 00:02:08,834
I'm going to compare it to a bunch of windows in my right image.

44
00:02:08,834 --> 00:02:09,371
And the kuh,

45
00:02:09,371 --> 00:02:13,550
the matching cost is computed everywhere, and so this is just a not,

46
00:02:13,550 --> 00:02:18,420
a notional description of what to the matching costs as a function of disparity.

47
00:02:18,420 --> 00:02:21,930
So how far off I am from the, the first match.

48
00:02:21,930 --> 00:02:22,840
And of course the idea is,

49
00:02:22,840 --> 00:02:26,600
well, we're going to pick the value that has the best score.

50
00:02:26,600 --> 00:02:30,760
So, I might use something called sum of squared differences,

51
00:02:30,760 --> 00:02:33,240
which is the sum of the squared differences.

52
00:02:33,240 --> 00:02:34,070
Wasn't that a surprise?

53
00:02:34,070 --> 00:02:37,530
No. What you do is you take the two pixel windows, you overlap them,

54
00:02:37,530 --> 00:02:42,190
you subtract them, you square the differences, and then you sum them up.

55
00:02:42,190 --> 00:02:46,230
So that would be a measure, and that's why at the top it says dissimilarities.

56
00:02:46,230 --> 00:02:50,390
Now, sometimes, let's suppose one image was a little bit brighter than the other

57
00:02:50,390 --> 00:02:54,070
image, you know, for some reason the gains weren't set so well on the camera.

58
00:02:54,070 --> 00:03:01,350
If I just do direct subtraction, even if the match is exactly the right place.

59
00:03:01,350 --> 00:03:04,570
Because of that scaling of the intensity, I'm going to get

60
00:03:04,570 --> 00:03:08,780
square difference error, and it might not lead me to get to the best match.

61
00:03:08,780 --> 00:03:12,160
Now we've already talked about how to eliminate the problem of scaling.

62
00:03:12,160 --> 00:03:14,930
Remember, we talked about doing normalized correlation where

63
00:03:14,930 --> 00:03:18,830
we scale the value of the window so it has the same standard deviation?

64
00:03:18,830 --> 00:03:19,960
So, you could do that here, too.

65
00:03:19,960 --> 00:03:22,090
You could take your window and slide it across,

66
00:03:22,090 --> 00:03:25,220
doing normalized correlation instead of sum of square differences.

67
00:03:25,220 --> 00:03:27,410
And that's actually a similarity constraint.
