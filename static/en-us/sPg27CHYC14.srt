1
00:00:00,310 --> 00:00:01,910
So here's the first property.

2
00:00:01,910 --> 00:00:06,700
First property says that for
all Q functions,

3
00:00:06,700 --> 00:00:10,778
U1 and U2, and
see I used a Q function and U together.

4
00:00:10,778 --> 00:00:11,784
>> Uh-huh.

5
00:00:11,784 --> 00:00:16,300
>> Just because you thought it was funny
that I kept saying Q function and Q.

6
00:00:16,300 --> 00:00:17,775
So now I said Q function and U.

7
00:00:17,775 --> 00:00:18,615
>> [LAUGH]
>> All right,

8
00:00:18,615 --> 00:00:21,220
for all
>> Q functions U1 and U2 and

9
00:00:21,220 --> 00:00:22,680
state action pair SA.

10
00:00:24,170 --> 00:00:26,440
This is true, all right, what the heck.

11
00:00:26,440 --> 00:00:30,250
What's happening here,
we're taking this B operator,

12
00:00:30,250 --> 00:00:34,800
applying it to U1 to get a new
operator that we apply to Q star and

13
00:00:34,800 --> 00:00:39,160
we compare that to that same
Operator Bt applied to U2.

14
00:00:39,160 --> 00:00:42,770
Whatever operator we get out of
that we also apply to Q star.

15
00:00:42,770 --> 00:00:45,760
What has to be true,
what we need to be true,

16
00:00:45,760 --> 00:00:49,930
is that this is going to be less than or
equal to one minus the learning rate,

17
00:00:49,930 --> 00:00:52,550
times the difference
between the U functions.

18
00:00:52,550 --> 00:00:56,450
So this is a non-expansion
property again.

19
00:00:56,450 --> 00:01:02,056
Right, that the update rule, the
>> Right,

20
00:01:02,056 --> 00:01:06,903
that the update rule, the operator
that we're using to modify the inner

21
00:01:06,903 --> 00:01:11,750
value function at the B, is going to
have this averaging property to it that

22
00:01:11,750 --> 00:01:16,710
what we're ultimately doing is
computing the expected value.

23
00:01:16,710 --> 00:01:20,330
It's not exactly what this says, but
that's how it's going to be used.

24
00:01:20,330 --> 00:01:21,130
>> Okay.
>> So the important thing

25
00:01:21,130 --> 00:01:23,880
here is this just doesn't make
things get farther apart.

26
00:01:23,880 --> 00:01:27,080
Okay, by the way, I just want to
say I really appreciate your proper

27
00:01:27,080 --> 00:01:28,590
use of farther instead of further.

28
00:01:28,590 --> 00:01:30,410
It makes me very happy.

29
00:01:30,410 --> 00:01:32,100
>> I try really hard
when I'm talking to you.

30
00:01:32,100 --> 00:01:33,000
>> Thank you, I appreciate that.

31
00:01:33,000 --> 00:01:35,970
>> All right, so here's the second
condition that has to be true.

32
00:01:35,970 --> 00:01:41,810
That for all Q functions Q,
Q functions U, and state S action a,

33
00:01:41,810 --> 00:01:46,440
we need another kind of, well in this
case, contraction property to hold true.

34
00:01:46,440 --> 00:01:50,230
There's a, our gamma is sitting
in there, gamma is less that 1.

35
00:01:50,230 --> 00:01:51,108
See.

36
00:01:51,108 --> 00:01:52,435
>> Mm-hm.

37
00:01:52,435 --> 00:01:57,460
>> And what we're saying is that
if we hold fix this U value,

38
00:01:57,460 --> 00:02:01,190
this value that plays this
role in the operator, and

39
00:02:01,190 --> 00:02:06,120
the other 1 is Q* and Q
>> That we actually get a contraction of

40
00:02:06,120 --> 00:02:10,476
Q towards Q* by applying
this operator in both cases.

41
00:02:10,476 --> 00:02:14,840
All right, so
[LAUGH] we're almost there.

42
00:02:16,060 --> 00:02:20,130
Lastly, we're going to need our standard
condition on the learning rates to hold,

43
00:02:20,130 --> 00:02:22,320
right, which is that they
sum up to infinity and

44
00:02:22,320 --> 00:02:24,840
the square sum of less than infinity
>> But

45
00:02:25,840 --> 00:02:28,130
there's something hidden
in this definition.

46
00:02:28,130 --> 00:02:30,650
It took me a long time when I read
the first proofs of this, like,

47
00:02:30,650 --> 00:02:32,320
no this can't be true.

48
00:02:32,320 --> 00:02:36,010
In fact, what's happening here is that
given that we set the learning rate

49
00:02:36,010 --> 00:02:39,550
to zero, when there's state-action
pairs that we're not visiting.

50
00:02:39,550 --> 00:02:43,730
The only way that this sum of learning
rates for state-action pairs is going to

51
00:02:43,730 --> 00:02:49,590
be infinity, Is if we visit every
state action pair infinitely often.

52
00:02:49,590 --> 00:02:52,770
So not only is this saying something
about the learning rates have to change.

53
00:02:52,770 --> 00:02:57,090
It's giving an additional constraint on
how we have to visit state action pairs.

54
00:02:57,090 --> 00:03:00,010
>> Wait, so then if that's true that
gives you infinity why doesn't that give

55
00:03:00,010 --> 00:03:01,430
you the squared?

56
00:03:01,430 --> 00:03:04,360
Why does that still get you
the square less than infinity?

57
00:03:04,360 --> 00:03:08,110
>> So the infinity and
the square less than infinity is here,

58
00:03:08,110 --> 00:03:11,630
because we're going to be doing the
standard kind of averaging trick, and

59
00:03:11,630 --> 00:03:14,060
we need the learning rates
to decay the right way.

60
00:03:14,060 --> 00:03:17,920
But what I'm pointing out is that in
addition to that condition that we

61
00:03:17,920 --> 00:03:22,030
generally we need when we're doing
convergence of stochastic things.

62
00:03:22,030 --> 00:03:24,890
We also have an additional
constraints that's hidden in here.

63
00:03:24,890 --> 00:03:28,980
Which is it's saying, we have to visit
all state action pairs infinitely often.

64
00:03:28,980 --> 00:03:32,980
If we don't,
then the sum of the learning rates is

65
00:03:32,980 --> 00:03:34,620
not going to be infinity,
it's going to be something finite.

66
00:03:36,400 --> 00:03:37,220
Oh, I see.

67
00:03:37,220 --> 00:03:39,640
No, no, no, that's right,
that makes sense, that makes sense.

68
00:03:39,640 --> 00:03:40,280
Oh, so cool.
So

69
00:03:40,280 --> 00:03:42,650
basically our algorithms
will converge so

70
00:03:42,650 --> 00:03:45,445
long as we take an infinite
amount of time.

71
00:03:45,445 --> 00:03:46,380
>> [LAUGH] Well,

72
00:03:46,380 --> 00:03:50,102
convergence is an infinite amount of
time kind of thing, just to be fair.

73
00:03:50,102 --> 00:03:52,480
>> Mm-hm, mm-hm, no,
that's very, very satisfying.

74
00:03:53,690 --> 00:03:56,980
Later in the class we'll talk about
some results that actually hold,

75
00:03:56,980 --> 00:03:59,060
believe it or not, infinite time.

76
00:03:59,060 --> 00:04:02,820
But this, yeah, this result is
intended to hold in infinite time.

77
00:04:04,330 --> 00:04:05,410
>> I'll believe it when I see it.
