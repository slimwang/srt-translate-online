1
00:00:00,440 --> 00:00:02,980
Now, we kind of cheated here. Because I told you there's just

2
00:00:02,980 --> 00:00:05,720
these, those two strategies. But there's actually a bunch of other strategies

3
00:00:05,720 --> 00:00:08,550
you can play against tit for tat. And it's worth thinking through,

4
00:00:08,550 --> 00:00:12,830
how do you compute a best response to some finite-state strategy? So

5
00:00:12,830 --> 00:00:15,000
tit for tat is a finite-state strategy in that it has these

6
00:00:15,000 --> 00:00:19,630
two [LAUGH], these two states. And the strategies expressed in terms of

7
00:00:19,630 --> 00:00:22,650
transitions between those two states. But in general, if we have some

8
00:00:22,650 --> 00:00:25,640
kind of finite-state strategy, like tit for tat, how do we figure

9
00:00:25,640 --> 00:00:28,320
out how to maximize our own reward in the

10
00:00:28,320 --> 00:00:31,410
face of playing against that strategy? So in this

11
00:00:31,410 --> 00:00:33,810
picture here that I drew, the states are labeled

12
00:00:33,810 --> 00:00:37,874
with the opponent's choice, the finite state strategies choice, okay?

13
00:00:37,874 --> 00:00:38,792
>> Mm-hm.

14
00:00:38,792 --> 00:00:42,100
>> The edges, that's in black, the edges and

15
00:00:42,100 --> 00:00:44,270
labeled in green here, are labeled with our choice.

16
00:00:44,270 --> 00:00:46,100
So, for example, if we're in this state of

17
00:00:46,100 --> 00:00:48,160
the, sorry, if our opponent is in this state.

18
00:00:48,160 --> 00:00:49,001
>> Mm-hm.

19
00:00:49,001 --> 00:00:50,140
>> We have a choice. We can either

20
00:00:50,140 --> 00:00:52,130
cooperate or defect. On this round.

21
00:00:52,130 --> 00:00:52,950
>> Mm-hm.

22
00:00:52,950 --> 00:00:57,310
>> So, the green arrows tell us how that will impact the state of the

23
00:00:57,310 --> 00:00:59,060
opponent. And then these red numbers, I

24
00:00:59,060 --> 00:01:01,560
just added the information about well I know

25
00:01:01,560 --> 00:01:05,540
that if the opponant is about to cooperate and I choose to cooperate. I can

26
00:01:05,540 --> 00:01:09,040
just look up in the pay off matrix that that's a -1 for me. Right? Agreed?

27
00:01:09,040 --> 00:01:09,430
>> Agreed.

28
00:01:09,430 --> 00:01:11,920
>> So I just annotated all these edges, all these choices with these

29
00:01:11,920 --> 00:01:15,510
extra numbers. So, one of the things that's cool about this is unlike

30
00:01:15,510 --> 00:01:18,890
just the payoff matrix representation that we had before, our

31
00:01:18,890 --> 00:01:21,490
choice, it impacts the payoff, which is the same as

32
00:01:21,490 --> 00:01:24,540
that, but it also impacts the future decisions of the

33
00:01:24,540 --> 00:01:27,050
opponent. And that gives us this structure here and also

34
00:01:27,050 --> 00:01:29,620
says that maybe this is a slightly harder thing to

35
00:01:29,620 --> 00:01:32,720
figure out because of the fact that we can't just

36
00:01:32,720 --> 00:01:36,400
maximize our, the number. We actually have to think about

37
00:01:36,400 --> 00:01:38,520
where that's going to lead us in the future as well.

38
00:01:38,520 --> 00:01:40,520
>> So two things then. One,

39
00:01:41,590 --> 00:01:44,040
I was always fond of saying that the matrix was all that you

40
00:01:44,040 --> 00:01:47,900
needed. But that really only made sense when you were just playing once.

41
00:01:47,900 --> 00:01:49,050
>> Yes. That's right.

42
00:01:49,050 --> 00:01:53,100
>> Right? And, two, I look at this and it's a finite state machine

43
00:01:53,100 --> 00:01:55,990
but you know what else it looks like to me? It looks like an MDP.

44
00:01:55,990 --> 00:01:58,930
>> Excellent. It is indeed an MDP. Now,

45
00:01:58,930 --> 00:02:01,320
it's a, in this case, my opponent's finite

46
00:02:01,320 --> 00:02:03,740
state strategy is deterministic, so it's a deterministic

47
00:02:03,740 --> 00:02:06,350
MDP, but it is. It's a discounted MDP.

48
00:02:06,350 --> 00:02:08,590
Gamma's playing the role of the discount factor.

49
00:02:08,590 --> 00:02:10,960
The entries from the payoff matrix are playing

50
00:02:10,960 --> 00:02:13,330
the roles of rewards Our action is playing

51
00:02:13,330 --> 00:02:17,460
the choice of our action, and the opponent's

52
00:02:17,460 --> 00:02:19,530
internal state structure is playing the role our

53
00:02:19,530 --> 00:02:21,620
states. So it is, it's an MDP, and

54
00:02:21,620 --> 00:02:23,010
so how do we figure out what an

55
00:02:23,010 --> 00:02:26,780
optimal strategy is against a finite state strategy?

56
00:02:26,780 --> 00:02:27,560
>> We solve the MDP.

57
00:02:27,560 --> 00:02:31,610
>> Yeah, exactly. So any, any method for solving an MDP can then be used

58
00:02:31,610 --> 00:02:35,680
to actually compute the strategy, so what is the strategy going to look like? It

59
00:02:35,680 --> 00:02:40,468
is going to be a mapping from states of the opponent to action choices for us.

60
00:02:40,468 --> 00:02:43,300
>> Right, but that's fine because a state

61
00:02:43,300 --> 00:02:46,020
does not have to be your state, it's

62
00:02:46,020 --> 00:02:48,200
just what matters. What matters in this case

63
00:02:48,200 --> 00:02:49,900
is what they opponent is going to do.

64
00:02:49,900 --> 00:02:52,030
>> Right. So now what are the strategies

65
00:02:52,030 --> 00:02:56,382
that can be meaningful against tit for tat?

66
00:02:56,382 --> 00:02:56,780
>> So

67
00:02:56,780 --> 00:02:59,790
if we cooperate then we're going to stay in

68
00:02:59,790 --> 00:03:01,140
this state and it's always going to be the

69
00:03:01,140 --> 00:03:03,170
right thing to do to cooperate. So always

70
00:03:03,170 --> 00:03:07,060
cooperate is one. If we always, if we defect,

71
00:03:07,060 --> 00:03:08,910
now we have a choice again so we

72
00:03:08,910 --> 00:03:11,760
could defect from this state which would cause us

73
00:03:11,760 --> 00:03:14,610
to defect forever, so always defect is another

74
00:03:14,610 --> 00:03:16,360
one. But what's the other thing that could happen?

75
00:03:16,360 --> 00:03:18,450
>> Well, we could tit for tat ourselves.

76
00:03:18,450 --> 00:03:21,929
>> Well, sort of. I mean, so, we could defect, so we could

77
00:03:21,929 --> 00:03:26,190
defect against cooperate, but cooperate against defect. Which

78
00:03:26,190 --> 00:03:29,954
would actually cause us to do D-C, D-C,

79
00:03:29,954 --> 00:03:36,220
D-C. So those are the only, oh I see. No, you're right. I'm not sure how to

80
00:03:36,220 --> 00:03:38,580
say it. But the policy is, defect when

81
00:03:38,580 --> 00:03:40,440
you're in this state, and cooperate when you're in

82
00:03:40,440 --> 00:03:44,130
this state. But the effect of that is to go back and forth against tit for tat.

83
00:03:44,130 --> 00:03:44,530
>> Right.

84
00:03:44,530 --> 00:03:47,700
>> Basically, take this loop here.

85
00:03:47,700 --> 00:03:50,860
And those are the only policies that matter. And in this case, we

86
00:03:50,860 --> 00:03:55,060
worked out that. Always cooperate is good against tit for tat if it has

87
00:03:55,060 --> 00:03:58,070
a high discount factor and always defect is better if you have a

88
00:03:58,070 --> 00:04:01,542
low discount factor. But, we can get that for real by solving the MDP.

89
00:04:01,542 --> 00:04:03,570
>> Right and that makes sense and the reason that those are only

90
00:04:03,570 --> 00:04:05,520
3, let me see if I get this right, the reason those are the

91
00:04:05,520 --> 00:04:08,690
only 3 that makes sense because if you think of this as an MDP

92
00:04:08,690 --> 00:04:12,870
then it has no history, so when you are in C there are only

93
00:04:12,870 --> 00:04:14,210
2 choices and when you are in D there are

94
00:04:14,210 --> 00:04:16,197
really only two choices so if you look at the way

95
00:04:16,197 --> 00:04:18,510
you've drawn it. You either stay were you are in

96
00:04:18,510 --> 00:04:20,459
c or d, or you take the loop. And those are

97
00:04:20,459 --> 00:04:22,650
really the only three options because the rest of them

98
00:04:22,650 --> 00:04:26,250
would require you remember what you did, you know, a time

99
00:04:26,250 --> 00:04:28,110
step or two ago, and there's no way to do

100
00:04:28,110 --> 00:04:29,990
that in an MDP, at least not as you've written it.

101
00:04:29,990 --> 00:04:32,490
>> Well, there's a way to do it, it just would never be better

102
00:04:32,490 --> 00:04:37,974
than doing it this way. So an MDP always has a mark off deterministic

103
00:04:37,974 --> 00:04:39,550
optimal policy.

104
00:04:39,550 --> 00:04:41,010
>> Right.

105
00:04:41,010 --> 00:04:42,240
>> So we only need to consider those.

106
00:04:42,240 --> 00:04:44,140
>> I think that was the same thing that

107
00:04:44,140 --> 00:04:46,000
I was trying to say, but with different words.

108
00:04:46,000 --> 00:04:47,510
>> [LAUGH] Ok.
