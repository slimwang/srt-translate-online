1
00:00:00,000 --> 00:00:03,330
in 2014 google published its own network

2
00:00:03,330 --> 00:00:06,269
in the image net competition and in

3
00:00:06,269 --> 00:00:09,449
homage to yawn lagoon and Lynette google

4
00:00:09,449 --> 00:00:11,189
name their network

5
00:00:11,189 --> 00:00:15,689
wait for it goog lennette it's spelled

6
00:00:15,689 --> 00:00:17,460
like Google met but it's pronounced

7
00:00:17,460 --> 00:00:21,480
google and that go figure in the image

8
00:00:21,480 --> 00:00:24,210
net competition google Annette performed

9
00:00:24,210 --> 00:00:27,719
even a little better than VG 6.7 percent

10
00:00:27,719 --> 00:00:30,210
compared to 7.3 percent although at that

11
00:00:30,210 --> 00:00:31,890
level it kind of feels like we're

12
00:00:31,890 --> 00:00:33,719
splitting hairs google and that's great

13
00:00:33,719 --> 00:00:36,149
advantage is that it runs really fast

14
00:00:36,149 --> 00:00:37,829
the team that developed googling that

15
00:00:37,829 --> 00:00:39,628
developed a clever concept called an

16
00:00:39,628 --> 00:00:41,640
inception module which trains really

17
00:00:41,640 --> 00:00:44,340
well and is efficiently deployable do

18
00:00:44,340 --> 00:00:46,950
you remember inception Vincent explain

19
00:00:46,950 --> 00:00:48,960
the concept earlier we're going to show

20
00:00:48,960 --> 00:00:51,509
it again here in case you forgot it's

21
00:00:51,509 --> 00:00:54,359
called an inception module it's going to

22
00:00:54,359 --> 00:00:56,488
look a little more complicated

23
00:00:56,488 --> 00:00:59,128
the idea is that at each layer of your

24
00:00:59,128 --> 00:01:01,979
cognate you can make a choice have a

25
00:01:01,979 --> 00:01:04,890
cooling operation have a convolution and

26
00:01:04,890 --> 00:01:06,359
then you need to decide is it a

27
00:01:06,359 --> 00:01:08,670
one-by-one convolution or three by three

28
00:01:08,670 --> 00:01:10,530
or five by five

29
00:01:10,530 --> 00:01:13,019
all of these are actually beneficial to

30
00:01:13,019 --> 00:01:15,239
the modeling power of your network so

31
00:01:15,239 --> 00:01:17,368
why choose let's use them all

32
00:01:17,368 --> 00:01:19,618
here's what an inception module looks

33
00:01:19,618 --> 00:01:21,359
like instead of having a single

34
00:01:21,359 --> 00:01:23,728
convolution you have a composition of

35
00:01:23,728 --> 00:01:26,368
average cooling followed by one by one

36
00:01:26,368 --> 00:01:30,090
then a one-by-one convolution then one

37
00:01:30,090 --> 00:01:32,759
by one followed by three by three then a

38
00:01:32,759 --> 00:01:35,340
1 by 1 followed by a five-by-five and at

39
00:01:35,340 --> 00:01:37,019
the top you simply concatenate the

40
00:01:37,019 --> 00:01:38,909
output of each of them it looks

41
00:01:38,909 --> 00:01:41,310
complicated but what's interesting is

42
00:01:41,310 --> 00:01:43,349
that you can choose these parameters in

43
00:01:43,349 --> 00:01:45,359
such a way that the total number of

44
00:01:45,359 --> 00:01:47,670
parameters in your model is very small

45
00:01:47,670 --> 00:01:50,188
yet the model performs better than if

46
00:01:50,188 --> 00:01:52,950
you had a simple convolution as Vincent

47
00:01:52,950 --> 00:01:55,319
says the inception modules create a

48
00:01:55,319 --> 00:01:57,269
situation in which the total number of

49
00:01:57,269 --> 00:01:59,790
parameters is very small this is my

50
00:01:59,790 --> 00:02:01,739
google and that runs almost as fast as

51
00:02:01,739 --> 00:02:04,259
Alex net and of course Google annette

52
00:02:04,259 --> 00:02:06,239
has great accuracy like we mentioned

53
00:02:06,239 --> 00:02:08,610
earlier it's imagenet error was only

54
00:02:08,610 --> 00:02:11,098
seven percent google Annette is a great

55
00:02:11,098 --> 00:02:12,870
choice to investigate if you need to run

56
00:02:12,870 --> 00:02:13,270
your name

57
00:02:13,270 --> 00:02:15,159
work in real time like maybe in a

58
00:02:15,159 --> 00:02:20,879
self-driving car

