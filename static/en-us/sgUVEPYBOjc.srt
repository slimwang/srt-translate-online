1
00:00:00,210 --> 00:00:02,930
We are now entering the modeling phase.

2
00:00:02,930 --> 00:00:06,170
Let's switch back to the iPython Notebook.

3
00:00:06,170 --> 00:00:11,780
To recall briefly we had chosen person 1 as B and person 2 as F.

4
00:00:11,780 --> 00:00:16,260
And we are going to classify them according to their location patterns.

5
00:00:16,260 --> 00:00:21,060
We did a final sanity check to ensure that the features chosen actually seem to

6
00:00:21,060 --> 00:00:22,790
have discriminating power.

7
00:00:22,790 --> 00:00:25,700
At this point let's run this piece of code.

8
00:00:25,700 --> 00:00:30,720
What it does is, it fills an array named classification_events with

9
00:00:30,720 --> 00:00:34,460
the events of person B and person F.

10
00:00:34,460 --> 00:00:39,630
We are now going to split the data in a training set and a test set.

11
00:00:39,630 --> 00:00:45,420
In this case we are going to use 60% of the data on training, and 40% on test.

12
00:00:45,420 --> 00:00:49,700
Let's go ahead and do that first.

13
00:00:49,700 --> 00:00:54,870
At this point, we have split the data into training and test sets.

14
00:00:54,870 --> 00:00:57,840
We are using a large portion of the data for

15
00:00:57,840 --> 00:01:04,040
testing, as we will be illustrating several validation matrix on the test data.

16
00:01:04,040 --> 00:01:05,810
Just as a sanity check.

17
00:01:05,810 --> 00:01:10,390
We want to plot our features within our training data.

18
00:01:10,390 --> 00:01:14,520
Once you have run the above code, you should get histograms for

19
00:01:14,520 --> 00:01:19,770
the distribution of different distances at a certain time for each person.

20
00:01:19,770 --> 00:01:24,180
Remember we wanted to make three different classifiers.

21
00:01:24,180 --> 00:01:27,340
To do so we have now split our data set.

22
00:01:27,340 --> 00:01:29,840
Into the training and the test set.

23
00:01:29,840 --> 00:01:31,690
We also asked a quick question.

24
00:01:31,690 --> 00:01:35,640
Are the features different enough in the training data set?

25
00:01:35,640 --> 00:01:40,720
We validated that again by looking at the histogram of the different features.

26
00:01:40,720 --> 00:01:45,560
So now we are ready to run the three classification models.

27
00:01:45,560 --> 00:01:48,030
Let's get back to the iPython notebook again.

28
00:01:49,050 --> 00:01:53,570
In this part of the code, we are setting up the three models for

29
00:01:53,570 --> 00:01:55,370
our classification problems.

30
00:01:55,370 --> 00:01:59,220
We are using the sklearns logistic

31
00:01:59,220 --> 00:02:04,170
regression support vector classifier and the random forest classifier.

32
00:02:04,170 --> 00:02:08,820
This method here simply returns the model that we want to train.

33
00:02:08,820 --> 00:02:10,979
So now let's run this code.

34
00:02:10,979 --> 00:02:16,350
After you're done with defining the three models, let's simply build the models.

35
00:02:16,350 --> 00:02:20,540
It's as simple as this one line of code.

36
00:02:20,540 --> 00:02:21,910
Let's run it.

37
00:02:21,910 --> 00:02:23,410
And there you have it.

38
00:02:23,410 --> 00:02:26,470
We have the models built.

39
00:02:26,470 --> 00:02:31,250
In the following videos we will use some of Sklearn's built in

40
00:02:31,250 --> 00:02:35,870
model alidation metrics to give us the performance of these models.

41
00:02:35,870 --> 00:02:40,020
Before that, let us define some of the quantities we might want to

42
00:02:40,020 --> 00:02:44,100
look at,when evaluating the performance of classifiers
