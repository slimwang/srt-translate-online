1
00:00:00,000 --> 00:00:03,740
Stratton and colleagues call their final technique regularization,

2
00:00:03,740 --> 00:00:07,082
and regularization is all about load balancing.

3
00:00:07,082 --> 00:00:11,082
Load balancing is a problem that's plagued parallel programming since its inception.

4
00:00:11,082 --> 00:00:14,650
Now to illustrate the idea of load imbalance,

5
00:00:14,650 --> 00:00:19,572
let's go back to our example for technique 5 where we were binning the cities of the United States.

6
00:00:19,572 --> 00:00:22,858
If you look at this map you'll notice that the cities aren't spread out evenly.

7
00:00:22,858 --> 00:00:25,605
Some grid cells are going to have a lot of cities,

8
00:00:25,605 --> 00:00:27,936
like up in this region,

9
00:00:27,936 --> 00:00:30,192
and some grid cells are going to have relatively few cities.

10
00:00:30,192 --> 00:00:36,242
So any threads that are adding up the city population to nearby cities in these cells--

11
00:00:36,242 --> 00:00:38,342
they've got a lot of work to do, right?

12
00:00:38,342 --> 00:00:42,938
They've got lots of cities to look at in the neighboring cells

13
00:00:42,938 --> 00:00:46,181
so that they can look at those cities and compute distances.

14
00:00:46,181 --> 00:00:51,198
So any threads that are adding up the city population and cells up here have a lot of work to do.

15
00:00:51,198 --> 00:00:53,212
They've got a lot of cities to compare to,

16
00:00:53,212 --> 00:00:57,246
while other threads that are in the same warp or the same block

17
00:00:57,246 --> 00:01:01,688
might be responsible for a city in 1 of these grid cells

18
00:01:01,688 --> 00:01:03,858
and have a lot less work to do,

19
00:01:03,858 --> 00:01:07,176
and so it will complete quickly and sit around waiting for these long running threads.

20
00:01:07,176 --> 00:01:10,860
This is an example--a classic example of load imbalance.

21
00:01:10,860 --> 00:01:17,001
So regularization is all about reorganizing the input data to reduce load imbalance.

22
00:01:17,001 --> 00:01:22,406
In other words you're taking irregular parallelism and turning it into regular parallelism.

23
00:01:22,406 --> 00:01:25,688
For example, in the US cities' example we've been looking at

24
00:01:25,688 --> 00:01:28,947
some bins might contain more cities than the average bin,

25
00:01:28,947 --> 00:01:33,283
so you can imagine provisioning each bin to have a fixed number of cities, say 5,

26
00:01:33,283 --> 00:01:37,157
and then have a special way of handling those relatively few overflow cities.

27
00:01:37,157 --> 00:01:41,296
For example, you might handle the cities or grid cells that overflow on the CPU,

28
00:01:41,296 --> 00:01:44,229
or you might use a different kernel that implements a different algorithm

29
00:01:44,229 --> 00:01:46,662
such as sorting the cities by longitude or latitude.

30
00:01:46,662 --> 00:01:50,142
There are many ways you could do this computation that we were trying to do

31
00:01:50,142 --> 00:01:54,480
with figuring out which cities were within 50 or 300 kilometers of each other.

32
00:01:54,480 --> 00:01:57,779
And now the storage in the main kernel code get's a lot simpler, right?

33
00:01:57,779 --> 00:02:01,330
Every bin has 5 slots; each thread loops over exactly 5 cities.

34
00:02:01,330 --> 00:02:05,328
And the fact that you'll occasionally waste a bit of compute while 1 thread sits idle for a slot,

35
00:02:05,328 --> 00:02:08,107
because it only had 3 cities or 4 cities in its bin

36
00:02:08,107 --> 00:02:10,273
is more than made up for by the fact

37
00:02:10,273 --> 00:02:13,767
that you never have an entire warp or an entire thread block or an entire kernel

38
00:02:13,767 --> 00:02:18,741
waiting on a single thread that has 127 cities to check or 1,000 cities to check.

39
00:02:18,741 --> 00:02:21,573
You've regularized the problem.
