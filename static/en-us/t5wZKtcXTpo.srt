1
00:00:00,380 --> 00:00:02,110
This is about the time
when you might say,

2
00:00:02,110 --> 00:00:04,370
what does this have to
do with computer vision?

3
00:00:04,370 --> 00:00:06,340
>> What does this have
to do with vision?

4
00:00:06,340 --> 00:00:08,920
>> I'm so glad you asked, all right?

5
00:00:08,920 --> 00:00:13,470
Well, another way of phrasing what we've
been doing is, given some sequence of

6
00:00:13,470 --> 00:00:19,077
observations, which model was most
likely to have generated those?

7
00:00:19,077 --> 00:00:22,880
So using our previous clothing and
weather example.

8
00:00:22,880 --> 00:00:26,620
So, suppose you're seeing some
sequence of clothing, right?

9
00:00:26,620 --> 00:00:29,096
So you, you check the clothing that
people are wearing each day, and

10
00:00:29,096 --> 00:00:31,510
you see this, coat, coat, whatever.

11
00:00:31,510 --> 00:00:35,030
And then the question you want to
ask is, is this Philadelphia,

12
00:00:35,030 --> 00:00:36,800
Boston, or Newark?

13
00:00:36,800 --> 00:00:39,273
The idea is that presumably,
what you've been doing is,

14
00:00:39,273 --> 00:00:42,655
you've been collecting sequences of
these observations from Philadelphia,

15
00:00:42,655 --> 00:00:45,090
a bunch of them from Boston,
a bunch of them from Newark.

16
00:00:45,090 --> 00:00:48,780
You have a trained a model, and
we'll talk about that later.

17
00:00:48,780 --> 00:00:53,980
You've created a model that will tend
to generate sequences, like you see in

18
00:00:53,980 --> 00:00:58,280
Philadelphia, or in Boston, or Newark,
with the same statistics that they have.

19
00:00:58,280 --> 00:01:02,210
And then given some new observation
sequence, you'd like to say, you know,

20
00:01:02,210 --> 00:01:03,870
which one is this?

21
00:01:03,870 --> 00:01:08,190
Now, notice that if we were
checking Boston versus Arizona,

22
00:01:09,580 --> 00:01:11,220
you basically wouldn't
need the sequence.

23
00:01:11,220 --> 00:01:13,180
It doesn't rain in Arizona,
for the most part.

24
00:01:13,180 --> 00:01:16,250
And you could say,
well do I see umbrellas, okay?

25
00:01:16,250 --> 00:01:18,970
And since it's always lousy
weather in Boston, I live there,

26
00:01:18,970 --> 00:01:20,920
if you see bathing suits,
you know it's actually Cape Cod.

27
00:01:20,920 --> 00:01:24,780
So the idea is, you know, just from
the individual elements themselves,

28
00:01:24,780 --> 00:01:29,290
you could determine whether
it was Boston or Arizona.

29
00:01:29,290 --> 00:01:32,820
The whole idea of
representing the time series

30
00:01:32,820 --> 00:01:35,970
is that there's something about
the sequentiality that matters.

31
00:01:35,970 --> 00:01:39,140
It's the statistics of one
thing following another,

32
00:01:39,140 --> 00:01:42,840
that is indicative of the actual class.

33
00:01:42,840 --> 00:01:43,630
And what you're doing is,

34
00:01:43,630 --> 00:01:47,560
you're building some models of those
time series, so you can then given

35
00:01:47,560 --> 00:01:51,430
some observation sequence,
you can say which one's most likely.

36
00:01:51,430 --> 00:01:54,901
And what we're going to to do is, we're
going to apply that to computer vision.
