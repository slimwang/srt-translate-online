1
00:00:00,210 --> 00:00:03,120
So you successfully learned about three different supervised learning

2
00:00:03,120 --> 00:00:04,780
algorithms, now it's time for the fourth.

3
00:00:04,780 --> 00:00:07,510
But this time, we won't prescribe one for you.

4
00:00:07,510 --> 00:00:09,720
>> That's right. We're going to give you a choice of three, and

5
00:00:09,720 --> 00:00:12,270
it's up to you to figure out which one you want to pursue on your own.

6
00:00:12,270 --> 00:00:13,270
>> And what are the choices?

7
00:00:13,270 --> 00:00:15,170
>> The choices are, k nearest neighbors.

8
00:00:15,170 --> 00:00:18,330
Very simple, very straightforward algorithm, a great one to know.

9
00:00:18,330 --> 00:00:19,035
Ataboost.

10
00:00:19,035 --> 00:00:21,420
>> Mm-hm. >> Very powerful and random forest.

11
00:00:21,420 --> 00:00:23,990
Those, those latter two are usually used with decision trees,

12
00:00:23,990 --> 00:00:25,020
which you know all about by now.

13
00:00:25,020 --> 00:00:26,570
>> Do you have a favorite?

14
00:00:26,570 --> 00:00:27,350
>> I like eta boost.

15
00:00:27,350 --> 00:00:27,920
>> Eta boost girl.

16
00:00:27,920 --> 00:00:28,870
>> I love eta boost, yes.

17
00:00:28,870 --> 00:00:30,470
>> So you're going to go out and

18
00:00:30,470 --> 00:00:34,410
check on the documentation, pick an algorithm and run it, and report results,

19
00:00:34,410 --> 00:00:37,340
and see if it can beat any of the algorithms here in about so far.

20
00:00:37,340 --> 00:00:38,640
>> That's right, lets get started
