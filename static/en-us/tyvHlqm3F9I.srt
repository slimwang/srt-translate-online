1
00:00:00,270 --> 00:00:04,360
So here it's just a table and I've highlighted a couple of entries.

2
00:00:04,360 --> 00:00:06,680
Lets first take a look at, s equal 2 here.

3
00:00:06,680 --> 00:00:10,010
So lets suppose we were doing fitting a line or if we're

4
00:00:10,010 --> 00:00:13,990
doing a transformation that's a similarity transform where you take two pairs.

5
00:00:13,990 --> 00:00:20,120
Notice that if my percentage of outliers is 50%.

6
00:00:20,120 --> 00:00:22,700
So half my matches are bad.

7
00:00:22,700 --> 00:00:27,800
I only have to choose 17 examples, for

8
00:00:27,800 --> 00:00:34,790
me to have a 99% chance, that at least one of them was the correct one.

9
00:00:34,790 --> 00:00:38,830
So doing something 17 times in a computer like that, that's pretty fast.

10
00:00:38,830 --> 00:00:41,846
If I'm computing homography, s is now equal to 4.

11
00:00:41,846 --> 00:00:45,660
Even with 50%, I only have to try 72 samples.

12
00:00:45,660 --> 00:00:49,100
So even though I'm totally randomly pulling these things, and

13
00:00:49,100 --> 00:00:51,460
I have no idea which points are right and which points are wrong,

14
00:00:51,460 --> 00:00:56,050
and half the matches are wrong, with just 72 of them.

15
00:00:56,050 --> 00:01:02,230
I have a better than 99% likelihood that one of my sets is the correct one.

16
00:01:02,230 --> 00:01:07,210
And in fact, even if I'm doing a fundamental matrix, all right, looking for

17
00:01:07,210 --> 00:01:12,690
eight matches, I only have to check less than 1200 of them in order for it to be

18
00:01:12,690 --> 00:01:16,930
likely that one of those matches, at least one, will be the cor, a correct set

19
00:01:16,930 --> 00:01:21,300
of matches so the fundamental matrix that I would get would be the correct one.

20
00:01:21,300 --> 00:01:26,010
One thing to notice about this table is that N does not go up

21
00:01:26,010 --> 00:01:30,290
very much as the percentage of outliers goes up, but

22
00:01:30,290 --> 00:01:34,550
it does go up pretty steeply as s gets bigger.

23
00:01:34,550 --> 00:01:37,770
So as the number of parameters that you need gets larger,

24
00:01:37,770 --> 00:01:42,400
all the sudden the number of sample sets you have to check before you,

25
00:01:42,400 --> 00:01:45,040
pretty sure you'll have one that's right, goes up as well.

26
00:01:45,040 --> 00:01:48,910
Now some of you are not table people, some of you are graph people.

27
00:01:48,910 --> 00:01:53,370
So what I have here is a graph where I just did s equals 4.

28
00:01:53,370 --> 00:01:55,060
So like a homography.

29
00:01:55,060 --> 00:01:59,860
And on the axis on the bottom you should see the percentage of outliers.

30
00:01:59,860 --> 00:02:02,491
And you can see that the number of samples required.

31
00:02:02,491 --> 00:02:07,261
Which goes all the way up here to well at 0.8 it's above 2000.

32
00:02:07,261 --> 00:02:11,420
But it stays low for a very long time.

33
00:02:11,420 --> 00:02:13,790
And that's the really cool thing about RANSAC,

34
00:02:13,790 --> 00:02:19,410
is that it stays low even with a relatively high percentage of outliers.
