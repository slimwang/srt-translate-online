1
00:00:00,000 --> 00:00:04,440
Interviewer: So this is really interesting and very powerful, but it raises a lot of questions

2
00:00:04,440 --> 00:00:08,189
that certainly deal with intercepting people's cellular communication

3
00:00:08,189 --> 00:00:12,000
could be used for evil. Presumably you're not using it for evil.

4
00:00:12,000 --> 00:00:14,170
So what's the motivation for doing this and

5
00:00:14,170 --> 00:00:18,410
and kind of how can you do this in an ethical way?

6
00:00:18,410 --> 00:00:22,290
Carson: We're clearly not doing this to do evil ourselves.

7
00:00:22,290 --> 00:00:27,380
However, we do this because it is already used to do evil by others.

8
00:00:27,380 --> 00:00:33,700
For at least 10 years industrial-scale GSM cracking equipment has been available

9
00:00:33,700 --> 00:00:38,120
and there's been very little talk about the system so far.

10
00:00:38,120 --> 00:00:44,100
So this is an attempt to shine that light onto evil that is ongoing

11
00:00:44,100 --> 00:00:49,590
spying on citizens, spying on host countries from embassies

12
00:00:49,590 --> 00:00:56,590
spying in war zones on civilian populations that we want to uncover

13
00:00:56,590 --> 00:01:02,020
and the result of this discussion that we've been having very publicly

14
00:01:02,020 --> 00:01:06,210
was to GSM networks over the past two years is hopefully that these networks

15
00:01:06,210 --> 00:01:11,400
now implement protections against what they perceive mostly as a publicity threat.

16
00:01:11,400 --> 00:01:16,400
Because we are not actually doing anything evil but we say we could.

17
00:01:16,400 --> 00:01:22,790
It is the ultimate convincing argument that you can intercept

18
00:01:22,790 --> 00:01:26,290
the phones of even the phone company's executives.

19
00:01:26,290 --> 00:01:31,540
So the ethical part of hacking includes both not doing evil

20
00:01:31,540 --> 00:01:37,980
but convincing everybody to do the counter, in this case deploy

21
00:01:37,980 --> 00:01:43,020
technical countermeasures or at least to warn customers that cellphones

22
00:01:43,020 --> 00:01:47,110
are not as secure as companies would like them to be.

23
00:01:47,110 --> 00:01:49,330
It always hard to say what would have happened had we not done this

24
00:01:49,330 --> 00:01:54,370
but it may be time coincidental, it may be because of this research

25
00:01:54,370 --> 00:01:59,310
networks are starting to upgrade or have been upgraded these past years.

26
00:01:59,310 --> 00:02:06,160
More in newer networks, that is everywhere outside of the western world

27
00:02:06,160 --> 00:02:12,590
but also in Europe and hopefully the US soon will start rolling out countermeasures.

28
00:02:12,590 --> 00:02:16,350
Often times they find that these countermeasures are little more than

29
00:02:16,350 --> 00:02:22,470
configuration changes, software patches, things that are overdue for many years.

30
00:02:22,470 --> 00:02:27,350
Technology twenty years old that has been upgraded many times

31
00:02:27,350 --> 00:02:32,100
adding MMS and fast-internet connections and visual voice mail

32
00:02:32,100 --> 00:02:35,650
and all these things but the security hasn't been patched, even once.

33
00:02:35,650 --> 00:02:38,070
Same works for the T-Mobile network here.

34
00:02:38,070 --> 00:02:42,820
Same works against every network in Europe right now

35
00:02:42,820 --> 00:02:47,340
pretty much every network outside of Europe. A few have been patched now.

36
00:02:47,340 --> 00:02:51,660
The most secure network that we have seen recently was in Egypt.

37
00:02:51,660 --> 00:02:57,260
Given that it's now not just defending your customers from ongoing evil

38
00:02:57,260 --> 00:03:00,940
but also a possible publicity threat you're avoiding

39
00:03:00,940 --> 00:03:05,580
there's a lot to gain for the networks and at the same it doesn't cost them very much.

40
00:03:05,580 --> 00:03:12,410
So it just took a few research years to create the information base for them to act upon.

41
00:03:12,410 --> 00:03:14,680
Interviewer: Thanks very much, Carson, this has been really interesting

42
00:03:14,680 --> 00:03:17,940
and very cool what you showed us, thanks. Carson: Thank you.
