1
00:00:00,150 --> 00:00:01,440
All right, so here's another state.

2
00:00:01,440 --> 00:00:04,950
I just transported you randomly
to another start state, and

3
00:00:04,950 --> 00:00:06,650
you claim that you understand
how things work now.

4
00:00:06,650 --> 00:00:08,050
So can you explain?

5
00:00:08,050 --> 00:00:09,950
>> I think I do.

6
00:00:09,950 --> 00:00:13,230
The goal is to go get
the little yellow circle or

7
00:00:13,230 --> 00:00:17,020
the circle which was yellow
to begin with the last time.

8
00:00:17,020 --> 00:00:18,400
I don't know if that means anything.

9
00:00:18,400 --> 00:00:19,680
And I
>> I think it was green last time.

10
00:00:19,680 --> 00:00:20,180
>> Was it?

11
00:00:21,190 --> 00:00:26,620
And you want to pick it up,
which was I think 5.

12
00:00:26,620 --> 00:00:30,570
And when you do that, what I don't yet
know is whether it will change color.

13
00:00:30,570 --> 00:00:32,901
But whatever color it
is when you pick it up,

14
00:00:32,901 --> 00:00:35,930
you want to take it to the square
that matches that color.

15
00:00:35,930 --> 00:00:38,840
>> Okay.
>> Then put it down, which is Action 1.

16
00:00:38,840 --> 00:00:44,040
Now I should say, because I didn't say
it before, that what I thought the point

17
00:00:44,040 --> 00:00:48,740
was the first time was just to get the
square and the circle in the same place.

18
00:00:48,740 --> 00:00:49,890
>> The square and the circle.

19
00:00:49,890 --> 00:00:51,030
Yeah, you did that.

20
00:00:51,030 --> 00:00:53,675
But you didn't get any reward for that.

21
00:00:53,675 --> 00:00:56,434
>> Right, so then I figured out
maybe I didn't do anything but

22
00:00:56,434 --> 00:00:59,870
at that time I was also just trying to
figure out what all the commands did.

23
00:00:59,870 --> 00:01:01,400
>> Good.
>> I was doing a lot of exploring.

24
00:01:01,400 --> 00:01:03,380
>> All right, so learned a bit
about the transition function,

25
00:01:03,380 --> 00:01:07,950
you learned a little about how
actions change the state and

26
00:01:07,950 --> 00:01:10,790
you also learned a little bit
about what states are rewarding.

27
00:01:10,790 --> 00:01:11,430
>> Yes.

28
00:01:11,430 --> 00:01:13,820
>> And so now you think even though
things are a bit different you think you

29
00:01:13,820 --> 00:01:17,200
can actually get kind of on
a minimal path to a gold state now?

30
00:01:17,200 --> 00:01:17,900
>> Sure.

31
00:01:17,900 --> 00:01:21,055
So from here I would go 3,3.

32
00:01:23,376 --> 00:01:30,900
Then I would go 4,4 then
5 which keeps it yellow.

33
00:01:30,900 --> 00:01:33,380
So then I need to go as
quickly to yellow as I can.

34
00:01:33,380 --> 00:01:37,561
There's a lot of ways of doing that but
let's just do 2,2.

35
00:01:37,561 --> 00:01:41,837
6,6,6,6.

36
00:01:41,837 --> 00:01:43,980
2,2.

37
00:01:43,980 --> 00:01:45,510
And then that doesn't work.

38
00:01:45,510 --> 00:01:47,650
>> Is it possible you forgot something?

39
00:01:47,650 --> 00:01:48,949
>> Oh, 1, I forgot to put it down.

40
00:01:48,949 --> 00:01:49,831
>> Boom!

41
00:01:49,831 --> 00:01:50,505
>> Done.

42
00:01:50,505 --> 00:01:53,233
>> All right, so good excellent job.

43
00:01:53,233 --> 00:01:56,863
So that was an MDP and in fact,
you solved that a lot faster than any of

44
00:01:56,863 --> 00:02:00,500
the algorithms [LAUGH] that
we're going to be talking about.

45
00:02:00,500 --> 00:02:05,123
Because you made use of all kinds of
interesting background information about

46
00:02:05,123 --> 00:02:09,618
how you can- What navigation does and
how it's consistent across states.

47
00:02:09,618 --> 00:02:12,496
But generally in the MDP model and
the reinforcement learning model,

48
00:02:12,496 --> 00:02:14,150
we don't necessarily assume that.

49
00:02:14,150 --> 00:02:18,252
It could very well be that what you're-
In each state, the actions all do some

50
00:02:18,252 --> 00:02:22,360
other kind of crazy different thing,
and you have to learn that mapping.

51
00:02:22,360 --> 00:02:24,210
>> Right, so let me say two things.

52
00:02:24,210 --> 00:02:25,532
Actually three thing.

53
00:02:25,532 --> 00:02:29,690
One, is when I trying to figure out
what the actions were, I considered for

54
00:02:29,690 --> 00:02:33,716
a moment, even though I had already
figured out that 3 moves you right,

55
00:02:33,716 --> 00:02:37,808
I considered trying to go right a couple
of times just to see if there was any

56
00:02:37,808 --> 00:02:39,207
randomness [CROSSTALK].

57
00:02:39,207 --> 00:02:40,480
>> Mm.

58
00:02:40,480 --> 00:02:43,565
But then I decided you wouldn't do that
to me, you're too nice of a person.

59
00:02:43,565 --> 00:02:44,262
>> [LAUGH]
>> And so

60
00:02:44,262 --> 00:02:46,370
I decided they were deterministic and
then do that.

61
00:02:46,370 --> 00:02:47,760
But you point out that yeah,

62
00:02:47,760 --> 00:02:52,120
I did it kind of fast because I
had a lot of background knowledge.

63
00:02:52,120 --> 00:02:55,040
I'd really say that it was
more about assumptions.

64
00:02:55,040 --> 00:02:56,200
>> Okay.

65
00:02:56,200 --> 00:02:59,500
>> And
in fact my first assumption was wrong.

66
00:02:59,500 --> 00:03:00,220
Oh.

67
00:03:00,220 --> 00:03:02,860
>> The goal was just to get in
the same place as the circle and

68
00:03:02,860 --> 00:03:04,070
that was the whole point.

69
00:03:04,070 --> 00:03:05,320
>> That's true.

70
00:03:05,320 --> 00:03:08,810
>> And
then the last thing I'll say is that

71
00:03:08,810 --> 00:03:10,810
as long I've been thinking
about reinforcement learning.

72
00:03:10,810 --> 00:03:13,085
As long as I've been thinking
about search algorithms and AI.

73
00:03:13,085 --> 00:03:16,360
As long as I've been machine learning I
don't think I ever really appreciated

74
00:03:16,360 --> 00:03:19,730
how incredibly frustrating it is
[LAUGH] when you don't actually know

75
00:03:19,730 --> 00:03:23,590
what the rules are and you're just
trying to figure out what's going on.

76
00:03:23,590 --> 00:03:26,760
And I now am going to be much kinder
to all of my search algorithms.

77
00:03:26,760 --> 00:03:28,390
>> That's what I was hoping
you'd get out of that.

78
00:03:28,390 --> 00:03:29,270
Thank you.
Yes.

79
00:03:29,270 --> 00:03:32,840
So sometimes it's really frustrating
watching these algorithms do what

80
00:03:32,840 --> 00:03:33,740
they do.

81
00:03:33,740 --> 00:03:37,910
And in some cases just repeatedly
bashing their heads against the wall.

82
00:03:37,910 --> 00:03:40,190
Which for what it's worth is
something that you didn't do.

83
00:03:40,190 --> 00:03:42,042
When you were moving around in the grid,

84
00:03:42,042 --> 00:03:44,282
you were purposely avoiding
these black lines.

85
00:03:44,282 --> 00:03:46,255
Do you know why?

86
00:03:46,255 --> 00:03:47,990
[LAUGH] Maybe those
are actually reward lines.

87
00:03:47,990 --> 00:03:49,760
If you bump into them you win.

88
00:03:49,760 --> 00:03:53,000
>> Yeah, but every time I've ever
played any game, they're walls.

89
00:03:53,000 --> 00:03:53,890
>> Yeah, they look like walls.

90
00:03:53,890 --> 00:03:55,690
And, in fact, they are in this case.

91
00:03:55,690 --> 00:04:00,298
So that again, that was an assumption
that you brought to bear.

92
00:04:00,298 --> 00:04:04,240
But, right, so when you watch a learning
algorithm, reinforcement learning

93
00:04:04,240 --> 00:04:06,620
algorithm actually interacting
with a grid like this.

94
00:04:06,620 --> 00:04:09,470
It doesn't have those
biases necessarily.

95
00:04:09,470 --> 00:04:12,240
And so it can actually bash its
head against this wall, and

96
00:04:12,240 --> 00:04:15,510
then maybe this wall for a while,
and hey, this wall looks really fun.

97
00:04:15,510 --> 00:04:16,390
And so, yeah,

98
00:04:16,390 --> 00:04:21,260
it's good that we have a little bit
of empathy for the poor reinforcement

99
00:04:21,260 --> 00:04:26,360
learning agent that's trying to master
this environment given very complex and

100
00:04:28,380 --> 00:04:32,470
hard to parse apart representations for
the actions and the states.

101
00:04:32,470 --> 00:04:33,590
>> Hmm, that's very good.

102
00:04:33,590 --> 00:04:36,730
Probably the only thing more
frustrating than my trying to play this

103
00:04:36,730 --> 00:04:39,420
was all the people watching
me trying to play this.

104
00:04:39,420 --> 00:04:40,450
>> Oh, I think they loved it.

105
00:04:40,450 --> 00:04:42,710
For what it's worth,
we can make this available.

106
00:04:42,710 --> 00:04:44,405
>> [LAUGH] Who would play
it on their home computers?

107
00:04:44,405 --> 00:04:46,590
>> [LAUGH]
>> Yeah, but now they know the answer.

108
00:04:46,590 --> 00:04:49,600
Can you just like randomly
change what the actions are?

109
00:04:49,600 --> 00:04:50,950
>> Let's say that I did that.

110
00:04:50,950 --> 00:04:52,970
>> Okay, that was actually quite good.

111
00:04:52,970 --> 00:04:55,749
I'm glad you didn't let me
know what it was before hand.

112
00:04:55,749 --> 00:04:57,331
>> [LAUGH] Do you recognize it now?

113
00:04:57,331 --> 00:04:59,620
Do I recognize what now?

114
00:04:59,620 --> 00:05:01,880
It's a taxi cab to me.

115
00:05:01,880 --> 00:05:06,195
I almost said that [LAUGH] and then
realized that would break the illusion.

116
00:05:06,195 --> 00:05:09,870
>> [LAUGHTER] So when I had Molly
do this a long a time ago, and

117
00:05:09,870 --> 00:05:10,538
I asked her at the end.

118
00:05:10,538 --> 00:05:13,992
What is exactly the task that
this is supposed to be doing?

119
00:05:13,992 --> 00:05:16,240
She's like well you have
to rescue the dog, and

120
00:05:16,240 --> 00:05:17,529
it just wants to go to its house.

121
00:05:18,570 --> 00:05:19,800
Wow, that is-
>> Yeah,

122
00:05:19,800 --> 00:05:21,600
I thought that was kind of awesome.

123
00:05:21,600 --> 00:05:23,500
>> We should try that with
my daughter and see if,

124
00:05:23,500 --> 00:05:26,580
assuming she can sit still long enough,
and see what she would come up with.

125
00:05:26,580 --> 00:05:28,770
>> The other thing is when
you had in this position and

126
00:05:28,770 --> 00:05:31,990
you really like the kind of
symmetries of it and stuff.

127
00:05:31,990 --> 00:05:36,114
We actually did this in a mall in New
Jersey where we had people come by and

128
00:05:36,114 --> 00:05:37,860
just see what they would do.

129
00:05:37,860 --> 00:05:38,880
You'd give them the game and they'd.

130
00:05:38,880 --> 00:05:41,780
And there was one woman who was a real
estate agent, who could just not

131
00:05:41,780 --> 00:05:47,300
get over the idea that the actual
goal is to fix the Feng Shui.

132
00:05:47,300 --> 00:05:50,550
So if you look there's
a color in every corner,

133
00:05:50,550 --> 00:05:53,010
except the blue is not
quite in the corner.

134
00:05:53,010 --> 00:05:56,540
So she kept trying to move
the blue into the corner.

135
00:05:56,540 --> 00:05:59,850
>> And when I told her that she should
stop doing that, she just kept doing it

136
00:05:59,850 --> 00:06:03,010
because [LAUGH] she was convinced
that the task was one of feng shui.

137
00:06:03,010 --> 00:06:04,810
>> I like that.

138
00:06:04,810 --> 00:06:06,400
>> Yeah.
>> And that tells you everything you

139
00:06:06,400 --> 00:06:09,350
need to know about why our real
estate market is the way it is.

140
00:06:09,350 --> 00:06:10,920
[LAUGH]
>> And New Jersey.
