1
00:00:00,150 --> 00:00:03,130
Let's get back to the map of our models.

2
00:00:03,130 --> 00:00:09,260
We've so far built three different models and used several validation methods,

3
00:00:09,260 --> 00:00:14,510
including ROC curves, to choose the model that performs best.

4
00:00:14,510 --> 00:00:18,090
We could end our investigation here.

5
00:00:18,090 --> 00:00:20,460
However, we can ask a further question.

6
00:00:21,520 --> 00:00:25,860
Will changing the classes change the model?

7
00:00:25,860 --> 00:00:28,430
Let's investigate this a little bit further.

8
00:00:29,460 --> 00:00:32,369
To investigate this question a little bit further,

9
00:00:32,369 --> 00:00:37,540
we come back to our original point where we started building our models.

10
00:00:37,540 --> 00:00:39,660
To continue that investigation,

11
00:00:39,660 --> 00:00:44,600
we'll now build new classifiers by redefining the classes.

12
00:00:44,600 --> 00:00:50,030
Then we'll use different validation metrics and choose a new model.

13
00:00:50,030 --> 00:00:53,830
At this point, we have our entire map of our model-building and

14
00:00:53,830 --> 00:00:55,520
validation process.

15
00:00:55,520 --> 00:01:00,340
Let's investigate this end a little bit more to see what metrics we

16
00:01:00,340 --> 00:01:04,819
can use to validate models with our new classes.

17
00:01:04,819 --> 00:01:08,350
We're back to the precision, recall and F-Score video 28.

18
00:01:08,350 --> 00:01:13,940
The sensitivity and specificity of a classifier are symmetric

19
00:01:13,940 --> 00:01:19,160
measurements in the sense that the changes in false positives or

20
00:01:19,160 --> 00:01:25,080
false negatives do not affect the sensitivity or specificity respectively.

21
00:01:25,080 --> 00:01:30,100
Thus in our example we had two instances of classes, B and F.

22
00:01:30,100 --> 00:01:33,380
And we decided, thus in our example,

23
00:01:33,380 --> 00:01:38,388
we had two classes B and F and we classified between those two.

24
00:01:38,388 --> 00:01:42,120
Now we re-ask the question to see if we

25
00:01:42,120 --> 00:01:46,280
can choose between two classes that are asymmetric.

26
00:01:46,280 --> 00:01:50,520
In our new problem, we have slightly redefined the problem.

27
00:01:50,520 --> 00:01:55,640
We want to ask if something belongs to Class G or not Class G.

28
00:01:55,640 --> 00:01:58,680
This is a one versus all classifier.

29
00:01:58,680 --> 00:02:04,035
We're going to look at some metrics called precision, recall and

30
00:02:04,035 --> 00:02:08,490
F-score, that helps us in validating classification problems and

31
00:02:08,490 --> 00:02:11,950
models based on these kinds of classifiers.

32
00:02:11,950 --> 00:02:17,000
The difference being, the instances for Class G are a lot less

33
00:02:17,000 --> 00:02:22,270
than the instances for not Class G in the data.

34
00:02:22,270 --> 00:02:24,850
Let's get back to our Python notebook and

35
00:02:24,850 --> 00:02:27,100
see how we can build these models first.

36
00:02:30,500 --> 00:02:36,350
In this piece of code, we are starting to classify person1 vs all.

37
00:02:36,350 --> 00:02:38,955
We call that ova_person, or

38
00:02:38,955 --> 00:02:44,520
One Versus All person, and we choose G as that class.

39
00:02:44,520 --> 00:02:51,790
We now divide up the events such that we have G and not g as the two classes.

40
00:02:51,790 --> 00:02:54,270
Let's run this piece of code first.

41
00:02:54,270 --> 00:03:00,110
In the previous piece of code, we have setup the one versus all data.

42
00:03:00,110 --> 00:03:05,690
Let's look at what the y values are between then this is 220 to 230.

43
00:03:05,690 --> 00:03:06,910
Run this piece of code now.

44
00:03:08,550 --> 00:03:16,140
You see the ten values are Fs and Gs, with the last four values being G.

45
00:03:16,140 --> 00:03:20,810
Now let's see how this looks when we have the one versus all.

46
00:03:21,880 --> 00:03:25,805
Let's see how this looks for the one versus all data.

47
00:03:25,805 --> 00:03:27,830
Run this line of code.

48
00:03:27,830 --> 00:03:33,370
Notice, all the labels that are not G are labelled as false.

49
00:03:33,370 --> 00:03:38,270
All the labels that are G are labelled as true.

50
00:03:38,270 --> 00:03:43,220
Running the next line of code gives you the total number of false and

51
00:03:43,220 --> 00:03:47,630
true in each of the training and the test samples.

52
00:03:47,630 --> 00:03:50,825
We are now ready to build our models.

53
00:03:50,825 --> 00:03:55,360
Run this line of code that initializes the models and

54
00:03:55,360 --> 00:04:01,230
trains with x_train and y_train with the one verses all model.

55
00:04:01,230 --> 00:04:04,530
Now that we have built our one verses all models,

56
00:04:04,530 --> 00:04:10,780
let's try to print our accuracy, or score, for each of these models.

57
00:04:10,780 --> 00:04:16,250
Running this line gives us the accuracy for each of the LogisticRegression,

58
00:04:16,250 --> 00:04:19,704
RandomForest, and Support Vector Classifier models.

59
00:04:19,704 --> 00:04:26,400
Note, this time the classes are quite different than what we had before.

60
00:04:26,400 --> 00:04:31,030
Now we will define a few more metrics that are useful for

61
00:04:31,030 --> 00:04:35,270
selecting between these kind of classification models.

62
00:04:35,270 --> 00:04:40,050
We are now going to look at the definitions of precision, recall and

63
00:04:40,050 --> 00:04:44,990
f score and come back and calculate these for the model we just built.
