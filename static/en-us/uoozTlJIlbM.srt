1
00:00:00,260 --> 00:00:02,730
So at this philosophical level there's
one last thing I want to talk about.

2
00:00:02,730 --> 00:00:04,730
We just talked about
evaluating a policy but

3
00:00:04,730 --> 00:00:06,960
remember in the reinforcement
learning setting,

4
00:00:06,960 --> 00:00:11,550
the policy is what gets output as
a result of the learning process.

5
00:00:11,550 --> 00:00:13,970
So what if we want to actually
evaluate the learner?

6
00:00:13,970 --> 00:00:15,180
How good is this learner?

7
00:00:15,180 --> 00:00:19,490
Can you think of some ways that we might
be able to decide how good a learner is?

8
00:00:19,490 --> 00:00:20,160
>> Sure.

9
00:00:20,160 --> 00:00:21,300
It's as good as its policy.

10
00:00:21,300 --> 00:00:22,710
>> So that seems like a good idea.

11
00:00:22,710 --> 00:00:26,460
That a good learner is one that
returns a good policy, sure.

12
00:00:26,460 --> 00:00:30,815
What if we have two learners that return
the same policy say the optimal policy?

13
00:00:30,815 --> 00:00:32,870
>> Oh okay, well I can think
of two responses to that.

14
00:00:32,870 --> 00:00:34,590
One is who cares they're
both the same and

15
00:00:34,590 --> 00:00:38,438
the only thing that matters is how good
the policy is that you come up with.

16
00:00:38,438 --> 00:00:40,810
Or I could come up with
another answer which would be,

17
00:00:40,810 --> 00:00:44,290
I will take the one that
does it more quickly.

18
00:00:44,290 --> 00:00:45,610
>> Quickly in terms of what?

19
00:00:45,610 --> 00:00:46,408
>> Let's say time.

20
00:00:46,408 --> 00:00:50,190
>> [LAUGH] I think that's
what quickly means.

21
00:00:50,190 --> 00:00:53,561
Yes, but time of what?

22
00:00:53,561 --> 00:00:55,686
There's lots of different
kinds of time that matter.

23
00:00:55,686 --> 00:00:58,340
So one in particular
is computation time?

24
00:00:58,340 --> 00:00:59,800
>> Yeah, wall clock time.

25
00:00:59,800 --> 00:01:01,690
>> And that seems like an important one,
right?

26
00:01:01,690 --> 00:01:03,460
We want one that's going to
be more efficient in terms of

27
00:01:03,460 --> 00:01:06,400
the computations that it does in
the process of learning the policy.

28
00:01:06,400 --> 00:01:09,450
But there's another kind of time
that actually matters a lot

29
00:01:09,450 --> 00:01:12,060
in the reinforcement learning settings,
so I think it's worth mentioning.

30
00:01:12,060 --> 00:01:12,870
>> Okay.

31
00:01:12,870 --> 00:01:15,570
>> So the other kind of complexity that
turns out to be really important in this

32
00:01:15,570 --> 00:01:17,680
learning setting is
experience complexity.

33
00:01:17,680 --> 00:01:19,450
Do you have a sense of
what that might mean?

34
00:01:20,510 --> 00:01:22,040
>> How complex your experiences are?

35
00:01:23,440 --> 00:01:24,960
>> I'm going to say no.

36
00:01:24,960 --> 00:01:25,800
>> Oh, okay, I get it.

37
00:01:25,800 --> 00:01:29,010
So computational complexity is sort of
how much computational energy you have

38
00:01:29,010 --> 00:01:29,650
to put into it.

39
00:01:29,650 --> 00:01:33,460
So this would be how much experience
you have to have in order to learn.

40
00:01:33,460 --> 00:01:35,317
So it's the amount of
data that you need.

41
00:01:35,317 --> 00:01:38,924
>> Yeah, so if two different learners
can learn the same optimal policy, but

42
00:01:38,924 --> 00:01:42,531
one only requires a couple interactions
with the environment to do it, and

43
00:01:42,531 --> 00:01:44,191
the other one requires a billion,

44
00:01:44,191 --> 00:01:48,100
the one that has the lower experience
complexity should be preferred.

45
00:01:48,100 --> 00:01:49,390
Though of course there's trade-offs.

46
00:01:49,390 --> 00:01:52,087
If to do that it actually
has to compute for

47
00:01:52,087 --> 00:01:55,870
2 billion years then that seems
maybe not so good either.

48
00:01:55,870 --> 00:02:01,590
So there can be little trade-offs
between how much time that the learner

49
00:02:01,590 --> 00:02:05,080
takes in terms of interactions with the
environment and how much time that it

50
00:02:05,080 --> 00:02:08,590
takes in terms of the computations
that it does between interactions.

51
00:02:08,590 --> 00:02:09,758
>> Hm.
Do you know what this reminds me of?

52
00:02:09,758 --> 00:02:11,110
It reminds me of two things.

53
00:02:11,110 --> 00:02:12,400
It reminds me of MIMIC

54
00:02:13,660 --> 00:02:16,660
because that was the exact
trade-off that we were making then.

55
00:02:16,660 --> 00:02:17,220
>> Oh, yeah.

56
00:02:17,220 --> 00:02:18,410
Okay, sure.

57
00:02:18,410 --> 00:02:21,440
>> And the other thing is that it
reminds me of the theory lecture that

58
00:02:21,440 --> 00:02:23,950
we did in the Intro to
Machine Learning class

59
00:02:23,950 --> 00:02:26,380
where we talked about sample complexity.

60
00:02:26,380 --> 00:02:28,150
>> Yes, that's good.

61
00:02:28,150 --> 00:02:31,060
That probably is a better name
than experience complexity.

62
00:02:31,060 --> 00:02:32,450
Let's call it sample complexity.

63
00:02:33,700 --> 00:02:36,440
Yeah, because it really is about
the data that's necessary to achieve

64
00:02:36,440 --> 00:02:38,940
the learning ends.

65
00:02:38,940 --> 00:02:39,670
>> All right.

66
00:02:39,670 --> 00:02:43,140
>> All right, so this kind of sets the
stage for what reinforcement learning

67
00:02:43,140 --> 00:02:45,560
is, and how compare different
learners to each other, and

68
00:02:45,560 --> 00:02:47,530
how we compare the outputs of
those learners to each other.

69
00:02:47,530 --> 00:02:51,390
What we're going to dive into
next is actual algorithms for

70
00:02:51,390 --> 00:02:53,460
doing this kind of learning.

71
00:02:53,460 --> 00:02:54,880
>> Yeah that sounds good,
can I ask you a question?

72
00:02:54,880 --> 00:02:55,850
>> Sure.

73
00:02:55,850 --> 00:02:58,569
>> So,
why aren't we talking about space?

74
00:02:59,950 --> 00:03:03,310
>> Ooh, so space complexity.

75
00:03:03,310 --> 00:03:04,860
So that's a good question.

76
00:03:04,860 --> 00:03:07,830
In computer science,
usually computation time and

77
00:03:07,830 --> 00:03:13,610
computation space are the two dimensions
along which we evaluate algorithms.

78
00:03:13,610 --> 00:03:16,390
Here I guess we could do that too.

79
00:03:16,390 --> 00:03:19,280
You could talk about the space
that an algorithm uses.

80
00:03:19,280 --> 00:03:22,580
Our learning algorithm uses, but
it's generally not that interesting.

81
00:03:22,580 --> 00:03:25,850
Generally we don't, we're not
limited by the space complexity.

82
00:03:25,850 --> 00:03:29,440
We usually run into issues more
quickly on the computational or

83
00:03:29,440 --> 00:03:30,960
the sample complexity side.
