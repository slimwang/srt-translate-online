1
00:00:00,540 --> 00:00:02,415
So let's see what happens when the current

2
00:00:02,415 --> 00:00:06,670
lock-holder comes around to unlocking the lock. What he's

3
00:00:06,670 --> 00:00:09,570
going to do is, he's going to execute the unlock

4
00:00:09,570 --> 00:00:12,340
algorithm. And the unlock algorithm, the first thing that

5
00:00:12,340 --> 00:00:20,930
it does, is it sets this position that the lockholder had from HL to MW. And the

6
00:00:20,930 --> 00:00:22,820
reason for that is, is that this is a

7
00:00:22,820 --> 00:00:25,640
circular queue and since it's a circular queue even

8
00:00:25,640 --> 00:00:28,995
though queue last is here future requesters can, can come

9
00:00:28,995 --> 00:00:32,320
around and then eventually somebody may come here and may want

10
00:00:32,320 --> 00:00:35,350
to occupy this particular slot and they have to know that

11
00:00:35,350 --> 00:00:37,480
they have to wait. And that's the reason, the first thing

12
00:00:37,480 --> 00:00:40,320
that the current lock holder does, is to mark this

13
00:00:40,320 --> 00:00:44,110
spot that he used to be at, as hl. The next

14
00:00:44,110 --> 00:00:47,080
thing that the current lock holder is, is going to do is

15
00:00:47,080 --> 00:00:50,730
signal the next guy in the circular queue. So, the current

16
00:00:50,730 --> 00:00:53,500
lock holder was here, so you'd mark it as mw

17
00:00:53,500 --> 00:00:55,800
for future requesters that may come and wait on his

18
00:00:55,800 --> 00:01:00,310
spot. And the next request in the circular queue is

19
00:01:00,310 --> 00:01:02,410
the guy next to him. And therefore what he is

20
00:01:02,410 --> 00:01:05,074
doing is, he is saying you know, current plus one

21
00:01:05,074 --> 00:01:09,140
mode N, is going to be set to hl. And so,

22
00:01:09,140 --> 00:01:12,740
that guy would have been waiting in this position and

23
00:01:12,740 --> 00:01:15,760
so he'll get the signal. And therefore he will be

24
00:01:15,760 --> 00:01:17,600
getting ready to go. And he can get into the

25
00:01:17,600 --> 00:01:19,670
critical section and do whatever he wants to do with

26
00:01:19,670 --> 00:01:23,590
the Data structure that is protected by this particular lock.

27
00:01:23,590 --> 00:01:27,630
Now this will go on, and eventually, my predecessor will become

28
00:01:27,630 --> 00:01:30,912
the current lock holder. And when my predecessor is done

29
00:01:30,912 --> 00:01:33,726
using the lock, he'll come around to do an unlock

30
00:01:33,726 --> 00:01:37,076
and when the current lock holder who's my predecessor does

31
00:01:37,076 --> 00:01:40,761
the unlock operation, that's going to be resulting in a signal for

32
00:01:40,761 --> 00:01:44,810
me, because basically. He's going to set the flags array,

33
00:01:44,810 --> 00:01:47,450
the next spot in the flags array, as hl. And

34
00:01:47,450 --> 00:01:50,380
that's the spot I'm waiting on. So good news for

35
00:01:50,380 --> 00:01:55,435
me. I've got my position marked as hl, and what

36
00:01:55,435 --> 00:01:58,000
that means is that now I've got the lock. And

37
00:01:58,000 --> 00:01:59,590
now I can go off into the critical section do

38
00:01:59,590 --> 00:02:02,680
what I need to do in order to do the

39
00:02:02,680 --> 00:02:06,340
code that is associated with the critical section protected by,

40
00:02:06,340 --> 00:02:09,580
this particular lock out. Now that we understand that the

41
00:02:09,580 --> 00:02:14,100
lock and the unlock algorithm works with this array-based queuing,

42
00:02:14,100 --> 00:02:17,250
let's talk about some of the virtues of this algorithm.

43
00:02:17,250 --> 00:02:19,100
The first thing that you notice is that there is

44
00:02:19,100 --> 00:02:22,880
exactly one atomic operation that you have to carry out,

45
00:02:22,880 --> 00:02:26,910
put, put critical sections so,every time you want to acquire a

46
00:02:26,910 --> 00:02:29,670
lock you come in and do a fetch and increment

47
00:02:29,670 --> 00:02:31,470
and that is all that you do in order to get

48
00:02:31,470 --> 00:02:34,230
the lock. And so there's one atomic operation that

49
00:02:34,230 --> 00:02:38,510
you do per critical section, that's good news. And

50
00:02:38,510 --> 00:02:40,340
the other thing that you also notice is that,

51
00:02:40,340 --> 00:02:43,480
the processes are all sequenced in other words there is

52
00:02:43,480 --> 00:02:47,340
fairness uh, so whoever comes first. Gets into the

53
00:02:47,340 --> 00:02:49,850
queue ahead of me and when I come in

54
00:02:49,850 --> 00:02:52,150
if people are going to come after me they're going to

55
00:02:52,150 --> 00:02:54,390
get queued up after me. So that's good news also.

56
00:02:56,320 --> 00:03:00,240
And the spin variable we're going to mark my position

57
00:03:00,240 --> 00:03:03,990
in this array my spin variable is distinct from

58
00:03:03,990 --> 00:03:06,480
the spin variable of all the other guys that

59
00:03:06,480 --> 00:03:08,710
may be waiting for the same lock. That's another good

60
00:03:08,710 --> 00:03:12,590
thing. In other words, I'm completely unaffected by all

61
00:03:12,590 --> 00:03:16,300
the signaling that it will happen when the guys that

62
00:03:16,300 --> 00:03:18,960
are ahead of me were getting the lock and,

63
00:03:18,960 --> 00:03:21,710
and signaling the next guy and so on. I'm completely

64
00:03:21,710 --> 00:03:24,880
impervious to that because I'm spinning on my

65
00:03:24,880 --> 00:03:28,360
own private variable. Waiting for the lock. And

66
00:03:28,360 --> 00:03:30,630
of course correlating to what I just said

67
00:03:30,630 --> 00:03:35,020
is that whenever a lock is erased, exactly one

68
00:03:35,020 --> 00:03:37,540
guy is signaled to indicate that they've got

69
00:03:37,540 --> 00:03:41,900
the lock. And, and that's another important virtue of

70
00:03:41,900 --> 00:03:44,770
this particular algorithm. So, it is fair. And

71
00:03:44,770 --> 00:03:46,910
it is also not nice, so these are two

72
00:03:46,910 --> 00:03:50,965
things that very good things about this algorithm. And

73
00:03:50,965 --> 00:03:53,830
those we saw were you know the deficiency of the

74
00:03:53,830 --> 00:03:56,810
ticket log algorithm was exactly that where it is fair,

75
00:03:56,810 --> 00:03:58,760
but it is noisy when the lock is released. So

76
00:03:58,760 --> 00:04:02,070
that problem has gotten away with this queuing lock. Now

77
00:04:02,070 --> 00:04:04,630
you might be wondering, are there any downside to this

78
00:04:04,630 --> 00:04:08,740
array based queuing lock. I assure there is. The first

79
00:04:08,740 --> 00:04:12,270
thing I'm sure that you've noticed already is the size

80
00:04:12,270 --> 00:04:14,830
of the data structure is as big as the

81
00:04:14,830 --> 00:04:18,660
number of processors in the multiprocessor. So the space

82
00:04:18,660 --> 00:04:22,170
complexity [COUGH] for this algorithm is order of N

83
00:04:22,170 --> 00:04:25,780
for every lock that you have in the multiprogram. So

84
00:04:25,780 --> 00:04:28,010
if you have a large scale multiprocessor with dozens

85
00:04:28,010 --> 00:04:31,420
of processors, that can start eating into the memory

86
00:04:31,420 --> 00:04:34,120
space. So that's something that you have to watch

87
00:04:34,120 --> 00:04:37,230
out for. So the space can be a big overhead.

88
00:04:37,230 --> 00:04:39,820
And the reason I'm emphasizing that is because

89
00:04:39,820 --> 00:04:44,870
in any well-structure multi-threaded program even though we may

90
00:04:44,870 --> 00:04:48,170
have lots of threads executing in, in all

91
00:04:48,170 --> 00:04:50,750
the processors. At any point of time for a

92
00:04:50,750 --> 00:04:52,940
particular lock, they might not be in contention

93
00:04:52,940 --> 00:04:55,790
but all the processors, only a subset of them

94
00:04:55,790 --> 00:04:58,690
may be requesting the lock. But still, this

95
00:04:58,690 --> 00:05:02,060
particular algorithm has to worry about the worst case.

96
00:05:02,060 --> 00:05:04,870
Contention for a lock, and therefore it creates a data

97
00:05:04,870 --> 00:05:07,310
structure that is as big as a number of processes

98
00:05:07,310 --> 00:05:10,670
that you have in the multiprocessors. And that's the only

99
00:05:10,670 --> 00:05:13,280
downside to this, but all the other things are good stuff

100
00:05:13,280 --> 00:05:16,960
about this algorithm. And of course the reason why you

101
00:05:16,960 --> 00:05:21,320
have that downside with the, with this particular Anderson's queueing

102
00:05:21,320 --> 00:05:24,570
lock is the fact that the queue is being simulated

103
00:05:24,570 --> 00:05:27,100
by a static data structure, an array. And since it is

104
00:05:27,100 --> 00:05:28,700
a static data structure and you have to

105
00:05:28,700 --> 00:05:33,190
worry about the worst case contention among requesters for

106
00:05:33,190 --> 00:05:36,040
a lock we have to make this static array

107
00:05:36,040 --> 00:05:38,400
as big as the number of processors. So that's

108
00:05:38,400 --> 00:05:42,430
really the the catch in this particular algorithm.

109
00:05:42,430 --> 00:05:45,530
Next we will look at another algorithm, a lock

110
00:05:45,530 --> 00:05:48,930
algorithm that is also based on queuing, but it

111
00:05:48,930 --> 00:05:52,700
doesn't have the space complexity of Anderson's queuing lock.
