1
00:00:00,312 --> 00:00:04,372
Let's talk about ways to minimize time spent on memory accesses.

2
00:00:04,372 --> 00:00:09,993
The first strategy to think about is move frequently accessed data to fast memory.

3
00:00:09,993 --> 00:00:13,517
We've talked about the memory spaces available to the GPU.

4
00:00:13,517 --> 00:00:19,019
There's local memory, which represents a given thread's private variables, local variables,

5
00:00:19,019 --> 00:00:20,957
parameters, things like that.

6
00:00:20,957 --> 00:00:22,655
There's shared memory, shared by a thread block.

7
00:00:22,655 --> 00:00:24,988
There's global memory shared by all the threads.

8
00:00:24,988 --> 00:00:31,096
And more or less, it's true to say that local memory is faster than shared memory,

9
00:00:31,096 --> 00:00:33,432
which in turn is faster than global memory.

10
00:00:33,432 --> 00:00:38,043
In fact, shared memory and local memory are usually much faster than global memory.

11
00:00:38,043 --> 00:00:40,280
I should mention that there are subtleties here.

12
00:00:40,280 --> 00:00:43,174
For those of you who know something about computer organization,

13
00:00:43,174 --> 00:00:46,979
the reason why I'm labeling local memory as so fast is that it tends to live

14
00:00:46,979 --> 00:00:53,753
either in registers or in l1 cache, and those are both quite fast.

15
00:00:53,753 --> 00:00:56,027
This isn't a hard and fast rule. There's some subtleties here.

16
00:00:56,027 --> 00:01:00,977
But in general data that is kept local to a thread is going to be about as fast as possible.

17
00:01:00,977 --> 00:01:07,230
Data that is shared in a thread's thread block shared memory is going to be very fast,

18
00:01:07,230 --> 00:01:11,843
and data that is way out in global memory is going to be a lot slower,

19
00:01:11,843 --> 00:01:17,243
although this is still much faster then CPU memory, also known as host memory.

20
00:01:17,243 --> 00:01:21,577
Let's see an example of using local, shared, and global memory.

21
00:01:21,577 --> 00:01:23,149
Here's a kernel.

22
00:01:23,149 --> 00:01:27,182
I know that it's a kernel because it starts with either device or global.

23
00:01:27,182 --> 00:01:32,149
It's called use local memory GPU, it has one parameter called in,

24
00:01:32,149 --> 00:01:35,025
and it's got one local variable called f.

25
00:01:35,025 --> 00:01:39,465
Because this is a local variable it's in local memory it's private to this thread,

26
00:01:39,465 --> 00:01:42,300
every thread will have its own copy of a variable named f.

27
00:01:42,300 --> 00:01:44,451
And parameters are also local memory.

28
00:01:44,451 --> 00:01:48,375
Every thread will have it's own copy of a parameter called in.

29
00:01:48,375 --> 00:01:52,345
You know real code would presumably do something with these variables.

30
00:01:52,345 --> 00:01:54,980
But since this is just an example of how to use local memory,

31
00:01:54,980 --> 00:01:55,989
I don't need to do that.

32
00:01:55,989 --> 00:01:58,785
How would you call a kernel that shows using local memory?

33
00:01:58,785 --> 00:02:00,220
Well, you would call a kernel,

34
00:02:00,220 --> 00:02:05,863
you would have to launch it, meaning tell the GPU how many thread blocks to run with how many threads.

35
00:02:05,863 --> 00:02:11,797
You pass in any parameters. So in this case, 2.0. Pretty simple.
