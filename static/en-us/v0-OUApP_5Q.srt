1
00:00:00,000 --> 00:00:04,000
How can we optimize these two terms over here?

2
00:00:04,000 --> 00:00:06,000
The idea is to use gradient descent.

3
00:00:06,000 --> 00:00:13,000
That is, every time step we take a small step in the direction of minimizing the error over here.

4
00:00:13,000 --> 00:00:15,000
Here's the expression for the first objective.

5
00:00:15,000 --> 00:00:20,000
When we iterate, we assigned to yi recursively the old yi,

6
00:00:20,000 --> 00:00:26,000
but we subtract a term that's proportional to the deviation of yi to xi,

7
00:00:26,000 --> 00:00:28,000
weighted by a weight function alpha.

8
00:00:28,000 --> 00:00:31,000
That's not exactly the same alpha as before.

9
00:00:31,000 --> 00:00:34,000
We set this alpha over here to 0.5.

10
00:00:34,000 --> 00:00:37,000
For the second term, we could implement this as follows

11
00:00:37,000 --> 00:00:47,000
where we retain the old y variable, but we move a little bit in the direction of yi+1 and away from yi.

12
00:00:47,000 --> 00:00:50,000
But an even better implementation looks as follows.

13
00:00:50,000 --> 00:00:53,000
This is combining the step on the left and the step on the right.

14
00:00:53,000 --> 00:00:58,000
Realizing that each yi occurs twice in this optimization term,

15
00:00:58,000 --> 00:01:03,000
one here and one here, we can now go and implement this in a single update rule

16
00:01:03,000 --> 00:01:09,000
where we wish yi to be as close to yi-1 and simultaneously be as close as yi+1

17
00:01:09,000 --> 00:01:11,000
by optimizing this combined term.

18
00:01:11,000 --> 00:01:15,000
Think about this as little bit, but that's what I want you to implement.

19
00:01:15,000 --> 00:01:18,000
We're going to set beta to 0.1.

20
00:01:18,000 --> 00:01:21,000
Now let's go and implement this.

21
00:01:21,000 --> 00:01:27,000
As a last hint, I don't want you to apply this optimization for the first or the last node in the sequence.

22
00:01:27,000 --> 00:01:30,000
I want those to be unchanged, as we'll see in a second.

23
00:01:30,000 --> 00:01:32,000
Here's the code I'll be giving you.

24
00:01:32,000 --> 00:01:36,000
There's a path in a 5 x 5 grid, starting at [0, 0] to [4, 4].

25
00:01:36,000 --> 00:01:41,000
If you look very carefully, it goes to the right at first, then straight down, then to the right again.

26
00:01:41,000 --> 00:01:45,000
This is exactly the path we discussed so far and looks like this graphically.

27
00:01:45,000 --> 00:01:51,000
I now want you to implement the function "smooth," which takes as an input the path,

28
00:01:51,000 --> 00:01:54,000
our two weighting factors, and a small tolerance variable,

29
00:01:54,000 --> 00:01:57,000
which I'll explain to you in a second, and it creates the new path,

30
00:01:57,000 --> 00:02:03,000
which are the y's in our equations so far from the old path.

31
00:02:03,000 --> 00:02:05,000
This is a deep copy over here.

32
00:02:05,000 --> 00:02:07,000
Then below the line, I want you to implement the smoother.

33
00:02:07,000 --> 00:02:11,000
What the smoother does is iteratively applies the two equations I just gave you to all nodes

34
00:02:11,000 --> 00:02:14,000
except for the first and the last,

35
00:02:14,000 --> 00:02:20,000
and it does so until the total change observed in the update step becomes smaller than tolerance,

36
00:02:20,000 --> 00:02:23,000
at which point we consider the smoother to have converged.

37
00:02:23,000 --> 00:02:28,000
Here is my command. I compute a new path as a result of the function smooth.

38
00:02:28,000 --> 00:02:31,000
In your test, you should uncomment the "newpath" smooth routine

39
00:02:31,000 --> 00:02:33,000
and the print routine that outputs my result,

40
00:02:33,000 --> 00:02:41,000
"Thank to EnTeer," a student who posted a much better way to output matrices on the discussion forum.

41
00:02:41,000 --> 00:02:44,000
I'm going to use his or her code. Thank you so much.

42
00:02:44,000 --> 00:02:52,000
Here's the result. After hitting "Run," I have the original path over here--zeros all the way to [4, 4].

43
00:02:52,000 --> 00:02:56,000
The two initial and the end position, should be the same as before, so please don't modify them,

44
00:02:56,000 --> 00:03:00,000
but in between we get these interpolation positions over here.

45
00:03:00,000 --> 00:03:05,000
If you look at this, my original path didn't vary the x's at all for the first three steps

46
00:03:05,000 --> 00:03:11,000
whereas this one goes from [0, 0] to 0.17, so it got closer. It went down a little bit.

47
00:03:11,000 --> 00:03:14,000
Also, it went less to the right side than my original path.

48
00:03:14,000 --> 00:03:17,000
We went all the way to 2 over here to 1.8 over here.

49
00:03:17,000 --> 00:03:22,000
What this means is that our new points lie a little bit like this.

50
00:03:22,000 --> 00:03:27,000
As you go through the list over here, you'll find that our new points really smooth out

51
00:03:27,000 --> 00:03:30,880
the path to something more like that.

52
00:03:32,055 --> 00:03:34,510
Hi, I'm Andy, the assistant instructor for this class,

53
00:03:34,510 --> 00:03:37,070
and I just wanted to provide some clarification about

54
00:03:37,070 --> 00:03:40,538
how you're going to use gradient descent to minimize these functions.

55
00:03:40,538 --> 00:03:43,956
First, I'd like to point out that there was a slight error

56
00:03:43,956 --> 00:03:46,119
in the path used in Sebastian's code.

57
00:03:46,119 --> 00:03:50,007
That [4,4] that he was using should actually be replaced with a [4,2].

58
00:03:50,007 --> 00:03:54,683
Also, those minus signs that you saw here should actually be replaced with plus signs

59
00:03:54,683 --> 00:03:57,571
if we want this gradient descent implementation to converge.

60
00:03:57,571 --> 00:04:01,803
Finally, even though these yi's and xi's are two-dimensional vectors,

61
00:04:01,803 --> 00:04:04,311
when you implement your code, it may be easier

62
00:04:04,311 --> 00:04:07,075
to just iterate over each individual entry.

63
00:04:07,075 --> 00:04:12,183
So, for example, these xi's would be these values here.
