1
00:00:00,510 --> 00:00:04,530
But you know, monitoring is pretty
vital for operations work, too.

2
00:00:04,530 --> 00:00:07,490
From an ops standpoint,
we can talk about measuring facts about

3
00:00:07,490 --> 00:00:12,120
our infrastructure resources,
like individual servers and our network.

4
00:00:12,120 --> 00:00:16,720
Measuring resources like CPU
utilization, RAM usage, disk space,

5
00:00:16,720 --> 00:00:20,280
network bandwidth, lets us know if
our infrastructure's overloaded.

6
00:00:20,280 --> 00:00:23,600
Or better yet, it can give us warning
well before it's overloaded so

7
00:00:23,600 --> 00:00:25,110
it can scale our service correctly.

8
00:00:26,280 --> 00:00:29,730
On servers, we might also want to record
things like the hardware temperature and

9
00:00:29,730 --> 00:00:31,640
the disk I/O error rate.

10
00:00:31,640 --> 00:00:32,360
By looking at that,

11
00:00:32,360 --> 00:00:34,990
you can often predict a disk failure
before it breaks your machine.

12
00:00:36,300 --> 00:00:38,200
How about on the application side?

13
00:00:38,200 --> 00:00:41,590
If we have ten web servers
with a load balancer in front,

14
00:00:41,590 --> 00:00:44,500
we probably want to know how many
requests each server is handling.

15
00:00:44,500 --> 00:00:47,230
And the monitoring system
can sum those numbers

16
00:00:47,230 --> 00:00:49,650
up to get the total number of
queries the whole app is taking.

17
00:00:50,660 --> 00:00:53,240
If you care about how fast or
slow your service is, well,

18
00:00:53,240 --> 00:00:55,710
you have to measure its latency.

19
00:00:55,710 --> 00:00:58,870
And likewise, if you want those
web servers to be serving

20
00:00:58,870 --> 00:01:03,050
200s like a happy web server,
instead of 500s like a broken one,

21
00:01:03,050 --> 00:01:05,780
you'd better monitor whether all those
requests are succeeding or failing.

22
00:01:06,820 --> 00:01:10,330
And once you have all this information
recorded, you can do things like

23
00:01:10,330 --> 00:01:14,840
calculate how much total CPU is needed
to handle the average transaction.

24
00:01:14,840 --> 00:01:18,240
Or how service latency responds
to increased RAM pressure.

25
00:01:18,240 --> 00:01:20,180
Or any number of other things.

26
00:01:20,180 --> 00:01:21,302
In a really awesome world,

27
00:01:21,302 --> 00:01:24,810
you could even plug that back into
your continuous delivery automation.

28
00:01:24,810 --> 00:01:26,907
And before letting a release
go out to production,

29
00:01:26,907 --> 00:01:29,735
load test that release and make sure
that it's not a lot more resource

30
00:01:29,735 --> 00:01:31,170
intensive than the last version.
