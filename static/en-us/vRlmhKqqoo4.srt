1
00:00:00,410 --> 00:00:03,310
But when we date discriminative
classification we said, you know nearest

2
00:00:03,310 --> 00:00:06,720
neighbor has some power, but, it can be
kind of expensive in terms of storage

3
00:00:06,720 --> 00:00:09,200
and access, and maybe there
are better ways we can do things.

4
00:00:09,200 --> 00:00:12,020
And in fact,
we talked about training classifiers, so

5
00:00:12,020 --> 00:00:15,150
we talked about boosting or SVM.

6
00:00:15,150 --> 00:00:17,830
So, we can do that for
this example, too, right?

7
00:00:17,830 --> 00:00:20,870
I have a whole bunch
of images of violins.

8
00:00:20,870 --> 00:00:23,440
I've got a whole bunch
of images of people.

9
00:00:23,440 --> 00:00:25,680
I've got a whole bunch
of images of planes.

10
00:00:25,680 --> 00:00:29,700
I take all those images together,
I find all the visual words.

11
00:00:29,700 --> 00:00:31,250
All right, that gives me a vocabulary.

12
00:00:31,250 --> 00:00:34,550
I can build a histogram for
each of the objects.

13
00:00:34,550 --> 00:00:37,480
And you know, so I've brought
a bunch of training data, so

14
00:00:37,480 --> 00:00:39,380
I got a bunch of histograms for
planes, I've got histograms for

15
00:00:39,380 --> 00:00:41,060
cars, histograms for faces.

16
00:00:41,060 --> 00:00:42,080
And what do I do?

17
00:00:42,080 --> 00:00:45,310
I just train a support vector machine
to make the decision, you know,

18
00:00:45,310 --> 00:00:48,120
is this a, a person,
a plane, a car, et cetera.

19
00:00:48,120 --> 00:00:50,490
And in fact that's
exactly what was done.

20
00:00:50,490 --> 00:00:52,370
This work comes from 04.

21
00:00:52,370 --> 00:00:55,430
There was a database, still is a
database referred to as the Caltech 101.

22
00:00:55,430 --> 00:01:00,190
It was one of the original
datasets of enough images of

23
00:01:00,190 --> 00:01:04,709
enough object types to start to explore
this notion of database access.

24
00:01:04,709 --> 00:01:08,240
And, and what they were doing was
they trained exactly a linear SVM,

25
00:01:08,240 --> 00:01:11,770
we talked about those before,
using a bag of words on vectors and

26
00:01:11,770 --> 00:01:13,580
there were a couple
of different classes.

27
00:01:13,580 --> 00:01:16,580
Faces, airplanes, cars,
motorbikes, et cetera.

28
00:01:16,580 --> 00:01:21,000
And what's being reported here is that
for each of the actual faces, you know,

29
00:01:21,000 --> 00:01:24,420
out of, you know,
the average percentage of time.

30
00:01:24,420 --> 00:01:29,390
That it was the best rank was 94, 96,
90 so you can see that it's pretty good.

31
00:01:29,390 --> 00:01:33,530
And then the other thing that
they report is the mean rank.

32
00:01:33,530 --> 00:01:37,210
So when I try to find, you know,
whether or not, you know,

33
00:01:37,210 --> 00:01:40,390
when I show a plane and I say well,
do I think it's a plane,

34
00:01:40,390 --> 00:01:42,890
do I think its a face,
do I think its a motorbike, et cetera?

35
00:01:42,890 --> 00:01:46,470
You know, how what is the average
ranking of the correct answer?

36
00:01:46,470 --> 00:01:48,470
And you can see the value
is 1.0 something.

37
00:01:48,470 --> 00:01:52,030
Meaning that it almost
always got the answer right.

38
00:01:52,030 --> 00:01:55,990
But it was just an example of this
bag of words approach that says,

39
00:01:55,990 --> 00:02:00,620
I don't know anything about parts,
I don't know anything about structure.

40
00:02:00,620 --> 00:02:04,210
What I know about is images and
I take locations and

41
00:02:04,210 --> 00:02:07,900
images and I find interesting points,
I build some description.

42
00:02:07,900 --> 00:02:11,350
Give me a word-like collection
of those descriptors.

43
00:02:11,350 --> 00:02:15,140
And then for any new image, try to
find the descriptors that are present.

44
00:02:15,140 --> 00:02:17,140
And that's what's referred
to as bag of words.
