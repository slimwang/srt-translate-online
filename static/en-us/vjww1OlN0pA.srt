1
00:00:00,300 --> 00:00:03,750
Shelly, is there any idea of reducing
the amount of randomness over

2
00:00:03,750 --> 00:00:06,509
time in genetic algorithms,
like say in simulating kneeling?

3
00:00:07,580 --> 00:00:09,500
>> Well,
not limitations that we've shown so far.

4
00:00:09,500 --> 00:00:12,310
But the fitness function
naturally reduces the randomness,

5
00:00:12,310 --> 00:00:15,140
as each generation gets
closer to the solution.

6
00:00:15,140 --> 00:00:18,089
However, we could argue that
the method could do better.

7
00:00:18,089 --> 00:00:20,649
In fact, there are a lot
publications that talk about tuning,

8
00:00:20,649 --> 00:00:24,339
crossover mutations, number of parents
and all the other parameters to

9
00:00:24,339 --> 00:00:27,969
optimize genetic algorithms to
converge as quickly as possible.

10
00:00:27,969 --> 00:00:28,879
>> In some sense,

11
00:00:28,879 --> 00:00:31,980
genetic algorithms are a fancy
version of stochastic beam search.

12
00:00:31,980 --> 00:00:34,600
It happens to make a nice
analogy with biology.

13
00:00:34,600 --> 00:00:35,190
>> Yep.

14
00:00:35,189 --> 00:00:38,906
Some people call genetic algorithms
the second best solution to any problem.

15
00:00:38,906 --> 00:00:42,779
But analogies are nice things when
learning or using different methods.

16
00:00:42,780 --> 00:00:44,609
We used a lot throughout this section.

17
00:00:44,609 --> 00:00:45,969
Hill climbing, annealing and

18
00:00:45,969 --> 00:00:49,710
genetic algorithms are all analogies
to some physical or biological process.

