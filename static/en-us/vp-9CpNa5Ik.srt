1
00:00:00,100 --> 00:00:02,930
The next step takes us from S3 to SF.

2
00:00:02,930 --> 00:00:05,440
Then we get reward R3 when that happens.

3
00:00:05,440 --> 00:00:08,368
The first thing that happens is we
update the eligibility for that state.

4
00:00:08,368 --> 00:00:12,612
Then, we compute this quantity that
we're going to add to all the state

5
00:00:12,612 --> 00:00:13,680
updates.

6
00:00:13,680 --> 00:00:18,734
This gives us R3 plus gamma times
the previous value of the state

7
00:00:18,734 --> 00:00:23,236
that we just ended up in minus
the state that we came from.

8
00:00:23,236 --> 00:00:26,156
And this update is going to
get applied to all the states,

9
00:00:26,156 --> 00:00:28,930
proportional to their eligibility.

10
00:00:28,930 --> 00:00:30,511
So, we can do that same thing again,

11
00:00:30,511 --> 00:00:33,061
just add this quantity into
all these things and simplify.

12
00:00:33,061 --> 00:00:34,675
Does that sound okay?

13
00:00:34,675 --> 00:00:38,120
>> It does sound okay and I think
I finally see where this is going.

14
00:00:38,120 --> 00:00:42,223
So, if you look at the pseudo code
right, you say for all s, and

15
00:00:42,223 --> 00:00:46,481
you update the value of the state,
if you look at the stuff that's

16
00:00:46,481 --> 00:00:50,677
multiplied by alpha sub T,
all that is basically is your error.

17
00:00:50,677 --> 00:00:52,170
Right?
[CROSSTALK]

18
00:00:52,170 --> 00:00:52,990
>> Right, that's why this

19
00:00:52,990 --> 00:00:54,270
is TD learning.

20
00:00:54,270 --> 00:00:57,658
>> Right, it's what you thought it was.

21
00:00:57,658 --> 00:00:59,776
The difference between what
you thought it was and

22
00:00:59,776 --> 00:01:02,652
what it turned out to be when you
actually saw the reward if you assume

23
00:01:02,652 --> 00:01:04,940
that your future guess is
about the values are right.

24
00:01:04,940 --> 00:01:05,947
>> Exactly.

25
00:01:05,947 --> 00:01:10,033
>> So, because of that cute little
compactify telescoping thing that

26
00:01:10,033 --> 00:01:13,975
you just did, I think without
actually writing everything out,

27
00:01:13,975 --> 00:01:18,120
I can guess what the next
values are going to look like.

28
00:01:18,120 --> 00:01:21,969
So, and tell me if I'm right.

29
00:01:21,969 --> 00:01:27,530
The delta for VT of S1 is basically
going to have seen one more thing.

30
00:01:27,530 --> 00:01:35,753
So, it'll end up being R1 plus
gamma R2 plus gamma squared R3.

31
00:01:35,753 --> 00:01:37,050
>> And where does that come from?

32
00:01:38,380 --> 00:01:41,564
>> Well, that comes from the term
that you just added over there.

33
00:01:41,564 --> 00:01:44,630
>> The R3 and
the eligibility for state S1.

34
00:01:45,630 --> 00:01:48,177
>> Right, which you've managed
to make the gamma squared.

35
00:01:48,177 --> 00:01:51,720
So, the eligibility isn't just
whether you've seen a state before.

36
00:01:51,720 --> 00:01:55,513
It's actually keeping track of
how long ago you saw that state.

37
00:01:55,513 --> 00:01:56,745
>> Good.

38
00:01:56,745 --> 00:02:00,367
>> Right and so, if there was another
state after SF and we kept going, we'd

39
00:02:00,367 --> 00:02:04,224
see it get that would become gamma cube,
then S2 would become gamma squared,

40
00:02:04,224 --> 00:02:06,750
and S3 would become gamma,
and so on and so forth.

41
00:02:06,750 --> 00:02:10,056
That's quite clever.

42
00:02:10,056 --> 00:02:15,486
Okay, so you would see R1 plus gamma R2

43
00:02:15,486 --> 00:02:23,799
plus gamma squared R3 plus
gamma cubed (VT-1(S4)).

44
00:02:23,799 --> 00:02:25,800
>> Well,
there is no S4 to the final state.

45
00:02:25,800 --> 00:02:28,277
>> I'm sorry, SF, thank you,
thank you very much.

46
00:02:28,277 --> 00:02:32,330
SF minus (VT-1(S1)), so that stays.

47
00:02:32,330 --> 00:02:35,965
In all that is is the error,
it's what you're guess was of the value.

48
00:02:35,965 --> 00:02:39,744
And what you actually ended up seeing,
which was all the rewards that you saw

49
00:02:39,744 --> 00:02:42,121
plus whatever future value
there's going to be.

50
00:02:42,121 --> 00:02:42,667
>> Good.

51
00:02:42,667 --> 00:02:45,620
All right, we may have done
a little too much jumping.

52
00:02:45,620 --> 00:02:48,635
So, can I fill that in with the way
that you just described it?

53
00:02:48,635 --> 00:02:50,085
>> Okay.

54
00:02:50,085 --> 00:02:53,424
So, some frustrating amount of
algebra and rewriting later,

55
00:02:53,424 --> 00:02:55,755
it seems to have fallen
into this pattern and

56
00:02:55,755 --> 00:02:58,760
this is what you're talking about,
right Charles?

57
00:02:58,760 --> 00:03:00,405
>> Yeah,
that's exactly what I was thinking.

58
00:03:00,405 --> 00:03:02,530
>> So, we have this sort of
temporal difference thing.

59
00:03:02,530 --> 00:03:08,129
So, we can now state a claim which just
follows very clearly from the example.

60
00:03:08,129 --> 00:03:12,205
And that is that this update, this
TD(1) update that we just talked about,

61
00:03:12,205 --> 00:03:16,219
actually does the same thing as the
outcome-based update, which is to say,

62
00:03:16,219 --> 00:03:19,430
we wait to see what all the rewards,
the discounted rewards,

63
00:03:19,430 --> 00:03:23,198
are on the entire trajectory, and
then we just update our prediction for

64
00:03:23,198 --> 00:03:26,760
the state that they started
from with those rewards.

65
00:03:26,760 --> 00:03:28,572
Keep in mind that these things are zero.

66
00:03:28,572 --> 00:03:31,549
The VT minus one of SF is zero,
so this kind of goes away, and

67
00:03:31,549 --> 00:03:35,539
this kind of goes away, and this kind of
goes away and we're really just talking

68
00:03:35,539 --> 00:03:38,920
about the discounted sum of
rewards minus the old prediction.

69
00:03:38,920 --> 00:03:41,450
The discounted sum of rewards
minus the old prediction.

70
00:03:41,450 --> 00:03:44,020
The discounted sum of rewards
minus the old prediction.

71
00:03:44,020 --> 00:03:46,570
So, at least in the case where
there is no repeated states,

72
00:03:46,570 --> 00:03:48,769
we visit a state more than
once along a trajectory.

73
00:03:48,769 --> 00:03:53,500
Everything beautifully cancels and
what you get is exactly the same update.

74
00:03:53,500 --> 00:03:56,618
The TD(1) update is exactly
the same update as just waiting for

75
00:03:56,618 --> 00:03:58,610
the outcomes and updating based on that.

76
00:03:58,610 --> 00:04:02,712
>> That's actually really impressive.
