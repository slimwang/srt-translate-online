1
00:00:00,380 --> 00:00:04,689
An efficient cache aware matrix multiply
performs a sequence of of submatrix or

2
00:00:04,689 --> 00:00:06,580
block by block multiplies.

3
00:00:06,580 --> 00:00:10,700
You choose the block size so that,
nominally, three blocks fit in cache.

4
00:00:10,700 --> 00:00:14,370
The corresponding algorithm looks like
this, and notice that the block size is

5
00:00:14,370 --> 00:00:17,140
denoted by little b appears
directly in the algorithm.

6
00:00:17,140 --> 00:00:21,410
Now you can show that the number of
cache misses is asymptotically n cubed

7
00:00:21,410 --> 00:00:23,550
divided by L times b.

8
00:00:23,550 --> 00:00:25,820
And since b is proportional
to square root of Z,

9
00:00:25,820 --> 00:00:28,400
that's just n cubed over L root z.

10
00:00:28,400 --> 00:00:31,480
As it happens, for
any non-Strassen matrix multiply,

11
00:00:31,480 --> 00:00:34,410
no algorithm can do
asymptotically better than this.

12
00:00:34,410 --> 00:00:37,400
Now, since b is a function
of the cache size, and

13
00:00:37,400 --> 00:00:41,020
it appears in the algorithm,
we say this algorithm is cache-aware.

14
00:00:41,020 --> 00:00:42,320
Here's a question for you.

15
00:00:42,320 --> 00:00:46,350
Is there a different algorithm
that dos not refer to L or Z, yet

16
00:00:46,350 --> 00:00:48,850
somehow still attains the lower bound?

17
00:00:48,850 --> 00:00:50,390
The answer is yes.

18
00:00:50,390 --> 00:00:52,850
It's based on the the idea of divide and
conquer.

19
00:00:52,850 --> 00:00:55,800
Let's assume for simplicity,
that the matrices are n by n,

20
00:00:55,800 --> 00:00:58,010
where n is an integer power of two.

21
00:00:58,010 --> 00:01:02,280
The algorithm first partitions the
matrices into two by two submatrices.

22
00:01:02,280 --> 00:01:05,400
Then performs eight recursive
matrix multiplies to update

23
00:01:05,400 --> 00:01:07,250
the two by two C block.

24
00:01:07,250 --> 00:01:09,910
To be more precise,
here's the pseudocode algorithm.

25
00:01:09,910 --> 00:01:13,750
The base case occurs when A,
B and C are scalars.

26
00:01:13,750 --> 00:01:16,340
The algorithm just
performs a scalar update.

27
00:01:16,340 --> 00:01:19,710
Otherwise, the input matrices are
logically partitioned into quadrants as

28
00:01:19,710 --> 00:01:20,910
shown in the figure.

29
00:01:20,910 --> 00:01:24,150
The algorithm performs eight
recursive matrix multiplies to

30
00:01:24,150 --> 00:01:26,460
update the four quadrants of C.

31
00:01:26,460 --> 00:01:30,348
Now as a pseudo code reveals,
this algorithm is cache oblivious.

32
00:01:30,348 --> 00:01:34,570
Unlike the block algorithm, it makes no
reference to the size of the cache, or

33
00:01:34,570 --> 00:01:35,990
of the line size.

34
00:01:35,990 --> 00:01:39,430
Now we need to analyze this algorithm
Let's forget about cache misses for

35
00:01:39,430 --> 00:01:42,130
the moment and suppose you just wanted
to count the number of adds and

36
00:01:42,130 --> 00:01:42,794
multiplies.

37
00:01:42,794 --> 00:01:43,990
How would you do it?

38
00:01:43,990 --> 00:01:45,910
Well the algorithm's recursive so

39
00:01:45,910 --> 00:01:48,880
you'd write down a recurrence
relation maybe like this one.

40
00:01:48,880 --> 00:01:51,430
The first case counts
the eight recursive calls

41
00:01:51,430 --> 00:01:53,310
on half the problem size.

42
00:01:53,310 --> 00:01:57,700
The base case counts the multiplies and
adds or flops and namely there are two.

43
00:01:57,700 --> 00:02:01,300
If you solve this recurrence exactly
you would get 2 n cubed flops which is

44
00:02:01,300 --> 00:02:02,880
exactly what you would expect.

45
00:02:02,880 --> 00:02:04,570
Now, what about cache misses?

46
00:02:04,570 --> 00:02:06,510
Imagine the recursion tree.

47
00:02:06,510 --> 00:02:08,320
Each node is a function call.

48
00:02:08,320 --> 00:02:10,479
There's eight way
branching at each node,

49
00:02:10,479 --> 00:02:12,970
and the leaves correspond
to the base case.

50
00:02:12,970 --> 00:02:17,510
And of course the problem size shrinks
progressively from n down to one.

51
00:02:17,510 --> 00:02:22,210
At some point in this recursion, all
the operands of a subtree fit in cache.

52
00:02:22,210 --> 00:02:26,800
Let's say that level is little l,
and call that size n sub l.

53
00:02:26,800 --> 00:02:30,620
At that point, it must be that
three blocks fit in cache.

54
00:02:30,620 --> 00:02:32,090
If the matrix is stored in row or

55
00:02:32,090 --> 00:02:36,300
column major layout, then you'd
also need to assume tall caches.

56
00:02:36,300 --> 00:02:39,890
Then you can conclude that n
sub l will be less than or

57
00:02:39,890 --> 00:02:43,180
equal to some constant fraction of z.

58
00:02:43,180 --> 00:02:46,940
I'll denote that fraction by
the fudge constant f for the moment.

59
00:02:46,940 --> 00:02:50,650
So a recurrence for
the cache misses will have two cases.

60
00:02:50,650 --> 00:02:53,300
The first is when
the operands fit in cache.

61
00:02:53,300 --> 00:02:55,960
The number of cache misses
is just proportional to

62
00:02:55,960 --> 00:02:58,410
n sub L squared divided by L.

63
00:02:58,410 --> 00:02:59,850
That's the base case.

64
00:02:59,850 --> 00:03:02,020
Otherwise, there's the recursive case.

65
00:03:02,020 --> 00:03:05,540
You pay for misses at each of
the eight branches plus, let's assume,

66
00:03:05,540 --> 00:03:08,540
a constant number within
the function call itself.

67
00:03:08,540 --> 00:03:09,750
If you solve this recurrence,

68
00:03:09,750 --> 00:03:13,920
you should get the following,
n cubed over L root z.

69
00:03:13,920 --> 00:03:18,400
This matches the cache aware algorithm,
as well as the lower bound, yet

70
00:03:18,400 --> 00:03:22,390
remember that the algorithm
itself never refers to z or L.

71
00:03:22,390 --> 00:03:23,470
That's oblivious, baby!
