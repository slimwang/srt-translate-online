1
00:00:00,060 --> 00:00:03,610
Well having only 1 thread issuing memory transactions certainly limits

2
00:00:03,610 --> 00:00:06,512
the number of bytes delivered and that's our total achieved bandwidth.

3
00:00:06,512 --> 00:00:12,640
Version 2 with a single thread per a row still will only have a single thread block running on

4
00:00:12,641 --> 00:00:15,512
a single SM issuing transactions, and again

5
00:00:15,512 --> 00:00:18,126
this is not going to be enough to fill this big fat pipe.

6
00:00:18,126 --> 00:00:21,656
Version 3 had plenty of parallelism and plenty of transactions and flights.

7
00:00:21,656 --> 00:00:27,778
The problem there was the uncoalesced right ack operations limited our useful bytes delivered.

8
00:00:27,778 --> 00:00:31,755
And our current version of the code, which uses shared memory to achieve

9
00:00:31,755 --> 00:00:35,070
better coalescing among the threads and get higher numbers

10
00:00:35,070 --> 00:00:37,657
of useful bytes delivered for every transaction,

11
00:00:37,657 --> 00:00:43,164
still uses 1 thread per element, and therefore is achieving plenty of transactions to fill the pipeline.

12
00:00:43,164 --> 00:00:47,753
So where does that leave us? We're still achieving lower bandwidth than we would have expected.

13
00:00:47,753 --> 00:00:51,757
And we know that we're delivering plenty of useful bytes per transaction.

14
00:00:51,757 --> 00:00:55,260
So, the problem really must be the average latency.

15
00:00:55,260 --> 00:00:58,728
There must be something that's keeping the time between transactions

16
00:00:58,728 --> 00:01:01,993
higher than it should be to fill this pipeline.
