1
00:00:00,250 --> 00:00:03,760
Okay. Let's just simply try and substitute our values in the

2
00:00:03,760 --> 00:00:06,890
formulas that we know of. Since A and B are independent

3
00:00:06,890 --> 00:00:10,580
events, the triangle probably is given by the product of A,

4
00:00:10,580 --> 00:00:14,153
product of probability of A and B, so that gives us 0.25.

5
00:00:16,660 --> 00:00:19,550
Probability of A given B, since A and B

6
00:00:19,550 --> 00:00:22,040
are [UNKNOWN] of each other. Probability of A given

7
00:00:22,040 --> 00:00:28,644
B is just probability of A, which is 0.5. So then the entropy of A is given by

8
00:00:28,644 --> 00:00:35,290
this formula. And if we expand on this we get, we get the entropy of A as 1.

9
00:00:35,290 --> 00:00:38,010
Similarly the entropy of B is also 1. What

10
00:00:38,010 --> 00:00:42,360
is the joint entropy? The joint entropy is given as

11
00:00:42,360 --> 00:00:48,174
this formula. So if we substitute the values we get the joint entropy of A

12
00:00:48,174 --> 00:00:54,000
and B as 2. What is the condition entropy of A given B? It is given as this

13
00:00:54,000 --> 00:00:56,200
formula. And if you substitute the values, we

14
00:00:56,200 --> 00:01:00,160
get the conditional entropy as 1. Mutual information between

15
00:01:00,160 --> 00:01:03,380
A and B is given by this formula.

16
00:01:03,380 --> 00:01:07,380
And if we substitute the values of the variables

17
00:01:07,380 --> 00:01:10,128
that we have already calculated, entropy of A and

18
00:01:10,128 --> 00:01:13,144
entropy of A given B, we get 1 minus

19
00:01:13,144 --> 00:01:16,420
1, which is zero. So, since the two coins

20
00:01:16,420 --> 00:01:19,170
are independent, there is no mutual information between them.
