1
00:00:00,240 --> 00:00:03,370
Now if you look at the memory footprint of

2
00:00:03,370 --> 00:00:06,650
a process. And the amount of time it takes to

3
00:00:06,650 --> 00:00:10,280
load all of its working sect into the cache.

4
00:00:10,280 --> 00:00:13,190
The, the bigger the memory footprint, the more time it's

5
00:00:13,190 --> 00:00:16,760
going to take for the processor to get the working

6
00:00:16,760 --> 00:00:19,900
set of a particular thread into the cache. So that

7
00:00:19,900 --> 00:00:22,160
the cache is warm enough, and the process of

8
00:00:22,160 --> 00:00:25,390
the thread can do its work. Without having to have

9
00:00:25,390 --> 00:00:30,380
those hiccups where it has to go to the memory in order to fetch the contents in

10
00:00:30,380 --> 00:00:33,330
the cache. So what this suggests is that it's

11
00:00:33,330 --> 00:00:37,430
important to pay attention to cache affinity in scheduling.

12
00:00:37,430 --> 00:00:39,950
And so the variance of cache affinity scheduling

13
00:00:39,950 --> 00:00:42,910
that we talked about are all excellent candidates to

14
00:00:42,910 --> 00:00:45,990
run on a multiprocessor. And in fact, the minimum

15
00:00:45,990 --> 00:00:50,850
intervention, or minimum intervening scheduling policy, and the minimum

16
00:00:50,850 --> 00:00:54,460
intervening scheduling with queuing, both of those are

17
00:00:54,460 --> 00:00:57,890
very good policies to use when you have a

18
00:00:57,890 --> 00:01:02,060
fairly light to medium load on a multiprocessor.

19
00:01:02,060 --> 00:01:05,400
Because that is the time when it is likely

20
00:01:05,400 --> 00:01:09,730
that a thread, when it is run on a processor, if it has an affinity for that

21
00:01:09,730 --> 00:01:12,530
particular processor, the contents of the cache are going

22
00:01:12,530 --> 00:01:16,890
to contain the memory contents for that particular thread.

23
00:01:16,890 --> 00:01:19,070
But on the other hand, if you have a very

24
00:01:19,070 --> 00:01:22,960
heavy load in the system, then it is likely that

25
00:01:22,960 --> 00:01:26,260
by the time a thread is run on a processor,

26
00:01:26,260 --> 00:01:30,200
on which it supposedly having an affinity, all of the

27
00:01:30,200 --> 00:01:32,110
cache may have been polluted because the load is very

28
00:01:32,110 --> 00:01:35,200
heavy. So, in between the time that a thread got

29
00:01:35,200 --> 00:01:37,900
run on a particular processor, next time it runs on

30
00:01:37,900 --> 00:01:42,040
the same processor, maybe it's cache contents have been highly polluted

31
00:01:42,040 --> 00:01:44,250
by other threads. And therefore, if the load

32
00:01:44,250 --> 00:01:48,340
is very heavy then maybe a fixed processor scheduling

33
00:01:48,340 --> 00:01:51,280
may work out to be much better than

34
00:01:51,280 --> 00:01:55,300
the variants of minimum intervening scheduling policies. So, the

35
00:01:55,300 --> 00:01:57,680
moral of the story is that you really

36
00:01:57,680 --> 00:02:01,230
have to pay attention to both how heavily loaded

37
00:02:01,230 --> 00:02:04,760
your processor is, or system is and also what

38
00:02:04,760 --> 00:02:07,080
is the kind of workload that you are catering

39
00:02:07,080 --> 00:02:09,370
to, both those things play a part in

40
00:02:09,370 --> 00:02:11,830
deciding what what we will be best scheduling policy

41
00:02:11,830 --> 00:02:13,740
and it may not always be the case

42
00:02:13,740 --> 00:02:17,730
that the same scheduling policy applies in all circumstances.

43
00:02:17,730 --> 00:02:21,350
So, a real agile operating system may choose

44
00:02:21,350 --> 00:02:25,080
to vary the scheduling policy based on the load

45
00:02:25,080 --> 00:02:29,020
as well as the current set of threads that

46
00:02:29,020 --> 00:02:32,230
need to run on the system. Another interesting wrinkle

47
00:02:32,230 --> 00:02:35,420
to taking a scheduling policy is the idea of

48
00:02:35,420 --> 00:02:40,660
procrastination. And that is, normally we think of the scheduler

49
00:02:40,660 --> 00:02:43,060
when the processor is looking for work, it's going

50
00:02:43,060 --> 00:02:45,280
to the, to the run queue and saying well I

51
00:02:45,280 --> 00:02:47,350
need to, to do something.and let me pick the

52
00:02:47,350 --> 00:02:51,170
next thread to run on myself. That's what a processor

53
00:02:51,170 --> 00:02:54,790
is going to do. Perhaps procrastination may help. Why would

54
00:02:54,790 --> 00:02:58,700
procrastination help? First of all, how do we implement procrastination?

55
00:02:58,700 --> 00:03:01,000
Well, what the processor can do is, it is actually

56
00:03:01,000 --> 00:03:03,830
ready to do, do some work. Now, what it does

57
00:03:03,830 --> 00:03:06,680
is it, it's going to insert an idle loop. Why would

58
00:03:06,680 --> 00:03:09,930
it insert an idle loop? It'll insert an idle loop

59
00:03:09,930 --> 00:03:13,400
because it has, it's looking in the, the scheduling queue

60
00:03:13,400 --> 00:03:16,350
and it sees that there is no thread in the

61
00:03:16,350 --> 00:03:20,620
scheduling queue that has run on it before. And therefore,

62
00:03:20,620 --> 00:03:23,820
if it schedules any one of those threads though all

63
00:03:23,820 --> 00:03:26,860
of those threads are not going to find any of

64
00:03:26,860 --> 00:03:29,880
their working set in the cache of the processor.

65
00:03:29,880 --> 00:03:31,870
And therefore the processor says okay, now let me

66
00:03:31,870 --> 00:03:35,630
just spin my wheels for a while, not schedule anything.

67
00:03:35,630 --> 00:03:38,670
It is likely that a thread that has its

68
00:03:38,670 --> 00:03:42,580
cache content in that processor becomes runable again. And

69
00:03:42,580 --> 00:03:45,220
then you can schedule that, and that might be

70
00:03:45,220 --> 00:03:48,510
a win, in terms of performance. So in other words,

71
00:03:48,510 --> 00:03:51,110
procrastination may help boost performance. We saw that

72
00:03:51,110 --> 00:03:54,800
already in the synchronization algorithms where we talked about

73
00:03:54,800 --> 00:03:58,460
inserting delays in the scheduling algorithm in order to

74
00:03:58,460 --> 00:04:00,590
reduce the amount of contention in the connection of

75
00:04:00,590 --> 00:04:03,070
the network. It's the same sort of principle. Often

76
00:04:03,070 --> 00:04:07,390
times you'll see in system design, procrastination actually helps

77
00:04:07,390 --> 00:04:11,360
in boosting performance. It helps in the synchronizational rhythms,

78
00:04:11,360 --> 00:04:13,580
it helps in scheduling and later on when we

79
00:04:13,580 --> 00:04:15,810
talk about file systems you'll see that it

80
00:04:15,810 --> 00:04:17,579
helps in the design of file systems also.
