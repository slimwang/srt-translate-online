1
00:00:00,090 --> 00:00:03,590
Now that our model is built, let's examine how well it performs.

2
00:00:03,590 --> 00:00:05,910
There are many ways to evaluate models, but

3
00:00:05,910 --> 00:00:08,950
the bottom line is to evaluate predictive accuracy.

4
00:00:08,950 --> 00:00:12,700
If our model cannot generalize to instances it has not seen,

5
00:00:12,700 --> 00:00:14,990
in most cases it is not a very useful model.

6
00:00:14,990 --> 00:00:18,840
First, we'll evaluate our model on both a training set and a test set.

7
00:00:18,840 --> 00:00:22,550
On the training data, our model produced a mean squared error of 32.87,

8
00:00:22,550 --> 00:00:25,259
and an R squared of 0.072.

9
00:00:25,259 --> 00:00:29,700
We can also run this cell to visualize the performance of our model.

10
00:00:29,700 --> 00:00:33,320
The green line is our actual interselection times of Starburst.

11
00:00:33,320 --> 00:00:36,640
The blue line represents our predicted interselection time.

12
00:00:36,640 --> 00:00:38,830
Now, we can see a couple of things in this plot.

13
00:00:38,830 --> 00:00:43,240
First, the prediction is missing the occasional bursts and drops in demand.

14
00:00:43,240 --> 00:00:45,520
Second, it seems unnecessarily wiggly.

15
00:00:45,520 --> 00:00:48,580
It's clear that we must return to a choice that we made earlier to

16
00:00:48,580 --> 00:00:50,550
improve the performance of our model.

17
00:00:50,550 --> 00:00:54,080
Let's continue adding to our diagram on the right side over here.

18
00:00:54,080 --> 00:00:57,050
It's clear that we must return to a choice we made earlier to

19
00:00:57,050 --> 00:00:59,020
improve the performance of our model.

20
00:00:59,020 --> 00:01:03,150
For example, we might want to revisit the feature selection phase.

21
00:01:03,150 --> 00:01:06,880
Or we might want to switch to a different model to use the same features.

22
00:01:06,880 --> 00:01:10,620
The highly wiggly behavior of our regression function suggests that our

23
00:01:10,620 --> 00:01:12,610
model suffers from overfitting.

24
00:01:12,610 --> 00:01:15,770
Let's try to address this by returning to the question phase and

25
00:01:15,770 --> 00:01:19,270
reducing our feature set to the top three performing features.

26
00:01:19,270 --> 00:01:22,950
Specifically, we will update our statistical inference problem

27
00:01:22,950 --> 00:01:26,360
from this expression to this expression in which we

28
00:01:26,360 --> 00:01:31,070
only use the interselection time of Airheads, Hershey's, and Kit Kat.

29
00:01:31,070 --> 00:01:34,150
Let's add a new Q node to the tree to reflect our update.
