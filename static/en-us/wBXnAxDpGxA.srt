1
00:00:00,833 --> 00:00:06,866
The first question is true. There exists at least one environment in which every agent is rational.

2
00:00:06,867 --> 00:00:11,366
Take an environment where the actions have no effect on the performance whatsoever.

3
00:00:11,367 --> 00:00:18,599
So any agent that acts in any possible way will be the same performance, and it'll be rational, it'll be the optimal one.

4
00:00:18,600 --> 00:00:26,399
Second one is also true. For every agent, there exists at least one environment in which the agent is rational.

5
00:00:26,400 --> 00:00:37,232
So an agent generates action sequences, and just make an environment that pre-guesses those actions, and this agent will be optimal in this environment.

6
00:00:37,233 --> 00:00:43,399
You can also use the example from the first question here, an environment where the actions have no effect.

7
00:00:43,400 --> 00:00:48,266
And yes, for the specific environment I just gave you, the agent will actually be rational.

8
00:00:48,267 --> 00:00:55,532
The third one is also true. It turns out a table lookup reflex agent would have to have a huge table to cover every possible

9
00:00:55,533 --> 00:01:02,799
observation in the sliding tile 15 puzzle. That's much better with a planning agent, so it tends to require much less memory

10
00:01:02,800 --> 00:01:06,266
than pre-caching every possible situation.

11
00:01:06,267 --> 00:01:13,932
And the final one is false. It turns out that you can actually pre-cache the optimal action in every possible situation.

12
00:01:13,933 --> 00:01:22,366
So a table lookup reflex agent might be optimal, it might be rational, but as a result, a planning agent will not always do better;

13
00:01:22,367 --> 00:01:25,267
It might actually do just as good.
