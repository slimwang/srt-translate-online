1
00:00:00,000 --> 00:00:03,000
In this question, we apply naive Bayes with Laplacian smoothing--

2
00:00:03,000 --> 00:00:05,000
the same as we have learned in class.

3
00:00:05,000 --> 00:00:11,000
We have now 2 classes of movies. One is called "old" and one is called "new."

4
00:00:11,000 --> 00:00:15,000
There are titles in here. There's three old movies--Top Gun, Shy People, Top Hat.

5
00:00:15,000 --> 00:00:18,000
Two new movies--Top Gear, Gun Shy.

6
00:00:18,000 --> 00:00:24,000
Use Laplacian smoothing with k=1 to compute the probability of a movie being old--

7
00:00:24,000 --> 00:00:28,000
this is a prior probability, which is just based on class counts--

8
00:00:28,000 --> 00:00:34,000
the probability of the word "top" as a title word in the class of old movies,

9
00:00:34,000 --> 00:00:37,000
and the probability that a new movie that we look at--

10
00:00:37,000 --> 00:00:40,000
by new I mean a movie we've never seen before--

11
00:00:40,000 --> 00:00:45,000
that is called "top," the probability this movie that corresponds

12
00:00:45,000 --> 00:00:48,000
to the old movie class with the new movie class.

13
00:00:48,000 --> 00:00:51,000
I recommend you use a single dictionary for smoothing,

14
00:00:51,000 --> 00:00:55,000
so look at all the words and see how large the dictionary is.

15
00:00:55,000 --> 00:00:57,000
Top occurs here in two different ways.

16
00:00:57,000 --> 00:01:01,000
One is a word over here, but one also is a movie title over here.

17
00:01:01,000 --> 00:01:05,000
Don't pay too much attention to it, just don't get confused by it.

18
00:01:05,000 --> 99:59:59,999
Again, use Laplacian smoothing with k=1.
