1
00:00:00,033 --> 00:00:01,918
Now you know what this is really useful for?

2
00:00:01,918 --> 00:00:05,497
Sometimes you need to perform a computation on a really big hunk of data,

3
00:00:05,497 --> 00:00:08,653
maybe so big that it won't even fit into the GPU memory.

4
00:00:08,653 --> 00:00:14,176
No problem, you say. I'll break up the data into chunks that will fit on GPU memory.

5
00:00:14,176 --> 00:00:19,763
I'll copy each chunk over, do my processing, and then copy each chunk back.

6
00:00:19,763 --> 00:00:22,938
Then I'll do the same thing with the next chunk and so on.

7
00:00:22,938 --> 00:00:26,236
And this will work fine, and it will get the job done.

8
00:00:26,236 --> 00:00:31,310
But the problem is if this is a high-end GPU, it can easily have several gigabytes of memory.

9
00:00:31,310 --> 00:00:36,046
And so these copy operations where you're copying several gigabytes of data,

10
00:00:36,046 --> 00:00:41,115
enough to fill the GPU memory, do your processing, and then copying several gigabytes of data back,

11
00:00:41,115 --> 00:00:43,629
these copy operations can end up taking a significant amount of the time

12
00:00:43,629 --> 00:00:45,275
of your total computation.

13
00:00:45,275 --> 00:00:46,968
You see our problem.

14
00:00:46,968 --> 00:00:51,194
If this is the timeline, we spend some time copying, then we spend some time processing,

15
00:00:51,194 --> 00:00:55,399
then we spend some time copying back, and the process repeats.

16
00:00:55,399 --> 00:00:58,357
So here's where asynchronous copies can come to the rescue.

17
00:00:58,357 --> 00:01:02,777
Instead, we can break up our data into chunks that are half the size

18
00:01:02,777 --> 00:01:06,570
and we can do an asynchronous copy, filling half the GPU.

19
00:01:06,570 --> 00:01:10,968
Then we can launch some kernels on the GPU to start processing that data

20
00:01:10,968 --> 00:01:16,113
and immediately do another asynchronous copy, filling the rest of the GPU data,

21
00:01:16,113 --> 00:01:19,361
and immediately start processing that data.

22
00:01:19,361 --> 00:01:22,301
When the first chunk of data completes, we'll copy it back

23
00:01:22,301 --> 00:01:28,036
and start copying the next half size chunk of data, all while this one is still completing.

24
00:01:28,036 --> 00:01:29,378
So you get the idea.

25
00:01:29,378 --> 00:01:31,971
We're going to copy over half the data at a time

26
00:01:31,971 --> 00:01:36,112
and immediately start processing it while we copy the next half of the data.

27
00:01:36,112 --> 00:01:38,271
Now the timeline looks like this.

28
00:01:38,271 --> 00:01:45,072
And the important point is that we're managing to overlap data transfers and computation.
