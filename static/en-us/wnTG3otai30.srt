1
00:00:00,430 --> 00:00:02,670
The question is why map reduce is

2
00:00:02,670 --> 00:00:05,600
a programming framework for big data applications.

3
00:00:05,600 --> 00:00:09,310
It turns out that several processing steps

4
00:00:09,310 --> 00:00:12,907
in giant-scale services are expressible as map

5
00:00:12,907 --> 00:00:15,790
reduce. For example, let's say that you're

6
00:00:15,790 --> 00:00:19,610
looking for seat availability for selected dates

7
00:00:19,610 --> 00:00:22,780
to selected destinations on different airlines. That

8
00:00:22,780 --> 00:00:25,940
can be expressed as a map reduce computation.

9
00:00:25,940 --> 00:00:29,090
Let's say you want to access frequency of

10
00:00:29,090 --> 00:00:32,460
the URLs on the website that you've designed.

11
00:00:32,460 --> 00:00:34,340
That can be quoted up as a map

12
00:00:34,340 --> 00:00:37,900
reduce application. Let's say you want to create. Word

13
00:00:37,900 --> 00:00:42,380
indexes to facilitate document searches on the web.

14
00:00:42,380 --> 00:00:44,070
That can be coded up as a map

15
00:00:44,070 --> 00:00:47,210
reduce application. Or let's say that you want

16
00:00:47,210 --> 00:00:51,650
to do ranking of pages. When a user is

17
00:00:51,650 --> 00:00:54,300
doing a search, how to present present the

18
00:00:54,300 --> 00:00:58,090
search results May depend on the popularity of pages

19
00:00:58,090 --> 00:00:59,660
and that is what is often referred to as

20
00:00:59,660 --> 00:01:02,650
page ranking. So if page ranking has to be

21
00:01:02,650 --> 00:01:05,550
done for all the documents that is another

22
00:01:05,550 --> 00:01:07,980
application that can be [UNKNOWN] up as a map-reduce

23
00:01:07,980 --> 00:01:12,370
application. The list goes on. All such examples that

24
00:01:12,370 --> 00:01:16,770
are mentioned share some common property. They're embarrassingly parallel,

25
00:01:16,770 --> 00:01:19,890
and they're common in giant-scale services. And all

26
00:01:19,890 --> 00:01:22,400
of them tend to work on big data

27
00:01:22,400 --> 00:01:26,030
sets. Therefore there is plenty of opportunity for

28
00:01:26,030 --> 00:01:30,040
taking advantage of the computation resources that are

29
00:01:30,040 --> 00:01:33,520
available in a data center. And all such

30
00:01:33,520 --> 00:01:37,220
applications need domain expertise in terms of what

31
00:01:37,220 --> 00:01:39,850
to do with the data. Which is expressible

32
00:01:39,850 --> 00:01:42,600
as a map function and a reduce function, and

33
00:01:42,600 --> 00:01:45,120
this is the only thing that is required

34
00:01:45,120 --> 00:01:47,580
of the domain expert to provide to the programming

35
00:01:47,580 --> 00:01:50,760
system, because that is domain expertise that lives

36
00:01:50,760 --> 00:01:54,380
with the app developer. So here is another example

37
00:01:54,380 --> 00:01:57,110
of how an application may be structured as

38
00:01:57,110 --> 00:02:00,380
a map_reduce application. And in this case, I'm showing

39
00:02:00,380 --> 00:02:03,990
you a page ranking application that is, I'm

40
00:02:03,990 --> 00:02:07,960
interested in knowing what is the popularity of different

41
00:02:07,960 --> 00:02:14,130
URLs that occur in a document corpus. So the keyspace that is input to this

42
00:02:14,130 --> 00:02:19,300
application is a set of URLs. And the key value pair that is coming into each

43
00:02:19,300 --> 00:02:26,080
of the mapper is a source URL and the contents of that web page that corresponds

44
00:02:26,080 --> 00:02:29,020
to this particular URL. So what this mapper

45
00:02:29,020 --> 00:02:33,000
is doing is, in the given page defined

46
00:02:33,000 --> 00:02:38,780
by this URL the contents of which is the input to this mapper it is looking for

47
00:02:38,780 --> 00:02:44,350
different targets. Maybe it is looking for a particular URL target one, another

48
00:02:44,350 --> 00:02:50,390
URL target two, and so on, target N, and that's what each of these mappers are

49
00:02:50,390 --> 00:02:58,450
doing. So the keyspace that is output from the mapper is unique target names.

50
00:02:58,450 --> 00:03:00,400
So the keyspace that is output from the

51
00:03:00,400 --> 00:03:06,000
mapper is unique, target URLs and, the value

52
00:03:06,000 --> 00:03:11,840
is the URL in which it was actually phoned. So the corpus of input URLs it is

53
00:03:11,840 --> 00:03:14,490
taking, and saying well, in this particular URL

54
00:03:14,490 --> 00:03:16,530
I phoned this target. If it did. It

55
00:03:16,530 --> 00:03:19,770
is emitting that this target was found in

56
00:03:19,770 --> 00:03:24,150
a particular URL. And this reducer is going to get

57
00:03:24,150 --> 00:03:26,680
all the hits for a particular target that

58
00:03:26,680 --> 00:03:30,720
was found in the input corpus of URLs. So

59
00:03:30,720 --> 00:03:33,730
all the mappers they're going to send their results to

60
00:03:33,730 --> 00:03:37,390
this reducer if they found in the input -

61
00:03:37,390 --> 00:03:40,620
Surl the target, target 1, if they did,

62
00:03:40,620 --> 00:03:42,830
they are going to send their results to this

63
00:03:42,830 --> 00:03:46,790
reducer. Similarly if they found target n, each of

64
00:03:46,790 --> 00:03:49,720
these mappers are going to send this reducer that

65
00:03:49,720 --> 00:03:52,380
in the input URL they found this target

66
00:03:52,380 --> 00:03:54,920
n and the job of the reducer [INAUDIBLE] Is

67
00:03:54,920 --> 00:03:58,870
once again aggregation, and you have as many reducers

68
00:03:58,870 --> 00:04:01,940
as the number of unique targets you're trying to

69
00:04:01,940 --> 00:04:05,030
identify in the input dataset. Very similar to the

70
00:04:05,030 --> 00:04:08,510
previous application that we went over. So the output

71
00:04:08,510 --> 00:04:11,460
of the reducer is going to be the specific

72
00:04:11,460 --> 00:04:15,860
target that this guy has been asked to accumulate.

73
00:04:15,860 --> 00:04:22,670
And, a source list, meaning all the source pages in which this particular target

74
00:04:22,670 --> 00:04:27,700
was found. So each of these reduces is going to find the number of times a

75
00:04:27,700 --> 00:04:30,690
particular URL is found in the input

76
00:04:30,690 --> 00:04:34,800
corpus of webpages that came into the system

77
00:04:34,800 --> 00:04:41,370
as a whole. For instance, if I wanted to find out how many times my webpage

78
00:04:41,370 --> 00:04:44,470
appears in the universal web pages all over

79
00:04:44,470 --> 00:04:47,050
the world, we can take the entire corpus of

80
00:04:47,050 --> 00:04:49,800
web page available in the universals input, and the

81
00:04:49,800 --> 00:04:53,390
map that's we're going to look for occurence of my

82
00:04:53,390 --> 00:04:55,840
web page in each one of those input web

83
00:04:55,840 --> 00:04:58,660
pages. And if they find that, they're going to

84
00:04:58,660 --> 00:05:01,980
send it to this reducer and if target one

85
00:05:01,980 --> 00:05:06,420
corresponds to my web page then this reducer is

86
00:05:06,420 --> 00:05:09,410
going to say, okay, show his webpage, was found

87
00:05:09,410 --> 00:05:12,380
in this list of source webpages all over the

88
00:05:12,380 --> 00:05:15,670
Universe. That in a sense gives a rank for.

89
00:05:15,670 --> 00:05:18,210
That particular web page that we're looking at. So

90
00:05:18,210 --> 00:05:21,440
we're able to rank the target web pages 1

91
00:05:21,440 --> 00:05:25,350
through n based on the number of source web

92
00:05:25,350 --> 00:05:29,460
pages that contain that particular target. And that's what

93
00:05:29,460 --> 00:05:31,810
page ranking is all about. So I'm giving you

94
00:05:31,810 --> 00:05:34,830
yet another example of how This map

95
00:05:34,830 --> 00:05:39,170
reduce functionality can be applied for an application

96
00:05:39,170 --> 00:05:44,210
such as page ranking. All the heavy lifting that needs to be done, in terms of

97
00:05:44,210 --> 00:05:47,420
instantiating the number of mappers, instantiating the

98
00:05:47,420 --> 00:05:50,930
number of reducers, The data movement between the

99
00:05:50,930 --> 00:05:54,180
mappers and the reducers, all of those chores,

100
00:05:54,180 --> 00:05:57,830
are taken care of by the programming environment.

101
00:05:57,830 --> 00:05:59,960
All that the domain expert had to do was

102
00:05:59,960 --> 00:06:03,000
to write the map and reduce function that is unique

103
00:06:03,000 --> 00:06:07,150
to particular specifics of his application. The rest of

104
00:06:07,150 --> 00:06:10,940
the heavy lifting is all done by the programming framework.
