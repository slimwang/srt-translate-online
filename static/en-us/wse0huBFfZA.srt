1
00:00:00,190 --> 00:00:05,580
So now let's look at branch prediction accuracy and how it affect performance.

2
00:00:05,580 --> 00:00:12,680
Our CPI can be written as one, which is the CPI we get with ideal pipe lining,

3
00:00:12,680 --> 00:00:17,975
plus the cycles we add on average per instruction because of branch

4
00:00:17,975 --> 00:00:23,830
mis-predictions. And that can be written as how often we have missed predictions

5
00:00:23,830 --> 00:00:29,040
times the penalty we pay in terms of cycles every time we have

6
00:00:29,040 --> 00:00:34,160
a missed prediction. Note that this part is determined by predictor accuracy.

7
00:00:34,160 --> 00:00:37,250
It really says how often do we mispredict.

8
00:00:37,250 --> 00:00:42,420
This part is determined by our pipeline. Where in the pipeline we figure out

9
00:00:42,420 --> 00:00:48,230
that we have mispredicted. That's approximately how many cycles we pay.

10
00:00:48,230 --> 00:00:52,490
Let's look at a more specific example. Let's look at the processor that

11
00:00:52,490 --> 00:00:57,340
resolves branches in its third stage of the pipeline. And at the processor that

12
00:00:57,340 --> 00:01:02,200
resolves branches in its tenth stage of the pipeline. This is actually much

13
00:01:02,200 --> 00:01:07,310
closer to what modern processors do. Lets also look at different accuracies for

14
00:01:07,310 --> 00:01:11,850
predictors. We will look at the predictor that is 50% accurate for

15
00:01:11,850 --> 00:01:17,690
branches and 100% accurate for all other instructions.

16
00:01:17,690 --> 00:01:21,690
And we will look at the predictor that ID 90% accurate for

17
00:01:21,690 --> 00:01:26,580
branches and 100% accurate for all other instructions and in all of

18
00:01:26,580 --> 00:01:31,780
this we will be assuming that about 20% of all instructions are branches.

19
00:01:31,780 --> 00:01:37,370
This is pretty common in programs. Now, let's compute our CPIs.

20
00:01:37,370 --> 00:01:43,815
here we have a CPI of 1 plus how many mispredictions did we get per instruction.

21
00:01:43,815 --> 00:01:50,400
We get 50% this prediction for branches.

22
00:01:50,400 --> 00:01:57,480
So we get 0.5 of branches are mis-predicted, but branches are only 0.2 of

23
00:01:57,480 --> 00:02:03,070
all instructions. So these two really are the mis-predictions per instruction,

24
00:02:03,070 --> 00:02:08,250
it's really the mis-predictions per branch times branches per instruction and

25
00:02:08,250 --> 00:02:13,730
this is multiplied by the penalty that we get per misprediction. If we resolve

26
00:02:13,730 --> 00:02:19,310
branches in the third stage at that time we have two stages of the pipeline

27
00:02:19,310 --> 00:02:25,585
where wrong stuff is already fetched. So the penalty will be two cycles.

28
00:02:25,585 --> 00:02:28,960
Note that it will resolve the branch in the first stage, then there would be

29
00:02:28,960 --> 00:02:33,710
no penalty because next cycle we can fetch the correct instruction. So

30
00:02:33,710 --> 00:02:38,850
branch is being resolved in some stage means really that we pay one cycle less

31
00:02:38,850 --> 00:02:43,890
than that in penalties. And we get an overall CPI of 1.2 here.

32
00:02:45,080 --> 00:02:49,650
If we resolve the branches in the tenth stage, this part is the same,

33
00:02:49,650 --> 00:02:54,780
the accuracy of the predictor and the frequency of branches, but the penalty now

34
00:02:54,780 --> 00:03:01,540
would be nine cycles. So we have 1 plus 0.5 times 0.2

35
00:03:01,540 --> 00:03:08,620
times 9 in this case for the overall CPI of 1.9.

36
00:03:08,620 --> 00:03:13,980
This is a significantly worse CPI than we were getting here. Now let's look at

37
00:03:13,980 --> 00:03:20,740
the more accurate branch prediction. Now what we have is 1 plus mispredictions

38
00:03:20,740 --> 00:03:26,990
per instruction are going to be how many mispredictions we have per branch.

39
00:03:26,990 --> 00:03:32,851
We had 90% accurate, that means we have 10% mispredictions times

40
00:03:32,851 --> 00:03:37,910
0.2 because not all instructions are branches, times 2,

41
00:03:37,910 --> 00:03:43,480
which is our penalty. And we add that with 1.04, so

42
00:03:43,480 --> 00:03:48,380
this is a significant improvement from a more accurate predictor.

43
00:03:48,380 --> 00:03:55,126
Let's look now at this processor. Here we have 1 plus 0.1 times

44
00:03:55,126 --> 00:04:00,920
0.2 times 9, and when we compute this,

45
00:04:00,920 --> 00:04:06,830
we get 1.18. What we can conclude from this, is that a better branch

46
00:04:06,830 --> 00:04:12,770
vector will help us regardless of whether we have a shallow or a deep pipeline,

47
00:04:12,770 --> 00:04:18,279
but the amount of help from a better predictor changes depending on

48
00:04:18,279 --> 00:04:24,200
how deep the pipeline is. Here we have a speed up of 1.15 when

49
00:04:24,200 --> 00:04:30,040
we go from worse to better predictor in a shallow pipeline, but

50
00:04:30,040 --> 00:04:35,060
here we have a speed up of 1.61 when we go from the same worse

51
00:04:35,060 --> 00:04:40,020
predictor to the same better predictor in a deeper pipeline. As you can see,

52
00:04:40,020 --> 00:04:45,440
the deeper the pipeline, the more dependent it is on having a good predictor for

53
00:04:45,440 --> 00:04:49,710
good performance. And that is really why research in

54
00:04:49,710 --> 00:04:54,080
branch vectors continues to this day, although our predictors and

55
00:04:54,080 --> 00:04:59,690
now pretty good. They're significantly better than 90% accurate for branches.

56
00:04:59,690 --> 00:05:05,610
However, our pipelines are deep, so we still benefit from further improvements.
