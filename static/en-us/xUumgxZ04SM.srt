1
00:00:00,008 --> 00:00:03,050
Okay so uh,we've taking a fair amount of load off our

2
00:00:03,050 --> 00:00:06,450
database. Now if we were to go through that whole solution,

3
00:00:06,450 --> 00:00:09,390
we'd only be doing database right and we'd very rarely be

4
00:00:09,390 --> 00:00:11,490
doing a database read at all. And this is a big improvement

5
00:00:11,490 --> 00:00:14,600
over doing a database read on every page view. So lets

6
00:00:14,600 --> 00:00:16,980
go back to what our request does. And every request remember

7
00:00:16,980 --> 00:00:21,110
we, we process the request. You know, this was HTTP, URLs

8
00:00:21,110 --> 00:00:26,110
and all that stuff. We did the DB query, the database query.

9
00:00:26,110 --> 00:00:29,980
We collated the results, which for you know, ASCII Chan

10
00:00:29,980 --> 00:00:32,580
or the blog is, there's not really much involved in

11
00:00:32,580 --> 00:00:35,320
that at all. And then, we rendered the HTML. So,

12
00:00:35,320 --> 00:00:37,560
we've improved the database query, but what if we want to improve

13
00:00:37,560 --> 00:00:40,930
these other, other pieces. Yeah, we can use caching to

14
00:00:40,930 --> 00:00:44,720
render HTML. That's definitely a technique there, and we can actually

15
00:00:44,720 --> 00:00:47,380
use another technique for handling all three of these parts

16
00:00:47,380 --> 00:00:51,280
of the requests, which is adding additional app service and this

17
00:00:51,280 --> 00:00:55,230
looks something like this. To date conceptually we've basically had

18
00:00:55,230 --> 00:00:58,280
one program running, that handles all of our requests in

19
00:00:58,280 --> 00:01:00,700
your blog and an ASCII Chan. We've got the simple

20
00:01:00,700 --> 00:01:04,750
program you know, requests come in. Responses come back out, but

21
00:01:04,750 --> 00:01:08,320
if so many requests that one machine can't handle it.

22
00:01:08,320 --> 00:01:10,739
We can do is we can add multiple machines, to take

23
00:01:10,739 --> 00:01:13,030
up some of the load. So all of these extra

24
00:01:13,030 --> 00:01:16,960
requests can go to all of these machines, and these machines

25
00:01:16,960 --> 00:01:21,300
maybe interacting with the database. They may not be. Presumably

26
00:01:21,300 --> 00:01:24,450
they have their little caches that we just implemented that

27
00:01:24,450 --> 00:01:26,907
lives in our program and, and this helps so how

28
00:01:26,907 --> 00:01:30,920
do we get requests to multiple machines. Well, there's a piece

29
00:01:30,920 --> 00:01:34,570
of technology that sits between the user and all of

30
00:01:34,570 --> 00:01:37,760
your app servers called a load balancer. And this is

31
00:01:37,760 --> 00:01:40,230
a special machine, it's a physical machine just like your

32
00:01:40,230 --> 00:01:42,100
app server might be or just like your database server might

33
00:01:42,100 --> 00:01:45,280
be, that's optimized for doing one this, for spreading

34
00:01:45,280 --> 00:01:49,950
requests across multiple machines. So, what happens is, this load

35
00:01:49,950 --> 00:01:52,620
balancer has a list of all of the app servers

36
00:01:52,620 --> 00:01:56,360
that, that are in existence, and requests come in from

37
00:01:56,360 --> 00:01:58,880
the outside world, many, many, many of them. And the

38
00:01:58,880 --> 00:02:01,500
load balancer decides which app server to send the request

39
00:02:01,500 --> 00:02:04,420
to. Send one here, then send one here. Then send

40
00:02:04,420 --> 00:02:07,020
one here. And it can keep going to that process.

41
00:02:07,020 --> 00:02:09,030
And the reason this load balancer can handle all this

42
00:02:09,030 --> 00:02:11,360
traffic while the app servers can't, is the low balancer isn't

43
00:02:11,360 --> 00:02:15,740
doing anything other than taking in the request, choosing a server,

44
00:02:15,740 --> 00:02:20,080
and forwarding the connection along. It doesn't have to parse HTTP

45
00:02:20,080 --> 00:02:23,400
or it may only parse, parse minimal HTTP. It doesn't have

46
00:02:23,400 --> 00:02:25,530
to, it's not doing database queries, it's not rendering HTML, it's

47
00:02:25,530 --> 00:02:30,190
not, going to the cache it's, it's doing almost nothing at

48
00:02:30,190 --> 00:02:32,780
all, other than deciding which server to send a request to.

49
00:02:32,780 --> 00:02:35,850
You've probably won't ever have to write one of these, but it's

50
00:02:35,850 --> 00:02:38,530
good to know how they work. And when you're using App Engine,

51
00:02:38,530 --> 00:02:42,580
Google kind of does all of this for you. They'll automatically create new

52
00:02:42,580 --> 00:02:46,600
servers running your program and and scale. You can actually go into the

53
00:02:46,600 --> 00:02:50,130
app engine admin page and see how many servers they are using

54
00:02:50,130 --> 00:02:52,790
to host your app. Which is pretty cool. Normally this is a

55
00:02:52,790 --> 00:02:55,370
really challenging thing, and not knowing how to do it the first

56
00:02:55,370 --> 00:02:57,700
time, this took me a little while to figure out when we were

57
00:02:57,700 --> 00:03:01,020
scaling Reddit. That doesn't mean I'm not going to make you understand these

58
00:03:01,020 --> 00:03:04,130
things a little bit deeper. So, there are a couple algorithms a

59
00:03:04,130 --> 00:03:07,800
load balancer can use to determine which server to send traffic to.

60
00:03:07,800 --> 00:03:11,020
The simplest one is probably just to randomly choose a server. Now,

61
00:03:11,020 --> 00:03:13,930
a request comes into the load balancer and the load balancer just

62
00:03:13,930 --> 00:03:17,290
picks a server and sends a request there which will, you know,

63
00:03:17,290 --> 00:03:20,420
probably work pretty well. You know, over, over time, if you have

64
00:03:20,420 --> 00:03:22,890
enough requests, each server should get about the same amount of load.

65
00:03:22,890 --> 00:03:25,890
Other approach is round robin, and round robin just means a load

66
00:03:25,890 --> 00:03:29,260
balancer will choose one server at the time. You know, first this guy,

67
00:03:29,260 --> 00:03:32,270
then this guy, then this guy, then this guy, you know, just,

68
00:03:32,270 --> 00:03:35,740
in order. That's also a fairly simple algorithm. And then some of the

69
00:03:35,740 --> 00:03:38,690
balances are really smart and they know what the load is on

70
00:03:38,690 --> 00:03:42,160
each server, how many requests are outstanding at each server, and it may

71
00:03:42,160 --> 00:03:44,970
use some sort of load based algorithm just so you know. This guy's

72
00:03:44,970 --> 00:03:48,080
already handling like five requests and this guy's not doing anything so let's

73
00:03:48,080 --> 00:03:50,780
send, you know, future requests here until, you know, things

74
00:03:50,780 --> 00:03:53,640
even out. There's lots of approaches to doing this. What

75
00:03:53,640 --> 00:03:55,230
I'm going to ask you to do now in the form

76
00:03:55,230 --> 00:03:59,670
of a quiz is implement a basic round robin algorithm.
