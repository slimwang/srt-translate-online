1
00:00:00,210 --> 00:00:02,950
Another heavy-duty topic which is good to know about

2
00:00:02,950 --> 00:00:05,670
is edge caching. To describe this, let's look at

3
00:00:05,670 --> 00:00:09,150
the information flow for your App Engine application. First

4
00:00:09,150 --> 00:00:11,760
of all, users that want to use your application are

5
00:00:11,760 --> 00:00:15,670
connected to their internet service provider. This provider connects

6
00:00:15,670 --> 00:00:18,576
to Google data center. After the DNS lookup has

7
00:00:18,576 --> 00:00:22,036
determined that your application is hosted by Google, Google

8
00:00:22,036 --> 00:00:25,693
then identifies the data center where your App Engine application

9
00:00:25,693 --> 00:00:28,304
run, and starts talking to the App Engine front

10
00:00:28,304 --> 00:00:30,939
end. If the content is dynamic, the App Engine front

11
00:00:30,939 --> 00:00:34,350
end determines the instance that should manage the request.

12
00:00:34,350 --> 00:00:37,560
So these are your App Engine instances that run your

13
00:00:37,560 --> 00:00:40,890
application code. But if the request is for static

14
00:00:40,890 --> 00:00:44,880
content, for example images or static HTML, the front end

15
00:00:44,880 --> 00:00:48,370
can retrieve it directly from the static servers. And in

16
00:00:48,370 --> 00:00:51,960
both cases, the response is returned back to the user.

17
00:00:51,960 --> 00:00:54,350
So this is a good architecture. But as it looks

18
00:00:54,350 --> 00:00:57,000
right now, all the requests have to be sent to

19
00:00:57,000 --> 00:01:00,230
the data center, which hosts your App Engine application. It

20
00:01:00,230 --> 00:01:02,850
would be much better if more content could be served

21
00:01:02,850 --> 00:01:06,160
directly by this data center. First of all, it would

22
00:01:06,160 --> 00:01:09,640
ease the load on this data center, but more importantly,

23
00:01:09,640 --> 00:01:12,340
since it's closer to the users, the response would be

24
00:01:12,340 --> 00:01:16,150
delivered faster. This is exactly what edge caching is all about.

25
00:01:17,210 --> 00:01:19,620
Edge caching is a cache that sits in the

26
00:01:19,620 --> 00:01:22,840
data center closest to the user. So whenever there is

27
00:01:22,840 --> 00:01:25,290
a request, the result can be served directly from

28
00:01:25,290 --> 00:01:27,990
the cache if it's available there, rather than going through

29
00:01:27,990 --> 00:01:31,220
data center 2. That means less load on data

30
00:01:31,220 --> 00:01:34,700
center 2 in your application, and faster responses to your

31
00:01:34,700 --> 00:01:38,650
users. A win-win. So the question is, then, what

32
00:01:38,650 --> 00:01:41,070
do you need to think about to use edge caching?

33
00:01:42,230 --> 00:01:45,100
Well, there are two ways. The first one is

34
00:01:45,100 --> 00:01:49,070
to set the cache-control header, in the HTTP response. This

35
00:01:49,070 --> 00:01:51,490
should only be done if a subsequent request of this

36
00:01:51,490 --> 00:01:54,730
kind would return the same result. The second option is

37
00:01:54,730 --> 00:01:58,010
to define as much content as possible as static.

38
00:01:58,010 --> 00:02:00,900
Since static content does not change, it's great for edge

39
00:02:00,900 --> 00:02:04,892
caching. You can define which content is static through configuration

40
00:02:04,892 --> 00:02:07,356
files. A good opportunity for you to look at the

41
00:02:07,356 --> 00:02:11,190
online documentation. And remember, as most of the time

42
00:02:11,190 --> 00:02:14,180
with caching, there are no guarantees that the content will

43
00:02:14,180 --> 00:02:16,340
be cached, but when it is, it will be

44
00:02:16,340 --> 00:02:19,300
good for both your application as well as your users.
