1
00:00:00,410 --> 00:00:03,160
Here's the beauty of
the Span sync framework.

2
00:00:03,160 --> 00:00:07,410
You can analyze the work and the Span of
algorithms in almost exactly the same

3
00:00:07,410 --> 00:00:10,400
way that you do for
sequential algorithms.

4
00:00:10,400 --> 00:00:14,395
So almost everything you learned in
Algorithms 101 you get to reuse here.

5
00:00:14,395 --> 00:00:15,755
Hooray!

6
00:00:15,755 --> 00:00:18,065
Let me illustrate this by example.

7
00:00:18,065 --> 00:00:21,995
Here's pseudocode for doing a sequential
reduction using divide and conquer.

8
00:00:21,995 --> 00:00:26,635
If this were CS algorithms 101 and
we were analyzing this running time,

9
00:00:26,635 --> 00:00:31,490
we'd start by writing down a recurrence
relation and then solving the relation.

10
00:00:31,490 --> 00:00:36,270
So in this algorithm we divide the work
into two pieces and do recursive calls.

11
00:00:36,270 --> 00:00:39,630
And that translates into
a recurrence that looks like this,

12
00:00:39,630 --> 00:00:44,070
where we solve two sub-problems,
each one of half the size.

13
00:00:44,070 --> 00:00:46,760
And you can solve this recurrence
in any number of ways.

14
00:00:46,760 --> 00:00:49,180
For example,
you can use the master theorem.

15
00:00:49,180 --> 00:00:52,370
What you'll find is that
the time is linear in N.

16
00:00:52,370 --> 00:00:53,950
If you don't remember what
the master theorem is,

17
00:00:53,950 --> 00:00:56,350
we'll put a link in
the instructor's notes.

18
00:00:56,350 --> 00:00:58,640
Okay, so
what about the parallel version?

19
00:00:58,640 --> 00:01:01,480
Remember, you want to analyze work and
span.

20
00:01:01,480 --> 00:01:06,110
Now let's assume that each spawn and
sync is a constant time operation.

21
00:01:06,110 --> 00:01:09,160
It turns out, this is not
a bad assumption in practice.

22
00:01:09,160 --> 00:01:12,900
Now recall that analyzing the work
is just counting total operations.

23
00:01:12,900 --> 00:01:16,470
Therefore, if spawn and sync
are essentially constant time, then for

24
00:01:16,470 --> 00:01:19,390
the analysis,
we can effectively ignore the spawns and

25
00:01:19,390 --> 00:01:23,620
syncs and
just do the usual sequential analysis.

26
00:01:23,620 --> 00:01:26,800
So the recurrence for
work looks just like the recurrence for

27
00:01:26,800 --> 00:01:29,580
sequential execution time and
we'll get linear work.

28
00:01:29,580 --> 00:01:32,000
Hey, that's pretty neat.

29
00:01:32,000 --> 00:01:35,620
It means algorithm analysis with respect
to work is no harder than it was for

30
00:01:35,620 --> 00:01:37,580
sequential algorithms.

31
00:01:37,580 --> 00:01:39,400
Okay, what about span?

32
00:01:39,400 --> 00:01:40,490
Span is a little different.

33
00:01:40,490 --> 00:01:43,380
Let me explain this
by a simpler example.

34
00:01:44,430 --> 00:01:49,710
Now remember that a spawn creates a
branch and a dag which yields two paths.

35
00:01:49,710 --> 00:01:53,790
The critical path will be the longer
of these two paths Therefore if

36
00:01:53,790 --> 00:01:56,630
I knew the length of the path going
through A and the length of the path

37
00:01:56,630 --> 00:02:01,450
going through B, then the critical path
would just be the longer of those two.

38
00:02:01,450 --> 00:02:03,960
Mathematically, we say
the span is the maximum

39
00:02:03,960 --> 00:02:07,120
of the span going through A versus
the span going through B.

40
00:02:07,120 --> 00:02:10,197
Now for our divide and
conquer reduction,

41
00:02:10,197 --> 00:02:14,120
the span only depends
on the problem size N.

42
00:02:14,120 --> 00:02:18,280
And our cursive call solve
problems of roughly equal size.

43
00:02:18,280 --> 00:02:20,240
Therefore when we write down
the recurrence for span,

44
00:02:20,240 --> 00:02:21,860
we'll get something
that looks like this.

45
00:02:22,890 --> 00:02:28,400
So the recurrence in this case is
just a constant plus the span of n/2,

46
00:02:28,400 --> 00:02:29,720
and I'll let you solve this one.
