1
00:00:00,350 --> 00:00:04,830
When an object is rendered into an image, at each pixel, the distance from the

2
00:00:04,830 --> 00:00:09,066
object to the camera is used to compute its z depth, a value from 0 to 1. So,

3
00:00:09,066 --> 00:00:13,328
here for example, I've rendered a sphere. And at this pixel, I found that the

4
00:00:13,328 --> 00:00:17,724
depth of the sphere in 0.6. This value is then checked against the current value

5
00:00:17,724 --> 00:00:21,882
stored in the z buffer. Which you'll recall, we've initialized to all ones. If

6
00:00:21,882 --> 00:00:25,664
the object's distance is lower than the z depth value stored, the object is

7
00:00:25,664 --> 00:00:29,464
closer to the camera. And so the color of the object is then stored in the

8
00:00:29,464 --> 00:00:33,484
image's color buffer. So, in this case, the sphere's depth is clearly closer

9
00:00:33,484 --> 00:00:37,734
than the maximum value can store in the z depth. So it's visible at this point.

10
00:00:37,735 --> 00:00:42,836
Lets say we draw a cube. The cube's depth at this pixel is 0.3, which is closer

11
00:00:42,836 --> 00:00:48,354
than the 0.6 that we have storage for what the sphere did. So, since its closer,

12
00:00:48,354 --> 00:00:55,374
we use the cube's color at this pixel and replace this value, 0.3 replaces 0.6.

13
00:00:55,375 --> 00:00:59,540
Say, the last object we draw is this ground plane. At the pixel, it turns out

14
00:00:59,540 --> 00:01:04,924
the ground plane's depth is 0.8. This is higher than the current z depth 0.3.

15
00:01:04,924 --> 00:01:08,895
So, the ground plane fails, which is as it should be because the ground plane is

16
00:01:08,895 --> 00:01:13,182
obviously farther away than these two objects. The final conclusion of this

17
00:01:13,182 --> 00:01:17,854
process is that the current z depth stays at 0.3 and the color that's stored at

18
00:01:17,854 --> 00:01:22,234
the pixel, this blue cube, is indeed the color that gets displayed on the

19
00:01:22,234 --> 00:01:26,659
screen. By storing a depth at each pixel, the GPU can mindlessly keep track of

20
00:01:26,659 --> 00:01:30,762
what object is closest at any given moment. What's interesting to realize is

21
00:01:30,762 --> 00:01:34,125
that decades ago, when this idea first came up, of the z buffer, it was

22
00:01:34,125 --> 00:01:37,960
considered absurdly expensive because you had to add a big chunk of memory of z

23
00:01:37,960 --> 00:01:41,908
depth buffer that was just an outrageous amount. You'd have to add a whole mega

24
00:01:41,908 --> 00:01:45,520
byte of memory which would be outrageously expensive. So, this algorithm

25
00:01:45,520 --> 00:01:49,670
originally was a terrible idea. And memory costs came down just a tad and now

26
00:01:49,670 --> 00:01:52,812
it's the predominant way of rasterizing triangles.
