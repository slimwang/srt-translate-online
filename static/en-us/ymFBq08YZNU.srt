1
00:00:00,480 --> 00:00:03,640
This matrix vector multiply example
gives us a chance to introduce a couple

2
00:00:03,640 --> 00:00:05,055
of pseudocode shortcuts.

3
00:00:05,055 --> 00:00:09,890
The shortcuts are all based on
expressing operations on arrays

4
00:00:09,890 --> 00:00:12,060
as vector operations.

5
00:00:12,060 --> 00:00:14,160
So you see a hint of that here.

6
00:00:14,160 --> 00:00:17,430
Notice the declaration of
the temporary array t.

7
00:00:17,430 --> 00:00:20,880
I've used this,
what's called vector slicing notation.

8
00:00:20,880 --> 00:00:25,160
That is indexing with a range of values,
in this case 1 to n.

9
00:00:25,160 --> 00:00:27,740
Let's see where else we
can insert that notation.

10
00:00:27,740 --> 00:00:29,720
Let's take a look at this
inner most parfor loop.

11
00:00:29,720 --> 00:00:31,020
What's it doing?

12
00:00:31,020 --> 00:00:34,877
Well, it's basically taking a slice
of this two dimensional matrix and

13
00:00:34,877 --> 00:00:40,600
multiplying it component wise or
element wise with this vector x.

14
00:00:40,600 --> 00:00:46,060
So I can express this parfor loop in a
more compact single line of pseudocode.

15
00:00:46,060 --> 00:00:49,650
So I basically recognize that
all these objects are arrays.

16
00:00:49,650 --> 00:00:53,920
t, A sub i, and x.

17
00:00:53,920 --> 00:00:55,760
The arrays are all of length n.

18
00:00:55,760 --> 00:00:58,680
And they're all indexed
in the range 1 to n.

19
00:00:58,680 --> 00:01:02,920
Now this notation is common in
a bunch of modern languages.

20
00:01:02,920 --> 00:01:06,736
That includes Python,
Matlab and Cray Fortran.

21
00:01:06,736 --> 00:01:07,896
Cray who?

22
00:01:07,896 --> 00:01:12,590
Now if the range is the entire range of
the array object, then we can replace

23
00:01:12,590 --> 00:01:17,830
the explicate range in this case 1 to n,
with just a colon meaning all elements.

24
00:01:17,830 --> 00:01:22,215
So that will give us an even
sightly more compact notation.

25
00:01:22,215 --> 00:01:24,050
Let's go ahead and plug that in.

26
00:01:24,050 --> 00:01:26,920
And of course we're all mature enough
to see that this vector operation

27
00:01:26,920 --> 00:01:31,160
can be easily converted
into a parallel for loop.

28
00:01:31,160 --> 00:01:34,220
So when you are analyzing pseudocode
that includes these kinds of vector

29
00:01:34,220 --> 00:01:37,492
operations, just go ahead and
use the right work and span.

30
00:01:38,550 --> 00:01:43,230
So in particular, these element wise
operations will have linear work and

31
00:01:43,230 --> 00:01:44,510
logarithmic span.

32
00:01:45,550 --> 00:01:48,620
Now we'll allow ourselves to use
a second simplification which is to get

33
00:01:48,620 --> 00:01:50,870
rid of the temporary array.

34
00:01:50,870 --> 00:01:55,300
So it's understood that this element
wise product has to produce a temporary

35
00:01:55,300 --> 00:01:56,900
intermediate element wise result.

36
00:01:58,260 --> 00:02:00,230
Which we then pass to the reduce, so

37
00:02:00,230 --> 00:02:03,410
we can combine these
into a single statement.

38
00:02:03,410 --> 00:02:06,670
Again, the only subtle
thing is that this produces

39
00:02:06,670 --> 00:02:08,430
a bunch of intermediate values.

40
00:02:08,430 --> 00:02:10,710
So that may require a temporary.

41
00:02:11,840 --> 00:02:14,690
So if I ask you to
analyze storage costs,

42
00:02:14,690 --> 00:02:16,340
then you might need to
take that into account.
