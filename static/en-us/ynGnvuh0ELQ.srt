1
00:00:00,000 --> 00:00:04,000
So we now learned about fully observable environments,

2
00:00:04,000 --> 00:00:08,000
and planning in stochastic environments with MDPs

3
00:00:08,000 --> 00:00:12,000
I'd like to say a few words about partially observable environments,

4
00:00:12,000 --> 00:00:17,000
or POMDPs--which I won't go into in depth; the material is relatively complex.

5
00:00:17,000 --> 00:00:21,000
But I'd like to give you a feeling for why this is important, and what type of problems

6
00:00:21,000 --> 00:00:25,000
you can solve with this, that you could never possibly solve with MDPs.

7
00:00:25,000 --> 00:00:32,000
So, for example, POMDPs address problems of optimal exploration versus exploitation,

8
00:00:32,000 --> 00:00:35,000
where some of the actions might be information-gathering actions;

9
00:00:35,000 --> 00:00:39,000
whereas others might be goal-driven actions.

10
00:00:39,000 --> 00:00:43,000
That's not really possible in the MDPs because the state space is fully observable

11
00:00:43,000 --> 99:59:59,999
and therefore, there is no notion of information gathering.
