1
00:00:00,400 --> 00:00:02,310
Recall the reduction example.

2
00:00:02,310 --> 00:00:05,920
The work is linear, and the number
of transfers, is at least n over L.

3
00:00:05,920 --> 00:00:08,740
Now let's analyze a concrete
algorithm to see, whether or not,

4
00:00:08,740 --> 00:00:11,020
we can achieve this lower bound.

5
00:00:11,020 --> 00:00:14,840
Now here's the natural thing you would
write in the conventional RAM model.

6
00:00:14,840 --> 00:00:17,100
That is the one without the fast memory.

7
00:00:17,100 --> 00:00:20,950
It maintains an accumulator s, and
makes a sweep over all the elements,

8
00:00:20,950 --> 00:00:22,490
accumulating them.

9
00:00:22,490 --> 00:00:26,089
Now you need to modify this procedure,
to think about when to move data,

10
00:00:26,089 --> 00:00:27,630
between slow and fast memory.

11
00:00:27,630 --> 00:00:30,000
Now, the variable s is easy.

12
00:00:30,000 --> 00:00:33,870
You can just assume that it starts
locally, in the fast memory.

13
00:00:33,870 --> 00:00:36,840
It's the same way you might
treat any temporary scalar or

14
00:00:36,840 --> 00:00:40,220
local variable in your favorite
imperative programming language.

15
00:00:40,220 --> 00:00:43,660
For my pseudo code,
I've just declared s to be local.

16
00:00:43,660 --> 00:00:45,110
I'm doing that just to be clear.

17
00:00:45,110 --> 00:00:48,770
Most of the time you can ignore
these kinds of local variables.

18
00:00:48,770 --> 00:00:50,720
Now what about the array X?

19
00:00:50,720 --> 00:00:54,390
For simplicity, let's assume that
little n is, much bigger than,

20
00:00:54,390 --> 00:00:56,260
the size of fast memory.

21
00:00:56,260 --> 00:01:00,480
Let's further assume that X is
aligned,on an L word boundary.

22
00:01:00,480 --> 00:01:04,699
With these assumptions, let's transform
the program, to make slow and

23
00:01:04,699 --> 00:01:06,681
fast memory transfers explicit.

24
00:01:06,681 --> 00:01:07,563
Yikes.

25
00:01:07,563 --> 00:01:09,450
Let's start with the outer loop.

26
00:01:09,450 --> 00:01:12,810
As with the original algorithm, it steps
through the elements of the array but

27
00:01:12,810 --> 00:01:16,270
it does so,
one block of size L at a time.

28
00:01:16,270 --> 00:01:18,960
Next, there's the computation L hat.

29
00:01:18,960 --> 00:01:22,620
This mumbo jumbo just determines whether
the block that starts a position

30
00:01:22,620 --> 00:01:25,380
i is of length L, or
a little bit smaller.

31
00:01:25,380 --> 00:01:26,160
It's a detail.

32
00:01:26,160 --> 00:01:27,060
I just wanted to be clear.

33
00:01:27,060 --> 00:01:29,770
But most of the time,
we'll ignore this sort of detail.

34
00:01:29,770 --> 00:01:32,560
Next, there's
the assignment to little y.

35
00:01:32,560 --> 00:01:37,600
This is an explicit load or read,
from slow memory, to fast memory.

36
00:01:37,600 --> 00:01:42,290
Notice that it requests at most L words,
which is one block transfer.

37
00:01:42,290 --> 00:01:45,610
Now, since little y and
S are both local to fast memory,

38
00:01:45,610 --> 00:01:47,900
the processor can execute
this innermost loop.

39
00:01:48,900 --> 00:01:52,000
So what's the work in the number
of transfers for this algorithm?

40
00:01:53,000 --> 00:01:56,930
The work is just the same as this
conventional algorithm in the RAM model,

41
00:01:56,930 --> 00:01:59,240
that is, it's just theta of n.

42
00:01:59,240 --> 00:02:04,070
Here's the number of transfers, it's
just the ceiling of n over L, hopefully,

43
00:02:04,070 --> 00:02:06,450
you can see how this falls out,
very naturally,

44
00:02:06,450 --> 00:02:08,650
from the structure of the code.

45
00:02:08,650 --> 00:02:12,110
So how do these compare
to the lower bounds?

46
00:02:12,110 --> 00:02:14,350
Why they compare very well, indeed.

47
00:02:14,350 --> 00:02:18,000
Before moving on, I want to make two
remarks about what you've just done.

48
00:02:18,000 --> 00:02:22,100
First, I realize that was a lot of
painful detail to do what must seem like

49
00:02:22,100 --> 00:02:24,130
a really simple analysis.

50
00:02:24,130 --> 00:02:27,380
We will make simplifications, as we go,
but I wanted to start by just

51
00:02:27,380 --> 00:02:31,760
being clear about exactly what has to
happen under the hood in this model.

52
00:02:31,760 --> 00:02:33,140
Now, my second remark.

53
00:02:33,140 --> 00:02:35,080
Yes, I know about caches.

54
00:02:35,080 --> 00:02:39,200
They're those fast memory thingys that
the hardware manages automatically.

55
00:02:39,200 --> 00:02:42,660
In fact, there's an awesome OMSCS
class that covers their design in

56
00:02:42,660 --> 00:02:44,090
a lot of detail.

57
00:02:44,090 --> 00:02:46,920
While caches are very useful,
what you'll eventually see

58
00:02:46,920 --> 00:02:50,710
is that they aren't sufficient
to guarantee high performance.

59
00:02:50,710 --> 00:02:54,650
That is why we're discussing an explicit
model of locality, like this one.
