1
00:00:01,000 --> 00:00:02,960
Alright so, the, the whole goal of what we're

2
00:00:02,960 --> 00:00:04,760
going to add for boosting here is we're going to, we're going to

3
00:00:04,760 --> 00:00:07,400
expand on this notion of hardest examples and weighted

4
00:00:07,400 --> 00:00:09,790
mean. But before I can do that, I'm going to have

5
00:00:09,790 --> 00:00:11,770
to define a couple of terms. Okay. And you

6
00:00:11,770 --> 00:00:14,460
let me know Michael if, if these terms make sense.

7
00:00:14,460 --> 00:00:17,790
So, here's the first one. The first one is

8
00:00:17,790 --> 00:00:21,570
error. So how have we been defining error so far?

9
00:00:21,570 --> 00:00:26,370
>> Usually we take the square difference between the

10
00:00:26,370 --> 00:00:29,420
correct labels and the, what's produced

11
00:00:29,420 --> 00:00:31,650
by our classifier or regression algorithm.

12
00:00:31,650 --> 00:00:32,930
>> That's true. That is how we've been using

13
00:00:32,930 --> 00:00:36,020
error when we're thinking about regression error. How about, a

14
00:00:36,020 --> 00:00:39,500
notion of accuracy. About how good we are at,

15
00:00:39,500 --> 00:00:43,100
say, classifying examples. So let's, let's stick with classification formulas.

16
00:00:43,100 --> 00:00:44,740
>> Well, that would be the same as

17
00:00:44,740 --> 00:00:47,270
squared areas, except that it's not really meeting the

18
00:00:47,270 --> 00:00:49,070
whole powers [INAUDIBLE] area. That is to say, if

19
00:00:49,070 --> 00:00:51,790
the outputs are zeroes and ones, the squared area

20
00:00:51,790 --> 00:00:53,620
is just whether or not there's a mismatch. So

21
00:00:53,620 --> 00:00:56,620
it could just be the total number of wrong answers.

22
00:00:56,620 --> 00:00:57,720
>> Right. So, what we've been doing so

23
00:00:57,720 --> 00:01:00,430
far is counting mismatches. I like that word, mismatches.

24
00:01:00,430 --> 00:01:02,210
And we might call an error raid or

25
00:01:02,210 --> 00:01:05,610
an error percentage as the total number of mismatches

26
00:01:05,610 --> 00:01:07,920
over the total number of examples. And that

27
00:01:07,920 --> 00:01:11,370
tells us whether we're at 85% or 92%, or,

28
00:01:11,370 --> 00:01:13,100
or whatever, right? So that's what we've been doing

29
00:01:13,100 --> 00:01:16,820
so far. But implicit in that, Michael, is the

30
00:01:16,820 --> 00:01:20,600
idea that every single example is equally as important.

31
00:01:20,600 --> 00:01:23,900
So, that's not always the case. Now you might remember

32
00:01:23,900 --> 00:01:27,130
from the first talk that we had. We talked

33
00:01:27,130 --> 00:01:31,250
about distributions over examples. We said that, you know, learning

34
00:01:31,250 --> 00:01:33,530
only happens if you're training set has the same

35
00:01:33,530 --> 00:01:37,330
distribution as your future testing set. And if it doesn't,

36
00:01:37,330 --> 00:01:38,980
then all bets are off. And it's very difficult

37
00:01:38,980 --> 00:01:42,390
to talk about induction or learning. That notion of distribution

38
00:01:42,390 --> 00:01:44,850
is implicit in everything that we've been doing so far, and

39
00:01:44,850 --> 00:01:47,410
we haven't really been taking into account when we've been talking

40
00:01:47,410 --> 00:01:50,320
about error. So here's another definition of error and you tell

41
00:01:50,320 --> 00:01:51,850
me if you think it makes sense, given what we just

42
00:01:51,850 --> 00:01:55,700
said. So, this is my definition of error. So the subscript

43
00:01:55,700 --> 00:02:00,510
D, stands for distribution. So we don't know how new examples

44
00:02:00,510 --> 00:02:03,090
are being drawn, but however they're being drawn they're being drawn

45
00:02:03,090 --> 00:02:06,300
from some distribution, and I'm just going to call that distribution" D", okay?

46
00:02:06,300 --> 00:02:06,860
>> mhm

47
00:02:06,860 --> 00:02:09,639
Right. So H is our old friend the

48
00:02:09,639 --> 00:02:12,580
hypothesis. That's the specific hypothesis that our learner

49
00:02:12,580 --> 00:02:14,970
has output. That's what we think is the

50
00:02:14,970 --> 00:02:18,250
true concept, and C is whatever the true underlying

51
00:02:18,250 --> 00:02:21,770
concept is. So I'm going to define error as

52
00:02:21,770 --> 00:02:25,740
the probability, given the underlined distribution that I

53
00:02:25,740 --> 00:02:28,800
will disagree with the true concept on some

54
00:02:28,800 --> 00:02:31,590
particular instance X. Does that make sense for you?

55
00:02:31,590 --> 00:02:32,260
>> Yeah

56
00:02:32,260 --> 00:02:35,250
but I'm not seeing why that's different from number of mismatches in the

57
00:02:35,250 --> 00:02:39,750
sense that if we count mismatches on a sample drawn from D, which is

58
00:02:39,750 --> 00:02:42,660
how we would get our testing set anyway. Then I would think that would

59
00:02:42,660 --> 00:02:46,340
be you know if it's large enough a pretty good approximation of this value.

60
00:02:46,340 --> 00:02:48,590
>> So here Michael, let me give you a specific example.

61
00:02:48,590 --> 00:02:52,360
I'm going to draw four, four possible values of X. And when

62
00:02:52,360 --> 00:02:54,660
I say I'm going to draw four possible values of X, I

63
00:02:54,660 --> 00:02:56,330
mean I'm just going to put four dots on the the screen.

64
00:02:56,330 --> 00:02:56,940
>> Hm.

65
00:02:56,940 --> 00:02:58,070
>> Okay? And

66
00:02:58,070 --> 00:03:03,390
then I'm going to tell you this particular learner output a hypothesis.

67
00:03:03,390 --> 00:03:06,750
Output you know, a, a potential function that ends up getting

68
00:03:06,750 --> 00:03:09,750
the first one and the third one right, but gets the

69
00:03:09,750 --> 00:03:12,600
second and the fourth one wrong. So what's the error here?

70
00:03:12,600 --> 00:03:13,310
>> Mm.

71
00:03:13,310 --> 00:03:16,270
>> So let's just make sure that, that

72
00:03:16,270 --> 00:03:18,020
everybody's with us. Let's do this as a quiz.

73
00:03:18,020 --> 00:03:20,330
>> Okay, so let's ask the students what they

74
00:03:20,330 --> 00:03:23,620
think. So here's the question again. You've output some hypothesis

75
00:03:23,620 --> 00:03:27,270
over the four possible values of x, and it turns

76
00:03:27,270 --> 00:03:29,580
out that you get the first and the third one right,

77
00:03:29,580 --> 00:03:32,170
and you get the second and the fourth one wrong.

78
00:03:32,170 --> 00:03:34,330
If I look at it like this, what's the error rate?
