1
00:00:00,585 --> 00:00:03,620
Let's look at a few properties of the convolution method.

2
00:00:03,620 --> 00:00:08,100
One property is that basically a convolution output process of

3
00:00:08,100 --> 00:00:13,080
convoluting an image basically means that it's linear and shift invariant.

4
00:00:13,080 --> 00:00:16,390
What that primarily means is that it's the same everywhere.

5
00:00:16,390 --> 00:00:20,150
The value of the output depends on the pattern of the image neighborhood,

6
00:00:20,150 --> 00:00:22,050
not the position of the neighborhood.

7
00:00:22,050 --> 00:00:24,585
So basically it doesn't matter how we apply,

8
00:00:24,585 --> 00:00:27,800
it'll always will come up with the same answer.

9
00:00:27,800 --> 00:00:29,440
And that's an important part of it.

10
00:00:29,440 --> 00:00:31,740
Doesn't matter how much you shift the image.

11
00:00:31,740 --> 00:00:35,870
Another property that's extremely valuable is the commutative nature

12
00:00:35,870 --> 00:00:36,940
of convolution.

13
00:00:36,940 --> 00:00:41,190
That means that I can apply F and G in this order, or I can flip it and

14
00:00:41,190 --> 00:00:43,520
apply G and F in this order.

15
00:00:43,520 --> 00:00:46,540
It's also associative, which basically means that first,

16
00:00:46,540 --> 00:00:50,420
I can do a convolution of F and G and then convolve with H.

17
00:00:50,420 --> 00:00:54,910
Or, I can change the order and do a convolution of G and H before.

18
00:00:54,910 --> 00:00:57,870
And, and afterwards I can do a convolution with an F.

19
00:00:57,870 --> 00:01:01,280
Another property, and I think we've experimented with this already,

20
00:01:01,280 --> 00:01:05,670
if we take an identity, a unit response in this case shown by the simple thing.

21
00:01:05,670 --> 00:01:10,810
And if I actually do a convolution of a image with, or

22
00:01:10,810 --> 00:01:14,380
a function with an identity, we get the original one back.

23
00:01:14,380 --> 00:01:14,890
Question for

24
00:01:14,890 --> 00:01:19,820
you folks to think about on the forums is, is that true for cross-correlation?

25
00:01:19,820 --> 00:01:21,910
I look forward to seeing you discuss that there.

26
00:01:21,910 --> 00:01:27,020
Just to kind of prove this point here, I take this kernel, or

27
00:01:27,020 --> 00:01:28,570
an image here, sorry.

28
00:01:28,570 --> 00:01:29,700
And this is my impulse.

29
00:01:29,700 --> 00:01:31,339
And now notice it's not symmetric.

30
00:01:32,670 --> 00:01:37,980
And if I just do a, a convolution with this, we will get the original one back.

31
00:01:37,980 --> 00:01:41,710
One more important feature to remember is that convolution is

32
00:01:41,710 --> 00:01:43,220
a separable process.

33
00:01:43,220 --> 00:01:46,830
That basically means is that we can actually do the convolution just by

34
00:01:46,830 --> 00:01:51,290
actually having kernel that's captures the rows, and

35
00:01:51,290 --> 00:01:54,330
we can actually do it separately for the columns.

36
00:01:54,330 --> 00:01:57,170
We can actually now allow you to separate out

37
00:01:57,170 --> 00:01:59,360
even kernels to have two different kernels.

38
00:01:59,360 --> 00:02:02,700
That is one just has the rows and the columns themselves, and

39
00:02:02,700 --> 00:02:06,080
we can actually, you know, run the process one by one.

40
00:02:06,080 --> 00:02:09,930
Best part of this is actually man, many computational advantages including,

41
00:02:09,930 --> 00:02:12,060
of course, keeping a lot of less things in memory.
