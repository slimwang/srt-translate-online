1
00:00:00,230 --> 00:00:04,154
And now let's look at the second
possible write-update optimization,

2
00:00:04,154 --> 00:00:06,755
which is about reusing
the number of bus writes.

3
00:00:06,755 --> 00:00:09,147
So after we added our dirty bit,

4
00:00:09,147 --> 00:00:13,765
what we got is that the memory
now gets relatively few writes.

5
00:00:13,765 --> 00:00:17,272
Only those writes that
are coming from replacements and

6
00:00:17,272 --> 00:00:21,227
also the memory no longer needs
to respond to all the reads, but

7
00:00:21,227 --> 00:00:24,899
the bus still gets all of
the traffic for all of the writes.

8
00:00:24,899 --> 00:00:28,985
Every single write will need to go
on the bus and broadcast the value.

9
00:00:28,985 --> 00:00:33,709
So now the bus, which sees all of
the writes will become the bottleneck in

10
00:00:33,709 --> 00:00:38,280
the system, because every single
write from every single core ends up

11
00:00:38,280 --> 00:00:41,475
going to the bus and
the bus can only take so much.

12
00:00:41,475 --> 00:00:46,920
The bus broadcasts for writes that
are needed to update other copies of

13
00:00:46,920 --> 00:00:52,469
the data, need to happen,
because this is a write-update protocol.

14
00:00:52,469 --> 00:00:57,340
It needs to update other copies of
the data, but the optimization we

15
00:00:57,340 --> 00:01:02,480
can do is about the writes that
do not need to update anybody.

16
00:01:02,480 --> 00:01:07,830
So we will add another bit called the
shared bit to each block in each cache

17
00:01:07,830 --> 00:01:13,410
and that bit will tell us, whether
the block is shared with others or not.

18
00:01:13,410 --> 00:01:14,542
Let's see how things would work.

19
00:01:14,542 --> 00:01:17,073
Suppose we read A here.

20
00:01:17,073 --> 00:01:20,708
We get this valid not dirty,
but for the shared bit,

21
00:01:20,708 --> 00:01:24,768
we need to know whether others
also have this block or not.

22
00:01:24,768 --> 00:01:29,226
For this purpose,
we add a line to the bus.

23
00:01:29,226 --> 00:01:34,606
When our read goes to memory,
other's snoop this read and if they have

24
00:01:34,606 --> 00:01:39,723
the same block in the cache,
then they pull the shared line to one.

25
00:01:39,723 --> 00:01:45,070
If nobody pulls the shared line to one,
then it will remain at zero.

26
00:01:45,070 --> 00:01:49,735
So for this particular block,
because this is the first read,

27
00:01:49,735 --> 00:01:55,030
nobody pulls the shared line to one,
so the block we know is not shared.

28
00:01:55,030 --> 00:01:58,583
This is the tag and
let's say, we're at six.

29
00:01:58,583 --> 00:02:02,387
Now let's see what happens when
this processor writes to A, and

30
00:02:02,387 --> 00:02:05,050
let's say puts a value of 17 there.

31
00:02:05,050 --> 00:02:08,133
It's a miss, we wrote us both
the write and the value.

32
00:02:08,133 --> 00:02:12,598
The first time and
we see now that somebody is writing and

33
00:02:12,598 --> 00:02:17,164
this cache here, snoops that write and
does two things.

34
00:02:17,164 --> 00:02:19,505
One, it now knows that
the block is shared,

35
00:02:19,505 --> 00:02:21,349
because somebody is accessing it now.

36
00:02:21,349 --> 00:02:23,544
Second, it updates the value.

37
00:02:23,544 --> 00:02:29,860
Third, it pulls this line to 1, so that
this cache knows the block is shared and

38
00:02:29,860 --> 00:02:34,503
now it has the block in the dirty
state with a value of 17.

39
00:02:34,503 --> 00:02:39,907
So far, this has behaved exactly as
it should without the shared line and

40
00:02:39,907 --> 00:02:41,777
without the shared bit.

41
00:02:41,777 --> 00:02:43,983
So what's the benefit
of the shared bits?

42
00:02:43,983 --> 00:02:47,044
Well, the benefit is
that now this cache,

43
00:02:47,044 --> 00:02:51,464
if it wants to write again,
it sees that the shared bit is one,

44
00:02:51,464 --> 00:02:56,410
which means that it does need
to broadcast same as before.

45
00:02:56,410 --> 00:03:01,391
So the broadcast will happen exactly
as before, if there is another sharer,

46
00:03:01,391 --> 00:03:05,695
because we need to update that sharer
to the new value for the data.

47
00:03:05,695 --> 00:03:11,311
The benefit of the shared bit
is in that, if this block reads,

48
00:03:11,311 --> 00:03:18,340
let's say, B and gets a value of two
here and it's valid and it's not dirty.

49
00:03:18,340 --> 00:03:23,634
And it sees that so far nobody has B,
so sharing is zero here.

50
00:03:23,634 --> 00:03:29,381
And then once you write five to B,
it checks the shared bit here.

51
00:03:29,381 --> 00:03:36,514
And because we know that nobody else has
this block, we can write the value here.

52
00:03:36,514 --> 00:03:41,033
Make the thing dirty, because
the memory's no longer up to date, but

53
00:03:41,033 --> 00:03:43,491
because the shared bit stays at zero.

54
00:03:43,491 --> 00:03:46,000
Meaning, we are the only one who has it.

55
00:03:46,000 --> 00:03:48,391
We don't do a bus right here.

56
00:03:48,391 --> 00:03:51,553
So as long as some block is
being accessed only by one core,

57
00:03:51,553 --> 00:03:54,339
it's no longer going to
broadcast all of the writes.

58
00:03:54,339 --> 00:03:59,415
Meanwhile, this core could be
having in a non-shared state,

59
00:03:59,415 --> 00:04:04,510
for example, block C and
it can write anything it wants there.

60
00:04:04,510 --> 00:04:08,667
Can write 17, then 65, etc.

61
00:04:08,667 --> 00:04:14,374
So B and C, because they belong
to only one core at this time

62
00:04:14,374 --> 00:04:20,100
will not do bus writes,
while A will do bus writes.

63
00:04:20,100 --> 00:04:23,780
So we still get the write optic
behavior when there is sharing, but

64
00:04:23,780 --> 00:04:27,310
now we avoid writes going to
the bus when there is no sharing.

65
00:04:28,720 --> 00:04:30,580
This can happen a lot, for example,

66
00:04:30,580 --> 00:04:34,170
B could be something that belongs
to the stack of core zero.

67
00:04:34,170 --> 00:04:36,476
C could be something that is
on the stack of core one.

68
00:04:36,476 --> 00:04:40,476
So naturally, we will be just pushing
and popping things to our own stack and

69
00:04:40,476 --> 00:04:43,867
never really needing to broadcast
the updates somewhere else.

70
00:04:43,867 --> 00:04:46,080
But for data that is actually shared,

71
00:04:46,080 --> 00:04:49,758
we still get exactly the same
write update behavior as before.

72
00:04:49,758 --> 00:04:54,600
So this optimization will save
us a lot of writes on the bus.

73
00:04:54,600 --> 00:04:59,170
It will save us all the writes that
are not necessary to maintain coherence

74
00:04:59,170 --> 00:05:03,015
among multiple copies of the same
block in different caches.
